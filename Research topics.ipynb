{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7e818d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "be34a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID                                              TITLE  \\\n",
      "0     27309  Special zeta values using tensor powers of Dri...   \n",
      "1     29201  Absence of the Pauli-Paramagnetic Limit in a S...   \n",
      "2     26461                   Super learning in the SAS system   \n",
      "3     24032  General rogue waves in the nonlocal PT-symmetr...   \n",
      "4     27679  Investigating the Role of Socially Mediated Me...   \n",
      "...     ...                                                ...   \n",
      "8984  23868  Competing spin liquids and hidden nematic orde...   \n",
      "8985  28786  Optimal stability for a first order coefficien...   \n",
      "8986  21878  Feedback Techniques in Computer-Based Simulati...   \n",
      "8987  26165  A characterization of the Macaulay dual genera...   \n",
      "8988  21208  Two-stage multipolar ordering in Pr(TM)$_2$Al$...   \n",
      "\n",
      "                                               ABSTRACT  \n",
      "0       We study tensor powers of rank 1 sign-normal...  \n",
      "1       We performed $^{59}$Co nuclear magnetic reso...  \n",
      "2       Background and objective: Stacking is an ens...  \n",
      "3       Rogue waves in the nonlocal PT-symmetric non...  \n",
      "4       Developing students' ability to troubleshoot...  \n",
      "...                                                 ...  \n",
      "8984    Frustration in magnetic interactions can giv...  \n",
      "8985    This paper is focused on the study of an inv...  \n",
      "8986    Computer-based simulation training (CBST) is...  \n",
      "8987    Let $F$ be a homogeneous polynomial in $n$ v...  \n",
      "8988    Among heavy fermion materials, there is a se...  \n",
      "\n",
      "[8989 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"/Users/intesurahmed/Documents/Topic modeling diff domain/research articles/test.csv\", header=0)\n",
    "\n",
    "\n",
    "# Drop first column of dataframe using pop()\n",
    "# df.pop(df.columns[0])\n",
    "\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff348dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "article=df.ABSTRACT.values[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ef3758cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6ec0e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  We study tensor powers of rank 1 sign-normalized Drinfeld A-modules, where A\\nis the coordinate ring of an elliptic curve over a finite field. Using the\\ntheory of vector valued Anderson generating functions, we give formulas for the\\ncoefficients of the logarithm and exponential functions associated to these\\nA-modules. We then show that there exists a vector whose bottom coordinate\\ncontains a Goss zeta value, whose evaluation under the exponential function is\\ndefined over the Hilbert class field. This allows us to prove the transcendence\\nof Goss zeta values and periods of Drinfeld modules as well as the\\ntranscendence of certain ratios of those quantities.\\n'\n",
      " '  We performed $^{59}$Co nuclear magnetic resonance (NMR) measurements of\\nsingle-crystalline U$_6$Co. There is a small decrease in the Knight shift in\\nthe superconducting (SC) state, but this change mainly arises from the SC\\ndiamagnetic effect. The negligible change of the spin part of the Knight shift,\\ntogether with the absence of the Pauli-paramagnetic effect in the SC U$_6$Co,\\nis understood as a consequence of the small spin susceptibility. The nuclear\\nspin-lattice relaxation rate $1/T_1$ is also measured in the SC state under the\\nmagnetic field, and exhibits a tiny Hebel-Slichter peak just below the SC\\ntransition temperature and exponential behavior at lower temperatures. These\\nbehaviors are in agreement with the full-gap s-wave pairing in U$_6$Co.\\n'\n",
      " \"  Background and objective: Stacking is an ensemble machine learning method\\nthat averages predictions from multiple other algorithms, such as generalized\\nlinear models and regression trees. A recent iteration of stacking, called\\nsuper learning, has been developed as a general approach to black box\\nsupervised learning and has seen frequent usage, in part due to the\\navailability of an R package. I develop super learning in the SAS software\\nsystem using a new macro, and demonstrate its performance relative to the R\\npackage.\\nMethods: I follow closely previous work using the R SuperLearner package and\\nassess the performance of super learning in a number of domains. I compare the\\nR package with the new SAS macro in a small set of simulations assessing curve\\nfitting in a prediction model, a set of 14 publicly available datasets to\\nassess cross-validated, expected loss, and data from a randomized trial of job\\nseekers' training to assess the utility of super learning in causal inference\\nusing inverse probability weighting.\\nResults: Across the simulated data and the publicly available data, the macro\\nperformed similarly to the R package, even with a different set of potential\\nalgorithms available natively in R and SAS. The example with inverse\\nprobability weighting demonstrated the ability of the SAS macro to include\\nalgorithms developed in R.\\nConclusions: The super learner macro performs as well as the R package at a\\nnumber of tasks. Further, by extending the macro to include the use of R\\npackages, the macro can leverage both the robust, enterprise oriented\\nprocedures in SAS and the nimble, cutting edge packages in R. In the spirit of\\nensemble learning, this macro extends the potential library of algorithms\\nbeyond a single software system and provides a simple avenue into machine\\nlearning in SAS.\\n\"\n",
      " '  Rogue waves in the nonlocal PT-symmetric nonlinear Schrodinger (NLS) equation\\nare studied by Darboux transformation. Three types of rogue waves are derived,\\nand their explicit expressions in terms of Schur polynomials are presented.\\nThese rogue waves show a much wider variety than those in the local NLS\\nequation. For instance, the polynomial degrees of their denominators can be not\\nonly $n(n+1)$, but also $n(n-1)+1$ and $n^2$, where $n$ is an arbitrary\\npositive integer. Dynamics of these rogue waves is also examined. It is shown\\nthat these rogue waves can be bounded for all space and time, or develop\\ncollapsing singularities, depending on their types as well as values of their\\nfree parameters. In addition, the solution dynamics exhibits rich patterns,\\nmost of which have no counterparts in the local NLS equation.\\n'\n",
      " \"  Developing students' ability to troubleshoot is an important learning outcome\\nfor many undergraduate physics lab courses, especially electronics courses. In\\nother work, metacognition has been identified as an important feature of\\ntroubleshooting. However, that work has focused primarily on individual\\nstudents' metacognitive processes or troubleshooting abilities. In contrast,\\nelectronics courses often require students to work in pairs, and hence\\nstudents' in-class experiences likely have significant social dimensions that\\nare not well understood. In this work, we use an existing framework for\\nsocially mediated metacognition to analyze audiovisual data from think-aloud\\nactivities in which eight pairs of students from two institutions attempted to\\ndiagnose and repair a malfunctioning electric circuit. In doing so, we provide\\ninsight into some of the social metacognitive dynamics that arise during\\ncollaborative troubleshooting. We find that students engaged in socially\\nmediated metacognition at multiple key transitions during the troubleshooting\\nprocess. Reciprocated metacognitive dialogue arose when students were\\ncollectively strategizing about which measurements to perform, or reaching a\\nshared understanding of the circuit's behavior. In addition to elaborating upon\\nthese findings, we discuss implications for instruction, and we identify areas\\nfor potential future investigation.\\n\"\n",
      " '  We prove a new and general concentration inequality for the excess risk in\\nleast-squares regression with random design and heteroscedastic noise. No\\nspecific structure is required on the model, except the existence of a suitable\\nfunction that controls the local suprema of the empirical process. So far, only\\nthe case of linear contrast estimation was tackled in the literature with this\\nlevel of generality on the model. We solve here the case of a quadratic\\ncontrast, by separating the behavior of a linearized empirical process and the\\nempirical process driven by the squares of functions of models.\\n'\n",
      " '  In recent years, dynamic languages, such as JavaScript or Python, have faced\\nan important increment of usage in a wide range of fields and applications.\\nTheir tricky and misunderstood behaviors pose a hard challenge for static\\nanalysis of these programming languages. A key aspect of any dynamic language\\nprogram is the multiple usage of strings, since they can be implicitly\\nconverted to another type value, transformed by string-to-code primitives or\\nused to access an object-property. Unfortunately, string analyses for dynamic\\nlanguages still lack of precision and do not take into account some important\\nstring features. Moreover, string obfuscation is very popular in the context of\\ndynamic language malicious code, for example, to hide code information inside\\nstrings and then to dynamically transform strings into executable code. In this\\nscenario, more precise string analyses become a necessity. This paper proposes\\na new semantics for string analysis placing a first step for handling dynamic\\nlanguages string features.\\n'\n",
      " \"  From our experiences in the past, we have seen that the growth of cities is\\nvery much dependent on the transportation networks. In mega cities,\\ntransportation networks determine to a significant extent as to where the\\npeople will move and houses will be built. Hence, transportation network data\\nis crucial to an urban growth prediction system. Existing works have used\\nmanually derived distance based features based on the road networks to build\\nmodels on urban growth. But due to the non-generic and laborious nature of the\\nmanual feature engineering process, we can shift to End-to-End systems which do\\nnot rely on manual feature engineering. In this paper, we propose a method to\\nintegrate road network data to an existing Rule based End-to-End framework\\nwithout manual feature engineering. Our method employs recurrent neural\\nnetworks to represent road networks in a structured way such that it can be\\nplugged into the previously proposed End-to-End framework. The proposed\\napproach enhances the performance in terms of Figure of Merit, Producer's\\naccuracy, User's accuracy and Overall accuracy of the existing Rule based\\nEnd-to-End framework.\\n\"\n",
      " '  We introduce a new discrete coherence monotone named the \\\\emph{coherence\\nnumber}, which is a generalization of the coherence rank to mixed states. After\\ndefining the coherence number in a similar manner to the Schmidt number in\\nentanglement theory, we present a necessary and sufficient condition of the\\ncoherence number for a coherent state to be converted to an entangled state of\\nnonzero $k$-concurrence (a member of the generalized concurrence family with\\n$2\\\\le k \\\\le d$). It also turns out that the coherence number is a useful\\nmeasure to understand the process of Grover search algorithm of $N$ items. We\\nshow that the coherence number remains $N$ and falls abruptly when the success\\nprobability of the searching process becomes maximal. This phenomenon motivates\\nus to analyze the depletion pattern of $C_c^{(N)}$ (the last member of the\\ngeneralized coherence concurrence, nonzero when the coherence number is $N$),\\nwhich turns out to be an optimal resource for the process since it is\\ncompletely consumed to finish the searching task.\\n'\n",
      " '  We study dynamics of Dirac solitons in prototypical networks modeling them by\\nthe nonlinear Dirac equation on metric graphs. Soliton solutions of the\\nnonlinear Dirac equation on simple metric graphs are obtained. It is shown that\\nthese solutions provide reflectionless vertex transmission of the Dirac\\nsolitons under suitable conditions. The constraints for bond nonlinearity\\ncoefficients, allowing reflectionless transmission over a Y-junction are\\nderived. The analytical results are confirmed by direct numerical simulations.\\n'\n",
      " '  Threat intelligence sharing has become a growing concept, whereby entities\\ncan exchange patterns of threats with each other, in the form of indicators, to\\na community of trust for threat analysis and incident response. However,\\nsharing threat-related information have posed various risks to an organization\\nthat pertains to its security, privacy, and competitiveness. Given the\\ncoinciding benefits and risks of threat information sharing, some entities have\\nadopted an elusive behavior of \"free-riding\" so that they can acquire the\\nbenefits of sharing without contributing much to the community. So far,\\nunderstanding the effectiveness of sharing has been viewed from the perspective\\nof the amount of information exchanged as opposed to its quality. In this\\npaper, we introduce the notion of quality of indicators (\\\\qoi) for the\\nassessment of the level of contribution by participants in information sharing\\nfor threat intelligence. We exemplify this notion through various metrics,\\nincluding correctness, relevance, utility, and uniqueness of indicators. In\\norder to realize the notion of \\\\qoi, we conducted an empirical study and taken\\na benchmark approach to define quality metrics, then we obtained a reference\\ndataset and utilized tools from the machine learning literature for quality\\nassessment. We compared these results against a model that only considers the\\nvolume of information as a metric for contribution, and unveiled various\\ninteresting observations, including the ability to spot low quality\\ncontributions that are synonym to free riding in threat information sharing.\\n'\n",
      " \"  Estimating the angular separation between two incoherently radiating\\nmonochromatic point sources is a canonical toy problem to quantify spatial\\nresolution in imaging. In recent work, Tsang {\\\\em et al.} showed, using a\\nFisher Information analysis, that Rayleigh's resolution limit is just an\\nartifact of the conventional wisdom of intensity measurement in the image\\nplane. They showed that the optimal sensitivity of estimating the angle is only\\na function of the total photons collected during the camera's integration time\\nbut entirely independent of the angular separation itself no matter how small\\nit is, and found the information-optimal mode basis, intensity detection in\\nwhich achieves the aforesaid performance. We extend the above analysis, which\\nwas done for a Gaussian point spread function (PSF) to a hard-aperture pupil\\nproving the information optimality of image-plane sinc-Bessel modes, and\\ngeneralize the result further to an arbitrary PSF. We obtain new\\ncounterintuitive insights on energy vs. information content in spatial modes,\\nand extend the Fisher Information analysis to exact calculations of minimum\\nmean squared error, both for Gaussian and hard aperture pupils.\\n\"\n",
      " '  A particle swarm optimizer (PSO) loosely based on the phenomena of\\ncrystallization and a chaos factor which follows the complimentary error\\nfunction is described. The method features three phases: diffusion, directed\\nmotion, and nucleation. During the diffusion phase random walk is the only\\ncontributor to particle motion. As the algorithm progresses the contribution\\nfrom chaos decreases and movement toward global best locations is pursued until\\nconvergence has occurred. The algorithm was found to be more robust to local\\nminima in multimodal test functions than a standard PSO algorithm and is\\ndesigned for problems which feature experimental precision.\\n'\n",
      " '  We prove that any classical affine W-algebra W(g,f), where g is a classical\\nLie algebra and f is an arbitrary nilpotent element of g, carries an integrable\\nHamiltonian hierarchy of Lax type equations. This is based on the theories of\\ngeneralized Adler type operators and of generalized quasideterminants, which we\\ndevelop in the paper. Moreover, we show that under certain conditions, the\\nproduct of two generalized Adler type operators is a Lax type operator. We use\\nthis fact to construct a large number of integrable Hamiltonian systems,\\nrecovering, as a special case, all KdV type hierarchies constructed by Drinfeld\\nand Sokolov.\\n'\n",
      " '  Non-free data types are data types whose data have no canonical forms. For\\nexample, multisets are non-free data types because the multiset $\\\\{a,b,b\\\\}$ has\\ntwo other equivalent but literally different forms $\\\\{b,a,b\\\\}$ and $\\\\{b,b,a\\\\}$.\\nPattern matching is known to provide a handy tool set to treat such data types.\\nAlthough many studies on pattern matching and implementations for practical\\nprogramming languages have been proposed so far, we observe that none of these\\nstudies satisfy all the criteria of practical pattern matching, which are as\\nfollows: i) efficiency of the backtracking algorithm for non-linear patterns,\\nii) extensibility of matching process, and iii) polymorphism in patterns.\\nThis paper aims to design a new pattern-matching-oriented programming\\nlanguage that satisfies all the above three criteria. The proposed language\\nfeatures clean Scheme-like syntax and efficient and extensible pattern matching\\nsemantics. This programming language is especially useful for the processing of\\ncomplex non-free data types that not only include multisets and sets but also\\ngraphs and symbolic mathematical expressions. We discuss the importance of our\\ncriteria of practical pattern matching and how our language design naturally\\narises from the criteria. The proposed language has been already implemented\\nand open-sourced as the Egison programming language.\\n'\n",
      " '  This paper enlarges classical syllogistic logic with assertions having to do\\nwith comparisons between the sizes of sets. So it concerns a logical system\\nwhose sentences are of the following forms: {\\\\sf All $x$ are $y$} and {\\\\sf Some\\n$x$ are $y$}, {\\\\sf There are at least as many $x$ as $y$}, and {\\\\sf There are\\nmore $x$ than $y$}. Here $x$ and $y$ range over subsets (not elements) of a\\ngiven \\\\emph{infinite} set. Moreover, $x$ and $y$ may appear complemented (i.e.,\\nas $\\\\overset{-}{x}$ and $\\\\overset{-}{y}$), with the natural meaning. We\\nformulate a logic for our language that is based on the classical syllogistic.\\nThe main result is a soundness/completeness theorem. There are efficient\\nalgorithms for proof search and model construction.\\n'\n",
      " '  In this paper, we prove that for any fixed $205/243<\\\\gamma\\\\leqslant1$, every\\nsufficiently large $N$ satisfying $N\\\\equiv 5 \\\\pmod {24}$ can be represented as\\nfive squares of primes with one prime in $\\\\mathcal{P}_\\\\gamma$, which improves\\nthe previous result of Zhang and Zhai.\\n'\n",
      " '  The widely known linear time algorithm for computing the maximum area\\ntriangle in a convex polygon was found incorrect recently by Keikha et.\\nal.(arXiv:1705.11035). We present an alternative algorithm in this paper.\\nComparing to the only previously known correct solution, ours is much simpler\\nand more efficient. More importantly, our new approach is powerful in solving\\nrelated problems.\\n'\n",
      " \"  What does it take for a system, biological or not, to have goals? Here, this\\nquestion is approached in the context of in silico artificial evolution. By\\nexamining the informational and causal properties of artificial organisms\\n('animats') controlled by small, adaptive neural networks (Markov Brains), this\\nessay discusses necessary requirements for intrinsic information, autonomy, and\\nmeaning. The focus lies on comparing two types of Markov Brains that evolved in\\nthe same simple environment: one with purely feedforward connections between\\nits elements, the other with an integrated set of elements that causally\\nconstrain each other. While both types of brains 'process' information about\\ntheir environment and are equally fit, only the integrated one forms a causally\\nautonomous entity above a background of external influences. This suggests that\\nto assess whether goals are meaningful for a system itself, it is important to\\nunderstand what the system is, rather than what it does.\\n\"\n",
      " '  Neural language models are a critical component of state-of-the-art systems\\nfor machine translation, summarization, audio transcription, and other tasks.\\nThese language models are almost universally autoregressive in nature,\\ngenerating sentences one token at a time from left to right. This paper studies\\nthe influence of token generation order on model quality via a novel two-pass\\nlanguage model that produces partially-filled sentence \"templates\" and then\\nfills in missing tokens. We compare various strategies for structuring these\\ntwo passes and observe a surprisingly large variation in model quality. We find\\nthe most effective strategy generates function words in the first pass followed\\nby content words in the second. We believe these experimental results justify a\\nmore extensive investigation of generation order for neural language models.\\n'\n",
      " '  Internet greatly assist people in improving their quality of life. Almost all\\nareas of human life can be accessed using the internet. Human aided by the\\ninternet that provides all sorts of information that they need. Along with the\\ndevelopment of the Internet network infrastructure remotely control began to\\nchange using the internet. In this study using notebooks and servers Raspberry\\nPi to find out the quality control of each device server used. In this study we\\ninvestigate the possibility of improving the quality of web-based remote\\ncontrol to implement Raspberry Pi as a web server and how much improvement the\\nquality of web-based remote control obtained in this research.\\n'\n",
      " '  Dropout is used to avoid overfitting by randomly dropping units from the\\nneural networks during training. Inspired by dropout, this paper presents\\nGI-Dropout, a novel dropout method integrating with global information to\\nimprove neural networks for text classification. Unlike the traditional dropout\\nmethod in which the units are dropped randomly according to the same\\nprobability, we aim to use explicit instructions based on global information of\\nthe dataset to guide the training process. With GI-Dropout, the model is\\nsupposed to pay more attention to inapparent features or patterns. Experiments\\ndemonstrate the effectiveness of the dropout with global information on seven\\ntext classification tasks, including sentiment analysis and topic\\nclassification.\\n'\n",
      " '  Spectral methods provide an elegant and efficient way of numerically solving\\ndifferential equations of all kinds. For smooth problems, truncation error for\\nspectral methods vanishes exponentially in the infinity norm and $L_2$-norm.\\nHowever, for non-smooth problems, convergence is significantly worse---the\\n$L_2$-norm of the error for a discontinuous problem will converge at a\\nsub-linear rate and the infinity norm will not converge at all. We explore and\\nimprove upon a post-processing technique---optimally convergent mollifiers---to\\nrecover exponential convergence from a poorly-converging spectral\\nreconstruction of non-smooth data. This is an important first step towards\\nusing these techniques for simulations of realistic systems.\\n'\n",
      " '  Despite large incentives, ecorrectness in software remains an elusive goal.\\nDeclarative programming techniques, where algorithms are derived from a\\nspecification of the desired behavior, offer hope to address this problem,\\nsince there is a combinatorial reduction in complexity in programming in terms\\nof specifications instead of algorithms, and arbitrary desired properties can\\nbe expressed and enforced in specifications directly. However, limitations on\\nperformance have prevented programming with declarative specifications from\\nbecoming a mainstream technique for general-purpose programming. To address the\\nperformance bottleneck in deriving an algorithm from a specification, I propose\\ninformation-gain computation, a framework where an adaptive evaluation strategy\\nis used to efficiently perform a search which derives algorithms that provide\\ninformation about a query most directly. Within this framework, opportunities\\nto compress the search space present themselves, which suggest that\\ninformation-theoretic bounds on the performance of such a system might be\\narticulated and a system designed to achieve them. In a preliminary empirical\\nstudy of adaptive evaluation for a simple test program, the evaluation strategy\\nadapts successfully to evaluate a query efficiently.\\n'\n",
      " '  The sequence $3, 5, 9, 11, 15, 19, 21, 25, 29, 35,\\\\dots$ consists of odd legs\\nin right triangles with integer side lengths and prime hypotenuse. We show that\\nthe upper density of this sequence is zero, with logarithmic decay. The same\\nestimate holds for the sequence of even legs in such triangles. We expect our\\nupper bound, which involves the Erdős--Ford--Tenenbaum constant, to be\\nsharp up to a double-logarithmic factor. We also provide a nontrivial lower\\nbound. Our techniques involve sieve methods, the distribution of Gaussian\\nprimes in narrow sectors, and the Hardy--Ramanujan inequality.\\n'\n",
      " '  An improved algorithm is proposed for the reconstruction of singular\\nconnectivity from the available pairwise connections during preprocessing\\nphase. To evaluate the performance of the algorithm, an in-house computational\\nfluid dynamics (CFD) code is used in which high-order finite-difference method\\nfor spatial discretization running on the Tianhe-1A supercomputer is employed.\\nTest cases with a varied amount of mesh points are chosen, and the test results\\nindicate that the improved singular connection reconstruction algorithm can\\nachieve a speedup factor of 1000X or more when compared with the naive search\\nmethod adopted in the former version of our code. Moreover, the parallel\\nefficiency can benefit from the strategy of local communication based on the\\nalgorithm.\\n'\n",
      " '  Citations are the cornerstone of knowledge propagation and the primary means\\nof assessing the quality of research, as well as directing investments in\\nscience. Science is increasingly becoming \"data-intensive\", where large volumes\\nof data are collected and analyzed to discover complex patterns through\\nsimulations and experiments, and most scientific reference works have been\\nreplaced by online curated datasets. Yet, given a dataset, there is no\\nquantitative, consistent and established way of knowing how it has been used\\nover time, who contributed to its curation, what results have been yielded or\\nwhat value it has.\\nThe development of a theory and practice of data citation is fundamental for\\nconsidering data as first-class research objects with the same relevance and\\ncentrality of traditional scientific products. Many works in recent years have\\ndiscussed data citation from different viewpoints: illustrating why data\\ncitation is needed, defining the principles and outlining recommendations for\\ndata citation systems, and providing computational methods for addressing\\nspecific issues of data citation.\\nThe current panorama is many-faceted and an overall view that brings together\\ndiverse aspects of this topic is still missing. Therefore, this paper aims to\\ndescribe the lay of the land for data citation, both from the theoretical (the\\nwhy and what) and the practical (the how) angle.\\n'\n",
      " '  We address the issue of inter-particle dipolar interactions in the context of\\nmagnetic hyperthermia. More precisely, the main question dealt with here is\\nconcerned with the conditions under which the specific absorption rate is\\nenhanced or reduced by dipolar interactions. For this purpose, we propose a\\ntheory for the calculation of the AC susceptibility, and thereby the specific\\nabsorption rate, for a monodisperse two-dimensional assembly of nanoparticles\\nwith oriented anisotropy, in the presence of a DC magnetic field, in addition\\nto the AC magnetic field. We also study the competition between the dipolar\\ninteractions and the DC field, both in the transverse and longitudinal\\nconfigurations. In both cases, we find that the specific absorption rate has a\\nmaximum at some critical DC field that depends on the inter-particle\\nseparation. In the longitudinal setup, this critical field falls well within\\nthe range of experiments.\\n'\n",
      " '  Predicting long-term outcomes of interventions is necessary for educational\\nand social policy-making processes that might widely influence our society for\\nthe long-term. However, performing such predictions based on data from\\nlarge-scale experiments might be challenging due to the lack of time and\\nresources. In order to address this issue, computer simulations based on\\nEvolutionary Causal Matrices and Markov Chain can be used to predict long-term\\noutcomes with relatively small-scale lab data. In this paper, we introduce\\nPython classes implementing a computer simulation model and presented some\\npilots implementations demonstrating how the model can be utilized for\\npredicting outcomes of diverse interventions. We also introduce the\\nclass-structured simulation module both with real experimental data and with\\nhypothetical data formulated based on social psychological theories. Classes\\ndeveloped and tested in the present study provide researchers and practitioners\\nwith a feasible and practical method to simulate intervention outcomes\\nprospectively.\\n'\n",
      " '  Many physical processes involve spatio-temporal observations, which can be\\nstudied at different spatial and temporal scales. For example, rainfall data\\nmeasured daily by rain gauges can be considered at daily, monthly or annual\\ntemporal scales, and local, grid-wise, region-wise or country-wise spatial\\nscales. In this work, we focus on detection of anomalies in such multi-scale\\nspatio-temporal data. We consider an anomaly as an event where the measured\\nvalues over a spatio-temporally extended region are significantly different\\nfrom their long-term means. However we aim to avoid setting any thresholds on\\nthe measured values and spatio-temporal sizes, because not only are thresholds\\nsubjective but also the long-term mean values often vary spatially and\\ntemporally. For this purpose we use spatio-Temporal Markov Random Field, where\\nlatent states indicate anomaly type (positive anomaly, negative anomaly, no\\nanomaly/normal). Spatio-temporal coherence is maintained through suitable edge\\npotentials. The model is extended to multiple spatio-temporal scales to achieve\\nour second goal: anomalies at any scale should be defined both on the data at\\nthat scale, and also on anomalies at other scales. This allows us to trace an\\nanomaly at a coarse scale to finer scales. For example, whether rainfall in a\\nparticular year is anomalous over a region should depend not only on the total\\nvolume of rainfall over the entire region, but also on whether there were such\\nanomalies at the grid-scale, and the monthly scale. We use this approach to\\nstudy rainfall anomalies over India -extremely diverse with respect to\\nrainfall- for the period 1901-2011, and show its benefits over existing\\napproaches.\\n'\n",
      " \"  This paper has three main contributions to our understanding of fixed-depth\\nminimax search: (A) A new formulation for Stockman's SSS* algorithm, based on\\nAlpha-Beta, is presented. It solves all the perceived drawbacks of SSS*,\\nfinally transforming it into a practical algorithm. In effect, we show that\\nSSS* = alpha-beta + ransposition tables. The crucial step is the realization\\nthat transposition tables contain so-called solution trees, structures that are\\nused in best-first search algorithms like SSS*. Having created a practical\\nversion, we present performance measurements with tournament game-playing\\nprograms for three different minimax games, yielding results that contradict a\\nnumber of publications. (B) Based on the insights gained in our attempts at\\nunderstanding SSS*, we present a framework that facilitates the construction of\\nseveral best-first fixed- depth game-tree search algorithms, known and new. The\\nframework is based on depth-first null-window Alpha-Beta search, enhanced with\\nstorage to allow for the refining of previous search results. It focuses\\nattention on the essential differences between algorithms. (C) We present a new\\ninstance of the framework, MTD(f). It is well-suited for use with iterative\\ndeepening, and performs better than algorithms that are currently used in most\\nstate-of-the-art game-playing programs. We provide experimental evidence to\\nexplain why MTD(f) performs better than the other fixed-depth minimax\\nalgorithms.\\n\"\n",
      " \"  Humans are able to explain their reasoning. On the contrary, deep neural\\nnetworks are not. This paper attempts to bridge this gap by introducing a new\\nway to design interpretable neural networks for classification, inspired by\\nphysiological evidence of the human visual system's inner-workings. This paper\\nproposes a neural network design paradigm, termed InterpNET, which can be\\ncombined with any existing classification architecture to generate natural\\nlanguage explanations of the classifications. The success of the module relies\\non the assumption that the network's computation and reasoning is represented\\nin its internal layer activations. While in principle InterpNET could be\\napplied to any existing classification architecture, it is evaluated via an\\nimage classification and explanation task. Experiments on a CUB bird\\nclassification and explanation dataset show qualitatively and quantitatively\\nthat the model is able to generate high-quality explanations. While the current\\nstate-of-the-art METEOR score on this dataset is 29.2, InterpNET achieves a\\nmuch higher METEOR score of 37.9.\\n\"\n",
      " '  Global constraints and reranking have not been used in cognates detection\\nresearch to date. We propose methods for using global constraints by performing\\nrescoring of the score matrices produced by state of the art cognates detection\\nsystems. Using global constraints to perform rescoring is complementary to\\nstate of the art methods for performing cognates detection and results in\\nsignificant performance improvements beyond current state of the art\\nperformance on publicly available datasets with different language pairs and\\nvarious conditions such as different levels of baseline state of the art\\nperformance and different data size conditions, including with more realistic\\nlarge data size conditions than have been evaluated with in the past.\\n'\n",
      " '  We propose a method to optimise the parameters of a policy which will be used\\nto safely perform a given task in a data-efficient manner. We train a Gaussian\\nprocess model to capture the system dynamics, based on the PILCO framework. Our\\nmodel has useful analytic properties, which allow closed form computation of\\nerror gradients and estimating the probability of violating given state space\\nconstraints. During training, as well as operation, only policies that are\\ndeemed safe are implemented on the real system, minimising the risk of failure.\\n'\n",
      " '  Among the family of TMDs, ReS2 takes a special position, which crystalizes in\\na unique distorted low-symmetry structure at ambient conditions. The interlayer\\ninteraction in ReS2 is rather weak, thus its bulk properties are similar to\\nthat of monolayer. However, how does compression change its structure and\\nelectronic properties is unknown so far. Here using ab initio crystal structure\\nsearching techniques, we explore the high-pressure phase transitions of ReS2\\nextensively and predict two new high-pressure phases. The ambient pressure\\nphase transforms to a \"distorted-1T\" structure at very low pressure and then to\\na tetragonal I41/amd structure at around 90 GPa. The \"distorted-1T\" structure\\nundergoes a semiconductor-metal transition (SMT) at around 70 GPa with a band\\noverlap mechanism. Electron-phonon calculations suggest that the I41/amd\\nstructure is superconducting and has a critical superconducting temperature of\\nabout 2 K at 100 GPa. We further perform high-pressure electrical resistance\\nmeasurements up to 102 GPa. Our experiments confirm the SMT and the\\nsuperconducting phase transition of ReS2 under high pressure. These\\nexperimental results are in good agreement with our theoretical predictions.\\n'\n",
      " '  We propose a strategy to measure weak static magnetic fields with\\nnitrogen-vacancy color center in diamond. Inspired by avian magnetoreception\\nmodels, we consider the feasibility of utilizing quantum coherence phenomena to\\nmeasure weak static magnetic fields. Nitrogen-vacancy (NV) color centers are\\nregarded as the ideal platform to study quantum sciences as a result of its\\nlong coherence time up to a millisecond timescale. In high-purity diamond,\\nhyperfine interaction with 13C nuclear spins dominates the decoherence process.\\nIn this paper, we numerically simulate the decoherence process between 0 and +1\\nof the individual NV color center spin in 13C nuclear baths with various of\\nmagnitudes of external magnetic fields. By applying Hahn echo into the system,\\nwe obtain the coherence of NV color center spin as a function of total\\nevolution time and magnetic field. Furthermore we obtain the high-accuracy\\nrelationship between the three decoherence-characteristic timescales, i.e. T_W,\\nT_R, T_2, and magnetic field B. And we draw a conclusion that T_R has the\\nhighest sensitivity about magnetic field among the three time-scales. Thus, for\\na certain NV color center, T_R can be the scale for the magnitude of magnetic\\nfield, or rather, the component along the NV electronic spin axis. When\\nmeasuring an unknown magnetic field, we adjust the NV axis to three mutually\\northogonal directions respectively. By this means, we obtain the three\\ncomponents of the magnetic field and thus the magnitude and direction of the\\nactual magnetic field. The accuracy could reach 60 nT/Hz^{1/2},and could be\\ngreatly improved by using an ensemble of NV color centers or diamond crystals\\npurified with 12C atoms.\\n'\n",
      " '  We demonstrate that a broad class of excited state variational principles is\\nnot size consistent. In light of this difficulty, we develop and test an\\napproach to excited state optimization that transforms between variational\\nprinciples in order to achieve state selectivity, size consistency, and\\ncompatibility with quantum Monte Carlo. To complement our formal analysis, we\\nprovide numerical examples that confirm these properties and demonstrate how\\nthey contribute to a more black box approach to excited states in quantum Monte\\nCarlo.\\n'\n",
      " '  In German, relative clauses can be positioned in-situ or extraposed. A\\npotential factor for the variation might be information density. In this study,\\nthis hypothesis is tested with a corpus of 17th century German funeral sermons.\\nFor each referent in the relative clauses and their matrix clauses, the\\nattention state was determined (first calculation). In a second calculation,\\nfor each word the surprisal values were determined, using a bi-gram language\\nmodel. In a third calculation, the surprisal values were accommodated as to\\nwhether it is the first occurrence of the word in question or not. All three\\ncalculations pointed in the same direction: With in-situ relative clauses, the\\nrate of new referents was lower and the average surprisal values were lower,\\nespecially the accommodated surprisal values, than with extraposed relative\\nclauses. This indicated that in-formation density is a factor governing the\\nchoice between in-situ and extraposed relative clauses. The study also sheds\\nlight on the intrinsic relation-ship between the information theoretic concept\\nof information density and in-formation structural concepts such as givenness\\nwhich are used under a more linguistic perspective.\\n'\n",
      " '  Population protocols are a model of distributed computing, in which $n$\\nagents with limited local state interact randomly, and cooperate to\\ncollectively compute global predicates. An extensive series of papers, across\\ndifferent communities, has examined the computability and complexity\\ncharacteristics of this model. Majority, or consensus, is a central task, in\\nwhich agents need to collectively reach a decision as to which one of two\\nstates $A$ or $B$ had a higher initial count. Two complexity metrics are\\nimportant: the time that a protocol requires to stabilize to an output\\ndecision, and the state space size that each agent requires.\\nIt is known that majority requires $\\\\Omega(\\\\log \\\\log n)$ states per agent to\\nallow for poly-logarithmic time stabilization, and that $O(\\\\log^2 n)$ states\\nare sufficient. Thus, there is an exponential gap between the upper and lower\\nbounds.\\nWe address this question. We provide a new lower bound of $\\\\Omega(\\\\log n)$\\nstates for any protocol which stabilizes in $O( n^{1-c} )$ time, for any $c >\\n0$ constant. This result is conditional on basic monotonicity and output\\nassumptions, satisfied by all known protocols. Technically, it represents a\\nsignificant departure from previous lower bounds. Instead of relying on dense\\nconfigurations, we introduce a new surgery technique to construct executions\\nwhich contradict the correctness of algorithms that stabilize too fast.\\nSubsequently, our lower bound applies to general initial configurations.\\nWe give an algorithm for majority which uses $O(\\\\log n)$ states, and\\nstabilizes in $O(\\\\log^2 n)$ time. Central to the algorithm is a new leaderless\\nphase clock, which allows nodes to synchronize in phases of $\\\\Theta(n \\\\log{n})$\\nconsecutive interactions using $O(\\\\log n)$ states per node. We also employ our\\nphase clock to build a leader election algorithm with $O(\\\\log n )$ states,\\nwhich stabilizes in $O(\\\\log^2 n)$ time.\\n'\n",
      " '  The intrinsically hole-doped RbEuFe$_4$As$_4$ exhibits bulk superconductivity\\nat $T_{\\\\mathrm{sc}}=36.5$ K and ferromagnetic ordering in the Eu sublattice at\\n$T_\\\\mathrm{m}=15$ K. Here we present a hole-compensation study by introducing\\nextra itinerant electrons via a Ni substitution in the ferromagnetic\\nsuperconductor RbEuFe$_4$As$_4$ with $T_{\\\\mathrm{sc}}>T_{\\\\mathrm{m}}$. With the\\nNi doping, $T_{\\\\mathrm{sc}}$ decreases rapidly, and the Eu-spin ferromagnetism\\nand its $T_{\\\\mathrm{m}}$ remain unchanged. Consequently, the system\\nRbEu(Fe$_{1-x}$Ni$_x$)$_4$As$_4$ transforms into a superconducting ferromagnet\\nwith $T_{\\\\mathrm{m}}>T_{\\\\mathrm{sc}}$ for $0.07\\\\leq x\\\\leq0.08$. The occurrence\\nof superconducting ferromagnets is attributed to the decoupling between\\nEu$^{2+}$ spins and superconducting Cooper pairs. The superconducting and\\nmagnetic phase diagram is established, which additionally includes a recovered\\nyet suppressed spin-density-wave state.\\n'\n",
      " '  This paper addresses maximum likelihood (ML) estimation based model fitting\\nin the context of extrasolar planet detection. This problem is featured by the\\nfollowing properties: 1) the candidate models under consideration are highly\\nnonlinear; 2) the likelihood surface has a huge number of peaks; 3) the\\nparameter space ranges in size from a few to dozens of dimensions. These\\nproperties make the ML search a very challenging problem, as it lacks any\\nanalytical or gradient based searching solution to explore the parameter space.\\nA population based searching method, called estimation of distribution\\nalgorithm (EDA), is adopted to explore the model parameter space starting from\\na batch of random locations. EDA is featured by its ability to reveal and\\nutilize problem structures. This property is desirable for characterizing the\\ndetections. However, it is well recognized that EDAs can not scale well to\\nlarge scale problems, as it consists of iterative random sampling and model\\nfitting procedures, which results in the well-known dilemma curse of\\ndimensionality. A novel mechanism to perform EDAs in interactive random\\nsubspaces spanned by correlated variables is proposed and the hope is to\\nalleviate the curse of dimensionality for EDAs by performing the operations of\\nsampling and model fitting in lower dimensional subspaces. The effectiveness of\\nthe proposed algorithm is verified via both benchmark numerical studies and\\nreal data analysis.\\n'\n",
      " '  The recent proposed Tensor Nuclear Norm (TNN) [Lu et al., 2016; 2018a] is an\\ninteresting convex penalty induced by the tensor SVD [Kilmer and Martin, 2011].\\nIt plays a similar role as the matrix nuclear norm which is the convex\\nsurrogate of the matrix rank. Considering that the TNN based Tensor Robust PCA\\n[Lu et al., 2018a] is an elegant extension of Robust PCA with a similar tight\\nrecovery bound, it is natural to solve other low rank tensor recovery problems\\nextended from the matrix cases. However, the extensions and proofs are\\ngenerally tedious. The general atomic norm provides a unified view of\\nlow-complexity structures induced norms, e.g., the $\\\\ell_1$-norm and nuclear\\nnorm. The sharp estimates of the required number of generic measurements for\\nexact recovery based on the atomic norm are known in the literature. In this\\nwork, with a careful choice of the atomic set, we prove that TNN is a special\\natomic norm. Then by computing the Gaussian width of certain cone which is\\nnecessary for the sharp estimate, we achieve a simple bound for guaranteed low\\ntubal rank tensor recovery from Gaussian measurements. Specifically, we show\\nthat by solving a TNN minimization problem, the underlying tensor of size\\n$n_1\\\\times n_2\\\\times n_3$ with tubal rank $r$ can be exactly recovered when the\\ngiven number of Gaussian measurements is $O(r(n_1+n_2-r)n_3)$. It is order\\noptimal when comparing with the degrees of freedom $r(n_1+n_2-r)n_3$. Beyond\\nthe Gaussian mapping, we also give the recovery guarantee of tensor completion\\nbased on the uniform random mapping by TNN minimization. Numerical experiments\\nverify our theoretical results.\\n'\n",
      " '  Here, we explore some peculiar orbital features of the recently discovered\\nasteroid A/2017 U1, which is a clear outlier when considering the average value\\nof the eccentricity of known hyperbolic comets. As for the orientation of its\\norbit in space, the orbital plane of A/2017 U1 seems to be away from any\\nobvious clusters present for this population. The orbital nodes of A/2017 U1\\nare well away from the paths of the planets of the Solar System and the Sun.\\nAll these orbital properties appear to confirm A/2017 U1 as the first known\\ninterstellar asteroid.\\n'\n",
      " \"  Sensor data has been playing an important role in machine learning tasks,\\ncomplementary to the human-annotated data that is usually rather costly.\\nHowever, due to systematic or accidental mis-operations, sensor data comes very\\noften with a variety of missing values, resulting in considerable difficulties\\nin the follow-up analysis and visualization. Previous work imputes the missing\\nvalues by interpolating in the observational feature space, without consulting\\nany latent (hidden) dynamics. In contrast, our model captures the latent\\ncomplex temporal dynamics by summarizing each observation's context with a\\nnovel Iterative Imputing Network, thus significantly outperforms previous work\\non the benchmark Beijing air quality and meteorological dataset. Our model also\\nyields consistent superiority over other methods in cases of different missing\\nrates.\\n\"\n",
      " '  A linear connection is associated to a nonlinear connection on a vector\\nbundle by a linearization procedure. Our definition is intrinsic in terms of\\nvector fields on the bundle. For a connection on an affine bundle our procedure\\ncan be applied after homogenization and restriction. Several applications in\\nClassical Mechanics are provided.\\n'\n",
      " \"  We present a new stabilised and efficient high-order nodal spectral element\\nmethod based on the Mixed Eulerian Lagrangian (MEL) method for general-purpose\\nsimulation of fully nonlinear water waves and wave-body interactions. In this\\nMEL formulation a standard Laplace formulation is used to handle arbitrary body\\nshapes using unstructured - possibly hybrid - meshes consisting of high-order\\ncurvilinear iso-parametric quadrilateral/triangular elements to represent the\\nbody surfaces and for the evolving free surface. Importantly, our numerical\\nanalysis highlights that a single top layer of quadrilaterals elements resolves\\ntemporal instabilities in the numerical MEL scheme that are known to be\\nassociated with mesh topology containing asymmetric element orderings. The\\n'surface variable only' free surface formulation based on introducing a\\nparticle-following (Lagrangian) reference frame contains quartic nonlinear\\nterms that require proper treatment by numerical discretisation due to the\\npossibility of strong aliasing effects. We demonstrate how to stabilise this\\nnonlinear MEL scheme using an efficient combination of (i) global L2 projection\\nwithout quadrature errors, (ii) mild nonlinear spectral filtering and (iii)\\nre-meshing techniques. Numerical experiments revisiting known benchmarks are\\npresented, and highlights that modelling using a high-order spectral element\\nmethod provides excellent accuracy in prediction of nonlinear and dispersive\\nwave propagation, and of nonlinear wave-induced loads on fixed submerged and\\nsurface-piercing bodies.\\n\"\n",
      " '  The problem of sparse rewards is one of the hardest challenges in\\ncontemporary reinforcement learning. Hierarchical reinforcement learning (HRL)\\ntackles this problem by using a set of temporally-extended actions, or options,\\neach of which has its own subgoal. These subgoals are normally handcrafted for\\nspecific tasks. Here, though, we introduce a generic class of subgoals with\\nbroad applicability in the visual domain. Underlying our approach (in common\\nwith work using \"auxiliary tasks\") is the hypothesis that the ability to\\ncontrol aspects of the environment is an inherently useful skill to have. We\\nincorporate such subgoals in an end-to-end hierarchical reinforcement learning\\nsystem and test two variants of our algorithm on a number of games from the\\nAtari suite. We highlight the advantage of our approach in one of the hardest\\ngames -- Montezuma\\'s revenge -- for which the ability to handle sparse rewards\\nis key. Our agent learns several times faster than the current state-of-the-art\\nHRL agent in this game, reaching a similar level of performance. UPDATE\\n22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e.\\nextrinsic reward + feature control intrinsic reward, has comparable performance\\nto our agent in Montezuma Revenge. In light of the new experiments performed,\\nthe advantage of our HRL approach can be attributed more to its ability to\\nlearn useful features from intrinsic rewards rather than its ability to explore\\nand reuse abstracted skills with hierarchical components. This has led us to a\\nnew conclusion about the result.\\n'\n",
      " '  Various hypotheses exist about the paths used for communication between the\\nnodes of complex networks. Most studies simply suppose that communication goes\\nvia shortest paths, while others have more explicit assumptions about how\\nrouting (alternatively navigation or search) works or should work in real\\nnetworks. However, these assumptions are rarely checked against real data. Here\\nwe directly analyze the structure of operational paths using real measurements.\\nFor this purpose we use existing and newly created datasets having both the\\ntopology of the network and a sufficient number of empirically-determined paths\\nover it. Such datasets are processed for air transportation networks, the human\\nbrain, the Internet and the fit-fat-cat word ladder game. Our results suggest\\nthat from the great number of possible paths, nature seems to pick according to\\nsome simple rules, which we will refer to as routing policies. First we\\nconfirm, that the preference of short paths is an inevitable policy element,\\nhowever the observed stretch of the paths suggests that there are other\\npolicies at work simultaneously. We identify two additional policies common in\\nour networks: the \"conform hierarchy\", meaning that the paths should obey the\\nstructural hierarchy of the network, and the \"prefer downstream\" policy which\\npromotes avoiding the network core if possible. Building upon these simple\\npolicies, we propose a synthetic routing policy which can recover the basic\\nstatistical properties of the operational paths in networks. Our results can be\\nhelpful in estimating the reaction of complex systems for stress coming from\\nthe outside more accurately than the shortest path assumption permits.\\n'\n",
      " '  An evaluation of distributed word representation is generally conducted using\\na word similarity task and/or a word analogy task. There are many datasets\\nreadily available for these tasks in English. However, evaluating distributed\\nrepresentation in languages that do not have such resources (e.g., Japanese) is\\ndifficult. Therefore, as a first step toward evaluating distributed\\nrepresentations in Japanese, we constructed a Japanese word similarity dataset.\\nTo the best of our knowledge, our dataset is the first resource that can be\\nused to evaluate distributed representations in Japanese. Moreover, our dataset\\ncontains various parts of speech and includes rare words in addition to common\\nwords.\\n'\n",
      " \"  One single error can result in a total compromise of all security in today's\\nlarge, monolithic software. Partitioning of software can help simplify\\ncode-review and verification, whereas isolated execution of software-components\\nlimits the impact of incorrect implementations. However, existing application\\npartitioning techniques are too expensive, too imprecise, or involve unsafe\\nmanual steps. An automatic, yet safe, approach to dissect security protocols\\ninto component-based systems is not available. We present a method and toolset\\nto automatically segregate security related software into an indefinite number\\nof partitions, based on the security guarantees required by the deployed\\ncryptographic building blocks. As partitioning imposes communication overhead,\\nwe offer a range of sound performance optimizations. Furthermore, by applying\\nour approach to the secure messaging protocol OTR, we demonstrate its\\napplicability and achieve a significant reduction of the trusted computing\\nbase. Compared to a monolithic implementation, only 29% of the partitioned\\nprotocol requires confidentiality guarantees with a process overhead comparable\\nto common sandboxing techniques.\\n\"\n",
      " '  The incorporation of prior knowledge into learning is essential in achieving\\ngood performance based on small noisy samples. Such knowledge is often\\nincorporated through the availability of related data arising from domains and\\ntasks similar to the one of current interest. Ideally one would like to allow\\nboth the data for the current task and for previous related tasks to\\nself-organize the learning system in such a way that commonalities and\\ndifferences between the tasks are learned in a data-driven fashion. We develop\\na framework for learning multiple tasks simultaneously, based on sharing\\nfeatures that are common to all tasks, achieved through the use of a modular\\ndeep feedforward neural network consisting of shared branches, dealing with the\\ncommon features of all tasks, and private branches, learning the specific\\nunique aspects of each task. Once an appropriate weight sharing architecture\\nhas been established, learning takes place through standard algorithms for\\nfeedforward networks, e.g., stochastic gradient descent and its variations. The\\nmethod deals with domain adaptation and multi-task learning in a unified\\nfashion, and can easily deal with data arising from different types of sources.\\nNumerical experiments demonstrate the effectiveness of learning in domain\\nadaptation and transfer learning setups, and provide evidence for the flexible\\nand task-oriented representations arising in the network.\\n'\n",
      " '  We investigate the effect of disorder on the propagation of surface plasmon\\npolaritons in arrays of evanescently coupled dielectric loaded surface plasmon\\npolariton waveguides. Diagonal disorder is implemented by randomly varying the\\nheights of the waveguides. Real-space as well as Fourier-space images of the\\nsurface plasmon polariton intensity distribution in the waveguide arrays are\\nrecorded by leakage radiation microscopy. With these techniques we\\nexperimentally demonstrate the transverse localization of surface plasmon\\npolaritons with increasing disorder.\\n'\n",
      " '  Inspired by the combination of feedforward and iterative computations in the\\nvirtual cortex, and taking advantage of the ability of denoising autoencoders\\nto estimate the score of a joint distribution, we propose a novel approach to\\niterative inference for capturing and exploiting the complex joint distribution\\nof output variables conditioned on some input variables. This approach is\\napplied to image pixel-wise segmentation, with the estimated conditional score\\nused to perform gradient ascent towards a mode of the estimated conditional\\ndistribution. This extends previous work on score estimation by denoising\\nautoencoders to the case of a conditional distribution, with a novel use of a\\ncorrupted feedforward predictor replacing Gaussian corruption. An advantage of\\nthis approach over more classical ways to perform iterative inference for\\nstructured outputs, like conditional random fields (CRFs), is that it is not\\nany more necessary to define an explicit energy function linking the output\\nvariables. To keep computations tractable, such energy function\\nparametrizations are typically fairly constrained, involving only a few\\nneighbors of each of the output variables in each clique. We experimentally\\nfind that the proposed iterative inference from conditional score estimation by\\nconditional denoising autoencoders performs better than comparable models based\\non CRFs or those not using any explicit modeling of the conditional joint\\ndistribution of outputs.\\n'\n",
      " \"  Let $X_1,\\\\ldots,X_n$ be a standard normal sample in $\\\\mathbb R^d$. We compute\\nexactly the expected volume of the Gaussian polytope\\n$\\\\mathrm{conv}[X_1,\\\\ldots,X_n]$, the symmetric Gaussian polytope\\n$\\\\mathrm{conv}[\\\\pm X_1,\\\\ldots,\\\\pm X_n]$, and the Gaussian zonotope\\n$[0,X_1]+\\\\ldots+[0,X_n]$ by exploiting their connection to the regular simplex,\\nthe regular crosspolytope, and the cube with the aid of Tsirelson's formula.\\nThe expected volumes of these random polytopes are given by essentially the\\nsame expressions as the intrinsic volumes and external angles of the regular\\npolytopes. For all these quantities, we obtain asymptotic formulae which are\\nmore precise than the results which were known before. More generally, we\\ndetermine the expected volumes of some heteroscedastic random polytopes\\nincluding $ \\\\mathrm{conv}[l_1X_1,\\\\ldots,l_nX_n] $ and $ \\\\mathrm{conv}[\\\\pm l_1\\nX_1,\\\\ldots, \\\\pm l_n X_n], $ where $l_1,\\\\ldots,l_n\\\\geq 0$ are parameters, and\\nthe intrinsic volumes of the corresponding deterministic polytopes. Finally, we\\nrelate the $k$-th intrinsic volume of the regular simplex $S^{n-1}$ to the\\nexpected maximum of independent standard Gaussian random variables\\n$\\\\xi_1,\\\\ldots,\\\\xi_n$ given that the maximum has multiplicity $k$. Namely, we\\nshow that $$ V_k(S^{n-1}) = \\\\frac {(2\\\\pi)^{\\\\frac k2}} {k!} \\\\cdot\\n\\\\lim_{\\\\varepsilon\\\\downarrow 0} \\\\varepsilon^{1-k} \\\\mathbb E\\n[\\\\max\\\\{\\\\xi_1,\\\\ldots,\\\\xi_n\\\\} 1_{\\\\{\\\\xi_{(n)} - \\\\xi_{(n-k+1)}\\\\leq \\\\varepsilon\\\\}}],\\n$$ where $\\\\xi_{(1)} \\\\leq \\\\ldots \\\\leq \\\\xi_{(n)}$ denote the order statistics. A\\nsimilar result holds for the crosspolytope if we replace $\\\\xi_1,\\\\ldots,\\\\xi_n$\\nby their absolute values.\\n\"\n",
      " '  We investigate $n$-component systems of conservation laws that possess\\nthird-order Hamiltonian structures of differential-geometric type. The\\nclassification of such systems is reduced to the projective classification of\\nlinear congruences of lines in $\\\\mathbb{P}^{n+2}$ satisfying additional\\ngeometric constraints. Algebraically, the problem can be reformulated as\\nfollows: for a vector space $W$ of dimension $n+2$, classify $n$-tuples of\\nskew-symmetric 2-forms $A^{\\\\alpha} \\\\in \\\\Lambda^2(W)$ such that \\\\[ \\\\phi_{\\\\beta\\n\\\\gamma}A^{\\\\beta}\\\\wedge A^{\\\\gamma}=0, \\\\] for some non-degenerate symmetric\\n$\\\\phi$.\\n'\n",
      " '  We analyze holomorphic Jacobi forms of weight one with level. One such form\\nplays an important role in umbral moonshine, leading to simplifications of the\\nstatements of the umbral moonshine conjectures. We prove that non-zero\\nholomorphic Jacobi forms of weight one do not exist for many combinations of\\nindex and level, and use this to establish a characterization of the\\nMcKay--Thompson series of umbral moonshine in terms of Rademacher sums.\\n'\n",
      " '  The Weyl semimetal is a new quantum state of topological semimetal, of which\\ntopological surface states -- the Fermi arcs exist. In this paper, the Fermi\\narcs in Weyl semimetals are classified into two classes -- class-1 and class-2.\\nBased on a tight-binding model, the evolution and transport properties of\\nclass-1/2 Fermi arcs are studied via the tilting strength of the bulk Weyl\\ncones. The (residual) anomalous Hall conductivity of topological surface states\\nis a physical consequence of class-1 Fermi arc and thus class-1 Fermi arc\\nbecomes a nontrivial topological property for hybrid or type-II Weyl semimetal.\\nTherefore, this work provides an intuitive method to learn topological\\nproperties of Weyl semimetal.\\n'\n",
      " '  Consider the graph induced by $\\\\mathbb{Z}^d$, equipped with uniformly\\nelliptic random conductances. At time $0$, place a Poisson point process of\\nparticles on $\\\\mathbb{Z}^d$ and let them perform independent simple random\\nwalks. Tessellate the graph into cubes indexed by $i\\\\in\\\\mathbb{Z}^d$ and\\ntessellate time into intervals indexed by $\\\\tau$. Given a local event\\n$E(i,\\\\tau)$ that depends only on the particles inside the space time region\\ngiven by the cube $i$ and the time interval $\\\\tau$, we prove the existence of a\\nLipschitz connected surface of cells $(i,\\\\tau)$ that separates the origin from\\ninfinity on which $E(i,\\\\tau)$ holds. This gives a directly applicable and\\nrobust framework for proving results in this setting that need a multi-scale\\nargument. For example, this allows us to prove that an infection spreads with\\npositive speed among the particles.\\n'\n",
      " \"  The Wide-Field InfraRed Space Telescope (WFIRST) will be capable of\\ndelivering precise astrometry for faint sources over the enormous field of view\\nof its main camera, the Wide-Field Imager (WFI). This unprecedented combination\\nwill be transformative for the many scientific questions that require precise\\npositions, distances, and velocities of stars. We describe the expectations for\\nthe astrometric precision of the WFIRST WFI in different scenarios, illustrate\\nhow a broad range of science cases will see significant advances with such\\ndata, and identify aspects of WFIRST's design where small adjustments could\\ngreatly improve its power as an astrometric instrument.\\n\"\n",
      " '  A grand challenge of the 21st century cosmology is to accurately estimate the\\ncosmological parameters of our Universe. A major approach to estimating the\\ncosmological parameters is to use the large-scale matter distribution of the\\nUniverse. Galaxy surveys provide the means to map out cosmic large-scale\\nstructure in three dimensions. Information about galaxy locations is typically\\nsummarized in a \"single\" function of scale, such as the galaxy correlation\\nfunction or power-spectrum. We show that it is possible to estimate these\\ncosmological parameters directly from the distribution of matter. This paper\\npresents the application of deep 3D convolutional networks to volumetric\\nrepresentation of dark-matter simulations as well as the results obtained using\\na recently proposed distribution regression framework, showing that machine\\nlearning techniques are comparable to, and can sometimes outperform,\\nmaximum-likelihood point estimates using \"cosmological models\". This opens the\\nway to estimating the parameters of our Universe with higher accuracy.\\n'\n",
      " '  In contrast with goal-oriented dialogue, social dialogue has no clear measure\\nof task success. Consequently, evaluation of these systems is notoriously hard.\\nIn this paper, we review current evaluation methods, focusing on automatic\\nmetrics. We conclude that turn-based metrics often ignore the context and do\\nnot account for the fact that several replies are valid, while end-of-dialogue\\nrewards are mainly hand-crafted. Both lack grounding in human perceptions.\\n'\n",
      " \"  We propose a novel adaptive test of goodness-of-fit, with computational cost\\nlinear in the number of samples. We learn the test features that best indicate\\nthe differences between observed samples and a reference model, by minimizing\\nthe false negative rate. These features are constructed via Stein's method,\\nmeaning that it is not necessary to compute the normalising constant of the\\nmodel. We analyse the asymptotic Bahadur efficiency of the new test, and prove\\nthat under a mean-shift alternative, our test always has greater relative\\nefficiency than a previous linear-time kernel test, regardless of the choice of\\nparameters for that test. In experiments, the performance of our method exceeds\\nthat of the earlier linear-time test, and matches or exceeds the power of a\\nquadratic-time kernel test. In high dimensions and where model structure may be\\nexploited, our goodness of fit test performs far better than a quadratic-time\\ntwo-sample test based on the Maximum Mean Discrepancy, with samples drawn from\\nthe model.\\n\"\n",
      " '  Transient responses in disordered systems typically show a heavy-tail\\nrelaxation behavior: the decay time constant increases as time increases,\\nrevealing a spectral distribution of time constants. The asymptotic value of\\nsuch transients is notoriously difficult to experimentally measure due to the\\nincreasing decay time-scale. However, if the heavy-tail transient is plotted\\nversus log-time, a reduced set of data around the inflection point of such a\\nplot is sufficient for an accurate fit. From a derivative plot in log-time, the\\npeak height, position, line width, and, most importantly, skewness are all that\\nis needed to accurately predict the asymptotic value of various heavy-tail\\ndecay models to within less than a percent. This curve fitting strategy reduces\\nby orders of magnitude the amount of experimental data required, and clearly\\nidentifies a threshold below which the amount of data is insufficient to\\ndistinguish various models. The skew normal spectral fit and dispersive\\ndiffusion transient fit are proposed as four-parameter fits, with the latter\\nincluding the stretched exponential as a limiting case. The line fit and\\nasymptotic prediction are demonstrated using experimental transient responses\\nin previously published amorphous silicon and amorphous InGaZnO data.\\n'\n",
      " '  We numerically investigate dynamical property in the one-dimensional\\ntight-binding model with long-range correlated disorder having power spectrum\\n$1/f^\\\\alpha$ ($\\\\alpha:$spectrum exponent) generated by Fourier filtering\\nmethod. For relatively small $\\\\alpha<\\\\alpha_c(=2)$ time-dependence of mean\\nsquare displacement (MSD) of the initially localized wavepacket shows ballistic\\nspread and localizes as time elapses. It is shown that $\\\\alpha-$dependence of\\nthe dynamical localization length (DLL) determined by the MSD exhibits a simple\\nscaling law in the localization regime for the relatively weak disorder\\nstrength $W$. Furthermore, scaled MSD by the DLL almost obeys an universal\\nfunction from the ballistic to the localization regime in the various\\ncombinations of the parameters $\\\\alpha$ and $W$.\\n'\n",
      " '  The higher-order topological insulator (HOTI) protected by spacial symmetry\\nhas been studied in-depth on models with square lattice. Our work, based on an\\nalternative model on the breathing Kagome lattice, revealed that the different\\ntypes of corners in the lattice could actually be conditionally gapless, or\\nalways gapped. Using the Wilson loop formalism, we argue that these corner\\nstates occur when the eigenvalues of the Wannier Hamiltonian cross through a\\ncertain reference point during the conceptual \"pumping\" procedure. The results\\ndemonstrate the corner of the Kagome lattice based HOTI is a zero-dimensional\\nanalogue of the 1D chiral edge states on the boundary of a Chern insulator, but\\nwith a sensitive dependence on the shape of the corner. Our method of the\\npumping cylinder, which reveals the symmetry/gapless-ability correspondence,\\ncan be generalized into a general scheme in determining the classification of\\ncorner(hinge) states in HOTI.\\n'\n",
      " '  We give a complete characterization of invariant subspaces for $(M_{z_1},\\n\\\\ldots, M_{z_n})$ on the Hardy space $H^2(\\\\mathbb{D}^n)$ over the unit polydisc\\n$\\\\mathbb{D}^n$ in $\\\\mathbb{C}^n$, $n >1$. In particular, this yields a complete\\nset of unitary invariants for invariant subspaces for $(M_{z_1}, \\\\ldots,\\nM_{z_n})$ on $H^2(\\\\mathbb{D}^n)$, $n > 1$. As a consequence, we classify a\\nlarge class of $n$-tuples, $n > 1$, of commuting isometries. All of our results\\nhold for vector-valued Hardy spaces over $\\\\mathbb{D}^n$, $n > 1$. Our invariant\\nsubspace theorem solves the well-known open problem on characterizations of\\ninvariant subspaces of the Hardy space over the unit polydisc.\\n'\n",
      " '  In this note we present an explicit realization of the affine vertex algebra\\n$V^{cri}(\\\\frak{gl}(1 \\\\vert 1)) $ inside of the tensor product $F\\\\otimes M$\\nwhere $F$ is a fermionic verex algebra and $M$ is a commutative vertex algebra.\\nThis immediately gives an alternative description of the center of\\n$V^{cri}(\\\\frak{gl}(1 \\\\vert 1) ) )$ as a subalgebra $M _ 0$ of $M$. We\\nreconstruct the Molev-Mukhin formula for the Hilbert-Poincare series of the\\ncenter of $V^ {cri}(\\\\frak{gl}(1 \\\\vert 1) )$. Moreover, we construct a family of\\nirreducible $V^{cri}(\\\\frak{gl}(1 \\\\vert 1))$ -modules realized on $F$ and\\nparameterized by $\\\\chi^+, \\\\chi ^- \\\\in {\\\\Bbb C}((z)). $ We propose a\\ngeneralization of $V^ {cri}(\\\\frak{gl}(1 \\\\vert 1))$ as a critical level version\\nof the super $\\\\mathcal W_{1+\\\\infty}$ vertex algebra.\\n'\n",
      " '  Lifelong learning aims to develop machine learning systems that can learn new\\ntasks while preserving the performance on previous learned tasks. In this paper\\nwe present a method to overcome catastrophic forgetting on convolutional neural\\nnetworks, that learns new tasks and preserves the performance on old tasks\\nwithout accessing the data of the original model, by selective network\\naugmentation. The experiment results showed that SeNA-CNN, in some scenarios,\\noutperforms the state-of-art Learning without Forgetting algorithm. Results\\nalso showed that in some situations it is better to use SeNA-CNN instead of\\ntraining a neural network using isolated learning.\\n'\n",
      " '  In this paper, we investigate the sample size requirement for exact recovery\\nof a high order tensor of low rank from a subset of its entries. We show that a\\ngradient descent algorithm with initial value obtained from a spectral method\\ncan, in particular, reconstruct a ${d\\\\times d\\\\times d}$ tensor of multilinear\\nranks $(r,r,r)$ with high probability from as few as\\n$O(r^{7/2}d^{3/2}\\\\log^{7/2}d+r^7d\\\\log^6d)$ entries. In the case when the ranks\\n$r=O(1)$, our sample size requirement matches those for nuclear norm\\nminimization (Yuan and Zhang, 2016a), or alternating least squares assuming\\northogonal decomposability (Jain and Oh, 2014). Unlike these earlier\\napproaches, however, our method is efficient to compute, easy to implement, and\\ndoes not impose extra structures on the tensor. Numerical results are presented\\nto further demonstrate the merits of the proposed approach.\\n'\n",
      " '  The two-dimensional character and reduced screening in monolayer\\ntransition-metal dichalcogenides (TMDs) lead to the ubiquitous formation of\\nrobust excitons with binding energies orders of magnitude larger than in bulk\\nsemiconductors. Focusing on neutral excitons, bound electron-hole pairs, that\\ndominate the optical response in TMDs, it is shown that they can provide\\nfingerprints for magnetic proximity effects in magnetic heterostructures. These\\nproximity effects cannot be described by the widely used single-particle\\ndescription, but instead reveal the possibility of a conversion between\\noptically inactive and active excitons by rotating the magnetization of the\\nmagnetic substrate. With recent breakthroughs in fabricating Mo- and W-based\\nmagnetic TMD-heterostructures, this emergent optical response can be directly\\ntested experimentally.\\n'\n",
      " '  Rubenstein et al. present an interesting system of programmable\\nself-assembled structure formation using 1000 Kilobot robots. The paper claims\\nto advance work in artificial swarms similar to capabilities of natural systems\\nbesides being highly robust. However, the system lacks in terms of matching\\nmotility and complex shapes with holes, thereby limiting practical similarity\\nto self-assembly in living systems.\\n'\n",
      " '  In this note, given a regular Courant algebroid, we compute its group of\\nautomorphisms relative to a dissection. We also propose an infinitesimal\\nversion and recover examples of the literature.\\n'\n",
      " '  Categorical random variables are a common staple in machine learning methods\\nand other applications across disciplines. Many times, correlation within\\ncategorical predictors exists, and has been noted to have an effect on various\\nalgorithm effectiveness, such as feature ranking and random forests. We present\\na mathematical construction of a sequence of identically distributed but\\ndependent categorical random variables, and give a generalized multinomial\\ndistribution to model the probability of counts of such variables.\\n'\n",
      " '  The Subarcsecond Telescope And BaLloon Experiment, STABLE, is the fine stage\\nof a guidance system for a high-altitude ballooning platform designed to\\ndemonstrate subarcsecond pointing stability, over one minute using relatively\\ndim guide stars in the visible spectrum. The STABLE system uses an attitude\\nrate sensor and the motion of the guide star on a detector to control a Fast\\nSteering Mirror in order to stabilize the image. The characteristics of the\\nthermal-optical-mechanical elements in the system directly affect the quality\\nof the point spread function of the guide star on the detector, and so, a\\nseries of thermal, structural, and optical models were built to simulate system\\nperformance and ultimately inform the final pointing stability predictions.\\nThis paper describes the modeling techniques employed in each of these\\nsubsystems. The results from those models are discussed in detail, highlighting\\nthe development of the worst-case cold and hot cases, the optical metrics\\ngenerated from the finite element model, and the expected STABLE residual\\nwavefront error and decenter. Finally, the paper concludes with the predicted\\nsensitivities in the STABLE system, which show that thermal deadbanding,\\nstructural preloading and self-deflection under different loading conditions,\\nand the speed of individual optical elements were particularly important to the\\nresulting STABLE optical performance.\\n'\n",
      " '  A closure endomorphism of a Hilbert algebra A is a mapping that is\\nsimultaneously an endomorphism of and a closure operator on A. It is known that\\nthe set CE of all closure endomorphisms of A is a distributive lattice where\\nthe meet of two elements is defined pointwise and their join is given by their\\ncomposition. This lattice is shown in the paper to be isomorphic to the lattice\\nof certain filters of A, anti-isomorphic to the lattice of certain closure\\nretracts of A, and compactly generated. The set of compact elements of CE\\ncoincides with the adjoint semilattice of A, conditions under which two Hilbert\\nalgebras have isomorphic adjoint semilattices (equivalently, minimal Brouwerian\\nextensions) are discussed. Several consequences are drawn also for implication\\nalgebras.\\n'\n",
      " '  We present an attention based visual analysis framework to compute\\ngrasp-relevant information in order to guide grasp planning using a\\nmulti-fingered robotic hand. Our approach uses a computational visual attention\\nmodel to locate regions of interest in a scene, and uses a deep convolutional\\nneural network to detect grasp type and point for a sub-region of the object\\npresented in a region of interest. We demonstrate the proposed framework in\\nobject grasping tasks, in which the information generated from the proposed\\nframework is used as prior information to guide the grasp planning. Results\\nshow that the proposed framework can not only speed up grasp planning with more\\nstable configurations, but also is able to handle unknown objects. Furthermore,\\nour framework can handle cluttered scenarios. A new Grasp Type Dataset (GTD)\\nthat considers 6 commonly used grasp types and covers 12 household objects is\\nalso presented.\\n'\n",
      " '  As machine learning algorithms are increasingly applied to high impact yet\\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\\ncritical that researchers can explain how such algorithms arrived at their\\npredictions. In recent years, a number of image saliency methods have been\\ndeveloped to summarize where highly complex neural networks \"look\" in an image\\nfor evidence for their predictions. However, these techniques are limited by\\ntheir heuristic nature and architectural constraints. In this paper, we make\\ntwo main contributions: First, we propose a general framework for learning\\ndifferent kinds of explanations for any black box algorithm. Second, we\\nspecialise the framework to find the part of an image most responsible for a\\nclassifier decision. Unlike previous works, our method is model-agnostic and\\ntestable because it is grounded in explicit and interpretable image\\nperturbations.\\n'\n",
      " '  The ability to compare two degenerate probability distributions (i.e. two\\nprobability distributions supported on two distinct low-dimensional manifolds\\nliving in a much higher-dimensional space) is a crucial problem arising in the\\nestimation of generative models for high-dimensional observations such as those\\narising in computer vision or natural language. It is known that optimal\\ntransport metrics can represent a cure for this problem, since they were\\nspecifically designed as an alternative to information divergences to handle\\nsuch problematic scenarios. Unfortunately, training generative machines using\\nOT raises formidable computational and statistical challenges, because of (i)\\nthe computational burden of evaluating OT losses, (ii) the instability and lack\\nof smoothness of these losses, (iii) the difficulty to estimate robustly these\\nlosses and their gradients in high dimension. This paper presents the first\\ntractable computational method to train large scale generative models using an\\noptimal transport loss, and tackles these three issues by relying on two key\\nideas: (a) entropic smoothing, which turns the original OT loss into one that\\ncan be computed using Sinkhorn fixed point iterations; (b) algorithmic\\n(automatic) differentiation of these iterations. These two approximations\\nresult in a robust and differentiable approximation of the OT loss with\\nstreamlined GPU execution. Entropic smoothing generates a family of losses\\ninterpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus\\nallowing to find a sweet spot leveraging the geometry of OT and the favorable\\nhigh-dimensional sample complexity of MMD which comes with unbiased gradient\\nestimates. The resulting computational architecture complements nicely standard\\ndeep network generative models by a stack of extra layers implementing the loss\\nfunction.\\n'\n",
      " '  The GAPS experiment is designed to carry out a sensitive dark matter search\\nby measuring low-energy cosmic ray antideuterons and antiprotons. GAPS will\\nprovide a new avenue to access a wide range of dark matter models and masses\\nthat is complementary to direct detection techniques, collider experiments and\\nother indirect detection techniques. Well-motivated theories beyond the\\nStandard Model contain viable dark matter candidates which could lead to a\\ndetectable signal of antideuterons resulting from the annihilation or decay of\\ndark matter particles. The dark matter contribution to the antideuteron flux is\\nbelieved to be especially large at low energies (E < 1 GeV), where the\\npredicted flux from conventional astrophysical sources (i.e. from secondary\\ninteractions of cosmic rays) is very low. The GAPS low-energy antiproton search\\nwill provide stringent constraints on less than 10 GeV dark matter, will\\nprovide the best limits on primordial black hole evaporation on Galactic length\\nscales, and will explore new discovery space in cosmic ray physics.\\nUnlike other antimatter search experiments such as BESS and AMS that use\\nmagnetic spectrometers, GAPS detects antideuterons and antiprotons using an\\nexotic atom technique. This technique, and its unique event topology, will give\\nGAPS a nearly background-free detection capability that is critical in a\\nrare-event search. GAPS is designed to carry out its science program using\\nlong-duration balloon flights in Antarctica. A prototype instrument was\\nsuccessfully flown from Taiki, Japan in 2012. GAPS has now been approved by\\nNASA to proceed towards the full science instrument, with the possibility of a\\nfirst long-duration balloon flight in late 2020. Here we motivate low-energy\\ncosmic ray antimatter searches and discuss the current status of the GAPS\\nexperiment and the design of the payload.\\n'\n",
      " \"  The support vector machine (SVM) is a widely used machine learning tool for\\nclassification based on statistical learning theory. Given a set of training\\ndata, the SVM finds a hyperplane that separates two different classes of data\\npoints by the largest distance. While the standard form of SVM uses L2-norm\\nregularization, other regularization approaches are particularly attractive for\\nbiomedical datasets where, for example, sparsity and interpretability of the\\nclassifier's coefficient values are highly desired features. Therefore, in this\\npaper we consider different types of regularization approaches for SVMs, and\\nexplore them in both synthetic and real biomedical datasets.\\n\"\n",
      " '  Potassium (K) intercalated manganese phthalocyanine (MnPc) reveals vast\\nchanges of its electronic states close to the Fermi level. However, theoretical\\nstudies are controversial regarding the electronic configuration. Here, MnPc\\ndoped with K was studied by ultraviolet, X-ray, and inverse photoemission, as\\nwell as near edge X-ray absorption fine structure spectroscopy. Upon K\\nintercalation the Fermi level shifts toward the lowest unoccupied molecular\\norbital filling it up with donated electrons with the appearance of an\\nadditional feature in the energy region of the occupied states. The electronic\\nbands are pinned 0.5 eV above and 0.4 eV below the Fermi level. The branching\\nratio of the Mn L3 and L2 edges indicate an increase of the spin state.\\nMoreover, the evolution of the Mn L and N K edges reveals strong hybridization\\nbetween Mn 3d and N 2p states of MnPc and sheds light on the electron\\noccupation in the ground and n-doped configurations.\\n'\n",
      " '  The Intelligent vehicle (IV) is experiencing revolutionary growth in research\\nand industry, but it still suffers from many security vulnerabilities.\\nTraditional security methods are incapable to provide secure IV communication.\\nThe major issues in IV communication, are trust, data accuracy and reliability\\nof communication data in the communication channel. Blockchain technology works\\nfor the crypto currency, Bit-coin, which is recently used to build trust and\\nreliability in peer-to-peer networks having similar topologies as IV\\nCommunication. In this paper, we are proposing, Intelligent Vehicle-Trust Point\\n(IV-TP) mechanism for IV communication among IVs using Blockchain technology.\\nThe IVs communicated data provides security and reliability using our proposed\\nIV-TP. Our IV-TP mechanism provides trustworthiness for vehicles behavior, and\\nvehicles legal and illegal action. Our proposal presents a reward based system,\\nan exchange of some IV-TP among IVs, during successful communication. For the\\ndata management of the IV-TP, we are using blockchain technology in the\\nintelligent transportation system (ITS), which stores all IV-TP details of\\nevery vehicle and is accessed ubiquitously by IVs. In this paper, we evaluate\\nour proposal with the help of intersection use case scenario for intelligent\\nvehicles communication.\\n'\n",
      " '  Significant research contributions and Directives approach the issue of the\\ninsertion of renewable-based energy systems on urban territory in order to face\\nwith the growing energy needs of citizens. The introduction of such systems\\ngives raise to installers to both satisfy their energy demands and distribute\\neventual energy excesses to close neighbours. This paper presents a multi-layer\\nagent-based computational model that simulates multiple event of the network of\\nthe energy distribution occurring within urban areas. The model runs on the\\nNetLogo platform and aims at elaborating the most suitable strategy when\\ndealing with the design of a network of energy distribution. Experimental data\\nare discussed on the basis of two main scenarios within an operating period of\\n24 hours. Scenarios consider both the variation of the percentages of\\ninstallers of renewable-based energy systems and the distance along which\\nenergy exchanges occur.\\n'\n",
      " '  We obtain matching direct and inverse theorems for the degree of weighted\\n$L_p$-approximation by polynomials with the Jacobi weights $(1-x)^\\\\alpha\\n(1+x)^\\\\beta$. Combined, the estimates yield a constructive characterization of\\nvarious smoothness classes of functions via the degree of their approximation\\nby algebraic polynomials.\\n'\n",
      " '  Matrix decomposition is a popular and fundamental approach in machine\\nlearning and data mining. It has been successfully applied into various fields.\\nMost matrix decomposition methods focus on decomposing a data matrix from one\\nsingle source. However, it is common that data are from different sources with\\nheterogeneous noise. A few of matrix decomposition methods have been extended\\nfor such multi-view data integration and pattern discovery. While only few\\nmethods were designed to consider the heterogeneity of noise in such multi-view\\ndata for data integration explicitly. To this end, we propose a joint matrix\\ndecomposition framework (BJMD), which models the heterogeneity of noise by\\nGaussian distribution in a Bayesian framework. We develop two algorithms to\\nsolve this model: one is a variational Bayesian inference algorithm, which\\nmakes full use of the posterior distribution; and another is a maximum a\\nposterior algorithm, which is more scalable and can be easily paralleled.\\nExtensive experiments on synthetic and real-world datasets demonstrate that\\nBJMD considering the heterogeneity of noise is superior or competitive to the\\nstate-of-the-art methods.\\n'\n",
      " '  There are no two identical leaves in the world, so how to find effective\\nmarkers or features to distinguish them is an important issue. Function\\ntransformation, such as f(x,y) and f(x,y,z), can transform two, three, or\\nmultiple input/observation variables (in biology, it generally refers to the\\nobserved/measured value of biomarkers, biological characteristics, or other\\nindicators) into a new output variable (new characteristics or indicators).\\nThis provided us a chance to re-cognize objective things or relationships\\nbeyond the original measurements. For example, Body Mass Index, which transform\\nweight and high into a new indicator BMI=x/y^2 (where x is weight and y is\\nhigh), is commonly used in to gauge obesity. Here, we proposed a new system,\\nFunomics (Function Transformation Omics), for understanding the world in a\\ndifferent perspective. Funome can be understood as a set of math functions\\nconsist of basic elementary functions (such as power functions and exponential\\nfunctions) and basic mathematical operations (such as addition, subtraction).\\nBy scanning the whole Funome, researchers can identify some special functions\\n(called handsome functions) which can generate the novel important output\\nvariable (characteristics or indicators). We also start \"the Funome project\" to\\ndevelop novel methods, function library and analysis software for Funome\\nstudies. The Funome project will accelerate the discovery of new useful\\nindicators or characteristics, will improve the utilization efficiency of\\ndirectly measured data, and will enhance our ability to understand the world.\\nThe analysis tools and data resources about the Funome project can be found\\ngradually at this http URL.\\n'\n",
      " '  Videos for outdoor scene often show unpleasant blur effects due to the large\\nrelative motion between the camera and the dynamic objects and large depth\\nvariations. Existing works typically focus monocular video deblurring. In this\\npaper, we propose a novel approach to deblurring from stereo videos. In\\nparticular, we exploit the piece-wise planar assumption about the scene and\\nleverage the scene flow information to deblur the image. Unlike the existing\\napproach [31] which used a pre-computed scene flow, we propose a single\\nframework to jointly estimate the scene flow and deblur the image, where the\\nmotion cues from scene flow estimation and blur information could reinforce\\neach other, and produce superior results than the conventional scene flow\\nestimation or stereo deblurring methods. We evaluate our method extensively on\\ntwo available datasets and achieve significant improvement in flow estimation\\nand removing the blur effect over the state-of-the-art methods.\\n'\n",
      " '  The polycrystalline Sm2MgMnO6 (SMMO) was synthesized at 1173K by means of\\nsol-gel technique. Rietveld refine-ment of X-ray diffraction (XRD) pattern\\nconfirmed the formation of a single phase monoclinic structure with space group\\nP21/n. The band gap achieved from UV-vis spectra shows the semiconducting\\nnature of the material. To observe the effect of grains and grain-boundaries in\\nthe conduction process and dielectric relaxation measurements are carried out\\non SMMO sample at different frequencies between 313 K and 673 K. An electrical\\nequivalent circuit consisting of the resistance and constant phase element is\\nused to clarify the impedance data.\\n'\n",
      " \"  The multiplicity of a weight $\\\\mu$ in an irreducible representation of a\\nsimple Lie algebra $\\\\mathfrak{g}$ with highest weight $\\\\lambda$ can be computed\\nvia the use of Kostant's weight multiplicity formula. This formula is an\\nalternating sum over the Weyl group and involves the computation of a partition\\nfunction. In this paper we consider a $q$-analog of Kostant's weight\\nmultiplicity and present a SageMath program to compute $q$-multiplicities for\\nthe simple Lie algebras.\\n\"\n",
      " '  We investigate the dynamics of the localized nonlinear matter wave in spin-1\\nBose-Einstein condensates with trapping potentials and nonlinearities dependent\\non time and space. We solve the three coupled Gross-Pitaevskii equation by\\nsimilarity transformation and obtain two families of exact matter wave\\nsolutions in terms of Jacobi elliptic functions and Mathieu equation. The\\nlocalized states of the spinor matter wave describe the dynamics of vector\\nbreathing solitons, moving breathing solitons, quasibreathing solitons and\\nresonant solitons. The results of stability show that one order vector\\nbreathing solitons, quasibreathing solitons, resonant solitons, and the moving\\nbreathing solitons \\\\psi_{\\\\pm1} are all stable but the moving breathing solitons\\n\\\\psi_0 is unstable. We also present the experimental parameters to realize\\nthese phenomena in the future experiments.\\n'\n",
      " '  The tremendous growth of positioning technologies and GPS enabled devices has\\nproduced huge volumes of tracking data during the recent years. This source of\\ninformation constitutes a rich input for data analytics processes, either\\noffline (e.g. cluster analysis, hot motion discovery) or online (e.g.\\nshort-term forecasting of forthcoming positions). This paper focuses on\\npredictive analytics for moving objects (could be pedestrians, cars, vessels,\\nplanes, animals, etc.) and surveys the state-of-the-art in the context of\\nfuture location and trajectory prediction. We provide an extensive review of\\nover 50 works, also proposing a novel taxonomy of predictive algorithms over\\nmoving objects. We also list the properties of several real datasets used in\\nthe past for validation purposes of those works and, motivated by this, we\\ndiscuss challenges that arise in the transition from conventional to Big Data\\napplications.\\nCCS Concepts: Information systems > Spatial-temporal systems; Information\\nsystems > Data analytics; Information systems > Data mining; Computing\\nmethodologies > Machine learning Additional Key Words and Phrases: mobility\\ndata, moving object trajectories, trajectory prediction, future location\\nprediction.\\n'\n",
      " '  Many neuroimaging studies focus on the cortex, in order to benefit from\\nbetter signal to noise ratios and reduced computational burden. Cortical data\\nare usually projected onto a reference mesh, where subsequent analyses are\\ncarried out. Several multiscale approaches have been proposed for analyzing\\nthese surface data, such as spherical harmonics and graph wavelets. As far as\\nwe know, however, the hierarchical structure of the template icosahedral meshes\\nused by most neuroimaging software has never been exploited for cortical data\\nfactorization. In this paper, we demonstrate how the structure of the\\nubiquitous icosahedral meshes can be exploited by data factorization methods\\nsuch as sparse dictionary learning, and we assess the optimization speed-up\\noffered by extrapolation methods in this context. By testing different\\nsparsity-inducing norms, extrapolation methods, and factorization schemes, we\\ncompare the performances of eleven methods for analyzing four datasets: two\\nstructural and two functional MRI datasets obtained by processing the data\\npublicly available for the hundred unrelated subjects of the Human Connectome\\nProject. Our results demonstrate that, depending on the level of details\\nrequested, a speedup of several orders of magnitudes can be obtained.\\n'\n",
      " '  Voice conversion (VC) using sequence-to-sequence learning of context\\nposterior probabilities is proposed. Conventional VC using shared context\\nposterior probabilities predicts target speech parameters from the context\\nposterior probabilities estimated from the source speech parameters. Although\\nconventional VC can be built from non-parallel data, it is difficult to convert\\nspeaker individuality such as phonetic property and speaking rate contained in\\nthe posterior probabilities because the source posterior probabilities are\\ndirectly used for predicting target speech parameters. In this work, we assume\\nthat the training data partly include parallel speech data and propose\\nsequence-to-sequence learning between the source and target posterior\\nprobabilities. The conversion models perform non-linear and variable-length\\ntransformation from the source probability sequence to the target one. Further,\\nwe propose a joint training algorithm for the modules. In contrast to\\nconventional VC, which separately trains the speech recognition that estimates\\nposterior probabilities and the speech synthesis that predicts target speech\\nparameters, our proposed method jointly trains these modules along with the\\nproposed probability conversion modules. Experimental results demonstrate that\\nour approach outperforms the conventional VC.\\n'\n",
      " \"  We prove a downward separation for $\\\\mathsf{\\\\Sigma}_2$-time classes.\\nSpecifically, we prove that if $\\\\Sigma_2$E does not have polynomial size\\nnon-deterministic circuits, then $\\\\Sigma_2$SubEXP does not have \\\\textit{fixed}\\npolynomial size non-deterministic circuits. To achieve this result, we use\\nSanthanam's technique on augmented Arthur-Merlin protocols defined by\\nAydinlioğlu and van Melkebeek. We show that augmented Arthur-Merlin\\nprotocols with one bit of advice do not have fixed polynomial size\\nnon-deterministic circuits. We also prove a weak unconditional derandomization\\nof a certain type of promise Arthur-Merlin protocols. Using Williams' easy\\nhitting set technique, we show that $\\\\Sigma_2$-promise AM problems can be\\ndecided in $\\\\Sigma_2$SubEXP with $n^c$ advice, for some fixed constant $c$.\\n\"\n",
      " '  We introduce a new type of categorical object called a \\\\emph{hom-tensor\\ncategory} and show that it provides the appropriate setting for modules over an\\narbitrary hom-bialgebra. Next we introduce the notion of \\\\emph{hom-braided\\ncategory} and show that this is the right setting for modules over\\nquasitriangular hom-bialgebras. We also show how the hom-Yang-Baxter equation\\nfits into this framework and how the category of Yetter-Drinfeld modules over a\\nhom-bialgebra with bijective structure map can be organized as a hom-braided\\ncategory. Finally we prove that, under certain conditions, one can obtain a\\ntensor category (respectively a braided tensor category) from a hom-tensor\\ncategory (respectively a hom-braided category).\\n'\n",
      " '  Our goal is to design architectures that retain the groundbreaking\\nperformance of CNNs for landmark localization and at the same time are\\nlightweight, compact and suitable for applications with limited computational\\nresources. To this end, we make the following contributions: (a) we are the\\nfirst to study the effect of neural network binarization on localization tasks,\\nnamely human pose estimation and face alignment. We exhaustively evaluate\\nvarious design choices, identify performance bottlenecks, and more importantly\\npropose multiple orthogonal ways to boost performance. (b) Based on our\\nanalysis, we propose a novel hierarchical, parallel and multi-scale residual\\narchitecture that yields large performance improvement over the standard\\nbottleneck block while having the same number of parameters, thus bridging the\\ngap between the original network and its binarized counterpart. (c) We perform\\na large number of ablation studies that shed light on the properties and the\\nperformance of the proposed block. (d) We present results for experiments on\\nthe most challenging datasets for human pose estimation and face alignment,\\nreporting in many cases state-of-the-art performance. Code can be downloaded\\nfrom this https URL\\n'\n",
      " '  Trained recurrent networks are powerful tools for modeling dynamic neural\\ncomputations. We present a target-based method for modifying the full\\nconnectivity matrix of a recurrent network to train it to perform tasks\\ninvolving temporally complex input/output transformations. The method\\nintroduces a second network during training to provide suitable \"target\"\\ndynamics useful for performing the task. Because it exploits the full recurrent\\nconnectivity, the method produces networks that perform tasks with fewer\\nneurons and greater noise robustness than traditional least-squares (FORCE)\\napproaches. In addition, we show how introducing additional input signals into\\nthe target-generating network, which act as task hints, greatly extends the\\nrange of tasks that can be learned and provides control over the complexity and\\nnature of the dynamics of the trained, task-performing network.\\n'\n",
      " '  Learning sparse combinations is a frequent theme in machine learning. In this\\npaper, we study its associated optimization problem in the distributed setting\\nwhere the elements to be combined are not centrally located but spread over a\\nnetwork. We address the key challenges of balancing communication costs and\\noptimization errors. To this end, we propose a distributed Frank-Wolfe (dFW)\\nalgorithm. We obtain theoretical guarantees on the optimization error\\n$\\\\epsilon$ and communication cost that do not depend on the total number of\\ncombining elements. We further show that the communication cost of dFW is\\noptimal by deriving a lower-bound on the communication cost required to\\nconstruct an $\\\\epsilon$-approximate solution. We validate our theoretical\\nanalysis with empirical studies on synthetic and real-world data, which\\ndemonstrate that dFW outperforms both baselines and competing methods. We also\\nstudy the performance of dFW when the conditions of our analysis are relaxed,\\nand show that dFW is fairly robust.\\n'\n",
      " '  Explainable recommendation is an important task. Many methods have been\\nproposed which generate explanations from the content and reviews written for\\nitems. When review text is unavailable, generating explanations is still a hard\\nproblem. In this paper, we illustrate how explanations can be generated in such\\na scenario by leveraging external knowledge in the form of knowledge graphs.\\nOur method jointly ranks items and knowledge graph entities using a\\nPersonalized PageRank procedure to produce recommendations together with their\\nexplanations.\\n'\n",
      " '  Fractal scale-free networks are empirically known to exhibit disassortative\\ndegree mixing. It is, however, not obvious whether a negative degree\\ncorrelation between nearest neighbor nodes makes a scale-free network fractal.\\nHere we examine the possibility that disassortativity in complex networks is\\nthe origin of fractality. To this end, maximally disassortative (MD) networks\\nare prepared by rewiring edges while keeping the degree sequence of an initial\\nuncorrelated scale-free network that is guaranteed to become fractal by\\nrewiring edges. Our results show that most of MD networks with different\\ntopologies are not fractal, which demonstrates that disassortativity does not\\ncause the fractal property of networks. In addition, we suggest that fractality\\nof scale-free networks requires a long-range repulsive correlation in similar\\ndegrees.\\n'\n",
      " '  We incorporate the non-linear clustering of dark matter halos, as modelled by\\nJose et al. (2016) into the halo model to better understand the clustering of\\nLyman break galaxies (LBGs) in the redshift range $z=3-5$. We find that, with\\nthis change, the predicted LBG clustering increases significantly on\\nquasi-linear scales ($0.1 \\\\leq r\\\\,/\\\\,h^{-1} \\\\,{\\\\rm Mpc} \\\\leq 10$) compared to\\nthat in the linear halo bias model. This in turn results in an increase in the\\nclustering of LBGs by an order of magnitude on angular scales $5\" \\\\leq \\\\theta\\n\\\\leq 100\"$. Remarkably, the predictions of our new model on the whole remove\\nthe systematic discrepancy between the linear halo bias predictions and the\\nobservations. The correlation length and large scale galaxy bias of LBGs are\\nfound to be significantly higher in the non-linear halo bias model than in the\\nlinear halo bias model. The resulting two-point correlation function retains an\\napproximate power-law form in contrast with that computed using the linear halo\\nbias theory. We also find that the non-linear clustering of LBGs increases with\\nincreasing luminosity and redshift. Our work emphasizes the importance of using\\nnon-linear halo bias in order to model the clustering of high-z galaxies to\\nprobe the physics of galaxy formation and extract cosmological parameters\\nreliably.\\n'\n",
      " '  In 2010, Joyce et. al defined the leverage centrality of vertices in a graph\\nas a means to analyze functional connections within the human brain. In this\\nmetric a degree of a vertex is compared to the degrees of all it neighbors. We\\ninvestigate this property from a mathematical perspective. We first outline\\nsome of the basic properties and then compute leverage centralities of vertices\\nin different families of graphs. In particular, we show there is a surprising\\nconnection between the number of distinct leverage centralities in the\\nCartesian product of paths and the triangle numbers.\\n'\n",
      " \"  We address the problem of defining a network graph on a large collection of\\nclasses. Each class is comprised of a collection of data points, sampled in a\\nnon i.i.d. way, from some unknown underlying distribution. The application we\\nconsider in this paper is a large scale high dimensional survey of people\\nliving in the US, and the question of how similar or different are the various\\ncounties in which these people live. We use a co-clustering diffusion metric to\\nlearn the underlying distribution of people, and build an approximate earth\\nmover's distance algorithm using this data adaptive transportation cost.\\n\"\n",
      " '  We investigate the merits of replication, and provide methods for optimal\\ndesign (including replicates), with the goal of obtaining globally accurate\\nemulation of noisy computer simulation experiments. We first show that\\nreplication can be beneficial from both design and computational perspectives,\\nin the context of Gaussian process surrogate modeling. We then develop a\\nlookahead based sequential design scheme that can determine if a new run should\\nbe at an existing input location (i.e., replicate) or at a new one (explore).\\nWhen paired with a newly developed heteroskedastic Gaussian process model, our\\ndynamic design scheme facilitates learning of signal and noise relationships\\nwhich can vary throughout the input space. We show that it does so efficiently,\\non both computational and statistical grounds. In addition to illustrative\\nsynthetic examples, we demonstrate performance on two challenging real-data\\nsimulation experiments, from inventory management and epidemiology.\\n'\n",
      " '  We tackle the problem of object detection and pose estimation in a shared\\nspace downtown environment. For perception multiple laser scanners with\\n360° coverage were fused in a dynamic occupancy grid map (DOGMa). A\\nsingle-stage deep convolutional neural network is trained to provide object\\nhypotheses comprising of shape, position, orientation and an existence score\\nfrom a single input DOGMa. Furthermore, an algorithm for offline object\\nextraction was developed to automatically label several hours of training data.\\nThe algorithm is based on a two-pass trajectory extraction, forward and\\nbackward in time. Typical for engineered algorithms, the automatic label\\ngeneration suffers from misdetections, which makes hard negative mining\\nimpractical. Therefore, we propose a loss function counteracting the high\\nimbalance between mostly static background and extremely rare dynamic grid\\ncells. Experiments indicate, that the trained network has good generalization\\ncapabilities since it detects objects occasionally lost by the label algorithm.\\nEvaluation reaches an average precision (AP) of 75.9%\\n'\n",
      " '  This paper concerns statistical inference for the components of a\\nhigh-dimensional regression parameter despite possible endogeneity of each\\nregressor. Given a first-stage linear model for the endogenous regressors and a\\nsecond-stage linear model for the response variable, we develop a novel\\nadaptation of the parametric one-step update to a generic second-stage\\nestimator. We provide high-level conditions under which the scaled update is\\nasymptotically normal. We introduce a two-stage Lasso procedure and show that,\\nunder a sub-Gaussian noise regime, the second-stage Lasso estimator satisfies\\nthe aforementioned conditions. Using these results, we construct asymptotically\\nvalid confidence intervals for the components of the second-stage regression\\nvector. We complement our asymptotic theory with empirical studies, which\\ndemonstrate the relevance of our method in finite samples.\\n'\n",
      " '  Let $f$ be a holomorphic cusp form for $SL_2(\\\\mathbb{Z})$ of weight $k>1$. In\\nthese notes, we follow Munshi to prove the Burgess bound $$\\nL(1/2+it,f)\\\\ll_{f,\\\\varepsilon} (1+|t|)^{1/2-1/8+\\\\varepsilon}. $$\\n'\n",
      " '  We compute the (primary) equivariant Euler characteristics of the building\\nfor the general linear group over a finite field.\\n'\n",
      " '  With the nonuniform media taken into account, the nonisospectral and\\nvariable-coefficient Korteweg-de Vries equation, which describes various\\nphysical situations such as fluid dynamics and plasma, is under investigation\\nin this paper. With appropriate selection of wave functions, the Darboux\\ntransformation is constructed, by which the multi-soliton solutions are derived\\nand graphs are presented. The spectral parameters, coefficients and initial\\nphase are discussed analytically and numerically to demonstrate their\\nrespective effect on the soliton dynamics, which plays a role in achieving the\\nfeasible soliton management with explicit conditions taken into account.\\n'\n",
      " '  Prior change is discussed in observational constraints studies of nonlocally\\nmodified gravity. In the latter, a model characterized by a modification of the\\nform $\\\\sim m^2 R\\\\Box^{-2}R$ to the Einstein-Hilbert action was compared against\\nthe base $\\\\Lambda$CDM one in a Bayesian way. It was found that the competing\\nmodified gravity model is significantly disfavored (at $22 \\\\,$:$\\\\, 1$ in terms\\nof betting-odds) against $\\\\Lambda$CDM given CMB+SNIa+BAO data, because of a\\ndominant tension appearing in the $H_0 \\\\,$-$\\\\, \\\\Omega_M$ plan. We identify the\\nunderlying mechanism generating such a tension and show that it is mostly\\ncaused by the late-time, quite smooth, phantom nature of the effective dark\\nenergy described by the nonlocal model. We find possible solutions for it to be\\nresolved and explore a given one that consists in extending the initial\\nbaseline from one massive neutrino eigenstate to three degenerate ones, whose\\nabsolute mass $\\\\sum m_\\\\nu \\\\, / \\\\, 3$ is allowed to take values within a\\nreasonable prior interval. As a net effect, the absolute neutrino mass is\\ninferred to be non-vanishing at $2 \\\\sigma$ level, best-fitting at $\\\\sum m_\\\\nu\\n\\\\approx 0.21 {\\\\, \\\\rm eV}$, and the Bayesian tension disappears rendering the\\nnonlocal gravity model statistically equivalent to $\\\\Lambda$CDM, given recent\\nCMB+SNIa+BAO data. We also discuss constraints from growth rate measurements $f\\n\\\\sigma_8$ whose fit is found to be improved by a larger massive neutrino\\nfraction as well. The $\\\\nu$-extended nonlocal model also prefers a higher value\\nof $H_0$ than $\\\\Lambda$CDM, therefore in better agreement with local\\nmeasurements.\\n'\n",
      " '  We identify the Taylor coefficients of the transfer matrices corresponding to\\nquantum toroidal algebras with the elliptic local and non-local integrals of\\nmotion introduced by Kojima, Shiraishi, Watanabe, and one of the authors.\\nThat allows us to prove the Litvinov conjectures on the Intermediate Long\\nWave model.\\nWe also discuss the (gl(m),gl(n)) duality of XXZ models in quantum toroidal\\nsetting and the implications for the quantum KdV model. In particular, we\\nconjecture that the spectrum of non-local integrals of motion of Bazhanov,\\nLukyanov, and Zamolodchikov is described by Gaudin Bethe ansatz equations\\nassociated to affine sl(2).\\n'\n",
      " \"  In Geomagnetism it is of interest to separate the Earth's core magnetic field\\nfrom the crustal magnetic field. However, measurements by satellites can only\\nsense the sum of the two contributions. In practice, the measured magnetic\\nfield is expanded in spherical harmonics and separation into crust and core\\ncontribution is achieved empirically, by a sharp cutoff in the spectral domain.\\nIn this paper, we derive a mathematical setup in which the two contributions\\nare modeled by harmonic potentials $\\\\Phi_0$ and $\\\\Phi_1$ generated on two\\ndifferent spheres $\\\\mathbb{S}_{R_0}$ (crust) and $\\\\mathbb{S}_{R_1}$ (core) with\\nradii $R_1<R_0$. Although it is not possible in general to recover $\\\\Phi_0$ and\\n$\\\\Phi_1$ knowing their superposition $\\\\Phi_0+\\\\Phi_1$ on a sphere\\n$\\\\mathbb{S}_{R_2}$ with radius $R_2>R_0$, we show that it becomes possible if\\nthe magnetization $\\\\mathbf{m}$ generating $\\\\Phi_0$ is localized in a strict\\nsubregion of $\\\\mathbb{S}_{R_0}$. Beyond unique recoverability, we show in this\\ncase how to numerically reconstruct characteristic features of $\\\\Phi_0$ (e.g.,\\nspherical harmonic Fourier coefficients). An alternative way of phrasing the\\nresults is that knowledge of $\\\\mathbf{m}$ on a nonempty open subset of\\n$\\\\mathbb{S}_{R_0}$ allows one to perform separation.\\n\"\n",
      " \"  We generate coherent ultraviolet radiation at 313 nm as the third harmonic of\\nan external-cavity diode laser. We use this radiation for laser cooling of\\ntrapped beryllium atomic ions and sympathetic cooling of co-trapped\\nberyllium-hydride molecular ions. An LBO crystal in an enhancement cavity\\ngenerates the second harmonic, and a BBO crystal in a doubly resonant\\nenhancement cavity mixes this second harmonic with the fundamental to produce\\nthe third harmonic. Each enhancement cavity is preceded by a tapered amplifier\\nto increase the fundamental light. The 36-mW output power of this\\nall-semiconductor-gain system will enable quantum control of the beryllium\\nions' motion.\\n\"\n",
      " '  We discuss the generalized Kurepa hypothesis $KH_{\\\\lambda}$ at singular\\ncardinals $\\\\lambda$. In particular, we answer questions of Erdös-Hajnal [1]\\nand Todorcevic [6], [7] by showing that $GCH$ does not imply\\n$KH_{\\\\aleph_\\\\omega}$ nor the existence of a family $ \\\\mathcal{F} \\\\subseteq\\n[\\\\aleph_\\\\omega]^{\\\\aleph_0}$ of size $\\\\aleph_{\\\\omega+1}$ such that $\\\\mathcal{F}\\n\\\\restriction X$ has size $\\\\aleph_0$ for every $X \\\\subseteq S, |X|=\\\\aleph_0$.\\n'\n",
      " '  Consider estimating the G-formula for the counterfactual mean outcome under a\\ngiven treatment regime in a longitudinal study. Bang and Robins provided an\\nestimator for this quantity that relies on a sequential regression formulation\\nof this parameter. This approach is doubly robust in that it is consistent if\\neither the outcome regressions or the treatment mechanisms are consistently\\nestimated. We define a stronger notion of double robustness, termed sequential\\ndouble robustness, for estimators of the longitudinal G-formula. The definition\\nemerges naturally from a more general definition of sequential double\\nrobustness for the outcome regression estimators. An outcome regression\\nestimator is sequentially doubly robust (SDR) if, at each subsequent time\\npoint, either the outcome regression or the treatment mechanism is consistently\\nestimated. This form of robustness is exactly what one would anticipate is\\nattainable by studying the remainder term of a first-order expansion of the\\nG-formula parameter. We show that a particular implementation of an existing\\nprocedure is SDR. We also introduce a novel SDR estimator, whose development\\ninvolves a novel translation of ideas used in targeted minimum loss-based\\nestimation to the infinite-dimensional setting.\\n'\n",
      " '  Given a set of n points in a d-dimensional space, we seek to compute the\\nskyline, i.e., those points that are not strictly dominated by any other point,\\nusing few comparisons between elements. We study the crowdsourcing-inspired\\nsetting ([FRPU94]) where comparisons fail with constant probability. In this\\nmodel, Groz & Milo [GM15] show three bounds on the query complexity for the\\nskyline problem. We provide two output-sensitive algorithms computing the\\nskyline with query complexity O(nd log(dk)) and O(ndk log(k)), where k is the\\nsize of the skyline. These results improve significantly on the\\nstate-of-the-art and are tight for low dimensions.\\n'\n",
      " \"  Comparison of Lasserre's measure--based bounds for polynomial optimization to\\nbounds obtained by simulated annealing. We consider the problem of minimizing a\\ncontinuous function $f$ over a compact set $\\\\mathbf{K}$. We compare the\\nhierarchy of upper bounds proposed by Lasserre in [{\\\\em SIAM J. Optim.} $21(3)$\\n$(2011)$, pp. $864-885$] to bounds that may be obtained from simulated\\nannealing.\\nWe show that, when $f$ is a polynomial and $\\\\mathbf{K}$ a convex body, this\\ncomparison yields a faster rate of convergence of the Lasserre hierarchy than\\nwhat was previously known in the literature.\\n\"\n",
      " '  We study a classification problem where each feature can be acquired for a\\ncost and the goal is to optimize a trade-off between the expected\\nclassification error and the feature cost. We revisit a former approach that\\nhas framed the problem as a sequential decision-making problem and solved it by\\nQ-learning with a linear approximation, where individual actions are either\\nrequests for feature values or terminate the episode by providing a\\nclassification decision. On a set of eight problems, we demonstrate that by\\nreplacing the linear approximation with neural networks the approach becomes\\ncomparable to the state-of-the-art algorithms developed specifically for this\\nproblem. The approach is flexible, as it can be improved with any new\\nreinforcement learning enhancement, it allows inclusion of pre-trained\\nhigh-performance classifier, and unlike prior art, its performance is robust\\nacross all evaluated datasets.\\n'\n",
      " '  Internet-native audio-visual services are witnessing rapid development. Among\\nthese services, object-based audio-visual services are gaining importance. In\\n2014, we established the Software Defined Media (SDM) consortium to target new\\nresearch areas and markets involving object-based digital media and\\nInternet-by-design audio-visual environments. In this paper, we introduce the\\nSDM architecture that virtualizes networked audio-visual services along with\\nthe development of smart buildings and smart cities using Internet of Things\\n(IoT) devices and smart building facilities. Moreover, we design the SDM\\narchitecture as a layered architecture to promote the development of innovative\\napplications on the basis of rapid advancements in software-defined networking\\n(SDN). Then, we implement a prototype system based on the architecture, present\\nthe system at an exhibition, and provide it as an SDM API to application\\ndevelopers at hackathons. Various types of applications are developed using the\\nAPI at these events. An evaluation of SDM API access shows that the prototype\\nSDM platform effectively provides 3D audio reproducibility and interactiveness\\nfor SDM applications.\\n'\n",
      " '  The task of estimating the maximum number of concurrent speakers from single\\nchannel mixtures is important for various audio-based applications, such as\\nblind source separation, speaker diarisation, audio surveillance or auditory\\nscene classification. Building upon powerful machine learning methodology, we\\ndevelop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs\\nefficiently map input representations to output targets, it remains unclear how\\nto best handle the network output to infer integer source count estimates, as a\\ndiscrete count estimate can either be tackled as a regression or a\\nclassification problem. In this paper, we investigate this important design\\ndecision and also address complementary parameter choices such as the input\\nrepresentation. We evaluate a state-of-the-art DNN audio model based on a\\nBi-directional Long Short-Term Memory network architecture for speaker count\\nestimations. Through experimental evaluations aimed at identifying the best\\noverall strategy for the task and show results for five seconds speech segments\\nin mixtures of up to ten speakers.\\n'\n",
      " '  We investigate the role of the pairing field dynamics in low-energy heavy ion\\nreactions within the nuclear time-dependent density functional theory extended\\nto superfluid systems. Recently, we have reported on unexpectedly large effects\\nassociated with the relative phase of the pairing field of colliding nuclei on\\nthe reaction outcomes, such as the total kinetic energy and the fusion cross\\nsection [P. Magierski, K. Sekizawa, and G. Wlaz{\\\\l}owski, arXiv:1611.10261\\n[nucl-th]]. We have elucidated that the effects are due to creation of a\\n\"domain wall\" or a \"solitonic structure\" of the pairing field in the neck\\nregion, which hinders energy dissipation as well as the neck formation, leading\\nto significant changes of the reaction dynamics. The situation nicely mimics\\nthe one extensively studied experimentally with ultracold atomic gases, where\\ntwo clouds of superfluid atoms possessing different phases of the pairing field\\nare forced to merge, creating various topological excitations, quantum vortices\\nand solitons, as well as Josephson currents. In this paper, we present\\nunpublished results for a lighter system, namely, $^{44}$Ca+$^{44}$Ca. It is\\nshown that the pairing effects on the fusion hindrance are rather small in\\nlighter systems, due to a strong tendency towards fusion, which is consistent\\nwith an earlier study.\\n'\n",
      " '  The present paper is devoted to provide conditions for the Levi--Malcev\\ntheorem to hold or not to hold (i.e. for two Levi subalgebras to be or not\\nconjugate by an inner automorphism) in the context of finite-dimensional\\nLeibniz algebras over a field of characteristic zero. Particularly, in the case\\nof the field $\\\\mathbb{C}$ of complex numbers, we consider all possible cases in\\nwhich Levi subalgebras are conjugate and not conjugate.\\n'\n",
      " '  Understanding high-field amplitude electromagnetic heat loss phenomena is of\\ngreat importance, in particular in the biomedical field, since the\\nheat-delivery treatment plans might rely on analytical models that are only\\nvalid at low field amplitudes. Here, we develop a nonlinear response model\\nvalid for single- domain nanoparticles of larger particle sizes and higher\\nfield amplitudes in comparison to linear response theory. A nonlinear\\nmagnetization expression and a generalized heat loss power equation are\\nobtained and compared with the exact solution of the stochastic\\nLandau-Lifshitz-Gilbert equation assuming the giant-spin hypothesis. The model\\nis valid within the hyperthermia therapeutic window and predicts a shift of\\noptimum particle size and distinct heat loss field amplitude exponents.\\nExperimental hyperthermia data with distinct ferrite-based nanoparticles, as\\nwell as third harmonic magnetization data supports the nonlinear model, which\\nalso has implications for magnetic particle imaging and magnetic thermometry.\\n'\n",
      " '  The order parameter of a critical system defined in a layered parallel plate\\ngeometry subject to Neumann boundary conditions at the limiting surfaces is\\nstudied. We utilize a one-particle irreducible vertex parts framework in order\\nto study the critical behavior of such a system. The renormalized vertex parts\\nare defined at zero external quasi-momenta, which makes the analysis\\nparticularly simple. The distance between the boundary plates $L$\\ncharacterizing the finite size system direction perpendicular to the\\nhyperplanes plays a similar role here in comparison with our recent unified\\ntreatment for Neumann and Dirichlet boundary conditions. Critical exponents are\\ncomputed using diagrammatic expansion at least up to two-loop order and are\\nshown to be identical to those from the bulk theory (limit $L \\\\rightarrow\\n\\\\infty$).\\n'\n",
      " '  The purpose of this paper is to study Rota-Baxter structures for\\nBiHom-associative algebras. Moreover, we introduce and discuss the properties\\nof the notions of BiHom-(tri)dendriform algebras and BiHom-quadri-algebras. We\\nconstruct the free Rota-Baxter BiHom-associative algebra and present some\\nobservations about categories and functors related to Rota-Baxter structures.\\n'\n",
      " '  In this paper we introduce new, easily implementable designs for drawing\\ncausal inference from randomized experiments on networks with interference.\\nInspired by the idea of matching in observational studies, we introduce the\\nnotion of considering a treatment assignment as a quasi-coloring\" on a graph.\\nOur idea of a perfect quasi-coloring strives to match every treated unit on a\\ngiven network with a distinct control unit that has identical number of treated\\nand control neighbors. For a wide range of interference functions encountered\\nin applications, we show both by theory and simulations that the classical\\nNeymanian estimator for the direct effect has desirable properties for our\\ndesigns. This further extends to settings where homophily is present in\\naddition to interference.\\n'\n",
      " '  Implicit semantic role labeling (iSRL) is the task of predicting the semantic\\nroles of a predicate that do not appear as explicit arguments, but rather\\nregard common sense knowledge or are mentioned earlier in the discourse. We\\nintroduce an approach to iSRL based on a predictive recurrent neural semantic\\nframe model (PRNSFM) that uses a large unannotated corpus to learn the\\nprobability of a sequence of semantic arguments given a predicate. We leverage\\nthe sequence probabilities predicted by the PRNSFM to estimate selectional\\npreferences for predicates and their arguments. On the NomBank iSRL test set,\\nour approach improves state-of-the-art performance on implicit semantic role\\nlabeling with less reliance than prior work on manually constructed language\\nresources.\\n'\n",
      " '  Let $N$ be a lattice of rank $n$ and let $M = N^{\\\\vee}$ be its dual lattice.\\nIn this note we show that given two compact, bounded, full-dimensional convex\\nsets $K_1 \\\\subseteq K_2 \\\\subseteq M_{\\\\R} \\\\coloneqq M \\\\otimes_{\\\\Z} \\\\R$, there is\\na canonical convex decomposition of the difference $K_2 \\\\setminus K_1$ and we\\ninterpret the volume of the pieces geometrically in terms of intersection\\nnumbers of toric $b$-divisors.\\n'\n",
      " '  We present a novel distributed Gauss-Newton method for the non-linear state\\nestimation (SE) model based on a probabilistic inference method called belief\\npropagation (BP). The main novelty of our work comes from applying BP\\nsequentially over a sequence of linear approximations of the SE model, akin to\\nwhat is done by the Gauss-Newton method. The resulting iterative Gauss-Newton\\nbelief propagation (GN-BP) algorithm can be interpreted as a distributed\\nGauss-Newton method with the same accuracy as the centralized SE, however,\\nintroducing a number of advantages of the BP framework. The paper provides\\nextensive numerical study of the GN-BP algorithm, provides details on its\\nconvergence behavior, and gives a number of useful insights for its\\nimplementation.\\n'\n",
      " '  Considering Riemannian submersions, we find necessary and sufficient\\nconditions for when sub-Riemannian normal geodesics project to curves of\\nconstant first geodesic curvature or constant first and vanishing second\\ngeodesic curvatures. We describe a canonical extension of the sub-Riemannian\\nmetric and study geometric properties of the obtained Riemannian manifold. This\\nwork contains several examples illustrating the results.\\n'\n",
      " \"  We formulate the AJ-conjecture for the Teichmüller TQFT and we prove it in\\nthe case of the figure-eight knot complement and the $5_2$-knot complement.\\nThis states that the level-$N$ Andersen-Kashaev invariant,\\n$J^{(\\\\mathrm{b},N)}_{M,K}$, is annihilated by the non-homogeneous\\n$\\\\widehat{A}$-polynomial, evaluated at appropriate $q$-commutative operators.\\nThese are obtained via geometric quantisation on the moduli space of flat\\n$\\\\operatorname{SL}(2,\\\\mathbb{C})$-connections on a genus-$1$ surface. The\\nconstruction depends on a parameter $\\\\sigma$ in the Teichmüller space in a\\nway measured by the Hitchin-Witten connection, and results in Hitchin-Witten\\ncovariantly constant quantum operators for the holonomy functions $m$ and\\n$\\\\ell$ along the meridian and longitude. Their action on\\n$J^{(\\\\mathrm{b},N)}_{M,K}$ is then defined via a trivialisation of the\\nHitchin-Witten connection and the Weil-Gel'Fand-Zak transform.\\n\"\n",
      " '  We clarify relationships between conditional (CAR) and simultaneous (SAR)\\nautoregressive models. We review the literature on this topic and find that it\\nis mostly incomplete. Our main result is that a SAR model can be written as a\\nunique CAR model, and while a CAR model can be written as a SAR model, it is\\nnot unique. In fact, we show how any multivariate Gaussian distribution on a\\nfinite set of points with a positive-definite covariance matrix can be written\\nas either a CAR or a SAR model. We illustrate how to obtain any number of SAR\\ncovariance matrices from a single CAR covariance matrix by using Givens\\nrotation matrices on a simulated example. We also discuss sparseness in the\\noriginal CAR construction, and for the resulting SAR weights matrix. For a real\\nexample, we use crime data in 49 neighborhoods from Columbus, Ohio, and show\\nthat a geostatistical model optimizes the likelihood much better than typical\\nfirst-order CAR models. We then use the implied weights from the geostatistical\\nmodel to estimate CAR model parameters that provides the best overall\\noptimization.\\n'\n",
      " '  Graph embedding provides an efficient solution for graph analysis by\\nconverting the graph into a low-dimensional space which preserves the structure\\ninformation. In contrast to the graph structure data, the i.i.d. node embedding\\ncan be processed efficiently in terms of both time and space. Current\\nsemi-supervised graph embedding algorithms assume the labelled nodes are given,\\nwhich may not be always true in the real world. While manually label all\\ntraining data is inapplicable, how to select the subset of training data to\\nlabel so as to maximize the graph analysis task performance is of great\\nimportance. This motivates our proposed active graph embedding (AGE) framework,\\nin which we design a general active learning query strategy for any\\nsemi-supervised graph embedding algorithm. AGE selects the most informative\\nnodes as the training labelled nodes based on the graphical information (i.e.,\\nnode centrality) as well as the learnt node embedding (i.e., node\\nclassification uncertainty and node embedding representativeness). Different\\nquery criteria are combined with the time-sensitive parameters which shift the\\nfocus from graph based query criteria to embedding based criteria as the\\nlearning progresses. Experiments have been conducted on three public data sets\\nand the results verified the effectiveness of each component of our query\\nstrategy and the power of combining them using time-sensitive parameters. Our\\ncode is available online at: this https URL.\\n'\n",
      " '  Fashion landmarks are functional key points defined on clothes, such as\\ncorners of neckline, hemline, and cuff. They have been recently introduced as\\nan effective visual representation for fashion image understanding. However,\\ndetecting fashion landmarks are challenging due to background clutters, human\\nposes, and scales. To remove the above variations, previous works usually\\nassumed bounding boxes of clothes are provided in training and test as\\nadditional annotations, which are expensive to obtain and inapplicable in\\npractice. This work addresses unconstrained fashion landmark detection, where\\nclothing bounding boxes are not provided in both training and test. To this\\nend, we present a novel Deep LAndmark Network (DLAN), where bounding boxes and\\nlandmarks are jointly estimated and trained iteratively in an end-to-end\\nmanner. DLAN contains two dedicated modules, including a Selective Dilated\\nConvolution for handling scale discrepancies, and a Hierarchical Recurrent\\nSpatial Transformer for handling background clutters. To evaluate DLAN, we\\npresent a large-scale fashion landmark dataset, namely Unconstrained Landmark\\nDatabase (ULD), consisting of 30K images. Statistics show that ULD is more\\nchallenging than existing datasets in terms of image scales, background\\nclutters, and human poses. Extensive experiments demonstrate the effectiveness\\nof DLAN over the state-of-the-art methods. DLAN also exhibits excellent\\ngeneralization across different clothing categories and modalities, making it\\nextremely suitable for real-world fashion analysis.\\n'\n",
      " '  Online health communities are a valuable source of information for patients\\nand physicians. However, such user-generated resources are often plagued by\\ninaccuracies and misinformation. In this work we propose a method for\\nautomatically establishing the credibility of user-generated medical statements\\nand the trustworthiness of their authors by exploiting linguistic cues and\\ndistant supervision from expert sources. To this end we introduce a\\nprobabilistic graphical model that jointly learns user trustworthiness,\\nstatement credibility, and language objectivity. We apply this methodology to\\nthe task of extracting rare or unknown side-effects of medical drugs --- this\\nbeing one of the problems where large scale non-expert data has the potential\\nto complement expert medical knowledge. We show that our method can reliably\\nextract side-effects and filter out false statements, while identifying\\ntrustworthy users that are likely to contribute valuable medical information.\\n'\n",
      " '  This work addresses the task of generating English sentences from Abstract\\nMeaning Representation (AMR) graphs. To cope with this task, we transform each\\ninput AMR graph into a structure similar to a dependency tree and annotate it\\nwith syntactic information by applying various predefined actions to it.\\nSubsequently, a sentence is obtained from this tree structure by visiting its\\nnodes in a specific order. We train maximum entropy models to estimate the\\nprobability of each individual action and devise an algorithm that efficiently\\napproximates the best sequence of actions to be applied. Using a substandard\\nlanguage model, our generator achieves a Bleu score of 27.4 on the LDC2014T12\\ntest set, the best result reported so far without using silver standard\\nannotations from another corpus as additional training data.\\n'\n",
      " '  Topology changes in multi-phase fluid flows are difficult to model within a\\ntraditional sharp interface theory. Diffuse interface models turn out to be an\\nattractive alternative to model two-phase flows. Based on a\\nCahn-Hilliard-Navier-Stokes model introduced by Abels, Garcke and Grün\\n(Math. Models Methods Appl. Sci. 2012), which uses a volume averaged velocity,\\nwe derive a diffuse interface model in a Hele-Shaw geometry, which in the case\\nof non-matched densities, simplifies an earlier model of Lee, Lowengrub and\\nGoodman (Phys. Fluids 2002). We recover the classical Hele-Shaw model as a\\nsharp interface limit of the diffuse interface model. Furthermore, we show the\\nexistence of weak solutions and present several numerical computations\\nincluding situations with rising bubbles and fingering instabilities.\\n'\n",
      " \"  Kennedy and O'Hagan (2001) propose a model for calibrating some unknown\\nparameters in a computer model and estimating the discrepancy between the\\ncomputer output and physical response. This model is known to have certain\\nidentifiability issues. Tuo and Wu (2016) show that there are examples for\\nwhich the Kennedy-O'Hagan method renders unreasonable results in calibration.\\nIn spite of its unstable performance in calibration, the Kennedy-O'Hagan\\napproach has a more robust behavior in predicting the physical response. In\\nthis work, we present some theoretical analysis to show the consistency of\\npredictor based on their calibration model in the context of radial basis\\nfunctions.\\n\"\n",
      " '  In frustrated magnetism, making a stringent connection between microscopic\\nspin models and macroscopic properties of spin liquids remains an important\\nchallenge. A recent step towards this goal has been the development of the\\npseudofermion functional renormalization group approach (pf-FRG) which,\\nbuilding on a fermionic parton construction, enables the numerical detection of\\nthe onset of spin liquid states as temperature is lowered. In this work,\\nfocusing on the SU(N) Heisenberg model at large N, we extend this approach in a\\nway that allows us to directly enter the low-temperature spin liquid phase, and\\nto probe its character. Our approach proceeds in momentum space, making it\\npossible to keep the truncation minimalistic, while also avoiding the bias\\nintroduced by an explicit decoupling of the fermionic parton interactions into\\na given channel. We benchmark our findings against exact mean-field results in\\nthe large-N limit, and show that even without prior knowledge the pf-FRG\\napproach identifies the correct mean-field decoupling channel. On a technical\\nlevel, we introduce an alternative finite temperature regularization scheme\\nthat is necessitated to access the spin liquid ordered phase. In a companion\\npaper arXiv:1711.02182 we present a different set of modifications of the\\npf-FRG scheme that allow us to study SU(N) Heisenberg models (using a\\nreal-space RG approach) for arbitrary values of N, albeit only up to the phase\\ntransition towards spin liquid physics.\\n'\n",
      " '  Quantum dissipation arises when a large system can be split in a quantum\\nsystem and an environment where the energy of the former flows to.\\nUnderstanding the effect of dissipation on quantum many-body systems is of\\nparticular importance due to its potential relations with quantum information\\nprocessing. We propose a conceptually simple approach to introduce the\\ndissipation into interacting quantum systems in a thermodynamical context, in\\nwhich every site of a 1d lattice is coupled off-diagonally to its own bath. The\\ninterplay between quantum dissipation and interactions gives rise to\\ncounterintuitive interpretations such as a compressible zero-temperature state\\nwith spontaneous discrete symmetry breaking and a thermal phase transition in a\\none-dimensional dissipative quantum many-body system as revealed by Quantum\\nMonte Carlo path integral simulations.\\n'\n",
      " '  We propose a novel adaptive approximation approach for test-time\\nresource-constrained prediction. Given an input instance at test-time, a gating\\nfunction identifies a prediction model for the input among a collection of\\nmodels. Our objective is to minimize overall average cost without sacrificing\\naccuracy. We learn gating and prediction models on fully labeled training data\\nby means of a bottom-up strategy. Our novel bottom-up method first trains a\\nhigh-accuracy complex model. Then a low-complexity gating and prediction model\\nare subsequently learned to adaptively approximate the high-accuracy model in\\nregions where low-cost models are capable of making highly accurate\\npredictions. We pose an empirical loss minimization problem with cost\\nconstraints to jointly train gating and prediction models. On a number of\\nbenchmark datasets our method outperforms state-of-the-art achieving higher\\naccuracy for the same cost.\\n'\n",
      " '  In this paper we study the problem of learning Rectified Linear Units (ReLUs)\\nwhich are functions of the form $max(0,<w,x>)$ with $w$ denoting the weight\\nvector. We study this problem in the high-dimensional regime where the number\\nof observations are fewer than the dimension of the weight vector. We assume\\nthat the weight vector belongs to some closed set (convex or nonconvex) which\\ncaptures known side-information about its structure. We focus on the realizable\\nmodel where the inputs are chosen i.i.d.~from a Gaussian distribution and the\\nlabels are generated according to a planted weight vector. We show that\\nprojected gradient descent, when initialization at 0, converges at a linear\\nrate to the planted model with a number of samples that is optimal up to\\nnumerical constants. Our results on the dynamics of convergence of these very\\nshallow neural nets may provide some insights towards understanding the\\ndynamics of deeper architectures.\\n'\n",
      " \"  Graph coloring is one of the central problems in distributed graph\\nalgorithms. Much of the research on this topic has focused on coloring with\\n$\\\\Delta+1$ colors, where $\\\\Delta$ denotes the maximum degree. Using $\\\\Delta+1$\\ncolors may be unsatisfactory in sparse graphs, where not all nodes have such a\\nhigh degree; it would be more desirable to use a number of colors that improves\\nwith sparsity. A standard measure that captures sparsity is arboricity, which\\nis the smallest number of forests into which the edges of the graph can be\\npartitioned.\\nWe present simple randomized distributed algorithms that, with high\\nprobability, color any $n$-node $\\\\alpha$-arboricity graph:\\n- using $(2+\\\\varepsilon)\\\\cdot \\\\alpha$ colors, for constant $\\\\varepsilon>0$,\\nin $O(\\\\log n)$ rounds, if $\\\\alpha=\\\\tilde{\\\\Omega}(\\\\log n)$, or\\n- using $O(\\\\alpha \\\\log \\\\alpha )$ colors, in $O(\\\\log n)$ rounds, or\\n- using $O(\\\\alpha)$ colors, in $O(\\\\log n \\\\cdot \\\\min\\\\{\\\\log\\\\log n,\\\\; \\\\log\\n\\\\alpha\\\\})$ rounds.\\nThese algorithms are nearly-optimal, as it is known by results of Linial\\n[FOCS'87] and Barenboim and Elkin [PODC'08] that coloring with $\\\\Theta(\\\\alpha)$\\ncolors, or even poly$(\\\\alpha)$ colors, requires $\\\\Omega(\\\\log_{\\\\alpha} n)$\\nrounds. The previously best-known $O(\\\\log n)$-time result was a deterministic\\nalgorithm due to Barenboim and Elkin [PODC'08], which uses $\\\\Theta(\\\\alpha ^2)$\\ncolors. Barenboim and Elkin stated improving this number of colors as an open\\nproblem in their Distributed Graph Coloring Book.\\n\"\n",
      " '  We consider the sampling of the coupled cluster expansion within stochastic\\ncoupled cluster theory. Observing the limitations of previous approaches due to\\nthe inherently non-linear behaviour of a coupled cluster wavefunction\\nrepresentation we propose new approaches based upon an intuitive, well-defined\\ncondition for sampling weights and on sampling the expansion in cluster\\noperators of different excitation levels. We term these modifications even and\\ntruncated selection respectively. Utilising both approaches demonstrates\\ndramatically improved calculation stability as well as reduced computational\\nand memory costs. These modifications are particularly effective at higher\\ntruncation levels owing to the large number of terms within the cluster\\nexpansion that can be neglected, as demonstrated by the reduction of the number\\nof terms to be sampled at the level of CCSDT by 77% and at CCSDTQ56 by 98%.\\n'\n",
      " '  Exposure assessment models are deterministic models derived from\\nphysical-chemical laws. In real workplace settings, chemical concentration\\nmeasurements can be noisy and indirectly measured. In addition, inference on\\nimportant parameters such as generation and ventilation rates are usually of\\ninterest since they are difficult to obtain. In this paper we outline a\\nflexible Bayesian framework for parameter inference and exposure prediction. In\\nparticular, we propose using Bayesian state space models by discretizing the\\ndifferential equation models and incorporating information from observed\\nmeasurements and expert prior knowledge. At each time point, a new measurement\\nis available that contains some noise, so using the physical model and the\\navailable measurements, we try to obtain a more accurate state estimate, which\\ncan be called filtering. We consider Monte Carlo sampling methods for parameter\\nestimation and inference under nonlinear and non-Gaussian assumptions. The\\nperformance of the different methods is studied on computer-simulated and\\ncontrolled laboratory-generated data. We consider some commonly used exposure\\nmodels representing different physical hypotheses.\\n'\n",
      " '  We prove that a relatively hyperbolic pair $(G,P)$ has Bowditch boundary a\\n2-sphere if and only if it is a 3-dimensional Poincare duality pair. We prove\\nthis by studying the relationship between the Bowditch and Dahmani boundaries\\nof relatively hyperbolic groups.\\n'\n",
      " '  We consider the task of analyzing message-passing programs by observing their\\nrun-time behavior.\\nWe introduce a purely library-based instrumentation method to trace\\ncommunication events during execution. A model of the dependencies among events\\ncan be constructed to identify potential bugs. Compared to the vector clock\\nmethod, our approach is much simpler and has in general a significant lower\\nrun-time overhead.\\nA further advantage is that we also trace events that could not commit. Thus,\\nwe can infer alternative communications. This provides the user with additional\\ninformation to identify potential bugs.\\nWe have fully implemented our approach in the Go programming language and\\nprovide a number of examples to substantiate our claims.\\n'\n",
      " '  This research uses Twitter, as a social media device, to track communications\\nrelated to the 2015 U.S. foodborne illness outbreak linked to Salmonella in\\nimported cucumbers from Mexico. The relevant Twitter data are analyzed in light\\nof the timeline of the official announcements made by the Centers for Disease\\nControl and Prevention (CDC). The largest number of registered tweets is\\nassociated with the period immediately following the CDC initial announcement\\nand the official release of the first recall of cucumbers.\\n'\n",
      " '  In this work we define log-linear models to compare several square\\ncontingency tables under the quasi-independence or the quasi-symmetry model,\\nand the relevant Markov bases are theoretically characterized. Through Markov\\nbases, an exact test to evaluate if two or more tables fit a common model is\\nintroduced. Two real-data examples illustrate the use of these models in\\ndifferent fields of applications.\\n'\n",
      " \"  We present two efficient algorithms that compute the optimal strategy for cop\\nin the game of Cop v.s. Gambler where the gambler's strategy is not optimal but\\nknown to the cop. The first algorithm is analogous to Bellman-Ford algorithm\\nfor single source shortest path problem and runs in $O(|V(G)||E(G)|)$ time. The\\nsecond is analogous to Dijkstra's algorithm and runs in $O(|E(G)|+|V(G)|\\\\log\\n|V(G)|)$ time. Compared with each other, they are more suitable for sparse and\\ndense graphs, respectively.\\n\"\n",
      " '  The aim of the paper is to investigate the solutions of special inhomogeneous\\nlinear functional equations by using spectral analysis in a translation\\ninvariant closed linear subspace of additive/multiadditive functions containing\\nthe restrictions of the solutions to finitely generated fields. The application\\nof spectral analysis in some related varieties is a new and important trend in\\nthe theory of functional equations; especially they have successful\\napplications in case of homogeneous linear functional equations. The foundation\\nof the theory can be found in M. Laczkovich and G. Kiss \\\\cite{KL}, see also G.\\nKiss and A. Varga \\\\cite{KV}. We are going to adopt the main theoretical tools\\nto solve some inhomogeneous problems due to T. Szostok \\\\cite{KKSZ08}, see also\\n\\\\cite{KKSZ} and \\\\cite{KKSZW}. They are motivated by quadrature rules of\\napproximate integration.\\n'\n",
      " '  We capitalize on large amounts of readily-available, synchronous data to\\nlearn a deep discriminative representations shared across three major natural\\nmodalities: vision, sound and language. By leveraging over a year of sound from\\nvideo and millions of sentences paired with images, we jointly train a deep\\nconvolutional network for aligned representation learning. Our experiments\\nsuggest that this representation is useful for several tasks, such as\\ncross-modal retrieval or transferring classifiers between modalities. Moreover,\\nalthough our network is only trained with image+text and image+sound pairs, it\\ncan transfer between text and sound as well, a transfer the network never\\nobserved during training. Visualizations of our representation reveal many\\nhidden units which automatically emerge to detect concepts, independent of the\\nmodality.\\n'\n",
      " '  We introduce the notion of \"seminar users\", who are social media users\\nengaged in propaganda in support of a political entity. We develop a framework\\nthat can identify such users with 84.4% precision and 76.1% recall. While our\\ndataset is from the Arab region, omitting language-specific features has only a\\nminor impact on classification performance, and thus, our approach could work\\nfor detecting seminar users in other parts of the world and in other languages.\\nWe further explored a controversial political topic to observe the prevalence\\nand potential potency of such users. In our case study, we found that 25% of\\nthe users engaged in the topic are in fact seminar users and their tweets make\\nnearly a third of the on-topic tweets. Moreover, they are often successful in\\naffecting mainstream discourse with coordinated hashtag campaigns.\\n'\n",
      " '  A system of Lorentz oscillators is considered to interpret of spectral lines\\nof hydrogen atoms. The dielectric permittivity of this system, which takes into\\naccount its electric polarization, is considered. The substance is examined in\\nthe gas state or in the form of small dust of matter. It is shown that the\\nconsidering of the electric polarization results in a redshift of spectral\\nlines of the substance and the appearance of dip of curve of spectrum. This dip\\ntakes place in the blue side with respect to the spectral position of the\\nalready shifted line. The magnitude of the red shift of spectral line and the\\nwidth of this dip in the spectrum depend strongly on the concentration of\\nhydrogen atoms that create this spectrum and on the spectral position of line\\nthat not shifted.\\n'\n",
      " '  This study aims to inspect and evaluate the integration of database queries\\nand their use in e-commerce product searches. It has been observed that\\ne-commerce is one of the most prominent trends, which have been emerged in the\\nbusiness world, for the past decade. E-commerce has gained tremendous\\npopularity, as it offers higher flexibility, cost efficiency, effectiveness,\\nand convenience, to both, consumers and businesses. Large number of retailing\\ncompanies has adopted this technology, in order to expand their operations,\\nacross of the globe; hence they needs to have highly responsive and integrated\\ndatabases. In this regard, the approach of database queries is found to be the\\nmost appropriate and adequate techniques, as it simplifies the searches of\\ne-commerce products.\\n'\n",
      " '  Informally, a chemical reaction network is \"atomic\" if each reaction may be\\ninterpreted as the rearrangement of indivisible units of matter. There are\\nseveral reasonable definitions formalizing this idea. We investigate the\\ncomputational complexity of deciding whether a given network is atomic\\naccording to each of these definitions.\\nOur first definition, primitive atomic, which requires each reaction to\\npreserve the total number of atoms, is to shown to be equivalent to mass\\nconservation. Since it is known that it can be decided in polynomial time\\nwhether a given chemical reaction network is mass-conserving, the equivalence\\ngives an efficient algorithm to decide primitive atomicity.\\nAnother definition, subset atomic, further requires that all atoms are\\nspecies. We show that deciding whether a given network is subset atomic is in\\n$\\\\textsf{NP}$, and the problem \"is a network subset atomic with respect to a\\ngiven atom set\" is strongly $\\\\textsf{NP}$-$\\\\textsf{Complete}$.\\nA third definition, reachably atomic, studied by Adleman, Gopalkrishnan et\\nal., further requires that each species has a sequence of reactions splitting\\nit into its constituent atoms. We show that there is a $\\\\textbf{polynomial-time\\nalgorithm}$ to decide whether a given network is reachably atomic, improving\\nupon the result of Adleman et al. that the problem is $\\\\textbf{decidable}$. We\\nshow that the reachability problem for reachably atomic networks is\\n$\\\\textsf{Pspace}$-$\\\\textsf{Complete}$.\\nFinally, we demonstrate equivalence relationships between our definitions and\\nsome special cases of another existing definition of atomicity due to Gnacadja.\\n'\n",
      " '  We investigate from first principles the field-like spin-orbit torques (SOTs)\\nin a Ag$_{2}$Bi-terminated Ag(111) film grown on ferromagnetic Fe(110). We find\\nthat a large part of the SOT arises from the spin-orbit interaction (SOI) in\\nthe Ag$_{2}$Bi layer far away from the Fe layers. These results clearly hint at\\na long range spin transfer in the direction perpendicular to the film that does\\nnot originate in the spin Hall effect. In order to bring evidence of the\\nnon-local character of the computed SOT, we show that the torque acting on the\\nFe layers can be engineered by the introduction of Bi vacancies in the\\nAg$_{2}$Bi layer. Overall, we find a drastic dependence of the SOT on the\\ndisorder type, which we explain by a complex interplay of different\\ncontributions to the SOT in the Brillouin zone.\\n'\n",
      " '  Inspired by Nature, molecular communications (MC), i.e., use of molecules to\\nencode, transmit and receive information, stands as the most promising\\ncommunication paradigm to realize nanonetworks. Even though there has been\\nextensive theoretical research towards nanoscale MC, there are no examples of\\nimplemented nanoscale MC networks. The main reason for this lies in the\\npeculiarities of nanoscale physics, challenges in nanoscale fabrication and\\nhighly stochastic nature of biochemical domain of envisioned nanonetwork\\napplications. This mandates developing novel device architectures and\\ncommunication methods compatible with MC constraints. To that end, various\\ntransmitter and receiver designs for MC have been proposed in literature\\ntogether with numerable modulation, coding and detection techniques. However,\\nthese works fall into domains of a very wide spectrum of disciplines, including\\nbut not limited to information and communication theory, quantum physics,\\nmaterials science, nanofabrication, physiology and synthetic biology.\\nTherefore, we believe it is imperative for the progress of the field that, an\\norganized exposition of cumulative knowledge on subject matter be compiled.\\nThus, to fill this gap, in this comprehensive survey we review the existing\\nliterature on transmitter and receiver architectures towards realizing MC\\namongst nanomaterial-based nanomachines and/or biological entities, and provide\\na complete overview of modulation, coding and detection techniques employed for\\nMC. Moreover, we identify the most significant shortcomings and challenges in\\nall these research areas, and propose potential solutions to overcome some of\\nthem.\\n'\n",
      " '  We introduce a new method to estimate the Markov equivalence class of a\\ndirected acyclic graph (DAG) in the presence of hidden variables, in settings\\nwhere the underlying DAG among the observed variables is sparse, and there are\\na few hidden variables that have a direct effect on many of the observed ones.\\nBuilding on the so-called low rank plus sparse framework, we suggest a\\ntwo-stage approach which first removes the effect of the hidden variables, and\\nthen estimates the Markov equivalence class of the underlying DAG under the\\nassumption that there are no remaining hidden variables. This approach is\\nconsistent in certain high-dimensional regimes and performs favourably when\\ncompared to the state of the art, both in terms of graphical structure recovery\\nand total causal effect estimation.\\n'\n",
      " '  We study the problem of determining whether a given temporal specification\\ncan be implemented by a symmetric system, i.e., a system composed from\\nidentical components. Symmetry is an important goal in the design of\\ndistributed systems, because systems that are composed from identical\\ncomponents are easier to build and maintain. We show that for the class of\\nrotation-symmetric architectures, i.e., multi-process architectures where all\\nprocesses have access to all system inputs, but see different rotations of the\\ninputs, the symmetric synthesis problem is EXPTIME-complete in the number of\\nprocesses. In architectures where the processes do not have access to all input\\nvariables, the symmetric synthesis problem becomes undecidable, even in cases\\nwhere the standard distributed synthesis problem is decidable.\\n'\n",
      " \"  The Mott insulator $\\\\beta'$-EtMe$_3$Sb[Pd(dmit)$_2$]$_2$ belongs to a class\\nof charge transfer solids with highly-frustrated triangular lattice of $S=1/2$\\nmolecular dimers and a quantum-spin-liquid ground state. Our experimental and\\nab initio theoretical studies show the fingerprints of strong correlations and\\ndisorder, important role of cation-dimer bonding in charge redistribution, no\\nsign of intra- and inter-dimer dipoles, and the decisive van der Waals\\ncontribution to inter-dimer interactions and the ground state structure. The\\nlatter consists of quasi-degenerate electronic states related to the different\\nconfigurations of cation moieties which permit two different equally probable\\norientations. Upon reducing the temperature, the low-energy excitations slow\\ndown, indicating glassy signatures as the cation motion freezes out.\\n\"\n",
      " \"  A representation is supposed universal if it encodes any element of the\\nvisual world (e.g., objects, scenes) in any configuration (e.g., scale,\\ncontext). While not expecting pure universal representations, the goal in the\\nliterature is to improve the universality level, starting from a representation\\nwith a certain level. To do so, the state-of-the-art consists in learning\\nCNN-based representations on a diversified training problem (e.g., ImageNet\\nmodified by adding annotated data). While it effectively increases\\nuniversality, such approach still requires a large amount of efforts to satisfy\\nthe needs in annotated data. In this work, we propose two methods to improve\\nuniversality, but pay special attention to limit the need of annotated data. We\\nalso propose a unified framework of the methods based on the diversifying of\\nthe training problem. Finally, to better match Atkinson's cognitive study about\\nuniversal human representations, we proposed to rely on the transfer-learning\\nscheme as well as a new metric to evaluate universality. This latter, aims us\\nto demonstrates the interest of our methods on 10 target-problems, relating to\\nthe classification task and a variety of visual domains.\\n\"\n",
      " \"  Modularity plays an important role in brain networks' architecture and\\ninfluences its dynamics and the ability to integrate and segregate different\\nmodules of cerebral regions. Alterations in community structure are associated\\nwith several clinical disorders, specially schizophrenia, although its time\\nevolution is not clear yet. In the present work, we analyze fMRI functional\\nnetworks of $65$ healthy subjects (HC) and $44$ patients of schizophrenia (SZ),\\n$28$ of them in a chronic state (CR) of illness, and $16$ at early stage (ES).\\nWe find clear differences in edges' weights distribution, networks density,\\ncommunity structure consistency and robustness against edge removal. In\\ncomparison to healthy subjects, we found that networks from SZ patients\\nexhibits wider weight distribution, larger overall connectivity, and are more\\nconsistent in the community structure across subjects. We also showed that the\\nnetworks of SZ patients tend to be more robust to edge removal than healthy\\nsubjects, while having lower network density. In the case of early stages\\npatients, we found that their networks exhibit topological features\\nconsistently in between the ones obtained from the other two groups, resulting\\nin a tendency towards the chronic group state.\\n\"\n",
      " '  Recurrent neural networks can be difficult to train on long sequence data due\\nto the well-known vanishing gradient problem. Some architectures incorporate\\nmethods to reduce RNN state updates, therefore allowing the network to preserve\\nmemory over long temporal intervals. To address these problems of convergence,\\nthis paper proposes a timing-gated LSTM RNN model, called the Gaussian-gated\\nLSTM (g-LSTM). The time gate controls when a neuron can be updated during\\ntraining, enabling longer memory persistence and better error-gradient flow.\\nThis model captures long-temporal dependencies better than an LSTM and the time\\ngate parameters can be learned even from non-optimal initialization values.\\nBecause the time gate limits the updates of the neuron state, the number of\\ncomputes needed for the network update is also reduced. By adding a\\ncomputational budget term to the training loss, we can obtain a network which\\nfurther reduces the number of computes by at least 10x. Finally, by employing a\\ntemporal curriculum learning schedule for the g-LSTM, we can reduce the\\nconvergence time of the equivalent LSTM network on long sequences.\\n'\n",
      " '  This paper is concerned with a set of novel coupling conditions for the\\n$3\\\\times 3$ one-dimensional Euler system with source terms at a junction of\\npipes with possibly different cross-sectional areas. Beside conservation of\\nmass, we require the equality of the total enthalpy at the junction and that\\nthe specific entropy for pipes with outgoing flow equals the convex combination\\nof all entropies that belong to pipes with incoming flow. Previously used\\ncoupling conditions include equality of pressure or dynamic pressure. They are\\nrestricted to the special case of a junction having only one pipe with outgoing\\nflow direction. Recently, Reigstad [SIAM J. Appl. Math., 75:679--702, 2015]\\nshowed that such pressure-based coupling conditions can produce non-physical\\nsolutions for isothermal flows through the production of mechanical energy. Our\\nnew coupling conditions ensure energy as well as entropy conservation and also\\napply to junctions connecting an arbitrary number of pipes with flexible flow\\ndirections. We prove the existence and uniqueness of solutions to the\\ngeneralised Riemann problem at a junction in the neighbourhood of constant\\nstationary states which belong to the subsonic region. This provides the basis\\nfor the well-posedness of the homogeneous and inhomogeneous Cauchy problems for\\ninitial data with sufficiently small total variation.\\n'\n",
      " '  We call a positive real number $\\\\lambda$ admissible if it belongs to the\\nLagrange spectrum and there exists an irrational number $\\\\alpha$ such that\\n$\\\\mu(\\\\alpha)=\\\\lambda$. Here $\\\\mu(\\\\alpha)$ denotes the Lagrange constant of\\n$\\\\alpha$ - maximal real number $c$ such that $\\\\forall \\\\varepsilon>0$ the\\ninequality $|\\\\alpha-\\\\frac{p}{q}|\\\\le\\\\frac{1}{(c-\\\\varepsilon)q^2}$ has infinitely\\nmany solutions for relatively prime $p$ and $q$. In this paper we establish a\\nnecessary and sufficient condition of admissibility of the Lagrange spectrum\\nelement and construct an infinite series of not admissible numbers.\\n'\n",
      " '  Knowledge of the topology of the electronic ground state of materials has led\\nto deep insights to novel phenomena such as the integer quantum Hall effect and\\nfermion-number fractionalization, as well as other properties of matter.\\nJoining two insulators of different topological classes produces fascinating\\nboundary states in the band gap. Another exciting recent development is the\\nbottom-up synthesis (from molecular precursors) of graphene nanoribbons (GNRs)\\nwith atomic precision control of their edge and width. Here we connect these\\ntwo fields, and show for the first time that semiconducting GNRs of different\\nwidth, edge, and end termination belong to different topological classes. The\\ntopology of GNRs is protected by spatial symmetries and dictated by the\\nterminating unit cell. We have derived explicit formula for their topological\\ninvariants, and show that localized junction states developed between two GNRs\\nof distinct topology may be tuned by lateral junction geometry. The topology of\\na GNR can be further modified by dopants, such as a periodic array of boron\\natoms. In a superlattice consisted of segments of doped and pristine GNRs, the\\njunction states are stable spin centers, forming a Heisenberg antiferromagnetic\\nspin 1/2 chain with tunable exchange interaction. The discoveries here are not\\nonly of scientific interest for studies of quasi one-dimensional systems, but\\nalso open a new path for design principles of future GNR-based devices through\\ntheir topological characters.\\n'\n",
      " '  We study reinforcement learning under model misspecification, where we do not\\nhave access to the true environment but only to a reasonably close\\napproximation to it. We address this problem by extending the framework of\\nrobust MDPs to the model-free Reinforcement Learning setting, where we do not\\nhave access to the model parameters, but can only sample states from it. We\\ndefine robust versions of Q-learning, SARSA, and TD-learning and prove\\nconvergence to an approximately optimal robust policy and approximate value\\nfunction respectively. We scale up the robust algorithms to large MDPs via\\nfunction approximation and prove convergence under two different settings. We\\nprove convergence of robust approximate policy iteration and robust approximate\\nvalue iteration for linear architectures (under mild assumptions). We also\\ndefine a robust loss function, the mean squared robust projected Bellman error\\nand give stochastic gradient descent algorithms that are guaranteed to converge\\nto a local minimum.\\n'\n",
      " '  Algorithms are increasingly common components of high-impact decision-making,\\nand a growing body of literature on adversarial examples in laboratory settings\\nindicates that standard machine learning models are not robust. This suggests\\nthat real-world systems are also susceptible to manipulation or\\nmisclassification, which especially poses a challenge to machine learning\\nmodels used in financial services. We use the loan grade classification problem\\nto explore how machine learning models are sensitive to small changes in\\nuser-reported data, using adversarial attacks documented in the literature and\\nan original, domain-specific attack. Our work shows that a robust optimization\\nalgorithm can build models for financial services that are resistant to\\nmisclassification on perturbations. To the best of our knowledge, this is the\\nfirst study of adversarial attacks and defenses for deep learning in financial\\nservices.\\n'\n",
      " '  Metal-organic frameworks (MOFs) are an attractive substrate for catalytic\\nreactions due to the high area density of reaction sites and the ability to\\ntailor an array of material attributes. This study focuses on a thermally\\nstable crystalline UiO-66(Zr) MOF structure and the modulation of the\\nelectronic structure using two strategies to improve the catalytic conversion\\nand selectivity of benzene alcohol to benzedehyate. Those two strategies\\ninclude the functionalization of the organic struts with branched ligands and\\nmanually creating structural defects with unsaturated organic linkers. A\\ncombination of computational and experimental results provide evidence of\\nimproved catalytic activity of MOFs via these two approaches. Functional groups\\nattached to the main organic strut modify the electronic environment of the\\nphotoactive aromatic carbon and thereby decrease the optical band gap by 1eV.\\nWhereas the introduction of structural defects due to the organic linker\\ndesaturation provided a shift in the HUMO as a result of the decrease in strut\\ncoordination with the inorganic knots.\\n'\n",
      " \"  Solving a large-scale system of linear equations is a key step at the heart\\nof many algorithms in machine learning, scientific computing, and beyond. When\\nthe problem dimension is large, computational and/or memory constraints make it\\ndesirable, or even necessary, to perform the task in a distributed fashion. In\\nthis paper, we consider a common scenario in which a taskmaster intends to\\nsolve a large-scale system of linear equations by distributing subsets of the\\nequations among a number of computing machines/cores. We propose an accelerated\\ndistributed consensus algorithm, in which at each iteration every machine\\nupdates its solution by adding a scaled version of the projection of an error\\nsignal onto the nullspace of its system of equations, and where the taskmaster\\nconducts an averaging over the solutions with momentum. The convergence\\nbehavior of the proposed algorithm is analyzed in detail and analytically shown\\nto compare favorably with the convergence rate of alternative distributed\\nmethods, namely distributed gradient descent, distributed versions of\\nNesterov's accelerated gradient descent and heavy-ball method, the block\\nCimmino method, and ADMM. On randomly chosen linear systems, as well as on\\nreal-world data sets, the proposed method offers significant speed-up relative\\nto all the aforementioned methods. Finally, our analysis suggests a novel\\nvariation of the distributed heavy-ball method, which employs a particular\\ndistributed preconditioning, and which achieves the same theoretical\\nconvergence rate as the proposed consensus-based method.\\n\"\n",
      " '  Cloud computing is steadily growing and, as IaaS vendors have started to\\noffer pay-as-you-go billing policies, it is fundamental to achieve as much\\nelasticity as possible, avoiding over-provisioning that would imply higher\\ncosts. In this paper, we briefly analyse the orchestration characteristics of\\nPaaSSOA, a proposed architecture already implemented for Jolie microservices,\\nand Kubernetes, one of the various orchestration plugins for Docker; then, we\\noutline similarities and differences of the two approaches, with respect to\\ntheir own domain of application. Furthermore, we investigate some ideas to\\nachieve a federation of the two technologies, proposing an architectural\\ncomposition of Jolie microservices on Docker Container-as-a-Service layer.\\n'\n",
      " '  In recent years, endomicroscopy has become increasingly used for diagnostic\\npurposes and interventional guidance. It can provide intraoperative aids for\\nreal-time tissue characterization and can help to perform visual investigations\\naimed for example to discover epithelial cancers. Due to physical constraints\\non the acquisition process, endomicroscopy images, still today have a low\\nnumber of informative pixels which hampers their quality. Post-processing\\ntechniques, such as Super-Resolution (SR), are a potential solution to increase\\nthe quality of these images. SR techniques are often supervised, requiring\\naligned pairs of low-resolution (LR) and high-resolution (HR) images patches to\\ntrain a model. However, in our domain, the lack of HR images hinders the\\ncollection of such pairs and makes supervised training unsuitable. For this\\nreason, we propose an unsupervised SR framework based on an adversarial deep\\nneural network with a physically-inspired cycle consistency, designed to impose\\nsome acquisition properties on the super-resolved images. Our framework can\\nexploit HR images, regardless of the domain where they are coming from, to\\ntransfer the quality of the HR images to the initial LR images. This property\\ncan be particularly useful in all situations where pairs of LR/HR are not\\navailable during the training. Our quantitative analysis, validated using a\\ndatabase of 238 endomicroscopy video sequences from 143 patients, shows the\\nability of the pipeline to produce convincing super-resolved images. A Mean\\nOpinion Score (MOS) study also confirms this quantitative image quality\\nassessment.\\n'\n",
      " '  This article proposes a universal simulation platform for simulating systems\\nundergoing duress. In other words, this paper introduces a total simulation\\npackage which includes a number of methods of simulating the flexibility of a\\ngiven system. This platform includes detailed procedures for simulating a\\nflexible link by a numerical method called finite difference method. In order\\nto verify the effectiveness of the proposed process, two examples are covered\\nin different situations to discuss the importance of boundary control and mesh\\nselection in the way of ensuring the stability of the system. In addition, a\\ngraphical user interface (GUI) application called the SimuFlex is designed\\nhaving a selection of methods that the user can choose along with the\\nparameters of the controllers that can be easily manipulated from the GUI.\\n'\n",
      " '  Let $G$ be a simple algebraic group over an algebraically closed field $K$ of\\ncharacteristic $p > 0$. We consider connected reductive subgroups $X$ of $G$\\nthat contain a given distinguished unipotent element $u$ of $G$. A result of\\nTesterman and Zalesski (Proc. Amer. Math. Soc., 2013) shows that if $u$ is a\\nregular unipotent element, then $X$ cannot be contained in a proper parabolic\\nsubgroup of $G$. We generalize their result and show that if $u$ has order $p$,\\nthen except for two known examples which occur in the case $(G, p) = (C_2, 2)$,\\nthe subgroup $X$ cannot be contained in a proper parabolic subgroup of $G$. In\\nthe case where $u$ has order $> p$, we also present further examples arising\\nfrom indecomposable tilting modules with quasi-minuscule highest weight.\\n'\n",
      " '  We consider the problem of reconstructing a rank-$k$ $n \\\\times n$ matrix $M$\\nfrom a sampling of its entries. Under a certain incoherence assumption on $M$\\nand for the case when both the rank and the condition number of $M$ are\\nbounded, it was shown in \\\\cite{CandesRecht2009, CandesTao2010, keshavan2010,\\nRecht2011, Jain2012, Hardt2014} that $M$ can be recovered exactly or\\napproximately (depending on some trade-off between accuracy and computational\\ncomplexity) using $O(n \\\\, \\\\text{poly}(\\\\log n))$ samples in super-linear time\\n$O(n^{a} \\\\, \\\\text{poly}(\\\\log n))$ for some constant $a \\\\geq 1$.\\nIn this paper, we propose a new matrix completion algorithm using a novel\\nsampling scheme based on a union of independent sparse random regular bipartite\\ngraphs. We show that under the same conditions w.h.p. our algorithm recovers an\\n$\\\\epsilon$-approximation of $M$ in terms of the Frobenius norm using $O(n\\n\\\\log^2(1/\\\\epsilon))$ samples and in linear time $O(n \\\\log^2(1/\\\\epsilon))$. This\\nprovides the best known bounds both on the sample complexity and computational\\ncomplexity for reconstructing (approximately) an unknown low-rank matrix.\\nThe novelty of our algorithm is two new steps of thresholding singular values\\nand rescaling singular vectors in the application of the \"vanilla\" alternating\\nminimization algorithm. The structure of sparse random regular graphs is used\\nheavily for controlling the impact of these regularization steps.\\n'\n",
      " '  This paper provides an existence-and-uniqueness theorem characterizing the\\nstochastic integral with respect to a Wiener process. The integral is\\nrepresented as a mapping from the space of measurable and adapted pathwise\\nlocally integrable processes to the space of continuous adapted processes. It\\nis characterized in terms of two properties: (1) how the stochastic integrals\\nof simple processes are calculated and (2) how these integrals converge in\\nprobability when the time integrals of the squared integrands converge in\\nprobability.\\n'\n",
      " '  We propose a probabilistic model for interpreting gene expression levels that\\nare observed through single-cell RNA sequencing. In the model, each cell has a\\nlow-dimensional latent representation. Additional latent variables account for\\ntechnical effects that may erroneously set some observations of gene expression\\nlevels to zero. Conditional distributions are specified by neural networks,\\ngiving the proposed model enough flexibility to fit the data well. We use\\nvariational inference and stochastic optimization to approximate the posterior\\ndistribution. The inference procedure scales to over one million cells, whereas\\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\\nproposed procedure outperforms state-of-the-art methods like ZIFA and\\nZINB-WaVE. We also extend our framework to account for batch effects and other\\nconfounding factors, and propose a Bayesian hypothesis test for differential\\nexpression that outperforms DESeq2.\\n'\n",
      " '  We prove a well-posedness result for stochastic Allen-Cahn type equations in\\na bounded domain coupled with generic boundary conditions. The (nonlinear) flux\\nat the boundary aims at describing the interactions with the hard walls and is\\nmotivated by some recent literature in physics. The singular character of the\\ndrift part allows for a large class of maximal monotone operators, generalizing\\nthe usual double-well potentials. One of the main novelties of the paper is the\\nabsence of any growth condition on the drift term of the evolution, neither on\\nthe domain nor on the boundary. A well-posedness result for variational\\nsolutions of the system is presented using a priori estimates as well as\\nmonotonicity and compactness techniques. A vanishing viscosity argument for the\\ndynamic on the boundary is also presented.\\n'\n",
      " '  To estimate the value functions of policies from exploratory data, most\\nmodel-free off-policy algorithms rely on importance sampling, where the use of\\nimportance sampling ratios often leads to estimates with severe variance. It is\\nthus desirable to learn off-policy without using the ratios. However, such an\\nalgorithm does not exist for multi-step learning with function approximation.\\nIn this paper, we introduce the first such algorithm based on\\ntemporal-difference (TD) learning updates. We show that an explicit use of\\nimportance sampling ratios can be eliminated by varying the amount of\\nbootstrapping in TD updates in an action-dependent manner. Our new algorithm\\nachieves stability using a two-timescale gradient-based TD update. A prior\\nalgorithm based on lookup table representation called Tree Backup can also be\\nretrieved using action-dependent bootstrapping, becoming a special case of our\\nalgorithm. In two challenging off-policy tasks, we demonstrate that our\\nalgorithm is stable, effectively avoids the large variance issue, and can\\nperform substantially better than its state-of-the-art counterpart.\\n'\n",
      " '  Matrix factorization was used to generate investment recommendations for\\ninvestors. An iterative conjugate gradient method was used to optimize the\\nregularized squared-error loss function. The number of latent factors, number\\nof iterations, and regularization values were explored. Overfitting can be\\naddressed by either early stopping or regularization parameter tuning. The\\nmodel achieved the highest average prediction accuracy of 13.3%. With a similar\\nmodel, the same dataset was used to generate investor recommendations for\\ncompanies undergoing fundraising, which achieved highest prediction accuracy of\\n11.1%.\\n'\n",
      " '  Ambient backscatter communication technology has been introduced recently,\\nand is then quickly becoming a promising choice for self-sustainable\\ncommunication systems as an external power supply or a dedicated carrier\\nemitter is not required. By leveraging existing RF signal resources, ambient\\nbackscatter technology can support sustainable and independent communications\\nand consequently open up a whole new set of applications that facilitate\\nInternet-of-Things (IoT). In this article, we study an integration of ambient\\nbackscatter with wireless powered communication networks (WPCNs). We first\\npresent an overview of backscatter communication systems with an emphasis on\\nthe emerging ambient backscatter technology. Then we propose a novel hybrid\\ntransmitter design by combining the advantages of both ambient backscatter and\\nwireless powered communications. Furthermore, in the cognitive radio\\nenvironment, we introduce a multiple access scheme to coordinate the hybrid\\ndata transmissions. The performance evaluation shows that the hybrid\\ntransmitter outperforms traditional designs. In addition, we discuss some open\\nissues related to the ambient backscatter networking.\\n'\n",
      " '  Content-centric mobile hybrid Internet-of-Things (IoT) networks consisting of\\nmobile devices and static femto access points (FAPs) are studied, where each\\ndevice moves according to the random walk mobility model and requests a content\\nobject from the library independently at random according to a Zipf popularity\\ndistribution. Instead of allowing access to content objects at macro base\\nstations via costly backhaul providing connection to the core network, we\\nconsider a more practical scenario where mobile devices and static FAPs, each\\nhaving a finite-size cache space, are able to cache a subset of content objects\\nso that each request is served by other mobile devices or static FAPs. Under a\\ngeneral multihop-based content delivery protocol, we analyze the order-optimal\\nthroughput--delay trade-off by presenting a new cache allocation strategy. In\\nparticular, under a given caching strategy, we first characterize a\\nthroughput--delay trade-off in terms of scaling laws along with the general\\ncontent delivery multihop routing protocol. Then, the order-optimal\\nthroughput--delay trade-off is characterized by presenting the order-optimal\\ncache allocation strategy, which jointly finds the replication sets at mobile\\ndevices and static FAPs via a novel variable decoupling approach. In our mobile\\nIoT network, an interesting observation is that highly popular content objects\\nare mainly served by mobile devices while the rest of content objects are\\nserved by static FAPs. We perform numerical evaluation to validate our\\nanalytical results. We also show that the order-optimal strategy strictly\\noutperforms a baseline approach, where the replication sets at mobile devices\\nand static FAPs are optimized separately.\\n'\n",
      " '  We consider the class of control systems where the differential equation,\\nstate and control system are described by polynomials. Given a set of\\ntrajectories and a class of Lagrangians, we are interested to find a Lagrangian\\nin this class for which these trajectories are optimal. To model this inverse\\nproblem we use a relaxed version of Hamilton-Jacobi-Bellman optimality\\nconditions, in the continuity of previous work in this vein. Then we provide a\\ngeneral numerical scheme based on polynomial optimization and positivity\\ncertificates, and illustrate the concepts on a few academic examples.\\n'\n",
      " \"  We use Beltrami's theorem as an excuse to present some arguments from\\nparabolic differential geometry without any of the parabolic machinery.\\n\"\n",
      " '  The theory of multidimensional Poisson vertex algebras (mPVAs) provides a\\ncompletely algebraic formalism to study the Hamiltonian structure of PDEs, for\\nany number of dependent and independent variables. In this paper, we compute\\nthe cohomology of the PVAs associated with two-dimensional, two-components\\nPoisson brackets of hydrodynamic type at the third differential degree. This\\nallows us to obtain their corresponding Poisson-Lichnerowicz cohomology, which\\nis the main building block of the theory of their deformations. Such a\\ncohomology is trivial neither in the second group, corresponding to the\\nexistence of a class of not equivalent infinitesimal deformation, nor in the\\nthird, corresponding to the obstruction to extend such deformations\\n'\n",
      " '  An innovative model is presented for merging of bubbles inside a liquid\\nmetal. The proposed model is based on forming a thin film (narrow channel)\\nbetween merging bubbles during growth. Rupturing of the film occurs when an\\noscillation in velocity and pressure arises inside the channel followed by\\nmerging of the bubbles. The proposed model based on lattice Boltzmann Method is\\ncapable of simulating merging bubbles in micro, meso, and macro-scales with no\\nlimitation on the number of bubbles. Experimental studies reveal a good\\nconsistency between modeling results and real conditions.\\n'\n",
      " '  Concept maps can be used to concisely represent important information and\\nbring structure into large document collections. Therefore, we study a variant\\nof multi-document summarization that produces summaries in the form of concept\\nmaps. However, suitable evaluation datasets for this task are currently\\nmissing. To close this gap, we present a newly created corpus of concept maps\\nthat summarize heterogeneous collections of web documents on educational\\ntopics. It was created using a novel crowdsourcing approach that allows us to\\nefficiently determine important elements in large document collections. We\\nrelease the corpus along with a baseline system and proposed evaluation\\nprotocol to enable further research on this variant of summarization.\\n'\n",
      " '  We provide a mathematical definition of a low energy scaling limit of a\\nsequence of general non-relativistic quantum theories in any dimension, and\\napply our formalism to anyonic chains. We formulate Conjecture 4.3 on\\nconditions when a chiral unitary rational (1+1)-conformal field theory would\\narise as such a limit and verify the conjecture for the Ising minimal model\\n$M(4,3)$ using Ising anyonic chains. Part of the conjecture is a precise\\nrelation between Temperley-Lieb generators $\\\\{e_i\\\\}$ and some finite stage\\noperators of the Virasoro generators $\\\\{L_m+L_{-m}\\\\}$ and $\\\\{i(L_m-L_{-m})\\\\}$\\nfor unitary minimal models $M(k+2,k+1)$ in Conjecture 5.5. A similar earlier\\nrelation is known as the Koo-Saleur formula in the physics literature [39].\\nAssuming Conjecture 4.3, most of our main results for the Ising minimal model\\n$M(4,3)$ hold for unitary minimal models $M(k+2,k+1), k\\\\geq 3$ as well. Our\\napproach is inspired by an eventual application to an efficient simulation of\\nconformal field theories by quantum computers, and supported by extensive\\nnumerical simulation and physical proofs in the physics literature.\\n'\n",
      " '  Image segmentation is a fundamental problem in biomedical image analysis.\\nRecent advances in deep learning have achieved promising results on many\\nbiomedical image segmentation benchmarks. However, due to large variations in\\nbiomedical images (different modalities, image settings, objects, noise, etc),\\nto utilize deep learning on a new application, it usually needs a new set of\\ntraining data. This can incur a great deal of annotation effort and cost,\\nbecause only biomedical experts can annotate effectively, and often there are\\ntoo many instances in images (e.g., cells) to annotate. In this paper, we aim\\nto address the following question: With limited effort (e.g., time) for\\nannotation, what instances should be annotated in order to attain the best\\nperformance? We present a deep active learning framework that combines fully\\nconvolutional network (FCN) and active learning to significantly reduce\\nannotation effort by making judicious suggestions on the most effective\\nannotation areas. We utilize uncertainty and similarity information provided by\\nFCN and formulate a generalized version of the maximum set cover problem to\\ndetermine the most representative and uncertain areas for annotation. Extensive\\nexperiments using the 2015 MICCAI Gland Challenge dataset and a lymph node\\nultrasound image segmentation dataset show that, using annotation suggestions\\nby our method, state-of-the-art segmentation performance can be achieved by\\nusing only 50% of training data.\\n'\n",
      " '  This paper introduce a software system including widely-used Swarm\\nIntelligence algorithms or approaches to be used for the related scientific\\nresearch studies associated with the subject area. The programmatic\\ninfrastructure of the system allows working on a fast, easy-to-use, interactive\\nplatform to perform Swarm Intelligence based studies in a more effective,\\nefficient and accurate way. In this sense, the system employs all of the\\nnecessary controls for the algorithms and it ensures an interactive platform on\\nwhich computer users can perform studies on a wide spectrum of solution\\napproaches associated with simple and also more advanced problems.\\n'\n",
      " '  This paper provides a full characterization of the value function and\\nsolution(s) of an optimal stopping problem for a one-dimensional diffusion with\\nan integral criterion. The results hold under very weak assumptions, namely,\\nthe diffusion is assumed to be a weak solution of stochastic differential\\nequation satisfying the Engelbert-Schmidt conditions, while the (stochastic)\\ndiscount rate and the integrand are required to satisfy only general\\nintegrability conditions.\\n'\n",
      " '  Recent detections of merging black holes allow observational tests of the\\nnature of these objects. In some proposed models, non-trivial structure at or\\nnear the black hole horizon could lead to echo signals in gravitational wave\\ndata. Recently, Abedi et al. claimed tentative evidence for repeating damped\\necho signals following the gravitational-wave signals of the binary black hole\\nmerger events recorded in the first observational period of the Advanced LIGO\\ninterferometers. We reanalyse the same data, addressing some of the\\nshortcomings of their method using more background data and a modified\\nprocedure. We find a reduced statistical significance for the claims of\\nevidence for echoes, calculating increased p-values for the null hypothesis of\\necho-free noise. The reduced significance is entirely consistent with noise,\\nand so we conclude that the analysis of Abedi et al. does not provide any\\nobservational evidence for the existence of Planck-scale structure at black\\nhole horizons.\\n'\n",
      " '  The universe is permeated by magnetic fields, with strengths ranging from a\\nfemtogauss in the voids between the filaments of galaxy clusters to several\\nteragauss in black holes and neutron stars. The standard model behind\\ncosmological magnetic fields is the nonlinear amplification of seed fields via\\nturbulent dynamo to the values observed. We have conceived experiments that aim\\nto demonstrate and study the turbulent dynamo mechanism in the laboratory. Here\\nwe describe the design of these experiments through simulation campaigns using\\nFLASH, a highly capable radiation magnetohydrodynamics code that we have\\ndeveloped, and large-scale three-dimensional simulations on the Mira\\nsupercomputer at Argonne National Laboratory. The simulation results indicate\\nthat the experimental platform may be capable of reaching a turbulent plasma\\nstate and study dynamo amplification. We validate and compare our numerical\\nresults with a small subset of experimental data using synthetic diagnostics.\\n'\n",
      " '  The chemotaxis system \\\\[ \\\\left\\\\{ \\\\begin{array}{l} u_t = \\\\Delta u - \\\\chi\\\\nabla\\n\\\\cdot (\\\\frac{u}{v}\\\\nabla v), v_t=\\\\Delta v - v+u, \\\\end{array} \\\\right. \\\\] is\\nconsidered in a bounded domain $\\\\Omega\\\\subset \\\\mathbb{R}^n$ with smooth\\nboundary, where $\\\\chi>0$. An apparently novel type of generalized solution\\nframework is introduced within which an extension of previously known ranges\\nfor the key parameter $\\\\chi$ with regard to global solvability is achieved. In\\nparticular, it is shown that under the hypothesis that\\\\[ \\\\chi < \\\\left\\\\{\\n\\\\begin{array}{ll} \\\\infty \\\\qquad & \\\\mbox{if } n=2, \\\\sqrt{8} \\\\qquad & \\\\mbox{if }\\nn=3, \\\\frac{n}{n-2} \\\\qquad & \\\\mbox{if } n\\\\ge 4, \\\\end{array} \\\\right. \\\\] for all\\ninitial data satisfying suitable assumptions on regularity and positivity, an\\nassociated no-flux initial-boundary value problem admits a globally defined\\ngeneralized solution. This solution inter alia has the property that \\\\[ u\\\\in\\nL^1_{loc}(\\\\bar\\\\Omega\\\\times [0,\\\\infty)). \\\\]\\n'\n",
      " '  Exploration of an unknown environment by a mobile robot is a complex task\\ninvolving solution of many fundamental problems from data processing,\\nlocalization to high-level planning and decision making. The exploration\\nframework we developed is based on processing of RGBD data provided by a MS\\nKinect2 sensor, which allows to take advantage of state-of-the-art SLAM\\n(Simultaneous Localization and Mapping) algorithms and to autonomously build a\\nrealistic 3D map of the environment with projected visual information about the\\nscene. In this paper, we describe practical issues that appeared during\\ndeployment of the framework in real indoor and outdoor environments and discuss\\nespecially properties of SLAM algorithms processing MS Kinect2 data on an\\nembedded computer.\\n'\n",
      " '  Humans have rich understanding of liquid containers and their contents; for\\nexample, we can effortlessly pour water from a pitcher to a cup. Doing so\\nrequires estimating the volume of the cup, approximating the amount of water in\\nthe pitcher, and predicting the behavior of water when we tilt the pitcher.\\nVery little attention in computer vision has been made to liquids and their\\ncontainers. In this paper, we study liquid containers and their contents, and\\npropose methods to estimate the volume of containers, approximate the amount of\\nliquid in them, and perform comparative volume estimations all from a single\\nRGB image. Furthermore, we show the results of the proposed model for\\npredicting the behavior of liquids inside containers when one tilts the\\ncontainers. We also introduce a new dataset of Containers Of liQuid contEnt\\n(COQE) that contains more than 5,000 images of 10,000 liquid containers in\\ncontext labelled with volume, amount of content, bounding box annotation, and\\ncorresponding similar 3D CAD models.\\n'\n",
      " \"  A theoretical study of ionization of the hydrogen atom due to an XUV pulse in\\nthe presence of an IR laser is presented. Well-established theories are usually\\nused to describe the problem of laser assisted photoelectron effect. However,\\nthe well-known soft-photon approximation firstly posed by Maquet et al in\\nJournal of Modern Optics 54, 1847 (2007) and Kazansky's theory in Phys. Rev. A\\n82, 033420 (2010) completely fails to predict the electron emission\\nprependicularly to the polarization direction. Making use of a simple\\nsemiclassical model, we study the angle-resolved energy distribution of\\nphotoelectrons for the case that both fields are linearly polarized in the same\\ndirection. We thoroughly analize and characterize two different emission\\nregions in the angle-energy domain: (i) the parallel-like region with\\ncontribution of two classical trajectories per optical cycle and (ii) the\\nperpendicular-like region with contribution of four classical trajectories per\\noptical cycle. We show that our semiclassical model is able to asses the\\ninterference patterns of the angle-resolved photoelectron spectrum in the two\\ndifferent mentioned regions. Electron trajectories stemming from different\\noptical laser cycles give rise to angle-independent intercycle interference\\nknown as sidebands. These sidebands are modulated by an angle-dependent\\ncoarse-grained structure coming from the intracycle interference of the\\nelectron trajectories born during the same optical cycle. We show the accuracy\\nof our semiclassical model as a function of the time delay between the IR and\\nthe XUV pulses and also as a function of the laser intensity by comparing the\\nsemiclassical predictions of the angle-resolved photoelectron spectrum with the\\ncontinuum-distorted wave strong field approximation and the ab initio solution\\nof the time dependent Schrödinger equation.\\n\"\n",
      " '  We present an image-based method for comparing the structural properties of\\ngalaxies produced in hydrodynamical simulations to real galaxies in the Sloan\\nDigital Sky Survey. The key feature of our work is the introduction of\\nextensive observational realism, such as object crowding, noise and viewing\\nangle, to the synthetic images of simulated galaxies, so that they can be\\nfairly compared to real galaxy catalogs. We apply our methodology to the\\ndust-free synthetic image catalog of galaxies from the Illustris simulation at\\n$z=0$, which are then fit with bulge+disc models to obtain morphological\\nparameters. In this first paper in a series, we detail our methods, quantify\\nobservational biases, and present publicly available bulge+disc decomposition\\ncatalogs. We find that our bulge+disc decompositions are largely robust to the\\nobservational biases that affect decompositions of real galaxies. However, we\\nidentify a significant population of galaxies (roughly 30\\\\% of the full sample)\\nin Illustris that are prone to internal segmentation, leading to systematically\\nreduced flux estimates by up to a factor of 6, smaller half-light radii by up\\nto a factor of $\\\\sim$ 2, and generally erroneous bulge-to-total fractions of\\n(B/T)=0.\\n'\n",
      " '  We determine the irreducible components of the space of 3x3 matrices of\\nlinear forms with vanishing determinant. We show that there are four\\nirreducible components and we identify them concretely. In particular, under\\nelementary row and column operations with constant coefficients, a 3x3 matrix\\nwith vanishing determinant is equivalent to one of the following four: a matrix\\nwith a zero row, a zero column, a zero 2x2 square or an antisymmetric matrix.\\n'\n",
      " '  Deep reinforcement learning (DRL) has gained a lot of attention in recent\\nyears, and has been proven to be able to play Atari games and Go at or above\\nhuman levels. However, those games are assumed to have a small fixed number of\\nactions and could be trained with a simple CNN network. In this paper, we study\\na special class of Asian popular card games called Dou Di Zhu, in which two\\nadversarial groups of agents must consider numerous card combinations at each\\ntime step, leading to huge number of actions. We propose a novel method to\\nhandle combinatorial actions, which we call combinational Q-learning (CQL). We\\nemploy a two-stage network to reduce action space and also leverage\\norder-invariant max-pooling operations to extract relationships between\\nprimitive actions. Results show that our method prevails over state-of-the art\\nmethods like naive Q-learning and A3C. We develop an easy-to-use card game\\nenvironments and train all agents adversarially from sractch, with only\\nknowledge of game rules and verify that our agents are comparative to humans.\\nOur code to reproduce all reported results will be available online.\\n'\n",
      " \"  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\\nin deep learning. Specifically, cuDNN implements several equivalent convolution\\nalgorithms, whose performance and memory footprint may vary considerably,\\ndepending on the layer dimensions. When an algorithm is automatically selected\\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\\nresorts to slower algorithms that fit the workspace size constraints. We\\npresent {\\\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\\nProgramming and Integer Linear Programming, {\\\\mu}-cuDNN enables faster\\nalgorithms by decreasing the workspace requirements. At the same time,\\n{\\\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\\neffectiveness of {\\\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\\nGPU. These results indicate that using micro-batches can seamlessly increase\\nthe performance of deep learning, while maintaining the same memory footprint.\\n\"\n",
      " '  In this paper, we endeavour to show that from the noncommutative nature of\\nspacetime one can deduce the concept of relativity in the sense that the\\nvelocity cannot be infinite as in the case of Galilean relativity.\\n'\n",
      " '  We demonstrate a simple projective measurement based on the quantum eraser\\nconcept that can be used to characterize the disturbances of any communication\\nchannel. Quantum erasers are commonly implemented as spatially separated path\\ninterferometric schemes. Here we exploit the advantages of redefining the\\nwhich-path information in terms of spatial modes, replacing physical paths with\\nabstract paths of orbital angular momentum (OAM). Remarkably, vector modes\\n(natural modes of free-space and fiber) have a non-separable feature of\\nspin-orbit coupled states, equivalent to the description of two independently\\nmarked paths. We explore the effects of fiber perturbations by probing a\\nstep-index optical fiber channel with a vector mode, relevant to high-order\\nspatial mode encoding of information for ultra-fast fiber communications.\\n'\n",
      " '  In this paper we consider Anderson model with a large number of sites with\\nzero interaction. For such models we study the spectral statistics in the\\nregion of complete localization. We show that Poisson statistics holds for such\\nenergies, by proving the Minami estimate.\\n'\n",
      " '  We study the slowing down of particle beams passing through the dusty plasma\\nwith power-law kappa-distributions. Three plasma components, electrons, ions\\nand dust particles, can have different kappa-parameter. We derive the\\ndeceleration factor (the velocity moment equation) and the slowing down time of\\na test particle, and numerically study the slowing down properties of an\\nelectron beam, a proton beam and a dust particle beam, respectively, in the\\nkappa-distributed dusty plasma. We show that the slowing down properties of\\nparticle beams depend strongly on the kappa-parameters of the plasma\\ncomponents, and the dust component plays a dominant role in the slowing down.\\nAnd the slowing down also depends on mass and charge of the dust particles in\\nthe dusty plasma. More detailed results are shown in 17 numerical graphs.\\n'\n",
      " '  We explore a natural analogy between Bayesian statistics and thermal physics\\nin which sample size corresponds to inverse temperature. This analogy motivates\\nthe definition of two novel statistical quantities: a learning capacity and a\\nGibbs entropy. The analysis of the learning capacity, corresponding to the heat\\ncapacity in thermal physics, leads to a critical insight into why some models\\nhave anomalously good learning performance. The mechanism is a statistical\\nanalogue of the failure of the equipartition theorem formula for the heat\\ncapacity. We explore the properties of the learning capacity in a number of\\nexamples, including a sloppy model. We also propose that the Gibbs entropy\\nprovides a natural device for counting distinguishable distributions in the\\ncontext of Bayesian inference. This insight results in a new solution to a\\nlong-standing problem in Bayesian inference: the definition of an objective or\\nuninformative prior. We use the Gibbs entropy to define a generalized principle\\nof indifference (GPI) in which every distinguishable model is assigned equal a\\npriori probability. This approach both resolves a number of long standing\\ninconsistencies in objective Bayesian inference and unifies several seemingly\\nunrelated Bayesian methods with the information-based paradigm of inference.\\n'\n",
      " '  The majority of medical documents and electronic health records (EHRs) are in\\ntext format that poses a challenge for data processing and finding relevant\\ndocuments. Looking for ways to automatically retrieve the enormous amount of\\nhealth and medical knowledge has always been an intriguing topic. Powerful\\nmethods have been developed in recent years to make the text processing\\nautomatic. One of the popular approaches to retrieve information based on\\ndiscovering the themes in health & medical corpora is topic modeling, however,\\nthis approach still needs new perspectives. In this research we describe fuzzy\\nlatent semantic analysis (FLSA), a novel approach in topic modeling using fuzzy\\nperspective. FLSA can handle health & medical corpora redundancy issue and\\nprovides a new method to estimate the number of topics. The quantitative\\nevaluations show that FLSA produces superior performance and features to latent\\nDirichlet allocation (LDA), the most popular topic model.\\n'\n",
      " \"  Stakeholders in the science system need to decide where to place their bets.\\nExample questions include: Which areas of research should get more funding? Who\\nshould we hire? Which projects should we abandon and which new projects should\\nwe start? Making informed choices requires knowledge about these research\\noptions. Unfortunately, to date research portfolio options have not been\\ndefined in a consistent, transparent and relevant manner. Furthermore, we don't\\nknow how to define demand for these options. In this article, we address the\\nissues of consistency, transparency, relevance and demand by using a model of\\nscience consisting of 91,726 topics (or research options) that contain over 58\\nmillion documents. We present a new indicator of topic prominence - a measure\\nof visibility, momentum and, ultimately, demand. We assign over $203 billion of\\nproject-level funding data from STAR METRICS to individual topics in science,\\nand show that the indicator of topic prominence, explains over one-third of the\\nvariance in current (or future) funding by topic. We also show that highly\\nprominent topics receive far more funding per researcher than topics that are\\nnot prominent. Implications of these results for research planning and\\nportfolio analysis by institutions and researchers are emphasized.\\n\"\n",
      " '  Sufficient and necessary conditions for the stability of positive feedback\\ninterconnections of negative imaginary systems are derived via an integral\\nquadratic constraint (IQC) approach. The IQC framework accommodates\\ndistributed-parameter systems with irrational transfer function\\nrepresentations, while generalising existing results in the literature and\\nallowing exploitation of flexibility at zero and infinite frequencies to reduce\\nconservatism in the analysis. The main results manifest the important property\\nthat the negative imaginariness of systems gives rise to a certain form of IQCs\\non positive frequencies that are bounded away from zero and infinity. Two\\nadditional sets of IQCs on the DC and instantaneous gains of the systems are\\nshown to be sufficient and necessary for closed-loop stability along a homotopy\\nof systems.\\n'\n",
      " '  In the modern era where highly-commodified cultural products compete heavily\\nfor mass consumption, finding the principles behind the complex process of how\\nsuccessful, \"hit\" products emerge remains a vital scientific goal that requires\\nan interdisciplinary approach. Here we present a framework for tracing the\\ncycle of prosperity-and-decline of a product to find insights into influential\\nand potent factors that determine its success. As a rapid, high-throughput\\nindicator of the preference of the public, popularity charts have emerged as a\\nuseful information source for finding the market performance patterns of\\nproducts over time, which we call the on-chart life trajectories that show how\\nthe products enter the chart, fare inside it, and eventually exit from it. We\\npropose quantitative parameters to characterise a life trajectory, and analyse\\na large-scale data set of nearly $7\\\\,000$ songs from Gaon Chart, a major weekly\\nKorean Pop (K-Pop) chart that cover a span of six years. We find that a\\nsignificant role is played by non-musical extrinsic factors such as the\\nestablished fan base of the artist and the might of production companies in the\\non-chart success of songs, strongly indicative of the commodified nature of\\nmodern cultural products. We also review a possible mathematical model of this\\nphenomenon, and discuss several nontrivial yet intriguing trajectories that we\\ncall the \"Late Bloomers\" and the \"Re-entrants\" that appears to be strongly\\ndriven by serendipitous exposure on mass media and the changes of seasons.\\n'\n",
      " '  The existence of several 2D materials with heavy atoms in their composition\\nhas been recently demonstrated. The electronic and optical properties of these\\nmaterials can be accurately computed with numerically intensive density\\nfunctional theory methods. However, it is desirable to have simple effective\\nmodels that can accurately describe these properties at low energies. Here we\\npresent an effective model for stanene that is reliable for electronic and\\noptical properties for photon energies up to 1.1 eV. For this material, we find\\nthat a quadratic model with respect to the lattice momentum is the best suited\\nfor calculations based on the bandstructure, even with respect to band warping.\\nWe also find that splitting the two spin-z subsectors is a good approximation,\\nwhich indicates that the lattice buckling can be neglected in calculations\\nbased on the bandstructure. We illustrate the applicability of the model by\\ncomputing the linear optical injection rates of carrier and spin densities in\\nstanene. Our calculations indicate that an incident circularly polarized\\noptical field only excites electrons with spin that matches its helicity.\\n'\n",
      " '  We prove that it is decidable whether or not a finitely generated submonoid\\nof a virtually free group is graded, introduce a new geometric characterization\\nas quasi-geodesic monoids, and show that their word problem is rational (as a\\nrelation). We also solve the isomorphism problem for this class of monoids,\\ngeneralizing earlier results for submonoids of free monoids. We also prove that\\nthe classes of graded monoids, regular monoids and Kleene monoids coincide for\\nsubmonoids of free groups.\\n'\n",
      " '  In this paper, we prove the existence of certain lifts of Hilbert cusp forms\\nto general odd spin groups. We then use those lifts to provide evidence for a\\nconjecture of Gross on the modularity of abelian varieties not of ${\\\\rm\\nGL}_2$-type.\\n'\n",
      " '  Recurrent Neural Networks (RNN) are widely used to solve a variety of\\nproblems and as the quantity of data and the amount of available compute have\\nincreased, so have model sizes. The number of parameters in recent\\nstate-of-the-art networks makes them hard to deploy, especially on mobile\\nphones and embedded devices. The challenge is due to both the size of the model\\nand the time it takes to evaluate it. In order to deploy these RNNs\\nefficiently, we propose a technique to reduce the parameters of a network by\\npruning weights during the initial training of the network. At the end of\\ntraining, the parameters of the network are sparse while accuracy is still\\nclose to the original dense neural network. The network size is reduced by 8x\\nand the time required to train the model remains constant. Additionally, we can\\nprune a larger dense network to achieve better than baseline performance while\\nstill reducing the total number of parameters significantly. Pruning RNNs\\nreduces the size of the model and can also help achieve significant inference\\ntime speed-up using sparse matrix multiply. Benchmarks show that using our\\ntechnique model size can be reduced by 90% and speed-up is around 2x to 7x.\\n'\n",
      " '  We introduce a novel method of quantum emulation of a classical reversible\\ncellular automaton. By applying this method to a chaotic cellular automaton,\\nthe obtained quantum many-body system thermalizes while all the energy\\neigenstates and eigenvalues are solvable. These explicit solutions allow us to\\nverify the validity of some scenarios of thermalization to this system. We find\\nthat two leading scenarios, the eigenstate thermalization hypothesis scenario\\nand the large effective dimension scenario, do not explain thermalization in\\nthis model.\\n'\n",
      " '  Recently, Dil and Boyadzhiev \\\\cite{AD2015} proved an explicit formula for the\\nsum of multiple harmonic numbers whose indices are the sequence $\\\\left(\\n{{\\\\left\\\\{ 0 \\\\right\\\\}_r},1} \\\\right)$. In this paper we show that the sums of\\nmultiple harmonic numbers whose indices are the sequence $\\\\left( {{\\\\left\\\\{ 0\\n\\\\right\\\\}_r,1};{\\\\left\\\\{ 1 \\\\right\\\\}_{k-1}}} \\\\right)$ can be expressed in terms\\nof (multiple) zeta values, multiple harmonic numbers and Stirling numbers of\\nthe first kind, and give an explicit formula.\\n'\n",
      " '  We ascertain the modularity-like objective function whose optimization is\\nequivalent to the maximum likelihood in annotated networks. We demonstrate that\\nthe modularity-like objective function is a linear combination of modularity\\nand conditional entropy. In contrast with statistical inference methods, in our\\nmethod, the influence of the metadata is adjustable; when its influence is\\nstrong enough, the metadata can be recovered. Conversely, when it is weak, the\\ndetection may correspond to another partition. Between the two, there is a\\ntransition. This paper provides a concept for expanding the scope of modularity\\nmethods.\\n'\n",
      " '  We give an efficient algorithm to enumerate all sets of $r\\\\ge 1$ quadratic\\npolynomials over a finite field, which remain irreducible under iterations and\\ncompositions.\\n'\n",
      " '  Mn doping of group-IV semiconductors (Si/Ge) is achieved by embedding a thin\\nMn-film as a {\\\\delta}-doped layer in group-IV matrix. The Mn-layer consists of\\na dense layer of monoatomic Mn-wires, which are oriented perpendicular to the\\nSi(001)-(2x1) dimer rows, or Mn-clusters. The nanostructures are covered with\\nan amorphous Si or Ge capping layer, which conserves the identity of the\\n{\\\\delta}-doped layer. The analysis of the bonding environment with STM is\\ncombined with the element-specific detection of the magnetic signature with\\nX-ray magnetic circular dichroism. The largest moment (2.5 {\\\\mu}B/Mn) is\\nmeasured for Mn-wires, which have ionic bonding character, with an a-Ge\\noverlayer cap, a-Si capping leads to a slightly reduced moment which has its\\norigin in subtle variation of bonding geometry. Our results directly confirm\\ntheoretical predictions on magnetism for Mn-adatoms on Si(001). The moment is\\nquenched to 0.5{\\\\mu}B/Mn for {\\\\delta}-doped layers, which are dominated by\\nclusters, and thus develop an antiferromagnetic component from Mn-Mn bonding.\\n'\n",
      " '  Pain remains a major concern in patients suffering from metastatic cancer to\\nthe bone and more knowledge of the condition, as well as novel treatment\\navenues, are called for. Neuropeptide Y (NPY) is a highly conserved peptide\\nthat appears to play a central role in nociceptive signaling in inflammatory\\nand neuropathic pain. However, little is known about the peptide in\\ncancer-induced bone pain. Here, we evaluate the role of spinal NPY in the\\nMRMT-1 rat model of cancer-induced bone pain. Our studies revealed an\\nup-regulation of NPY-immunoreactivity in the dorsal horn of cancer-bearing rats\\n17 days after inoculation, which could be a compensatory antinociceptive\\nresponse. Consistent with this interpretation, intrathecal administration of\\nNPY to rats with cancer-induced bone pain caused a reduction in nociceptive\\nbehaviors that lasted up to 150 min. This effect was diminished by both Y1\\n(BIBO3304) and Y2 (BIIE0246) receptor antagonists, indicating that both\\nreceptors participate in mediating the antinociceptive effect of NPY. Y1 and Y2\\nreceptor binding in the spinal cord was unchanged in the cancer state as\\ncompared to sham-operated rats, consistent with the notion that increased NPY\\nresults in a net antinociceptive effect in the MRMT-1 model. In conclusion, the\\ndata indicate that NPY is involved in the spinal nociceptive signaling of\\ncancer-induced bone pain and could be a new therapeutic target for patients\\nwith this condition.\\n'\n",
      " '  The mineral linarite, PbCuSO$_4$(OH)$_2$, is a spin 1/2 chain with\\nfrustrating nearest neighbor ferromagnetic and next-nearest neighbor\\nantiferromagnetic exchange interactions. Our inelastic neutron scattering\\nexperiments performed above the saturation field establish that the ratio\\nbetween these exchanges is such that linarite is extremely close to the quantum\\ncritical point between spin-multipolar phases and the ferromagnetic state.\\nHowever, the measured complex magnetic phase diagram depends strongly on the\\nmagnetic field direction. The field-dependent phase sequence is explained by\\nour classical simulations of a nearly critical model with tiny orthorhombic\\nexchange anisotropy. The simulations also capture qualitatively the measured\\nvariations of the wave vector as well as the staggered and the uniform\\nmagnetizations in an applied field.\\n'\n",
      " '  We extend the idea of tempering stable Levy processes to tempering more\\ngeneral classes of Levy processes. We show that the original process can be\\ndecomposed into the sum of the tempered process and an independent point\\nprocess of large jumps. We then use this to set up a rejection sampling\\nalgorithm for sampling from the tempered process. A small scale simulation\\nstudy is given to help understand the performance of this algorithm.\\n'\n",
      " '  A collection of articles on the statistical modelling and inference of social\\nnetworks is analysed in a network fashion. The references of these articles are\\nused to construct a citation network data set, which is almost a directed\\nacyclic graph because only existing articles can be cited. A mixed membership\\nstochastic block model is then applied to this data set to soft cluster the\\narticles. The results obtained from a Gibbs sampler give us insights into the\\ninfluence and the categorisation of these articles.\\n'\n",
      " '  We employ the very large cosmological hydrodynamical simulation BLUETIDES to\\ninvestigate the predicted properties of the galaxy population during the epoch\\nof reionisation ($z>8$). BLUETIDES has a resolution and volume ($(400/h\\\\approx\\n577)^{3}\\\\,{\\\\rm cMpc^3}$) providing a population of galaxies which is well\\nmatched to depth and area of current observational surveys targeting the\\nhigh-redshift Universe. At $z=8$ BLUETIDES includes almost 160,000 galaxies\\nwith stellar masses $>10^{8}\\\\,{\\\\rm M_{\\\\odot}}$. The population of galaxies\\npredicted by BLUETIDES closely matches observational constraints on both the\\ngalaxy stellar mass function and far-UV ($150\\\\,{\\\\rm nm}$) luminosity function.\\nGalaxies in BLUETIDES are characterised by rapidly increasing star formation\\nhistories. Specific star formation rates decrease with redshift though remain\\nlargely insensitive to stellar mass. As a result of the enhanced surface\\ndensity of metals more massive galaxies are predicted to have higher dust\\nattenuation resulting in a significant steepening of the observed far-UV\\nluminosity function at high luminosities. The contribution of active SMBHs to\\nthe UV luminosities of galaxies with stellar masses $10^{9-10}\\\\,{\\\\rm\\nM_{\\\\odot}}$ is around $3\\\\%$ on average. Approximately $25\\\\%$ of galaxies with\\n$M_{*}\\\\approx 10^{10}\\\\,{\\\\rm M_{\\\\odot}}$ are predicted to have active SMBH which\\ncontribute $>10\\\\%$ of the total UV luminosity.\\n'\n",
      " '  Empirical copula functions can be used to model the dependence structure of\\nmultivariate data. The Greenwald and Khanna algorithm is adapted in order to\\nprovide a space-memory efficient approximation to the empirical copula function\\nof a bivariate stream of data. A succinct space-memory efficient summary of\\nvalues seen in the stream up to a certain time is maintained and can be queried\\nat any point to return an approximation to the empirical bivariate copula\\nfunction with guaranteed error bounds. An example then illustrates how these\\nsummaries can be used as a tool to compute approximations to higher dimensional\\ncopula decompositions containing bivariate copulas. The computational benefits\\nand approximation error of the algorithm is theoretically and numerically\\nassessed.\\n'\n",
      " '  We give a simple, fast algorithm for hyperparameter optimization inspired by\\ntechniques from the analysis of Boolean functions. We focus on the\\nhigh-dimensional regime where the canonical example is training a neural\\nnetwork with a large number of hyperparameters. The algorithm --- an iterative\\napplication of compressed sensing techniques for orthogonal polynomials ---\\nrequires only uniform sampling of the hyperparameters and is thus easily\\nparallelizable.\\nExperiments for training deep neural networks on Cifar-10 show that compared\\nto state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds\\nsignificantly improved solutions, in some cases better than what is attainable\\nby hand-tuning. In terms of overall running time (i.e., time required to sample\\nvarious settings of hyperparameters plus additional computation time), we are\\nat least an order of magnitude faster than Hyperband and Bayesian Optimization.\\nWe also outperform Random Search 8x.\\nAdditionally, our method comes with provable guarantees and yields the first\\nimprovements on the sample complexity of learning decision trees in over two\\ndecades. In particular, we obtain the first quasi-polynomial time algorithm for\\nlearning noisy decision trees with polynomial sample complexity.\\n'\n",
      " '  This paper introduces a novel neural network-based reinforcement learning\\napproach for robot gaze control. Our approach enables a robot to learn and to\\nadapt its gaze control strategy for human-robot interaction neither with the\\nuse of external sensors nor with human supervision. The robot learns to focus\\nits attention onto groups of people from its own audio-visual experiences,\\nindependently of the number of people, of their positions and of their physical\\nappearances. In particular, we use a recurrent neural network architecture in\\ncombination with Q-learning to find an optimal action-selection policy; we\\npre-train the network using a simulated environment that mimics realistic\\nscenarios that involve speaking/silent participants, thus avoiding the need of\\ntedious sessions of a robot interacting with people. Our experimental\\nevaluation suggests that the proposed method is robust against parameter\\nestimation, i.e. the parameter values yielded by the method do not have a\\ndecisive impact on the performance. The best results are obtained when both\\naudio and visual information is jointly used. Experiments with the Nao robot\\nindicate that our framework is a step forward towards the autonomous learning\\nof socially acceptable gaze behavior.\\n'\n",
      " '  With the aim to reveal universal features of hadronic matter and correlated\\nDirac insulators in strong AC-electric fields, we study the $\\\\mathcal{N}=2$\\nsupersymmetric QCD with a finite quark mass driven by a rotating electric field\\n$\\\\mathcal{E}_x+i\\\\mathcal{E}_y= E e^{i\\\\Omega t}$. The analysis is done in the\\nholographically dual D3/D7 system in the co-rotating frame, effectively. The\\nnonequilibrium phase diagram is determined from the threshold electric field at\\nwhich the insulator phase breaks down to a conductive phase due to the AC\\nversion of the Schwinger mechanism. The external field induces a rotating\\ncurrent $\\\\mathcal{J}_x + i \\\\mathcal{J}_y = J e^{i\\\\Omega t}$ originating from\\nvacuum polarization and dissipative current in the insulating and conductive\\nphases respectively. Intriguing features are observed as the frequency $\\\\Omega$\\napproaches resonance with the meson excitation energy $\\\\Omega_{\\\\rm meson}$.\\nThere, the threshold minimizes and a condensate of vector mesons with\\noscillating current exists even in the zero driving field limit. This state,\\nwhich we call Floquet condensate of vector mesons, is expected to be\\ndynamically stable realizing a non-thermal fixed point that breaks time\\ntranslational and reversal symmetries. Our finding has many similarities with\\nexciton BEC discussed in solid state systems, where the semiconductor is to be\\nreplaced by materials hosting gapped Dirac electrons, e.g. 3D topological\\ninsulators or bismuth. Vector meson Floquet condensate may also have\\nimplications in the pre-thermalized dynamics in heavy ion collision\\nexperiments.\\n'\n",
      " '  We investigate how three different possibilities of neutrino mass\\nhierarchies, namely normal, inverted, and degenerate, can affect the\\nobservational constraints on three well known dynamical dark energy models,\\nnamely the Chevallier-Polarski-Linder, logarithmic, and the\\nJassal-Bagla-Padmanabhan parametrizations. In order to impose the observational\\nconstraints on the models, we performed a robust analysis using Planck 2015\\ntemperature and polarization data, Supernovae type Ia from Joint Light curve\\nanalysis, baryon acoustic oscillations distance measurements, redshift space\\ndistortion characterized by $f(z)\\\\sigma_8(z)$ data, weak gravitational lensing\\ndata from Canada-France-Hawaii Telescope Lensing Survey, and cosmic\\nchronometers data plus the local value of the Hubble parameter. We find that\\ndifferent neutrino mass hierarchies return similar fit on almost all model\\nparameters and mildly change the dynamical dark energy properties.\\n'\n",
      " '  Despite the rapid progress of the techniques for image classification, video\\nannotation has remained a challenging task. Automated video annotation would be\\na breakthrough technology, enabling users to search within the videos.\\nRecently, Google introduced the Cloud Video Intelligence API for video\\nanalysis. As per the website, the system can be used to \"separate signal from\\nnoise, by retrieving relevant information at the video, shot or per frame\"\\nlevel. A demonstration website has been also launched, which allows anyone to\\nselect a video for annotation. The API then detects the video labels (objects\\nwithin the video) as well as shot labels (description of the video events over\\ntime). In this paper, we examine the usability of the Google\\'s Cloud Video\\nIntelligence API in adversarial environments. In particular, we investigate\\nwhether an adversary can subtly manipulate a video in such a way that the API\\nwill return only the adversary-desired labels. For this, we select an image,\\nwhich is different from the video content, and insert it, periodically and at a\\nvery low rate, into the video. We found that if we insert one image every two\\nseconds, the API is deceived into annotating the video as if it only contained\\nthe inserted image. Note that the modification to the video is hardly\\nnoticeable as, for instance, for a typical frame rate of 25, we insert only one\\nimage per 50 video frames. We also found that, by inserting one image per\\nsecond, all the shot labels returned by the API are related to the inserted\\nimage. We perform the experiments on the sample videos provided by the API\\ndemonstration website and show that our attack is successful with different\\nvideos and images.\\n'\n",
      " '  A new slow growth formulation for DNS of wall-bounded turbulent flow is\\ndeveloped and demonstrated to enable extension of slow growth modeling concepts\\nto complex boundary layer flows. As in previous slow growth approaches, the\\nformulation assumes scale separation between the fast scales of turbulence and\\nthe slow evolution of statistics such as the mean flow. This separation enables\\nthe development of approaches where the fast scales of turbulence are directly\\nsimulated while the forcing provided by the slow evolution is modeled. The\\nresulting model admits periodic boundary conditions in the streamwise\\ndirection, which avoids the need for extremely long domains and complex inflow\\nconditions that typically accompany spatially developing simulations. Further,\\nit enables the use of efficient Fourier numerics. Unlike previous approaches,\\nthe present approach is based on a temporally evolving boundary layer and is\\nspecifically tailored to give results for calibration and validation of RANS\\nturbulence models. The use of a temporal homogenization simplifies the\\nmodeling, enabling straightforward extension to flows with complicating\\nfeatures, including cold and blowing walls. To generate data useful for\\ncalibration and validation of RANS models, special care is taken to ensure that\\nthe mean slow growth forcing is closed in terms of the mean and other\\nquantities that appear in standard RANS models, ensuring that there is no\\nconfounding between typical RANS closures and additional closures required for\\nthe slow growth problem. The performance of the method is demonstrated on two\\nproblems: an essentially incompressible, zero-pressure-gradient boundary layer\\nand a transonic boundary layer over a cooled wall with wall transpiration.\\n'\n",
      " \"  The primary aim of market segmentation is to identify relevant groups of\\nconsumers that can be addressed efficiently by marketing or advertising\\ncampaigns. This paper addresses the issue whether consumer groups can be\\nidentified from background variables that are not brand-related and how much\\npersonality vs. socio-demographic variables contribute to the identification of\\nconsumer clusters. This is done by clustering aggregated preferences for 25\\nbrands across 5 different product categories, and by relating socio-demographic\\nand personality variables to the clusters using logistic regression and random\\nforests over a range of different numbers of clusters. Results indicate that\\nsome personality variables contribute significantly to the identification of\\nconsumer groups in one sample. However, these results were not replicated on a\\nsecond sample that was more heterogeneous in terms of socio-demographic\\ncharacteristics and not representative of the brands' target audience.\\n\"\n",
      " '  Reliable propagation of information through large networks, e.g.,\\ncommunication networks, social networks or sensor networks is very important in\\nmany applications concerning marketing, social networks, and wireless sensor\\nnetworks. However, social ties of friendship may be obsolete, and communication\\nlinks may fail, inducing the notion of uncertainty in such networks. In this\\npaper, we address the problem of optimizing information propagation in\\nuncertain networks given a constrained budget of edges. We show that this\\nproblem requires to solve two NP-hard subproblems: the computation of expected\\ninformation flow, and the optimal choice of edges. To compute the expected\\ninformation flow to a source vertex, we propose the F-tree as a specialized\\ndata structure, that identifies independent components of the graph for which\\nthe information flow can either be computed analytically and efficiently, or\\nfor which traditional Monte-Carlo sampling can be applied independently of the\\nremaining network. For the problem of finding the optimal edges, we propose a\\nseries of heuristics that exploit properties of this data structure. Our\\nevaluation shows that these heuristics lead to high quality solutions, thus\\nyielding high information flow, while maintaining low running time.\\n'\n",
      " '  We address the role of Sn-substitution and Pb-vacancy (Pb-$\\\\Box$) in\\nregulating stability and carrier concentration of\\nCH$_3$NH$_3$Pb$_{1-X-Y}$Sn$_X$$\\\\Box_Y$I$_3$ perovskite using density functional\\ntheory, where the performance of the exchange-correlation functional is\\ncarefully analyzed, and validated w.r.t. available experimental results. We\\nfind the most stable configuration does not prefer any Pb at 50\\\\% concentration\\nof Sn. However, the Pb-$\\\\Box$s become unfavourable above 250K due to the\\nreduced linearity of Sn-I bonds. For n-type host the Sn substitution is more\\npreferable than Pb-$\\\\Box$ formation, while for p-type host the trend is exactly\\nopposite. The charge states of both Sn and Pb-$\\\\Box$ are found to be dependent\\non the Sn concentration, which in turn alters the perovskite from n-type to\\np-type with increasing $X$ ($>$0.5).\\n'\n",
      " '  The goal of point set registration is to find point-by-point correspondences\\nbetween point sets, each of which characterizes the shape of an object. Because\\nlocal preservation of object geometry is assumed, prevalent algorithms in the\\narea can often elegantly solve the problems without using geometric information\\nspecific to the objects. This means that registration performance can be\\nfurther improved by using prior knowledge of object geometry. In this paper, we\\npropose a novel point set registration method using the Gaussian mixture model\\nwith prior shape information encoded as a statistical shape model. Our\\ntransformation model is defined as a combination of the similar transformation,\\nmotion coherence, and the statistical shape model. Therefore, the proposed\\nmethod works effectively if the target point set includes outliers and missing\\nregions, or if it is rotated. The computational cost can be reduced to linear,\\nand therefore the method is scalable to large point sets. The effectiveness of\\nthe method will be verified through comparisons with existing algorithms using\\ndatasets concerning human body shapes, hands, and faces.\\n'\n",
      " '  We study the phase transition between conducting and insulating states taking\\nplace in disordered multi-channel Luttinger liquids with inter-channel\\ninteractions. We derive renormalisation group equations which are perturbative\\nin disorder but nonperturbative in interaction. In the vicinity of the\\nsimultaneous phase transition in all channels, these equations become a set of\\ncoupled Berezinskii--Kosterlitz--Thouless equations, which we analyze within\\ntwo models: an array of identical wires and a two-channel model with distinct\\nchannels. We show that a competition between disorder and interaction results\\nin a variety of phases, expected to be observable at intermediate temperatures\\nwhere the interaction and disorder are relevant but weak hybridization and the\\ncharge-density wave interaction may be ignored.\\n'\n",
      " '  In this paper, we study isolated singular positive solutions for the\\nfollowing Kirchhoff--type Laplacian problem: \\\\begin{equation*}\\n-\\\\left(\\\\theta+\\\\int_{\\\\Omega} |\\\\nabla u| dx\\\\right)\\\\Delta u =u^p \\\\quad{\\\\rm\\nin}\\\\quad \\\\Omega\\\\setminus \\\\{0\\\\},\\\\qquad u=0\\\\quad {\\\\rm on}\\\\quad \\\\partial \\\\Omega,\\n\\\\end{equation*} where $p>1$, $\\\\theta\\\\in \\\\R$, $\\\\Omega$ is a bounded smooth\\ndomain containing the origin in $\\\\R^N$ with $N\\\\ge 2$. In the subcritical case:\\n$1<p<N/(N-2)$ if $N\\\\ge3$, $1<p<+\\\\infty$ if $N=2$, we employ the Schauder\\nfixed-point theorem to derive a sequence of positive isolated singular\\nsolutions for the above problem such that $M_\\\\theta(u)>0$. To estimate\\n$M_\\\\theta(u)$, we make use of the rearrangement argument. Furthermore, we\\nobtain a sequence of isolated singular solutions such that $M_\\\\theta(u)<0$, by\\nanalyzing relationship between the parameter $\\\\lambda$ and the unique solution\\n$u_\\\\lambda$ of $$-\\\\Delta u+\\\\lambda u^p=k\\\\delta_0\\\\quad{\\\\rm in}\\\\quad\\nB_1(0),\\\\qquad u=0\\\\quad {\\\\rm on}\\\\quad \\\\partial B_1(0).$$ In the supercritical\\ncase: $N/(N-2)\\\\le p<(N+2)/(N-2)$ with $N\\\\ge3$, we obtain two isolated singular\\nsolutions $u_i$ with $i=1,2$ such that $M_\\\\theta(u_i)>0$ under some appropriate\\nassumptions.\\n'\n",
      " '  General human action recognition requires understanding of various visual\\ncues. In this paper, we propose a network architecture that computes and\\nintegrates the most important visual cues for action recognition: pose, motion,\\nand the raw images. For the integration, we introduce a Markov chain model\\nwhich adds cues successively. The resulting approach is efficient and\\napplicable to action classification as well as to spatial and temporal action\\nlocalization. The two contributions clearly improve the performance over\\nrespective baselines. The overall approach achieves state-of-the-art action\\nclassification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover,\\nit yields state-of-the-art spatio-temporal action localization results on\\nUCF101 and J-HMDB.\\n'\n",
      " \"  The reinforcement learning community has made great strides in designing\\nalgorithms capable of exceeding human performance on specific tasks. These\\nalgorithms are mostly trained one task at the time, each new task requiring to\\ntrain a brand new agent instance. This means the learning algorithm is general,\\nbut each solution is not; each agent can only solve the one task it was trained\\non. In this work, we study the problem of learning to master not one but\\nmultiple sequential-decision tasks at once. A general issue in multi-task\\nlearning is that a balance must be found between the needs of multiple tasks\\ncompeting for the limited resources of a single learning system. Many learning\\nalgorithms can get distracted by certain tasks in the set of tasks to solve.\\nSuch tasks appear more salient to the learning process, for instance because of\\nthe density or magnitude of the in-task rewards. This causes the algorithm to\\nfocus on those salient tasks at the expense of generality. We propose to\\nautomatically adapt the contribution of each task to the agent's updates, so\\nthat all tasks have a similar impact on the learning dynamics. This resulted in\\nstate of the art performance on learning to play all games in a set of 57\\ndiverse Atari games. Excitingly, our method learned a single trained policy -\\nwith a single set of weights - that exceeds median human performance. To our\\nknowledge, this was the first time a single agent surpassed human-level\\nperformance on this multi-task domain. The same approach also demonstrated\\nstate of the art performance on a set of 30 tasks in the 3D reinforcement\\nlearning platform DeepMind Lab.\\n\"\n",
      " '  We present the first results of a search for transient hard X-ray (HXR)\\nemission in the quiet solar corona with the \\\\textit{Nuclear Spectroscopic\\nTelescope Array} (\\\\textit{NuSTAR}) satellite. While \\\\textit{NuSTAR} was\\ndesigned as an astrophysics mission, it can observe the Sun above 2~keV with\\nunprecedented sensitivity due to its pioneering use of focusing optics.\\n\\\\textit{NuSTAR} first observed quiet Sun regions on 2014 November 1, although\\nout-of-view active regions contributed a notable amount of background in the\\nform of single-bounce (unfocused) X-rays. We conducted a search for quiet Sun\\ntransient brightenings on time scales of 100 s and set upper limits on emission\\nin two energy bands. We set 2.5--4~keV limits on brightenings with time scales\\nof 100 s, expressed as the temperature T and emission measure EM of a thermal\\nplasma. We also set 10--20~keV limits on brightenings with time scales of 30,\\n60, and 100 s, expressed as model-independent photon fluxes. The limits in both\\nbands are well below previous HXR microflare detections, though not low enough\\nto detect events of equivalent T and EM as quiet Sun brightenings seen in soft\\nX-ray observations. We expect future observations during solar minimum to\\nincrease the \\\\textit{NuSTAR} sensitivity by over two orders of magnitude due to\\nhigher instrument livetime and reduced solar background.\\n'\n",
      " '  Let n points be placed on a closed convex domain on the plane, no three\\npoints on a straight line.\\n'\n",
      " '  Networked applications traditionally derive their identity from the identity\\nof the host on which they run. The default application identity acquired from\\nthe host results in subtle and substantial problems related to application\\ndeployment, discovery and access, especially for modern distributed\\napplications. A number of mechanisms and workarounds, often quite elaborate,\\nare used to address those problems but they only address them indirectly and\\nincompletely.\\nThis paper presents AppSwitch, a novel transport layer network element that\\ndecouples applications from underlying network at the system call layer and\\nenables them to be identified independently of the network. Without requiring\\nchanges to existing applications or infrastructure, it removes the cost and\\ncomplexity associated with operating distributed applications while offering a\\nnumber of benefits including an efficient implementation of common network\\nfunctions such as application firewall and load balancer. Experiments with our\\nimplementation show that AppSwitch model also effectively removes the\\nperformance penalty associated with unnecessary data path processing that is\\ntypical in those application environments.\\n'\n",
      " '  Code loops are certain Moufang $2$-loops constructed from doubly even binary\\ncodes that play an important role in the construction of local subgroups of\\nsporadic groups. More precisely, code loops are central extensions of the group\\nof order $2$ by an elementary abelian $2$-group $V$ in the variety of loops\\nsuch that their squaring map, commutator map and associator map are related by\\ncombinatorial polarization and the associator map is a trilinear alternating\\nform.\\nUsing existing classifications of trilinear alternating forms over the field\\nof $2$ elements, we enumerate code loops of dimension $d=\\\\mathrm{dim}(V)\\\\le 8$\\n(equivalently, of order $2^{d+1}\\\\le 512$) up to isomorphism. There are $767$\\ncode loops of order $128$, and $80826$ of order $256$, and $937791557$ of order\\n$512$.\\n'\n",
      " '  It is proved that the derived subgroup of a finite group is nilpotent if and\\nonly if $|ab|\\\\ge |a||b|$ for all primary commutators $a$ and $b$ of coprime\\norders.\\n'\n",
      " '  We examine many-body localization properties for the eigenstates that lie in\\nthe droplet sector of the random-field spin-$\\\\frac 1 2$ XXZ chain. These states\\nsatisfy a basic single cluster localization property (SCLP), derived in\\n\\\\cite{EKS}. This leads to many consequences, including dynamical exponential\\nclustering, non-spreading of information under the time evolution, and a zero\\nvelocity Lieb Robinson bound. Since SCLP is only applicable to the droplet\\nsector, our definitions and proofs do not rely on knowledge of the spectral and\\ndynamical characteristics of the model outside this regime. Rather, to allow\\nfor a possible mobility transition, we adapt the notion of restricting the\\nHamiltonian to an energy window from the single particle setting to the many\\nbody context.\\n'\n",
      " \"  We perform mathematical anaysis of the biofilm development process. A model\\ndescribing biomass growth is proposed: It arises from coupling three parabolic\\nnonlinear equations: a biomass equation with degenerate and singular diffusion,\\na nutrient tranport equation with a biomass-density dependent diffusion, and an\\nequation of the Navier-Stokes type, describing the fluid flow in which the\\nbiofilm develops. This flow is subject to a biomass--density dependent\\nobstacle. The model is treated as a system of three inclusions, or variational\\ninequalities; the third one causes major difficulties for the system's\\nsolvability. Our approach is based on the recent development of the theory on\\nNavier-Stokes variational inequalities.\\n\"\n",
      " \"  In this paper, we propose a hybrid analog-digital beamforming architecture\\nwith resolution-adaptive ADCs for millimeter wave (mmWave) receivers with large\\nantenna arrays. We adopt array response vectors for the analog combiners and\\nderive ADC bit-allocation (BA) solutions in closed form. The BA solutions\\nreveal that the optimal number of ADC bits is logarithmically proportional to\\nthe RF chain's signal-to-noise ratio raised to the 1/3 power. Using the\\nsolutions, two proposed BA algorithms minimize the mean square quantization\\nerror of received analog signals under a total ADC power constraint.\\nContributions of this paper include 1) ADC bit-allocation algorithms to improve\\ncommunication performance of a hybrid MIMO receiver, 2) approximation of the\\ncapacity with the BA algorithm as a function of channels, and 3) a worst-case\\nanalysis of the ergodic rate of the proposed MIMO receiver that quantifies\\nsystem tradeoffs and serves as the lower bound. Simulation results demonstrate\\nthat the BA algorithms outperform a fixed-ADC approach in both spectral and\\nenergy efficiency, and validate the capacity and ergodic rate formula. For a\\npower constraint equivalent to that of fixed 4-bit ADCs, the revised BA\\nalgorithm makes the quantization error negligible while achieving 22% better\\nenergy efficiency. Having negligible quantization error allows existing\\nstate-of-the-art digital beamformers to be readily applied to the proposed\\nsystem.\\n\"\n",
      " '  Recently, Factorization Machines (FM) has become more and more popular for\\nrecommendation systems, due to its effectiveness in finding informative\\ninteractions between features. Usually, the weights for the interactions is\\nlearnt as a low rank weight matrix, which is formulated as an inner product of\\ntwo low rank matrices. This low rank can help improve the generalization\\nability of Factorization Machines. However, to choose the rank properly, it\\nusually needs to run the algorithm for many times using different ranks, which\\nclearly is inefficient for some large-scale datasets. To alleviate this issue,\\nwe propose an Adaptive Boosting framework of Factorization Machines (AdaFM),\\nwhich can adaptively search for proper ranks for different datasets without\\nre-training. Instead of using a fixed rank for FM, the proposed algorithm will\\nadaptively gradually increases its rank according to its performance until the\\nperformance does not grow, using boosting strategy. To verify the performance\\nof our proposed framework, we conduct an extensive set of experiments on many\\nreal-world datasets. Encouraging empirical results shows that the proposed\\nalgorithms are generally more effective than state-of-the-art other\\nFactorization Machines.\\n'\n",
      " '  For a given region, we have a dataset composed of car theft locations along\\nwith a linked dataset of recovery locations which, due to partial recovery, is\\na relatively small subset of the set of theft locations. For an investigator\\nseeking to understand the behavior of car thefts and recoveries in the region,\\nseveral questions are addressed. Viewing the set of theft locations as a point\\npattern, can we propose useful models to explain the pattern? What types of\\npredictive models can be built to learn about recovery location given theft\\nlocation? Can the dependence between theft locations and recovery locations be\\nformalized? Can the flow between theft sites and recovery sites be captured?\\nOrigin-destination modeling offers a natural framework for such problems.\\nHowever, here the data is not for areal units but rather is a pair of point\\npatterns, with the recovery point pattern only partially observed. We offer\\nmodeling approaches for investigating the questions above and apply the\\napproaches to two datasets. One is small from the state of Neza in Mexico with\\nareal covariate information regarding population features and crime type. A\\nsecond, much larger one, is from Belo Horizonte in Brazil but lacks covariates.\\n'\n",
      " '  We consider a parameter estimation problem for one dimensional stochastic\\nheat equations, when data is sampled discretely in time or spatial component.\\nWe establish some general results on derivation of consistent and\\nasymptotically normal estimators based on computation of the $p$-variations of\\nstochastic processes and their smooth perturbations. We apply these results to\\nthe considered SPDEs, by using some convenient representations of the\\nsolutions. For some equations such results were ready available, while for\\nother classes of SPDEs we derived the needed representations along with their\\nstatistical asymptotical properties. We prove that the real valued parameter\\nnext to the Laplacian, and the constant parameter in front of the noise (the\\nvolatility) can be consistently estimated by observing the solution at a fixed\\ntime and on a discrete spatial grid, or at a fixed space point and at discrete\\ntime instances of a finite interval, assuming that the mesh-size goes to zero.\\n'\n",
      " '  We report the first experimental measurement of the near-threshold\\nphoto-ionization spectra of polycyclic aromatic hydrocarbon clusters made of\\npyrene C16H10 and coronene C24H12, obtained using imaging photoelectron\\nphotoion coincidence spectrometry with a VUV synchrotron beamline. The\\nexperimental results of the ionization energy are confronted to calculated ones\\nobtained from simulations using dedicated electronic structure treatment for\\nlarge ionized molecular clusters. Experiment and theory consistently find a\\ndecrease of the ionization energy with cluster size. The inclusion of\\ntemperature effects in the simulations leads to a lowering of this energy and\\nto a quantitative agreement with the experiment. In the case of pyrene, both\\ntheory and experiment show a discontinuity in the IE trend for the hexamer.\\n'\n",
      " '  We consider the problem of training generative models with deep neural\\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\\ndominant paradigm combines simple priors over codes with complex deterministic\\nmodels, we argue that it might be advantageous to use more flexible code\\ndistributions. We demonstrate how these distributions can be induced directly\\nfrom the data. The benefits include: more powerful generative models, better\\nmodeling of latent structure and explicit control of the degree of\\ngeneralization.\\n'\n",
      " \"  Let $K$ be a field. We simplify and extend work of Althaler \\\\& Dür on\\nfinite sequences over $K$ by regarding $K[x^{-1},z^{-1}]$ as a $K[x,z]$ module,\\nand studying forms in $K[x^{-1},z^{-1}]$ from first principles. Then we apply\\nour results to finite sequences.\\nFirst we define the annihilator ideal $I_F$ of a non-zero form $F\\\\in\\nK[x^{-1},z^{-1}]$, a homogeneous ideal. We inductively construct an ordered\\npair ($f_1$\\\\,,\\\\,$f_2$) of forms which generate $I_F$\\\\,; our generators are\\nspecial in that $z$ does not divide the leading grlex monomial of $f_1$ but $z$\\ndivides $f_2$\\\\,, and the sum of their total degrees is always $2-|F|$, where\\n$|F|$ is the total degree of $F$. We show that $f_1,f_2$ is a maximal regular\\nsequence for $I_F$, so that the height of $I_F$ is 2. The corresponding\\nalgorithm is $\\\\sim |F|^2/2$.\\nThe row vector obtained by accumulating intermediate forms of the\\nconstruction gives a minimal grlex Gröbner basis for $I_F$ for no extra\\ncomputational cost other than storage and apply this to determining $\\\\dim_K\\n(K[x,z] /I_F)$\\\\,. We show that either the form vector is reduced or a monomial\\nof $f_1$ can be reduced by $f_2$\\\\,. This enables us to efficiently construct\\nthe unique reduced Gröbner basis for $I_F$ from the vector extension of our\\nalgorithm.\\nThen we specialise to the inverse form of a finite sequence, obtaining\\ngenerator forms for its annihilator ideal and a corresponding algorithm which\\ndoes not use the last 'length change' of Massey. We compute the intersection of\\ntwo annihilator ideals using syzygies in $K[x,z]^5$. This improves a result of\\nAlthaler \\\\& Dür. Finally, dehomogenisation induces a one-to-one\\ncorrespondence ($f_1$\\\\,,$f_2$) $\\\\mapsto$ (minimal polynomial, auxiliary\\npolynomial), the output of the author's variant of the Berlekamp-Massey\\nalgorithm. So we can also solve the LFSR synthesis problem via the\\ncorresponding algorithm for sequences.\\n\"\n",
      " \"  Named Entity Recognition (NER) is one of the most common tasks of the natural\\nlanguage processing. The purpose of NER is to find and classify tokens in text\\ndocuments into predefined categories called tags, such as person names,\\nquantity expressions, percentage expressions, names of locations,\\norganizations, as well as expression of time, currency and others. Although\\nthere is a number of approaches have been proposed for this task in Russian\\nlanguage, it still has a substantial potential for the better solutions. In\\nthis work, we studied several deep neural network models starting from vanilla\\nBi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with\\nConditional Random Fields (CRF) as well as highway networks and finally adding\\nexternal word embeddings. All models were evaluated across three datasets:\\nGareev's dataset, Person-1000, FactRuEval-2016. We found that extension of\\nBi-LSTM model with CRF significantly increased the quality of predictions.\\nEncoding input tokens with external word embeddings reduced training time and\\nallowed to achieve state of the art for the Russian NER task.\\n\"\n",
      " '  Most visual odometry algorithm for a monocular camera focuses on points,\\neither by feature matching, or direct alignment of pixel intensity, while\\nignoring a common but important geometry entity: edges. In this paper, we\\npropose an odometry algorithm that combines points and edges to benefit from\\nthe advantages of both direct and feature based methods. It works better in\\ntexture-less environments and is also more robust to lighting changes and fast\\nmotion by increasing the convergence basin. We maintain a depth map for the\\nkeyframe then in the tracking part, the camera pose is recovered by minimizing\\nboth the photometric error and geometric error to the matched edge in a\\nprobabilistic framework. In the mapping part, edge is used to speed up and\\nincrease stereo matching accuracy. On various public datasets, our algorithm\\nachieves better or comparable performance than state-of-the-art monocular\\nodometry methods. In some challenging texture-less environments, our algorithm\\nreduces the state estimation error over 50%.\\n'\n",
      " '  Data for good implies unfettered access to data. But data owners must be\\nconservative about how, when, and why they share data or risk violating the\\ntrust of the people they aim to help, losing their funding, or breaking the\\nlaw. Data sharing agreements can help prevent privacy violations, but require a\\nlevel of specificity that is premature during preliminary discussions, and can\\ntake over a year to establish.\\nWe consider the generation and use of synthetic data to facilitate ad hoc\\ncollaborations involving sensitive data. A good synthetic dataset has two\\nproperties: it is representative of the original data, and it provides strong\\nguarantees about privacy.\\nIn this paper, we discuss important use cases for synthetic data that\\nchallenge the state of the art in privacy-preserving data generation, and\\ndescribe DataSynthesizer, a dataset generation tool that takes a sensitive\\ndataset as input and generates a structurally and statistically similar\\nsynthetic dataset, with strong privacy guarantees, as output. The data owners\\nneed not release their data, while potential collaborators can begin developing\\nmodels and methods with some confidence that their results will work similarly\\non the real dataset. The distinguishing feature of DataSynthesizer is its\\nusability - in most cases, the data owner need not specify any parameters to\\nstart generating and sharing data safely and effectively.\\nThe code implementing DataSynthesizer is publicly available on GitHub at\\nthis https URL. The work on DataSynthesizer is part of the\\nData, Responsibly project, where the goal is to operationalize responsibility\\nin data sharing, integration, analysis and use.\\n'\n",
      " '  We prove that when suitably normalized, small enough powers of the absolute\\nvalue of the characteristic polynomial of random Hermitian matrices, drawn from\\none-cut regular unitary invariant ensembles, converge in law to Gaussian\\nmultiplicative chaos measures. We prove this in the so-called $L^2$-phase of\\nmultiplicative chaos. Our main tools are asymptotics of Hankel determinants\\nwith Fisher-Hartwig singularities. Using Riemann-Hilbert methods, we prove a\\nrather general Fisher-Hartwig formula for one-cut regular unitary invariant\\nensembles.\\n'\n",
      " '  In horizontal collaborations, carriers form coalitions in order to perform\\nparts of their logistics operations jointly. By exchanging transportation\\nrequests among each other, they can operate more efficiently and in a more\\nsustainable way. Collaborative vehicle routing has been extensively discussed\\nin the literature. We identify three major streams of research: (i) centralized\\ncollaborative planning, (ii) decentralized planning without auctions, and (ii)\\nauction-based decentralized planning. For each of them we give a structured\\noverview on the state of knowledge and discuss future research directions.\\n'\n",
      " '  We use an atomistic spin model derived from density functional theory\\ncalculations for the ultra-thin film Pd/Fe/Ir(111) to show that temperature\\ninduces coexisting non-zero skyrmion and antiskyrmion densities. We apply the\\nparallel tempering Monte Carlo method in order to reliably compute\\nthermodynamical quantities and the B-T phase diagram in the presence of\\nfrustrated exchange interactions. We evaluate the critical temperatures using\\nthe topological susceptibility. We show that the critical temperatures depend\\non the magnetic field in contrast to previous work. In total, we identify five\\nphases: spin spiral, skyrmion lattice, ferromagnetic phase, intermediate region\\nwith finite topological charge and paramagnetic phase. To explore the effect of\\nfrustrated exchange interactions, we calculate the B-T phase diagram, when only\\neffective exchange parameters are taken into account.\\n'\n",
      " '  We present a framework to systematically analyze convolutional neural\\nnetworks (CNNs) used in classification of cars in autonomous vehicles. Our\\nanalysis procedure comprises an image generator that produces synthetic\\npictures by sampling in a lower dimension image modification subspace and a\\nsuite of visualization tools. The image generator produces images which can be\\nused to test the CNN and hence expose its vulnerabilities. The presented\\nframework can be used to extract insights of the CNN classifier, compare across\\nclassification models, or generate training and validation datasets.\\n'\n",
      " '  A geometrical pattern is a set of points with all pairwise distances (or,\\nmore generally, relative distances) specified. Finding matches to such patterns\\nhas applications to spatial data in seismic, astronomical, and transportation\\ncontexts. For example, a particularly interesting geometric pattern in\\nastronomy is the Einstein cross, which is an astronomical phenomenon in which a\\nsingle quasar is observed as four distinct sky objects (due to gravitational\\nlensing) when captured by earth telescopes. Finding such crosses, as well as\\nother geometric patterns, is a challenging problem as the potential number of\\nsets of elements that compose shapes is exponentially large in the size of the\\ndataset and the pattern. In this paper, we denote geometric patterns as\\nconstellation queries and propose algorithms to find them in large data\\napplications. Our methods combine quadtrees, matrix multiplication, and\\nunindexed join processing to discover sets of points that match a geometric\\npattern within some additive factor on the pairwise distances. Our distributed\\nexperiments show that the choice of composition algorithm (matrix\\nmultiplication or nested loops) depends on the freedom introduced in the query\\ngeometry through the distance additive factor. Three clearly identified blocks\\nof threshold values guide the choice of the best composition algorithm.\\nFinally, solving the problem for relative distances requires a novel\\ncontinuous-to-discrete transformation. To the best of our knowledge this paper\\nis the first to investigate constellation queries at scale.\\n'\n",
      " '  We present an Environmental Control System (ECS) designed to achieve\\nmilliKelvin (mK) level temperature stability for small-scale astronomical\\ninstruments. This ECS is inexpensive and is primarily built from commercially\\navailable components. The primary application for our ECS is the high-precision\\nDoppler spectrometer MINERVA-Red, where the thermal variations of the optical\\ncomponents within the instrument represent a major source of systematic error.\\nWe demonstrate $\\\\pm 2$ mK temperature stability within a 0.5 m$^{3}$ Thermal\\nEnclosure using resistive heaters in conjunction with a commercially available\\nPID controller and off-the-shelf thermal sensors. The enclosure is maintained\\nabove ambient temperature, enabling rapid cooling through heat dissipation into\\nthe surrounding environment. We demonstrate peak-to-valley (PV) temperature\\nstability of better than 5 mK within the MINERVA-Red vacuum chamber, which is\\nlocated inside the Thermal Enclosure, despite large temperature swings in the\\nambient laboratory environment. During periods of stable laboratory conditions,\\nthe PV variations within the vacuum chamber are less than 3 mK. This\\ntemperature stability is comparable to the best stability demonstrated for\\nDoppler spectrometers currently achieving 1 m s$^{-1}$ radial velocity\\nprecision. We discuss the challenges of using commercially available\\nthermoelectrically cooled CCD cameras in a temperature-stabilized environment,\\nand demonstrate that the effects of variable heat output from the CCD camera\\nbody can be mitigated using PID-controlled chilled water systems. The ECS\\npresented here could potentially provide the stable operating environment\\nrequired for future compact, \"astro-photonic\" precise radial velocity (PRV)\\nspectrometers to achieve high Doppler measurement precision with a modest\\nbudget.\\n'\n",
      " '  We consider a multi-server queueing system under the power-of-two policy with\\nPoisson job arrivals, heterogeneous servers and a general job requirement\\ndistribution; each server operates under the first-come first-serve policy and\\nthere are no buffer constraints. We analyze the performance of this system in\\nlight traffic by evaluating the first two light traffic derivatives of the\\naverage job response time. These expressions point to several interesting\\nstructural features associated with server heterogeneity in light traffic: For\\nunequal capacities, the average job response time is seen to decrease for small\\nvalues of the arrival rate, and the more diverse the server speeds, the greater\\nthe gain in performance. These theoretical findings are assessed through\\nlimited simulations.\\n'\n",
      " '  Can Crowds serve as useful allies in policy design? How do non-expert Crowds\\nperform relative to experts in the assessment of policy measures? Does the\\ngeographic location of non-expert Crowds, with relevance to the policy context,\\nalter the performance of non-experts Crowds in the assessment of policy\\nmeasures? In this work, we investigate these questions by undertaking\\nexperiments designed to replicate expert policy assessments with non-expert\\nCrowds recruited from Virtual Labor Markets. We use a set of ninety-six climate\\nchange adaptation policy measures previously evaluated by experts in the\\nNetherlands as our control condition to conduct experiments using two discrete\\nsets of non-expert Crowds recruited from Virtual Labor Markets. We vary the\\ncomposition of our non-expert Crowds along two conditions: participants\\nrecruited from a geographical location directly relevant to the policy context\\nand participants recruited at-large. We discuss our research methods in detail\\nand provide the findings of our experiments.\\n'\n",
      " '  Co-occurrences between two words provide useful insights into the semantics\\nof those words. Consequently, numerous prior work on word embedding learning\\nhave used co-occurrences between two words as the training signal for learning\\nword embeddings. However, in natural language texts it is common for multiple\\nwords to be related and co-occurring in the same context. We extend the notion\\nof co-occurrences to cover $k(\\\\geq\\\\!\\\\!2)$-way co-occurrences among a set of\\n$k$-words. Specifically, we prove a theoretical relationship between the joint\\nprobability of $k(\\\\geq\\\\!\\\\!2)$ words, and the sum of $\\\\ell_2$ norms of their\\nembeddings. Next, we propose a learning objective motivated by our theoretical\\nresult that utilises $k$-way co-occurrences for learning word embeddings. Our\\nexperimental results show that the derived theoretical relationship does indeed\\nhold empirically, and despite data sparsity, for some smaller $k$ values,\\n$k$-way embeddings perform comparably or better than $2$-way embeddings in a\\nrange of tasks.\\n'\n",
      " '  Recent advances in the understanding and control of quantum technologies,\\nsuch as those based on cold atoms, have resulted in devices with extraordinary\\nmetrological sensitivities. To realise this potential outside of a lab\\nenvironment the size, weight and power consumption need to be reduced. Here we\\ndemonstrate the use of laser powder bed fusion, an additive manufacturing\\ntechnique, as a production technique for the components that make up quantum\\nsensors. As a demonstration we have constructed two key components using\\nadditive manufacturing, namely magnetic shielding and vacuum chambers. The\\ninitial prototypes for magnetic shields show shielding factors within a factor\\nof 3 of conventional approaches. The vacuum demonstrator device shows that\\n3D-printed titanium structures are suitable for use as vacuum chambers, with\\nthe test system reaching base pressures of $5 \\\\pm 0.5 \\\\times 10^{-10}$ mbar.\\nThese demonstrations show considerable promise for the use of additive\\nmanufacturing for cold atom based quantum technologies, in future enabling\\nimproved integrated structures, allowing for the reduction in size, weight and\\nassembly complexity.\\n'\n",
      " \"  Graph layout is the process of creating a visual representation of a graph\\nthrough a node-link diagram. Node-attribute graphs have additional data stored\\non the nodes which describe certain properties of the nodes called attributes.\\nTypical force-directed representations often produce hairball-like structures\\nthat neither aid in understanding the graph's topology nor the relationship to\\nits attributes. The aim of this research was to investigate the use of\\nnode-attributes for graph layout in order to improve the analysis process and\\nto give further insight into the graph over purely topological layouts. In this\\narticle we present graphTPP, a graph based extension to targeted projection\\npursuit (TPP) --- an interactive, linear, dimension reduction technique --- as\\na method for graph layout and subsequent further analysis. TPP allows users to\\ncontrol the projection and is optimised for clustering. Three case studies were\\nconducted in the areas of influence graphs, network security, and citation\\nnetworks. In each case graphTPP was shown to outperform standard force-directed\\ntechniques and even other dimension reduction methods in terms of clarity of\\nclustered structure in the layout, the association between the structure and\\nthe attributes and the insights elicited in each domain area.\\n\"\n",
      " '  We study light propagation through a slab of cold gas using both the standard\\nelectrodynamics of polarizable media, and massive atom-by-atom simulations of\\nthe electrodynamics. The main finding is that the predictions from the two\\nmethods may differ qualitatively when the density of the atomic sample $\\\\rho$\\nand the wavenumber of resonant light $k$ satisfy $\\\\rho k^{-3}\\\\gtrsim 1$. The\\nreason is that the standard electrodynamics is a mean-field theory, whereas for\\nsufficiently strong light-mediated dipole-dipole interactions the atomic sample\\nbecomes correlated. The deviations from mean-field theory appear to scale with\\nthe parameter $\\\\rho k^{-3}$, and we demonstrate noticeable effects already at\\n$\\\\rho k^{-3} \\\\simeq 10^{-2}$. In dilute gases and in gases with an added\\ninhomogeneous broadening the simulations show shifts of the resonance lines in\\nqualitative agreement with the predicted Lorentz-Lorenz shift and \"cooperative\\nLamb shift\", but the quantitative agreement is unsatisfactory. Our\\ninterpretation is that the microscopic basis for the local-field corrections in\\nelectrodynamics is not fully understood.\\n'\n",
      " '  Big data has shown its uniquely powerful ability to reveal, model, and\\nunderstand driver behaviors. The amount of data affects the experiment cost and\\nconclusions in the analysis. Insufficient data may lead to inaccurate models\\nwhile excessive data waste resources. For projects that cost millions of\\ndollars, it is critical to determine the right amount of data needed. However,\\nhow to decide the appropriate amount has not been fully studied in the realm of\\ndriver behaviors. This paper systematically investigates this issue to estimate\\nhow much naturalistic driving data (NDD) is needed for understanding driver\\nbehaviors from a statistical point of view. A general assessment method is\\nproposed using a Gaussian kernel density estimation to catch the underlying\\ncharacteristics of driver behaviors. We then apply the Kullback-Liebler\\ndivergence method to measure the similarity between density functions with\\ndiffering amounts of NDD. A max-minimum approach is used to compute the\\nappropriate amount of NDD. To validate our proposed method, we investigated the\\ncar-following case using NDD collected from the University of Michigan Safety\\nPilot Model Deployment (SPMD) program. We demonstrate that from a statistical\\nperspective, the proposed approach can provide an appropriate amount of NDD\\ncapable of capturing most features of the normal car-following behavior, which\\nis consistent with the experiment settings in many literatures.\\n'\n",
      " '  We theoretically discuss why deep neural networks (DNNs) performs better than\\nother models in some cases by investigating statistical properties of DNNs for\\nnon-smooth functions. While DNNs have empirically shown higher performance than\\nother standard methods, understanding its mechanism is still a challenging\\nproblem. From an aspect of the statistical theory, it is known many standard\\nmethods attain the optimal rate of generalization errors for smooth functions\\nin large sample asymptotics, and thus it has not been straightforward to find\\ntheoretical advantages of DNNs. This paper fills this gap by considering\\nlearning of a certain class of non-smooth functions, which was not covered by\\nthe previous theory. We derive the generalization error of estimators by DNNs\\nwith a ReLU activation, and show that convergence rates of the generalization\\nby DNNs are almost optimal to estimate the non-smooth functions, while some of\\nthe popular models do not attain the optimal rate. In addition, our theoretical\\nresult provides guidelines for selecting an appropriate number of layers and\\nedges of DNNs. We provide numerical experiments to support the theoretical\\nresults.\\n'\n",
      " '  Large-scale collaborative analysis of brain imaging data, in psychiatry and\\nneu-rology, offers a new source of statistical power to discover features that\\nboost ac-curacy in disease classification, differential diagnosis, and outcome\\nprediction. However, due to data privacy regulations or limited accessibility\\nto large datasets across the world, it is challenging to efficiently integrate\\ndistributed information. Here we propose a novel classification framework\\nthrough multi-site weighted LASSO: each site performs an iterative weighted\\nLASSO for feature selection separately. Within each iteration, the\\nclassification result and the selected features are collected to update the\\nweighting parameters for each feature. This new weight is used to guide the\\nLASSO process at the next iteration. Only the fea-tures that help to improve\\nthe classification accuracy are preserved. In tests on da-ta from five sites\\n(299 patients with major depressive disorder (MDD) and 258 normal controls),\\nour method boosted classification accuracy for MDD by 4.9% on average. This\\nresult shows the potential of the proposed new strategy as an ef-fective and\\npractical collaborative platform for machine learning on large scale\\ndistributed imaging and biobank data.\\n'\n",
      " '  It is already known that the Cesàro matrices of orders one and two are\\ncoposinormal, hyponormal operators on $\\\\ell^2$. Here it is shown that the\\nCesàro matrices of order three and four are also coposinormal, hyponormal;\\nthe proofs employ posinormality, achieved by means of a diagonal interrupter,\\nand elementary computational techniques from calculus. A conjecture is then\\npropounded for the Cesàro matrix of positive integer order greater than\\nfour.\\n'\n",
      " '  We consider an energy harvesting communication system where the temperature\\ndynamics is governed by the transmission power policy. Different from the\\nprevious work, we consider a discrete time system where transmission power is\\nkept constant in each slot. We consider two models that capture different\\neffects of temperature. In the first model, the temperature is constrained to\\nbe below a critical temperature at all time instants; we coin this model as\\nexplicit temperature constrained model. We investigate throughput optimal power\\nallocation for multiple energy arrivals under general, as well as temperature\\nand energy limited regimes. We show that the optimal power allocation for the\\ntemperature limited case is monotone decreasing. In the second model, we\\nconsider the effect of the temperature on the channel quality via its influence\\non additive noise power; we coin this model as implicit temperature constrained\\nmodel. In this model, the change in the variance of the additive noise due to\\nprevious transmissions is non-negligible. In particular, transmitted signals\\ncontribute as interference for all subsequent slots and thus affect the signal\\nto interference plus noise ratio (SINR). In this case, we investigate\\nthroughput optimal power allocation under general, as well as low and high SINR\\nregimes. We show in the low SINR regime that the optimal allocation dictates\\nthe transmitter to save its harvested energy till the last slot. In the high\\nSINR regime, we show that the optimal power sequence is monotone increasing.\\nFinally, we consider the case in which implicit and explicit temperature\\nconstraints are simultaneously active and we show under certain conditions that\\nthe optimal power sequence is monotone decreasing.\\n'\n",
      " '  Consider an experiment involving a potentially small number of subjects. Some\\nrandom variables are observed on each subject: a high-dimensional one called\\nthe \"observed\" random variable, and a one-dimensional one called the \"outcome\"\\nrandom variable. We are interested in the dependencies between the observed\\nrandom variable and the outcome random variable. We propose a method to\\nquantify and validate the dependencies of the outcome random variable on the\\nvarious patterns contained in the observed random variable. Different degrees\\nof relationship are explored (linear, quadratic, cubic, ...). This work is\\nmotivated by the need to analyze educational data, which often involves\\nhigh-dimensional data representing a small number of students. Thus our\\nimplementation is designed for a small number of subjects; however, it can be\\neasily modified to handle a very large dataset. As an illustration, the\\nproposed method is used to study the influence of certain skills on the course\\ngrade of students in a signal processing class. A valid dependency of the grade\\non the different skill patterns is observed in the data.\\n'\n",
      " '  Sentence simplification aims to make sentences easier to read and understand.\\nMost recent approaches draw on insights from machine translation to learn\\nsimplification rewrites from monolingual corpora of complex and simple\\nsentences. We address the simplification problem with an encoder-decoder model\\ncoupled with a deep reinforcement learning framework. Our model, which we call\\n{\\\\sc Dress} (as shorthand for {\\\\bf D}eep {\\\\bf RE}inforcement {\\\\bf S}entence\\n{\\\\bf S}implification), explores the space of possible simplifications while\\nlearning to optimize a reward function that encourages outputs which are\\nsimple, fluent, and preserve the meaning of the input. Experiments on three\\ndatasets demonstrate that our model outperforms competitive simplification\\nsystems.\\n'\n",
      " '  In this manuscript, we demonstrate the ability of nonlinear light-atom\\ninteractions to produce tunably non-Gaussian, partially self-healing optical\\nmodes. Gaussian spatial-mode light tuned near to the atomic resonances in hot\\nrubidium vapor is shown to result in non-Gaussian output mode structures that\\nmay be controlled by varying either the input beam power or the temperature of\\nthe atomic vapor. We show that the output modes exhibit a degree of\\nself-reconstruction after encountering an obstruction in the beam path. The\\nresultant modes are similar to truncated Bessel-Gauss modes that exhibit the\\nability to self-reconstruct earlier upon propagation than Gaussian modes. The\\nability to generate tunable, self-reconstructing beams has potential\\napplications to a variety of imaging and communication scenarios.\\n'\n",
      " '  In this work we establish the first linear convergence result for the\\nstochastic heavy ball method. The method performs SGD steps with a fixed\\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\\nminimizing the expected loss and not on finite-sum minimization, which is\\ntypically a much harder problem. While in the analysis we constrain ourselves\\nto quadratic loss, the overall objective is not necessarily strongly convex.\\n'\n",
      " '  Many problems in computational science and engineering are simultaneously\\ncharacterized by the following challenging issues: uncertainty, nonlinearity,\\nnonstationarity and high dimensionality. Existing numerical techniques for such\\nmodels would typically require considerable computational and storage\\nresources. This is the case, for instance, for an optimization problem governed\\nby time-dependent Navier-Stokes equations with uncertain inputs. In particular,\\nthe stochastic Galerkin finite element method often leads to a prohibitively\\nhigh dimensional saddle-point system with tensor product structure. In this\\npaper, we approximate the solution by the low-rank Tensor Train decomposition,\\nand present a numerically efficient algorithm to solve the optimality equations\\ndirectly in the low-rank representation. We show that the solution of the\\nvorticity minimization problem with a distributed control admits a\\nrepresentation with ranks that depend modestly on model and discretization\\nparameters even for high Reynolds numbers. For lower Reynolds numbers this is\\nalso the case for a boundary control. This opens the way for a reduced-order\\nmodeling of the stochastic optimal flow control with a moderate cost at all\\nstages.\\n'\n",
      " '  We propose a method to generate multiple diverse and valid human pose\\nhypotheses in 3D all consistent with the 2D detection of joints in a monocular\\nRGB image. We use a novel generative model uniform (unbiased) in the space of\\nanatomically plausible 3D poses. Our model is compositional (produces a pose by\\ncombining parts) and since it is restricted only by anatomical constraints it\\ncan generalize to every plausible human 3D pose. Removing the model bias\\nintrinsically helps to generate more diverse 3D pose hypotheses. We argue that\\ngenerating multiple pose hypotheses is more reasonable than generating only a\\nsingle 3D pose based on the 2D joint detection given the depth ambiguity and\\nthe uncertainty due to occlusion and imperfect 2D joint detection. We hope that\\nthe idea of generating multiple consistent pose hypotheses can give rise to a\\nnew line of future work that has not received much attention in the literature.\\nWe used the Human3.6M dataset for empirical evaluation.\\n'\n",
      " '  Mechanical or electromechanical amplifiers can exploit the high-Q and low\\nnoise features of mechanical resonance, in particular when parametric\\nexcitation is employed. Multi-frequency parametric excitation introduces\\ntunability and is able to project weak input signals on a selected resonance.\\nThe present paper addresses multi degree of freedom mechanical amplifiers or\\nresonators whose analysis and features require treatment of the spatial as well\\nas temporal behavior. In some cases, virtual electronic coupling can alter the\\ngiven topology of the resonator to better amplify specific inputs. An\\nanalytical development is followed by a numerical and experimental sensitivity\\nand performance verifications, illustrating the advantages and disadvantages of\\nsuch topologies.\\n'\n",
      " '  In this paper, we analyze and compare three of the many algebraic structures\\nthat have been used for modeling dependent type theories: categories with\\nfamilies, split type-categories, and representable maps of presheaves. We study\\nthese in univalent type theory, where the comparisons between them can be given\\nmore elementarily than in set-theoretic foundations. Specifically, we construct\\nmaps between the various types of structures, and show that assuming the\\nUnivalence axiom, some of the comparisons are equivalences.\\nWe then analyze how these structures transfer along (weak and strong)\\nequivalences of categories, and, in particular, show how they descend from a\\ncategory (not assumed univalent/saturated) to its Rezk completion. To this end,\\nwe introduce relative universes, generalizing the preceding notions, and study\\nthe transfer of such relative universes along suitable structure.\\nWe work throughout in (intensional) dependent type theory; some results, but\\nnot all, assume the univalence axiom. All the material of this paper has been\\nformalized in Coq, over the UniMath library.\\n'\n",
      " \"  The spin-phonon interaction is the dominant process for spin relaxation in\\nSi, and as thermal transport in Si is dominated by phonons, one would expect\\nspin polarization to influence Si's thermal conductivity. Here we report the\\nexperimental evidence of just such a coupling. We have performed concurrent\\nmeasurements of spin, charge, and phonon transport in p-doped Si across a wide\\nrange of temperatures. In an experimental system of a freestanding two um p-Si\\nbeam coated on one side with a thin (25 nm) ferromagnetic spin injection layer,\\nwe use the self-heating 3 omega method to measure changes in electrical and\\nthermal conductivity under the influence of a magnetic field. These\\nmagneto-thermal transport measurements reveal signatures in the variation of\\nelectrical and thermal transport that are consistent with spin-phonon\\ninteraction. Raman spectroscopy measurements and first principle's calculations\\nsupport that these variations are due to spin-phonon interaction. Spin\\npolarization leads to softening of phonon modes, a reduction in the group\\nvelocity of acoustic modes, and a subsequent decrease in thermal conductivity\\nat room temperature. Moreover, magneto-thermal transport measurements as a\\nfunction of temperature indicate a change in the spin-phonon relaxation\\nbehavior at low temperature.\\n\"\n",
      " '  We prove the existence and the linear stability of Cantor families of small\\namplitude time quasi-periodic standing water wave solutions - namely periodic\\nand even in the space variable x - of a bi-dimensional ocean with finite depth\\nunder the action of pure gravity. Such a result holds for all the values of the\\ndepth parameter in a Borel set of asymptotically full measure. This is a small\\ndivisor problem. The main difficulties are the quasi-linear nature of the\\ngravity water waves equations and the fact that the linear frequencies grow\\njust in a sublinear way at infinity. We overcome these problems by first\\nreducing the linearized operators obtained at each approximate quasi-periodic\\nsolution along the Nash-Moser iteration to constant coefficients up to\\nsmoothing operators, using pseudo-differential changes of variables that are\\nquasi-periodic in time. Then we apply a KAM reducibility scheme which requires\\nvery weak Melnikov non-resonance conditions (losing derivatives both in time\\nand space), which we are able to verify for most values of the depth parameter\\nusing degenerate KAM theory arguments.\\n'\n",
      " '  Let $\\\\Omega\\\\subset{\\\\mathbb R}^n$ be a relatively compact domain. A finite\\ncollection of real-valued functions on $\\\\Omega$ is called a \\\\emph{Noetherian\\nchain} if the partial derivatives of each function are expressible as\\npolynomials in the functions. A \\\\emph{Noetherian function} is a polynomial\\ncombination of elements of a Noetherian chain. We introduce \\\\emph{Noetherian\\nparameters} (degrees, size of the coefficients) which measure the complexity of\\na Noetherian chain. Our main result is an explicit form of the Pila-Wilkie\\ntheorem for sets defined using Noetherian equalities and inequalities: for any\\n$\\\\epsilon>0$, the number of points of height $H$ in the transcendental part of\\nthe set is at most $C\\\\cdot H^{\\\\epsilon}$ where $C$ can be \\\\emph{explicitly}\\nestimated from the Noetherian parameters and $\\\\epsilon$.\\nWe show that many functions of interest in arithmetic geometry fall within\\nthe Noetherian class, including elliptic and abelian functions, modular\\nfunctions and universal covers of compact Riemann surfaces, Jacobi theta\\nfunctions, periods of algebraic integrals, and the uniformizing map of the\\nSiegel modular variety $\\\\mathcal{A}_g$. We thus effectivize the (geometric side\\nof) Pila-Zannier strategy for unlikely intersections in those instances that\\ninvolve only compact domains.\\n'\n",
      " '  We present a detailed analysis of the white dwarf luminosity functions\\nderived from the local 40 pc sample and the deep proper motion catalog of Munn\\net al (2014, 2017). Many of the previous studies ignored the contribution of\\nthick disk white dwarfs to the Galactic disk luminosity function, which results\\nin an erronous age measurement. We demonstrate that the ratio of thick/thin\\ndisk white dwarfs is roughly 20\\\\% in the local sample. Simultaneously fitting\\nfor both disk components, we derive ages of 6.8-7.0 Gyr for the thin disk and\\n8.7 $\\\\pm$ 0.1 Gyr for the thick disk from the local 40 pc sample. Similarly, we\\nderive ages of 7.4-8.2 Gyr for the thin disk and 9.5-9.9 Gyr for the thick disk\\nfrom the deep proper motion catalog, which shows no evidence of a deviation\\nfrom a constant star formation rate in the past 2.5 Gyr. We constrain the time\\ndifference between the onset of star formation in the thin disk and the thick\\ndisk to be $1.6^{+0.3}_{-0.4}$ Gyr. The faint end of the luminosity function\\nfor the halo white dwarfs is less constrained, resulting in an age estimate of\\n$12.5^{+1.4}_{-3.4}$ Gyr for the Galactic inner halo. This is the first time\\nages for all three major components of the Galaxy are obtained from a sample of\\nfield white dwarfs that is large enough to contain significant numbers of disk\\nand halo objects. The resultant ages agree reasonably well with the age\\nestimates for the oldest open and globular clusters.\\n'\n",
      " '  A novel deep learning architecture (XmasNet) based on convolutional neural\\nnetworks was developed for the classification of prostate cancer lesions, using\\nthe 3D multiparametric MRI data provided by the PROSTATEx challenge. End-to-end\\ntraining was performed for XmasNet, with data augmentation done through 3D\\nrotation and slicing, in order to incorporate the 3D information of the lesion.\\nXmasNet outperformed traditional machine learning models based on engineered\\nfeatures, for both train and test data. For the test data, XmasNet outperformed\\n69 methods from 33 participating groups and achieved the second highest AUC\\n(0.84) in the PROSTATEx challenge. This study shows the great potential of deep\\nlearning for cancer imaging.\\n'\n",
      " '  Payments architectures are on the verge of a great bifurcation that must be\\ndocumented in order to be debated. Google is moving towards a quasi bank while\\nApple and Google disseminate payment systems over smartphones. At the same\\ntime, block chain might become a distributed ledger introducing a radical new\\nmodel of trusted third-party. The detailed history of credit card systems helps\\nunderstand why the game of security has always been trigged by a delegation\\nprocess of the risk to third parties and by the cat-and-mouse game of security\\nand fraud. Technologies were designed to solve these issues but have always\\nbeen closely related to innovations in institutional assemblages. These\\npayments systems shape our social life and the stakes of trust that we put in\\nthese architectures require a truly political examination.\\n'\n",
      " \"  Social ties are the invisible glue that keeps together human ecosystems.\\nDespite the massive amount of research studying the role of social ties in\\ncommunities (groups, teams, etc.) and society at large, little attention has\\nbeen devoted to study their interplay with other human behavioral dynamics. Of\\nparticular interest is the influence that social ties have on human performance\\nin collaborative team-based settings. Our research aims to elucidate the\\ninfluence of social ties on individual and team performance dynamics. We will\\nfocus on a popular Multiplayer Online Battle Arena (MOBA) collaborative\\nteam-based game, Defense of the Ancients 2 (Dota 2), a rich dataset with\\nmillions of players and matches. Our research reveals that, when playing with\\ntheir friends, individuals are systematically more active in the game as\\nopposed to taking part in a team of strangers. However, we find that increased\\nactivity does not homogeneously lead to an improvement in players' performance.\\nDespite being beneficial to low skill players, playing with friends negatively\\naffects performance of high skill players. Our findings shed light on the mixed\\ninfluence of social ties on performance, and can inform new perspectives on\\nvirtual team management and on behavioral incentives.\\n\"\n",
      " \"  This paper is devoted to study multiplicity and regularity as well as to\\npresent some classifications of complex analytic sets. We present an\\nequivalence for complex analytical sets, namely blow-spherical equivalence and\\nwe receive several applications with this new approach. For example, we reduce\\nto homogeneous complex algebraic sets a version of Zariski's multiplicity\\nconjecture in the case of blow-spherical homeomorphism, we give some partial\\nanswers to the Zariski's multiplicity conjecture, we show that a blow-spherical\\nregular complex analytic set is smooth and we give a complete classification of\\ncomplex analytic curves.\\n\"\n",
      " '  Laboratory spectral measurements of relevant analogue materials were\\nperformed in the framework of the Rosetta mission in order to explain the\\nsurface spectral properties of comet 67P. Fine powders of coal, iron sulphides,\\nsilicates and their mixtures were prepared and their spectra measured in the\\nVis-IR range. These spectra are compared to a reference spectrum of 67P nucleus\\nobtained with the VIRTIS/Rosetta instrument up to 2.7 {\\\\mu}m, excluding the\\norganics band centred at 3.2 {\\\\mu}m. The species used are known to be chemical\\nanalogues for cometary materials which could be present at the surface of 67P.\\nGrain sizes of the powders range from tens of nanometres to hundreds of\\nmicrometres. Some of the mixtures studied here actually reach the very low\\nreflectance level observed by VIRTIS on 67P. The best match is provided by a\\nmixture of sub-micron coal, pyrrhotite, and silicates. Grain sizes are in\\nagreement with the sizes of the dust particles detected by the GIADA, MIDAS and\\nCOSIMA instruments on board Rosetta. The coal used in the experiment is\\nresponsible for the spectral slope in the visible and infrared ranges.\\nPyrrhotite, which is strongly absorbing, is responsible for the low albedo\\nobserved in the NIR. The darkest components dominate the spectra, especially\\nwithin intimate mixtures. Depending on sample preparation, pyrrhotite can coat\\nthe coal and silicate aggregates. Such coating effects can affect the spectra\\nas much as particle size. In contrast, silicates seem to play a minor role.\\n'\n",
      " '  Real world programming languages crucially depend on the availability of\\ncomputational effects to achieve programming convenience and expressive power\\nas well as program efficiency. Logical frameworks rely on predicates, or\\ndependent types, to express detailed logical properties about entities.\\nAccording to the Curry-Howard correspondence, programming languages and logical\\nframeworks should be very closely related. However, a language that has both\\ngood support for real programming and serious proving is still missing from the\\nprogramming languages zoo. We believe this is due to a fundamental lack of\\nunderstanding of how dependent types should interact with computational\\neffects. In this thesis, we make a contribution towards such an understanding,\\nwith a focus on semantic methods.\\n'\n",
      " '  The security of several post-quantum cryptosystems is based on the assumption\\nthat solving a system of multivariate (quadratic) polynomial equations\\n$p_1=\\\\dots=p_r=0$ over a finite field is hard. Such a system can be solved by\\ncomputing a lexicographic Gröbner basis of the ideal $(p_1,\\\\dots,p_r)$. The\\nmost efficient algorithms for computing Gröbner bases transform the problem\\ninto several instances of Gaussian elimination. The computational complexity of\\nthese algorithms is not completely understood, especially when the polynomials\\n$p_1,\\\\dots,p_r$ are not homogeneous. In this paper, we prove that this\\ncomplexity is controlled by the Castelnuovo-Mumford regularity of the ideal\\n$(p_1^h,\\\\dots,p_r^h)$ obtained by homogenizing the input polynomials. This\\nallows us to bound the complexity of solving a system of polynomial equations\\nwhen the associated ideal is zero-dimensional, a common situation in\\ncryptography. In combination with some theorems in commutative algebra, our\\nresults also allow us to bound the complexity of the ABC and cubic simple\\nmatrix schemes, as well as some instances of the MinRank Problem.\\n'\n",
      " '  Scientists are increasingly turning to datacenter-scale computers to produce\\nand analyze massive arrays. Despite decades of database research that extols\\nthe virtues of declarative query processing, scientists still write, debug and\\nparallelize imperative HPC kernels even for the most mundane queries. This\\nimpedance mismatch has been partly attributed to the cumbersome data loading\\nprocess; in response, the database community has proposed in situ mechanisms to\\naccess data in scientific file formats. Scientists, however, desire more than a\\npassive access method that reads arrays from files.\\nThis paper describes ArrayBridge, a bi-directional array view mechanism for\\nscientific file formats, that aims to make declarative array manipulations\\ninteroperable with imperative file-centric analyses. Our prototype\\nimplementation of ArrayBridge uses HDF5 as the underlying array storage library\\nand seamlessly integrates into the SciDB open-source array database system. In\\naddition to fast querying over external array objects, ArrayBridge produces\\narrays in the HDF5 file format just as easily as it can read from it.\\nArrayBridge also supports time travel queries from imperative kernels through\\nthe unmodified HDF5 API, and automatically deduplicates between array versions\\nfor space efficiency. Our extensive performance evaluation in NERSC, a\\nlarge-scale scientific computing facility, shows that ArrayBridge exhibits\\nstatistically indistinguishable performance and I/O scalability to the native\\nSciDB storage engine.\\n'\n",
      " '  Trans-dimensional random field language models (TRF LMs) where sentences are\\nmodeled as a collection of random fields, have shown close performance with\\nLSTM LMs in speech recognition and are computationally more efficient in\\ninference. However, the training efficiency of neural TRF LMs is not\\nsatisfactory, which limits the scalability of TRF LMs on large training corpus.\\nIn this paper, several techniques on both model formulation and parameter\\nestimation are proposed to improve the training efficiency and the performance\\nof neural TRF LMs. First, TRFs are reformulated in the form of exponential\\ntilting of a reference distribution. Second, noise-contrastive estimation (NCE)\\nis introduced to jointly estimate the model parameters and normalization\\nconstants. Third, we extend the neural TRF LMs by marrying the deep\\nconvolutional neural network (CNN) and the bidirectional LSTM into the\\npotential function to extract the deep hierarchical features and\\nbidirectionally sequential features. Utilizing all the above techniques enables\\nthe successful and efficient training of neural TRF LMs on a 40x larger\\ntraining set with only 1/3 training time and further reduces the WER with\\nrelative reduction of 4.7% on top of a strong LSTM LM baseline.\\n'\n",
      " '  In this paper we first identify a basic limitation in gradient descent-based\\noptimization methods when used in conjunctions with smooth kernels. An analysis\\nbased on the spectral properties of the kernel demonstrates that only a\\nvanishingly small portion of the function space is reachable after a polynomial\\nnumber of gradient descent iterations. This lack of approximating power\\ndrastically limits gradient descent for a fixed computational budget leading to\\nserious over-regularization/underfitting. The issue is purely algorithmic,\\npersisting even in the limit of infinite data.\\nTo address this shortcoming in practice, we introduce EigenPro iteration,\\nbased on a preconditioning scheme using a small number of approximately\\ncomputed eigenvectors. It can also be viewed as learning a new kernel optimized\\nfor gradient descent. It turns out that injecting this small (computationally\\ninexpensive and SGD-compatible) amount of approximate second-order information\\nleads to major improvements in convergence. For large data, this translates\\ninto significant performance boost over the standard kernel methods. In\\nparticular, we are able to consistently match or improve the state-of-the-art\\nresults recently reported in the literature with a small fraction of their\\ncomputational budget.\\nFinally, we feel that these results show a need for a broader computational\\nperspective on modern large-scale learning to complement more traditional\\nstatistical and convergence analyses. In particular, many phenomena of\\nlarge-scale high-dimensional inference are best understood in terms of\\noptimization on infinite dimensional Hilbert spaces, where standard algorithms\\ncan sometimes have properties at odds with finite-dimensional intuition. A\\nsystematic analysis concentrating on the approximation power of such algorithms\\nwithin a budget of computation may lead to progress both in theory and\\npractice.\\n'\n",
      " '  We present the first paper of a series focused on the Blazhko effect in RR\\nLyrae type stars pulsating in the fundamental mode, that are located in the\\nGalactic bulge. A~comprehensive overview about the incidence rate and\\nlight-curve characteristics of the Blazhko stars is given. We analysed 8\\\\,282\\nstars having the best quality data in the OGLE-IV survey, and found that at\\nleast $40.3$\\\\,\\\\% of stars show modulation of their light curves. The number of\\nBlazhko stars we identified is 3\\\\,341, which is the largest sample ever studied\\nimplying the most relevant statistical results currently available. Using\\ncombined data sets with OGLE-III observations, we found that 50\\\\,\\\\% of stars\\nthat show unresolved close peaks to the main component in OGLE-IV are actually\\nBlazhko stars with extremely long periods. Blazhko stars with modulation occur\\npreferentially among RR Lyrae stars with shorter pulsation periods in the\\nGalactic bulge. Fourier amplitude and phase coefficients based on the mean\\nlight curves appear to be substantially lower for Blazhko stars than for stars\\nwith unmodulated light curve in average. We derived new relations for the\\ncompatibility parameter $D_{m}$ in $I$ passband and relations that allow for\\ndifferentiating modulated and non-modulated stars easily on the basis of\\n$R_{31}$, $\\\\phi_{21}$ and $\\\\phi_{31}$. Photometric metallicities, intrinsic\\ncolours and absolute magnitudes computed using empirical relations are the same\\nfor Blazhko and non-modulated stars in the Galactic bulge suggesting no\\ncorrelation between the occurrence of the Blazhko effect and these parameters.\\n'\n",
      " \"  An autonomous and resilient controller is proposed for leader-follower\\nmulti-agent systems under uncertainties and cyber-physical attacks. The leader\\nis assumed non-autonomous with a nonzero control input, which allows changing\\nthe team behavior or mission in response to environmental changes. A resilient\\nlearning-based control protocol is presented to find optimal solutions to the\\nsynchronization problem in the presence of attacks and system dynamic\\nuncertainties. An observer-based distributed H_infinity controller is first\\ndesigned to prevent propagating the effects of attacks on sensors and actuators\\nthroughout the network, as well as to attenuate the effect of these attacks on\\nthe compromised agent itself. Non-homogeneous game algebraic Riccati equations\\nare derived to solve the H_infinity optimal synchronization problem and\\noff-policy reinforcement learning is utilized to learn their solution without\\nrequiring any knowledge of the agent's dynamics. A trust-confidence based\\ndistributed control protocol is then proposed to mitigate attacks that hijack\\nthe entire node and attacks on communication links. A confidence value is\\ndefined for each agent based solely on its local evidence. The proposed\\nresilient reinforcement learning algorithm employs the confidence value of each\\nagent to indicate the trustworthiness of its own information and broadcast it\\nto its neighbors to put weights on the data they receive from it during and\\nafter learning. If the confidence value of an agent is low, it employs a trust\\nmechanism to identify compromised agents and remove the data it receives from\\nthem from the learning process. Simulation results are provided to show the\\neffectiveness of the proposed approach.\\n\"\n",
      " '  It is demonstrated that non-coalescent droplets of acetone can be formed on\\nliquid substrates. The fluid flows around and in an acetone droplet hovering on\\nwater are recorded to shed light on the mechanisms which might lead to\\nnon-coalescence. For sufficiently low impact velocities, droplets undergo a\\ndamped oscillation on the surface of the liquid substrate but at higher\\nvelocities clean bounce-off occurs. Comparisons of experimentally observed\\nstatic configurations of floating droplets to predictions from a theoretical\\nmodel for a small non-wetting rigid sphere resting on a liquid substrate are\\nmade and a tentative strategy for determining the thickness of the vapor layer\\nunder a small droplet on a liquid is proposed. This strategy is based on the\\nnotion of effective surface tension. The droplets show self-propulsion in\\nstraight line trajectories in a manner which can be ascribed to a Marangoni\\neffect. Surprisingly, self-propelled droplets can become immersed beneath the\\nundisturbed water surface. This phenomenon is reasoned to be drag-inducing and\\nmight provide a basis for refining observations in previous work.\\n'\n",
      " '  In this note we show that the union of $r$ general lines and one fat line in\\n${\\\\mathbb P}^3$ imposes independent conditions on forms of sufficiently high\\ndegree $d$, where the bound on $d$ is independent of the number of lines. This\\nextends former results of Hartshorne and Hirschowitz on unions of general\\nlines, and of Aladpoosh on unions of general lines and one double line.\\n'\n",
      " '  With the advent of automated machine learning, automated hyperparameter\\noptimization methods are by now routinely used in data mining. However, this\\nprogress is not yet matched by equal progress on automatic analyses that yield\\ninformation beyond performance-optimizing hyperparameter settings. In this\\nwork, we aim to answer the following two questions: Given an algorithm, what\\nare generally its most important hyperparameters, and what are typically good\\nvalues for these? We present methodology and a framework to answer these\\nquestions based on meta-learning across many datasets. We apply this\\nmethodology using the experimental meta-data available on OpenML to determine\\nthe most important hyperparameters of support vector machines, random forests\\nand Adaboost, and to infer priors for all their hyperparameters. The results,\\nobtained fully automatically, provide a quantitative basis to focus efforts in\\nboth manual algorithm design and in automated hyperparameter optimization. The\\nconducted experiments confirm that the hyperparameters selected by the proposed\\nmethod are indeed the most important ones and that the obtained priors also\\nlead to statistically significant improvements in hyperparameter optimization.\\n'\n",
      " '  \"Hot super-Earths\" (or \"Mini-Neptunes\") between 1 and 4 times Earth\\'s size\\nwith period shorter than 100 days orbit 30-50\\\\% of Sun-like type stars. Their\\norbital configuration -- measured as the period ratio distribution of adjacent\\nplanets in multi-planet systems -- is a strong constraint for formation models.\\nHere we use N-body simulations with synthetic forces from an underlying\\nevolving gaseous disk to model the formation and long-term dynamical evolution\\nof super-Earth systems. While the gas disk is present, planetary embryos grow\\nand migrate inward to form a resonant chain anchored at the inner edge of the\\ndisk. These resonant chains are far more compact than the observed super-Earth\\nsystems. Once the gas dissipates resonant chains may become dynamically\\nunstable. They undergo a phase of giant impacts that spreads the systems out.\\nDisk turbulence has no measurable effect on the outcome. Our simulations match\\nobservations if a small fraction of resonant chains remain stable, while most\\nsuper-Earths undergo a late dynamical instability. Our statistical analysis\\nrestricts the contribution of stable systems to less than $25\\\\%$. Our results\\nalso suggest that the large fraction of observed single planet systems does not\\nnecessarily imply any dichotomy in the architecture of planetary systems.\\nFinally, we use the low abundance of resonances in Kepler data to argue that,\\nin reality, the survival of resonant chains happens likely only in $\\\\sim 5\\\\%$\\nof the cases. This leads to a mystery: in our simulations only 50-60\\\\% of\\nresonant chains became unstable whereas at least 75\\\\% (and probably 90-95\\\\%)\\nmust be unstable to match observations.\\n'\n",
      " '  We present a new technique for demonstrating the reachability of states in\\ndeterministic finite automata representing the concatenation of two languages.\\nSuch demonstrations are a necessary step in establishing the state complexity\\nof the concatenation of two languages, and thus in establishing the state\\ncomplexity of concatenation as an operation. Typically, ad-hoc induction\\narguments are used to show particular states are reachable in concatenation\\nautomata. We prove some results that seem to capture the essence of many of\\nthese induction arguments. Using these results, reachability proofs in\\nconcatenation automata can often be done more simply and without using\\ninduction directly.\\n'\n",
      " '  Smartphones are a popular device class for mobile Augmented Reality but\\nsuffer from a limited input space. Around-device interaction techniques aim at\\nextending this input space using various sensing modalities. In this paper we\\npresent our work towards extending the input area of mobile devices using\\nfront-facing device-centered cameras that capture reflections in the cornea. As\\ncurrent generation mobile devices lack high resolution front-facing cameras, we\\nstudy the feasibility of around-device interaction using corneal reflective\\nimaging based on a high resolution camera. We present a workflow, a technical\\nprototype and a feasibility evaluation.\\n'\n",
      " '  We present {\\\\it block analysis}, an efficient method to perform finite-size\\nscaling for obtaining the length scale of dynamic heterogeneity and the\\npoint-to-set length scale for generic glass-forming liquids. This method\\ninvolves considering blocks of varying sizes embedded in a system of a fixed\\n(large) size. The length scale associated with dynamic heterogeneity is\\nobtained from a finite-size scaling analysis of the dependence of the\\nfour-point dynamic susceptibility on the block size. The block size dependence\\nof the variance of the $\\\\alpha$-relaxation time yields the static point-to-set\\nlength scale. The values of the obtained length scales agree quantitatively\\nwith those obtained from other conventional methods. This method provides an\\nefficient experimental tool for studying the growth of length scales in systems\\nsuch as colloidal glasses for which performing finite-size scaling by carrying\\nout experiments for varying system sizes may not be feasible.\\n'\n",
      " '  Autonomous robotic grasp plays an important role in intelligent robotics.\\nHowever, it is challenging due to: (1) robotic grasp is a comprehensive task\\ninvolving perception, planning and control; (2) autonomous robotic grasp in\\ncomplex scenarios requires reasoning ability. In this paper, we propose a\\nmulti-task convolutional neural network for Robotic Perception, Reasoning and\\nGrasping (RPRG), which can help robot find the target, make the plan for\\ngrasping and finally grasp the target step by step in object stacking scenes.\\nWe integrate vision-based robotic grasp detection and visual manipulation\\nrelationship reasoning in one single deep network and build the autonomous\\nrobotic grasp system. The proposed network has state-of-the-art performance in\\nboth tasks. Experiments demonstrate that with our model, Baxter robot can\\nautonomously grasp the target with a success rate of 94.2%, 77.1% and 62.5% in\\nobject cluttered scenes, familiar stacking scenes and complex stacking scenes\\nrespectively at a speed of 6.5 FPS for each detection.\\n'\n",
      " '  We revisit the classical problem of optimal experimental design (OED) under a\\nnew mathematical model grounded in a geometric motivation. Specifically, we\\nintroduce models based on elementary symmetric polynomials; these polynomials\\ncapture \"partial volumes\" and offer a graded interpolation between the widely\\nused A-optimal design and D-optimal design models, obtaining each of them as\\nspecial cases. We analyze properties of our models, and derive both greedy and\\nconvex-relaxation algorithms for computing the associated designs. Our analysis\\nestablishes approximation guarantees on these algorithms, while our empirical\\nresults substantiate our claims and demonstrate a curious phenomenon concerning\\nour greedy method. Finally, as a byproduct, we obtain new results on the theory\\nof elementary symmetric polynomials that may be of independent interest.\\n'\n",
      " '  Deep learning is finding its way into the embedded world with applications\\nsuch as autonomous driving, smart sensors and aug- mented reality. However, the\\ncomputation of deep neural networks is demanding in energy, compute power and\\nmemory. Various approaches have been investigated to reduce the necessary\\nresources, one of which is to leverage the sparsity occurring in deep neural\\nnetworks due to the high levels of redundancy in the network parameters. It has\\nbeen shown that sparsity can be promoted specifically and the achieved sparsity\\ncan be very high. But in many cases the methods are evaluated on rather small\\ntopologies. It is not clear if the results transfer onto deeper topologies. In\\nthis paper, the TensorQuant toolbox has been extended to offer a platform to\\ninvestigate sparsity, especially in deeper models. Several practical relevant\\ntopologies for varying classification problem sizes are investigated to show\\nthe differences in sparsity for activations, weights and gradients.\\n'\n",
      " '  We study the behavior of a fundamental tool in sparse statistical modeling\\n--the best-subset selection procedure (aka \"best-subsets\"). Assuming that the\\nunderlying linear model is sparse, it is well known, both in theory and in\\npractice, that the best-subsets procedure works extremely well in terms of\\nseveral statistical metrics (prediction, estimation and variable selection)\\nwhen the signal to noise ratio (SNR) is high. However, its performance degrades\\nsubstantially when the SNR is low -- it is outperformed in predictive accuracy\\nby continuous shrinkage methods, such as ridge regression and the Lasso. We\\nexplain why this behavior should not come as a surprise, and contend that the\\noriginal version of the classical best-subsets procedure was, perhaps, not\\ndesigned to be used in the low SNR regimes. We propose a close cousin of\\nbest-subsets, namely, its $\\\\ell_{q}$-regularized version, for $q \\\\in\\\\{1, 2\\\\}$,\\nwhich (a) mitigates, to a large extent, the poor predictive performance of\\nbest-subsets in the low SNR regimes; (b) performs favorably and generally\\ndelivers a substantially sparser model when compared to the best predictive\\nmodels available via ridge regression and the Lasso. Our estimator can be\\nexpressed as a solution to a mixed integer second order conic optimization\\nproblem and, hence, is amenable to modern computational tools from mathematical\\noptimization. We explore the theoretical properties of the predictive\\ncapabilities of the proposed estimator and complement our findings via several\\nnumerical experiments.\\n'\n",
      " '  This work presents a novel ensemble of Bayesian Neural Networks (BNNs) for\\ncontrol of safety-critical systems. Decision making for safety-critical systems\\nis challenging due to performance requirements with significant consequences in\\nthe event of failure. In practice, failure of such systems can be avoided by\\nintroducing redundancies of control. Neural Networks (NNs) are generally not\\nused for safety-critical systems as they can behave in unexpected ways in\\nresponse to novel inputs. In addition, there may not be any indication as to\\nwhen they will fail. BNNs have been recognized for their ability to produce not\\nonly viable outputs but also provide a measure of uncertainty in these outputs.\\nThis work combines the knowledge of prediction uncertainty obtained from BNNs\\nand ensemble control for a redundant control methodology. Our technique is\\napplied to an agile autonomous driving task. Multiple BNNs are trained to\\ncontrol a vehicle in an end-to-end fashion on different sensor inputs provided\\nby the system. We show that an individual network is successful in maneuvering\\naround the track but crashes in the presence of unforeseen input noise. Our\\nproposed ensemble of BNNs shows successful task performance even in the event\\nof multiple sensor failures.\\n'\n",
      " '  In this paper, we propose a robust profile estimation method for the\\nparametric and nonparametric components of a single index model when the errors\\nhave a strongly unimodal density with unknown nuisance parameter. Under\\nregularity conditions, we derive consistency results for the link function\\nestimators as well as consistency and asymptotic distribution results for the\\nsingle index parameter estimators. Under a log--Gamma model, the sensitivity to\\nanomalous observations is studied by means of the empirical influence curve. We\\nalso discuss a robust $K-$fold procedure to select the smoothing parameters\\ninvolved. A numerical study is conducted to evaluate the small sample\\nperformance of the robust proposal with that of their classical relatives, both\\nfor errors following a log--Gamma model and for contaminated schemes. The\\nnumerical experiment shows the good robustness properties of the proposed\\nestimators and the advantages of considering a robust approach instead of the\\nclassical one.\\n'\n",
      " '  Hippocampal dentate granule cells are among the few neuronal cell types\\ngenerated throughout adult life in mammals. In the normal brain, new granule\\ncells are generated from progenitors in the subgranular zone and integrate in a\\ntypical fashion. During the development of epilepsy, granule cell integration\\nis profoundly altered. The new cells migrate to ectopic locations and develop\\nmisoriented basal dendrites. Although it has been established that these\\nabnormal cells are newly generated, it is not known whether they arise\\nubiquitously throughout the progenitor cell pool or are derived from a smaller\\nnumber of bad actor progenitors. To explore this question, we conducted a\\nclonal analysis study in mice expressing the Brainbow fluorescent protein\\nreporter construct in dentate granule cell progenitors. Mice were examined 2\\nmonths after pilocarpine-induced status epilepticus, a treatment that leads to\\nthe development of epilepsy. Brain sections were rendered translucent so that\\nentire hippocampi could be reconstructed and all fluorescently labeled cells\\nidentified. Our findings reveal that a small number of progenitors produce the\\nmajority of ectopic cells following status epilepticus, indicating that either\\nthe affected progenitors or their local microenvironments have become\\npathological. By contrast, granule cells with basal dendrites were equally\\ndistributed among clonal groups. This indicates that these progenitors can\\nproduce normal cells and suggests that global factors sporadically disrupt the\\ndendritic development of some new cells. Together, these findings strongly\\npredict that distinct mechanisms regulate different aspects\\n'\n",
      " '  We show that time-resolved x-ray scattering from molecules prepared in a\\nsuperposition of electronic states moving through an avoided crossing has new\\nfeatures not found in diffraction from the corresponding classical mixed state.\\nPhotoabsorption in molecular iodine at 520 nm produces a superposition of two\\ndipole-allowed nearly degenerate electronic states, which interact due to\\nnon-adiabatic coupling. We show experimental evidence that the mixing of the\\nnuclear wavepackets from the two electronic states at the avoided crossing\\nleads to ultrafast changes in the angular composition of the scattering\\npattern. This provides a novel means to study transitions in excited molecular\\nsystems. We reconstruct a movie of the nuclear probability density arising from\\nthis interference.\\n'\n",
      " '  The cutoff phenomenon was recently confirmed for random walks on Ramanujan\\ngraphs by the first author and Peres. In this work, we obtain analogs in higher\\ndimensions, for random walk operators on any Ramanujan complex associated with\\na simple group $G$ over a local field $F$. We show that if $T$ is any\\n$k$-regular $G$-equivariant operator on the Bruhat-Tits building with a simple\\ncombinatorial property (collision-free), the associated random walk on the\\n$n$-vertex Ramanujan complex has cutoff at time $\\\\log_k n$. The high\\ndimensional case, unlike that of graphs, requires tools from non-commutative\\nharmonic analysis and the infinite-dimensional representation theory of $G$.\\nVia these, we show that operators $T$ as above on Ramanujan complexes give rise\\nto Ramanujan digraphs with a special property ($r$-normal), implying cutoff.\\nApplications include geodesic flow operators, geometric implications, and a\\nconfirmation of the Riemann Hypothesis for the associated zeta functions over\\nevery group $G$, previously known for groups of type $\\\\widetilde A_n$ and\\n$\\\\widetilde C_2$.\\n'\n",
      " '  Let $\\\\ell$ denote a positive integer. A connected graph $\\\\G$ of diameter at\\nleast $\\\\ell$ is said to be $\\\\ell${\\\\it -distance-balanced} whenever for any pair\\nof vertices $u,v$ of $\\\\G$ such that $d(u,v)=\\\\ell$, the number of vertices\\ncloser to $u$ than to $v$ is equal to the number of vertices closer to $v$ than\\nto $u$. In this paper we present some basic properties of\\n$\\\\ell$-distance-balanced graphs and study in more detail\\n$\\\\ell$-distance-balanced graphs of diameter at most $3$. We also investigate\\nthe $\\\\ell$-distance-balanced property of some well known families of graphs\\nsuch as the generalized Petersen graphs.\\n'\n",
      " '  This paper proposes the use of a Spectral method to simulate diffusive\\nmoisture transfer through porous materials as a Reduced-Order Model (ROM). The\\nSpectral approach is an a priori method assuming a separated representation of\\nthe solution. The method is compared with both classical Euler implicit and\\nCrank-Nicolson schemes, considered as large original models. Their performance\\n- in terms of accuracy, complexity reduction and CPU time reduction - are\\ndiscussed for linear and nonlinear cases of moisture diffusive transfer through\\nsingle and multi-layered one-dimensional domains, considering highly\\nmoisture-dependent properties. Results show that the Spectral reduced-order\\nmodel approach enables to simulate accurately the field of interest.\\nFurthermore, numerical gains become particularly interesting for nonlinear\\ncases since the proposed method can drastically reduce the computer run time,\\nby a factor of 100, when compared to the traditional Crank-Nicolson scheme for\\none-dimensional applications.\\n'\n",
      " \"  We consider the $q$-totally asymmetric simple exclusion process ($q$-TASEP)\\nin the stationary regime and study the fluctuation of the position of a\\nparticle. We first observe that the problem can be studied as a limiting case\\nof an $N$-particle $q$-TASEP with a random initial condition and with particle\\ndependent hopping rate. Then we explain how this $N$-particle $q$-TASEP can be\\nencoded in a dynamics on a two-sided Gelfand-Tsetlin cone described by a\\ntwo-sided $q$-Whittaker process and present a Fredholm determinant formula for\\nthe $q$-Laplace transform of the position of a particle. Two main ingredients\\nin its derivation is the Ramanujan's bilateral summation formula and the Cauchy\\ndeterminant identity for the theta function with an extra parameter. Based on\\nthis we establish that the position of a particle obeys the universal\\nstationary KPZ distribution (the Baik-Rains distribution) in the long time\\nlimit.\\n\"\n",
      " \"  One of the biggest successes of the Cassini mission is the detection of small\\nmoons (moonlets) embedded in Saturn's rings which cause S-shaped density\\nstructures in their close vicinity, called propellers (Spahn and Sremcevic\\n2000; Tiscareno et al. 2006; Sremcevic et al. 2007). Here, we present\\nisothermal hydrodynamic simulations of moonlet-induced propellers in Saturn's A\\nring which denote a further development of the original model (Spahn and\\nSremcevic 2000). We find excellent agreement between these new hydrodynamic and\\ncorresponding N-body simulations. Furthermore, the hydrodynamic simulations\\nconfirm the predicted scaling laws (Spahn and Sremcevic 2000) and the\\nanalytical solution for the density in the propeller gaps (Sremcevic et al.\\n2002). Finally, this mean field approach allows us to simulate the pattern of\\nthe giant propeller Bleriot, which is too large to be modeled by direct N-body\\nsimulations. Our results are compared to two stellar occultation observations\\nby the Cassini Ultraviolet Imaging Spectrometer (UVIS), that intersect the\\npropeller Bleriot. Best fits to the UVIS optical depth profiles are achieved\\nfor a Hill radius of 590 m, which implies a moonlet diameter of about 860 m.\\nFurthermore, the model favours a kinematic shear viscosity of the surrounding\\nring material of $\\\\nu_0 = 340$ cm^2/s, a dispersion velocity in the range of\\n0.3 cm/s $< c_0 <$ 1.5 cm/s, and a fairly high bulk viscosity $7 < \\\\xi_0/\\\\nu_0\\n< 17$. These large transport values might be overestimated by our isothermal\\nring model and should be reviewed by an extended model including thermal\\nfluctuations.\\n\"\n",
      " '  We consider the problem of estimating means of two Gaussians in a 2-Gaussian\\nmixture, which is not balanced and is corrupted by noise of an arbitrary\\ndistribution. We present a robust algorithm to estimate the parameters,\\ntogether with upper bounds on the numbers of samples required for the estimate\\nto be correct, where the bounds are parametrised by the dimension, ratio of the\\nmixing coefficients, a measure of the separation of the two Gaussians, related\\nto Mahalanobis distance, and a condition number of the covariance matrix. In\\ntheory, this is the first sample-complexity result for imbalanced mixtures\\ncorrupted by adversarial noise. In practice, our algorithm outperforms the\\nvanilla Expectation-Maximisation (EM) algorithm in terms of estimation error.\\n'\n",
      " '  We present an approach using a combination of coupled channel scattering\\ncalculations with a machine- learning technique based on Gaussian Process\\nregression to determine the sensitivity of the rate constants for non-adiabatic\\ntransitions in inelastic atomic collisions to variations of the underlying\\nadiabatic interaction potentials. Using this approach, we improve the previous\\ncomputations of the rate constants for the fine-structure transitions in\\ncollisions of O(3Pj) with atomic H. We compute the error bars of the rate\\nconstants corresponding to 20 % variations of the ab initio potentials and show\\nthat this method can be used to determine which of the individual adiabatic\\npotentials are more or less important for the outcome of different\\nfine-structure changing collisions.\\n'\n",
      " '  In this paper a semi-supervised deep framework is proposed for the problem of\\n3D shape inverse rendering from a single 2D input image. The main structure of\\nproposed framework consists of unsupervised pre-trained components which\\nsignificantly reduce the need to labeled data for training the whole framework.\\nusing labeled data has the advantage of achieving to accurate results without\\nthe need to predefined assumptions about image formation process. Three main\\ncomponents are used in the proposed network: an encoder which maps 2D input\\nimage to a representation space, a 3D decoder which decodes a representation to\\na 3D structure and a mapping component in order to map 2D to 3D representation.\\nThe only part that needs label for training is the mapping part with not too\\nmany parameters. The other components in the network can be pre-trained\\nunsupervised using only 2D images or 3D data in each case. The way of\\nreconstructing 3D shapes in the decoder component, inspired by the model based\\nmethods for 3D reconstruction, maps a low dimensional representation to 3D\\nshape space with the advantage of extracting the basis vectors of shape space\\nfrom training data itself and is not restricted to a small set of examples as\\nused in predefined models. Therefore, the proposed framework deals directly\\nwith coordinate values of the point cloud representation which leads to achieve\\ndense 3D shapes in the output. The experimental results on several benchmark\\ndatasets of objects and human faces and comparing with recent similar methods\\nshows the power of proposed network in recovering more details from single 2D\\nimages.\\n'\n",
      " \"  Deep Neural Networks (DNN) are increasingly used in a variety of\\napplications, many of them with substantial safety and security concerns. This\\npaper introduces DeepCheck, a new approach for validating DNNs based on core\\nideas from program analysis, specifically from symbolic execution. The idea is\\nto translate a DNN into an imperative program, thereby enabling program\\nanalysis to assist with DNN validation. A basic translation however creates\\nprograms that are very complex to analyze. DeepCheck introduces novel\\ntechniques for lightweight symbolic analysis of DNNs and applies them in the\\ncontext of image classification to address two challenging problems in DNN\\nanalysis: 1) identification of important pixels (for attribution and\\nadversarial generation); and 2) creation of 1-pixel and 2-pixel attacks.\\nExperimental results using the MNIST data-set show that DeepCheck's lightweight\\nsymbolic analysis provides a valuable tool for DNN validation.\\n\"\n",
      " '  We consider the exploration/exploitation problem in reinforcement learning.\\nFor exploitation, it is well known that the Bellman equation connects the value\\nat any time-step to the expected value at subsequent time-steps. In this paper\\nwe consider a similar \\\\textit{uncertainty} Bellman equation (UBE), which\\nconnects the uncertainty at any time-step to the expected uncertainties at\\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\\npolicy beyond individual time-steps. We prove that the unique fixed point of\\nthe UBE yields an upper bound on the variance of the posterior distribution of\\nthe Q-values induced by any policy. This bound can be much tighter than\\ntraditional count-based bonuses that compound standard deviation rather than\\nvariance. Importantly, and unlike several existing approaches to optimism, this\\nmethod scales naturally to large systems with complex generalization.\\nSubstituting our UBE-exploration strategy for $\\\\epsilon$-greedy improves DQN\\nperformance on 51 out of 57 games in the Atari suite.\\n'\n",
      " '  Though a large body of computer vision research has investigated developing\\ngeneric semantic representations, efforts towards developing a similar\\nrepresentation for 3D has been limited. In this paper, we learn a generic 3D\\nrepresentation through solving a set of foundational proxy 3D tasks:\\nobject-centric camera pose estimation and wide baseline feature matching. Our\\nmethod is based upon the premise that by providing supervision over a set of\\ncarefully selected foundational tasks, generalization to novel tasks and\\nabstraction capabilities can be achieved. We empirically show that the internal\\nrepresentation of a multi-task ConvNet trained to solve the above core problems\\ngeneralizes to novel 3D tasks (e.g., scene layout estimation, object pose\\nestimation, surface normal estimation) without the need for fine-tuning and\\nshows traits of abstraction abilities (e.g., cross-modality pose estimation).\\nIn the context of the core supervised tasks, we demonstrate our representation\\nachieves state-of-the-art wide baseline feature matching results without\\nrequiring apriori rectification (unlike SIFT and the majority of learned\\nfeatures). We also show 6DOF camera pose estimation given a pair local image\\npatches. The accuracy of both supervised tasks come comparable to humans.\\nFinally, we contribute a large-scale dataset composed of object-centric street\\nview scenes along with point correspondences and camera pose information, and\\nconclude with a discussion on the learned representation and open research\\nquestions.\\n'\n",
      " '  In this work we study the determinant of the Laplace-Beltrami operator on\\nrectangular tori of unit area. We will see that the square torus gives the\\nextremal determinant within this class of tori. The result is established by\\nstudying properties of the Dedekind eta function for special arguments and\\nrefined logarithmic convexity and concavity results of the classical Jacobi\\ntheta functions of one real variable are deeply involved.\\n'\n",
      " '  Under mass-action kinetics, biochemical reaction networks give rise to\\npolynomial autonomous dynamical systems whose parameters are often difficult to\\nestimate. We deal in this paper with the problem of identifying the kinetic\\nparameters of a class of biochemical networks which are abundant, such as\\nmultisite phosphorylation systems and phosphorylation cascades (for example,\\nMAPK cascades). For any system of this class we explicitly exhibit a single\\nspecies for each connected component of the associated digraph such that the\\nsuccessive total derivatives of its concentration allow us to identify all the\\nparameters occurring in the component. The number of derivatives needed is\\nbounded essentially by the length of the corresponding connected component of\\nthe digraph. Moreover, in the particular case of the cascades, we show that the\\nparameters can be identified from a bounded number of successive derivatives of\\nthe last product of the last layer. This theoretical result induces also a\\nheuristic interpolation-based identifiability procedure to recover the values\\nof the rate constants from exact measurements.\\n'\n",
      " '  Missing values widely exist in many real-world datasets, which hinders the\\nperforming of advanced data analytics. Properly filling these missing values is\\ncrucial but challenging, especially when the missing rate is high. Many\\napproaches have been proposed for missing value imputation (MVI), but they are\\nmostly heuristics-based, lacking a principled foundation and do not perform\\nsatisfactorily in practice. In this paper, we propose a probabilistic framework\\nbased on deep generative models for MVI. Under this framework, imputing the\\nmissing entries amounts to seeking a fixed-point solution between two\\nconditional distributions defined on the missing entries and latent variables\\nrespectively. These distributions are parameterized by deep neural networks\\n(DNNs) which possess high approximation power and can capture the nonlinear\\nrelationships between missing entries and the observed values. The learning of\\nweight parameters of DNNs is performed by maximizing an approximation of the\\nlog-likelihood of observed values. We conducted extensive evaluation on 13\\ndatasets and compared with 11 baselines methods, where our methods largely\\noutperforms the baselines.\\n'\n",
      " \"  This paper presents smoothed combined field integral equations for the\\nsolution of Dirichlet and Neumann exterior Helmholtz problems. The integral\\nequations introduced in this paper are smooth in the sense that they only\\ninvolve continuously differentiable integrands in both Dirichlet and Neumann\\ncases. These integral equations coincide with the well-known combined field\\nequations and are therefore uniquely solvable for all frequencies. In\\nparticular, a novel regularization of the hypersingular operator is obtained,\\nwhich, unlike regularizations based on Maue's integration-by-parts formula,\\ndoes not give rise to involved Cauchy principal value integrals. The smoothed\\nintegral operators and layer potentials, on the other hand, can be numerically\\nevaluated at target points that are arbitrarily close to the boundary without\\nseverely compromising their accuracy. A variety of numerical examples in two\\nspatial dimensions that consider three different Nyström discretizations for\\nsmooth domains and domains with corners---one of which is based on direct\\napplication of the trapezoidal rule---demonstrates the effectiveness of the\\nproposed integral approach. In certain aspects, this work extends to the\\nuniquely solvable Dirichlet and Neumann combined field integral equations, the\\nideas presented in the recent contribution R. Soc. Open Sci. 2(140520), 2015.\\n\"\n",
      " '  This paper considers unbalanced multiphase distribution systems with generic\\ntopology and different load models, and extends the Z-bus iterative load-flow\\nalgorithm based on a fixed-point interpretation of the AC load-flow equations.\\nExplicit conditions for existence and uniqueness of load-flow solutions are\\npresented. These conditions also guarantee convergence of the load-flow\\nalgorithm to the unique solution. The proposed methodology is applicable to\\ngeneric systems featuring (i) wye connections; (ii) ungrounded delta\\nconnections; (iii) a combination of wye-connected and delta-connected\\nsources/loads; and, (iv) a combination of line-to-line and\\nline-to-grounded-neutral devices at the secondary of distribution transformers.\\nFurther, a sufficient condition for the non-singularity of the load-flow\\nJacobian is proposed. Finally, linear load-flow models are derived, and their\\napproximation accuracy is analyzed. Theoretical results are corroborated\\nthrough experiments on IEEE test feeders.\\n'\n",
      " '  In this paper, we use the house price data ranging from January 2004 to\\nOctober 2016 to predict the average house price of November and December in\\n2016 for each district in Beijing, Shanghai, Guangzhou and Shenzhen. We apply\\nAutoregressive Integrated Moving Average model to generate the baseline while\\nLSTM networks to build prediction model. These algorithms are compared in terms\\nof Mean Squared Error. The result shows that the LSTM model has excellent\\nproperties with respect to predict time series. Also, stateful LSTM networks\\nand stack LSTM networks are employed to further study the improvement of\\naccuracy of the house prediction model.\\n'\n",
      " '  Robins et al. (2008, 2016) applied the theory of higher order influence\\nfunctions (HOIFs) to derive an estimator of the mean of an outcome Y in a\\nmissing data model with Y missing at random conditional on a vector X of\\ncontinuous covariates; their estimator, in contrast to previous estimators, is\\nsemiparametric efficient under minimal conditions. However, the Robins et al.\\n(2008, 2016) estimator depends on a non-parametric estimate of the density of\\nX. In this paper, we introduce a new HOIF estimator that has the same\\nasymptotic properties as their estimator but does not require nonparametric\\nestimation of a multivariate density, which is important because accurate\\nestimation of a high dimensional density is not feasible at the moderate sample\\nsizes often encountered in applications. We also show that our estimator can be\\ngeneralized to the entire class of functionals considered by Robins et al.\\n(2008) which include the average effect of a treatment on a response Y when a\\nvector X suffices to control confounding and the expected conditional variance\\nof a response Y given a vector X.\\n'\n",
      " '  We present an overview of scenarios where the observed Dark Matter (DM)\\nabundance consists of Feebly Interacting Massive Particles (FIMPs), produced\\nnon-thermally by the so-called freeze-in mechanism. In contrast to the usual\\nfreeze-out scenario, frozen-in FIMP DM interacts very weakly with the particles\\nin the visible sector and never attained thermal equilibrium with the\\nbaryon-photon fluid in the early Universe. Instead of being determined by its\\nannihilation strength, the DM abundance depends on the decay and annihilation\\nstrengths of particles in equilibrium with the baryon-photon fluid, as well as\\ncouplings in the DM sector. This makes frozen-in DM very difficult but not\\nimpossible to test. In this review, we present the freeze-in mechanism and its\\nvariations considered in the literature (dark freeze-out and reannihilation),\\ncompare them to the standard DM freeze-out scenario, discuss several aspects of\\nmodel building, and pay particular attention to observational properties and\\ngeneral testability of such feebly interacting DM.\\n'\n",
      " '  Seymour\\'s second neighbourhood conjecture asserts that every oriented graph\\nhas a vertex whose second out-neighbourhood is at least as large as its\\nout-neighbourhood. In this paper, we prove that the conjecture holds for\\nquasi-transitive oriented graphs, which is a superclass of tournaments and\\ntransitive acyclic digraphs. A digraph $D$ is called quasi-transitive is for\\nevery pair $xy,yz$ of arcs between distinct vertices $x,y,z$, $xz$ or $zx$\\n(\"or\" is inclusive here) is in $D$.\\n'\n",
      " '  We describe and analyze some Monte Carlo methods for manifolds in Euclidean\\nspace defined by equality and inequality constraints. First, we give an MCMC\\nsampler for probability distributions defined by un-normalized densities on\\nsuch manifolds. The sampler uses a specific orthogonal projection to the\\nsurface that requires only information about the tangent space to the manifold,\\nobtainable from first derivatives of the constraint functions, hence avoiding\\nthe need for curvature information or second derivatives. Second, we use the\\nsampler to develop a multi-stage algorithm to compute integrals over such\\nmanifolds. We provide single-run error estimates that avoid the need for\\nmultiple independent runs. Computational experiments on various test problems\\nshow that the algorithms and error estimates work in practice. The method is\\napplied to compute the entropies of different sticky hard sphere systems. These\\npredict the temperature or interaction energy at which loops of hard sticky\\nspheres become preferable to chains.\\n'\n",
      " '  Long-range low-power wireless communications, such as LoRa, are used in many\\nIoT and environmental monitoring applications. They typically increase the\\ncommunication range to several kilometers, at the cost of reducing the bitrate\\nto a few bits per seconds. Collisions further reduce the performance of these\\ncommunications. In this paper, we propose two algorithms to decode colliding\\nsignals: one algorithm requires the transmitters to be slightly desynchronized,\\nand the other requires the transmitters to be synchronized. To do so, we use\\nthe timing information to match the correct symbols to the correct\\ntransmitters. We show that our algorithms are able to significantly improve the\\noverall throughput of LoRa.\\n'\n",
      " '  Astrophysics and cosmology are rich with data. The advent of wide-area\\ndigital cameras on large aperture telescopes has led to ever more ambitious\\nsurveys of the sky. Data volumes of entire surveys a decade ago can now be\\nacquired in a single night and real-time analysis is often desired. Thus,\\nmodern astronomy requires big data know-how, in particular it demands highly\\nefficient machine learning and image analysis algorithms. But scalability is\\nnot the only challenge: Astronomy applications touch several current machine\\nlearning research questions, such as learning from biased data and dealing with\\nlabel and measurement noise. We argue that this makes astronomy a great domain\\nfor computer science research, as it pushes the boundaries of data analysis. In\\nthe following, we will present this exciting application area for data\\nscientists. We will focus on exemplary results, discuss main challenges, and\\nhighlight some recent methodological advancements in machine learning and image\\nanalysis triggered by astronomical applications.\\n'\n",
      " '  Access to collective excitations lies at the heart of our understanding of\\nquantum many-body systems. We study the Higgs and Goldstone modes in a\\nsupersolid quantum gas that is created by coupling a Bose-Einstein condensate\\nsymmetrically to two optical cavities. The cavity fields form a U(1)-symmetric\\norder parameter that can be modulated and monitored along both quadratures in\\nreal time. This enables us to measure the excitation energies across the\\nsuperfluid-supersolid phase transition, establish their amplitude and phase\\nnature, as well as characterize their dynamics from an impulse response.\\nFurthermore, we can give a tunable mass to the Goldstone mode at the crossover\\nbetween continuous and discrete symmetry by changing the coupling of the\\nquantum gas with either cavity.\\n'\n",
      " '  The increased availability of massive data sets provides a unique opportunity\\nto discover subtle patterns in their distributions, but also imposes\\noverwhelming computational challenges. To fully utilize the information\\ncontained in big data, we propose a two-step procedure: (i) estimate\\nconditional quantile functions at different levels in a parallel computing\\nenvironment; (ii) construct a conditional quantile regression process through\\nprojection based on these estimated quantile curves. Our general quantile\\nregression framework covers both linear models with fixed or growing dimension\\nand series approximation models. We prove that the proposed procedure does not\\nsacrifice any statistical inferential accuracy provided that the number of\\ndistributed computing units and quantile levels are chosen properly. In\\nparticular, a sharp upper bound for the former and a sharp lower bound for the\\nlatter are derived to capture the minimal computational cost from a statistical\\nperspective. As an important application, the statistical inference on\\nconditional distribution functions is considered. Moreover, we propose\\ncomputationally efficient approaches to conducting inference in the distributed\\nestimation setting described above. Those approaches directly utilize the\\navailability of estimators from sub-samples and can be carried out at almost no\\nadditional computational cost. Simulations confirm our statistical inferential\\ntheory.\\n'\n",
      " '  A novel approach is presented for group statistical analysis of diffusion\\nweighted MRI datasets through voxelwise Orientation Distribution Functions\\n(ODF). Recent advances in MRI acquisition make it possible to use high quality\\ndiffusion weighted protocols (multi-shell, large number of gradient directions)\\nfor routine in vivo study of white matter architecture. The dimensionality of\\nthese data sets is however often reduced to simplify statistical analysis.\\nWhile these approaches may detect large group differences, they do not fully\\ncapitalize on all acquired image volumes. Incorporation of all available\\ndiffusion information in the analysis however risks biasing the outcome by\\noutliers. Here we propose a statistical analysis method operating on the ODF,\\neither the diffusion ODF or fiber ODF. To avoid outlier bias and reliably\\ndetect voxelwise group differences and correlations with demographic or\\nbehavioral variables, we apply the Low-Rank plus Sparse (L + S) matrix\\ndecomposition on the voxelwise ODFs which separates the sparse individual\\nvariability in the sparse matrix S whilst recovering the essential ODF features\\nin the low-rank matrix L. We demonstrate the performance of this ODF L + S\\napproach by replicating the established negative association between global\\nwhite matter integrity and physical obesity in the Human Connectome dataset.\\nThe volume of positive findings agrees with and expands on the volume found by\\nTBSS, Connectivity based fixel enhancement and Connectometry. In the same\\ndataset we further localize the correlations of brain structure with\\nneurocognitive measures such as fluid intelligence and episodic memory. The\\npresented ODF L + S approach will aid in the full utilization of all acquired\\ndiffusion weightings leading to the detection of smaller group differences in\\nclinically relevant settings as well as in neuroscience applications.\\n'\n",
      " \"  The application of GNC devices on small robots is a game-changer that enables\\nthese robots to be mobile on low-gravity planetary surfaces and small bodies.\\nUse of reaction wheels enables these robots to roll, hop, summersault and rest\\non precarious/sloped surfaces that would otherwise not be possible with\\nconven-tional wheeled robots. We are extending this technology to enable robots\\nto climb off-world canyons, cliffs and caves. A single robot may slip and fall,\\nhowever, a multirobot system can work cooperatively by being interlinked using\\nspring-tethers and work much like a team of mountaineers to systematically\\nclimb a slope. A multirobot system as we will show in this paper can climb\\nsur-faces not possible with a single robot alone. We consider a team of four\\nrobots that are interlinked with tethers in an 'x' configuration. Each robot\\nsecures itself to a slope using spiny gripping actuators, and one by one each\\nrobot moves up-wards by crawling, rolling or hopping up the slope. If any one\\nof the robots loses grip, slips or falls, the remaining robots will be holding\\nit up as they are anchored. This distributed controls approach to cliff\\nclimbing enables the system to reconfigure itself where possible and avoid\\ngetting stuck at one hard to reach location. Instead, the risk is distributed\\nand through close cooperation, the robots can identify multiple trajectories to\\nclimb a cliff or rugged surface. The benefits can also be realized on\\nmilligravity surfaces such as asteroids. Too fast a jump can result in the\\nrobot flying off the surface into space. Having multiple robots anchored to the\\nsurface keeps the entire system secure. Our work combines dynamics and control\\nsimulation to evaluate the feasibility of our approach. The simulation results\\nshow a promising pathway towards advanced development of this technology on a\\nteam of real robots.\\n\"\n",
      " '  Clustering is an essential data mining tool that aims to discover inherent\\ncluster structure in data. For most applications, applying clustering is only\\nappropriate when cluster structure is present. As such, the study of\\nclusterability, which evaluates whether data possesses such structure, is an\\nintegral part of cluster analysis. However, methods for evaluating\\nclusterability vary radically, making it challenging to select a suitable\\nmeasure. In this paper, we perform an extensive comparison of measures of\\nclusterability and provide guidelines that clustering users can reference to\\nselect suitable measures for their applications.\\n'\n",
      " '  We prove in this paper the convergence of the Marker and cell (MAC) scheme\\nfor the dis-cretization of the steady-state and unsteady-state incompressible\\nNavier-Stokes equations in primitive variables on non-uniform Cartesian grids,\\nwithout any regularity assumption on the solution. A priori estimates on\\nsolutions to the scheme are proven ; they yield the existence of discrete\\nsolutions and the compactness of sequences of solutions obtained with family of\\nmeshes the space step of which tends to zero. We then establish that the limit\\nis a weak solution to the continuous problem.\\n'\n",
      " '  Let $\\\\sigma =\\\\{\\\\sigma_{i} | i\\\\in I\\\\}$ be a partition of the set of all primes\\n$\\\\Bbb{P}$ and $G$ a finite group. Let $\\\\sigma (G)=\\\\{\\\\sigma _{i} : \\\\sigma\\n_{i}\\\\cap \\\\pi (G)\\\\ne \\\\emptyset$. A set ${\\\\cal H}$ of subgroups of $G$ is said to\\nbe a complete Hall $\\\\sigma $-set of $G$ if every member $\\\\ne 1$ of ${\\\\cal H}$\\nis a Hall $\\\\sigma _{i}$-subgroup of $G$ for some $i\\\\in I$ and $\\\\cal H$ contains\\nexactly one Hall $\\\\sigma _{i}$-subgroup of $G$ for every $i$ such that $\\\\sigma\\n_{i}\\\\in \\\\sigma (G)$. We say that $G$ is $\\\\sigma$-full if $G$ possesses a\\ncomplete Hall $\\\\sigma $-set. A complete Hall $\\\\sigma $-set $\\\\cal H$ of $G$ is\\nsaid to be a $\\\\sigma$-basis of $G$ if every two subgroups $A, B \\\\in\\\\cal H$ are\\npermutable, that is, $AB=BA$. In this paper, we study properties of finite\\ngroups having a $\\\\sigma$-basis. In particular, we prove that if $G$ has a a\\n$\\\\sigma$-basis, then $G$ is generalized $\\\\sigma$-soluble, that is, $G$ has a\\ncomplete Hall $\\\\sigma $-set and for every chief factor $H/K$ of $G$ we have\\n$|\\\\sigma (H/K)|\\\\leq 2$. Moreover, answering to Problem 8.28 in [A.N. Skiba, On\\nsome results in the theory of finite partially soluble groups, Commun. Math.\\nStat., 4(3) (2016), 281--309], we prove the following Theorem A. Suppose that\\n$G$ is $\\\\sigma$-full. Then every complete Hall $\\\\sigma$-set of $G$ forms a\\n$\\\\sigma$-basis of $G$ if and only if $G$ is generalized $\\\\sigma$-soluble and\\nfor the automorphism group $G/C_{G}(H/K)$, induced by $G$ on any its chief\\nfactor $H/K$, we have either $\\\\sigma (H/K)=\\\\sigma (G/C_{G}(H/K))$ or $\\\\sigma\\n(H/K) =\\\\{\\\\sigma _{i}\\\\}$ and $G/C_{G}(H/K)$ is a $\\\\sigma _{i} \\\\cup \\\\sigma\\n_{j}$-group for some $i\\\\ne j$.\\n'\n",
      " '  Through seven publications this dissertation shows how anonymized mobile\\nphone data can contribute to the social good and provide insights into human\\nbehaviour on a large scale. The size of the datasets analysed ranges from 500\\nmillion to 300 billion phone records, covering millions of people. The key\\ncontributions are two-fold:\\n1. Big Data for Social Good: Through prediction algorithms the results show\\nhow mobile phone data can be useful to predict important socio-economic\\nindicators, such as income, illiteracy and poverty in developing countries.\\nSuch knowledge can be used to identify where vulnerable groups in society are,\\nreduce economic shocks and is a critical component for monitoring poverty rates\\nover time. Further, the dissertation demonstrates how mobile phone data can be\\nused to better understand human behaviour during large shocks in society,\\nexemplified by an analysis of data from the terror attack in Norway and a\\nnatural disaster on the south-coast in Bangladesh. This work leads to an\\nincreased understanding of how information spreads, and how millions of people\\nmove around. The intention is to identify displaced people faster, cheaper and\\nmore accurately than existing survey-based methods.\\n2. Big Data for efficient marketing: Finally, the dissertation offers an\\ninsight into how anonymised mobile phone data can be used to map out large\\nsocial networks, covering millions of people, to understand how products spread\\ninside these networks. Results show that by including social patterns and\\nmachine learning techniques in a large-scale marketing experiment in Asia, the\\nadoption rate is increased by 13 times compared to the approach used by\\nexperienced marketers. A data-driven and scientific approach to marketing,\\nthrough more tailored campaigns, contributes to less irrelevant offers for the\\ncustomers, and better cost efficiency for the companies.\\n'\n",
      " \"  Higher-order probabilistic programming languages allow programmers to write\\nsophisticated models in machine learning and statistics in a succinct and\\nstructured way, but step outside the standard measure-theoretic formalization\\nof probability theory. Programs may use both higher-order functions and\\ncontinuous distributions, or even define a probability distribution on\\nfunctions. But standard probability theory does not handle higher-order\\nfunctions well: the category of measurable spaces is not cartesian closed.\\nHere we introduce quasi-Borel spaces. We show that these spaces: form a new\\nformalization of probability theory replacing measurable spaces; form a\\ncartesian closed category and so support higher-order functions; form a\\nwell-pointed category and so support good proof principles for equational\\nreasoning; and support continuous probability distributions. We demonstrate the\\nuse of quasi-Borel spaces for higher-order functions and probability by:\\nshowing that a well-known construction of probability theory involving random\\nfunctions gains a cleaner expression; and generalizing de Finetti's theorem,\\nthat is a crucial theorem in probability theory, to quasi-Borel spaces.\\n\"\n",
      " '  We show that the stochastic evolution of an interacting system of the Higgs\\nand a spectator scalar field naturally gives rise to an enhanced probability of\\nsettling down at the electroweak vacuum at the end of inflation. Subsequent\\ndestabilization due to parametric resonance between the Higgs and the spectator\\nfield can be avoided in a wide parameter range. We further argue that the\\nspectator field can play the role of dark matter.\\n'\n",
      " '  Feature extraction and feature selection are the first tasks in\\npre-processing of input logs in order to detect cyber security threats and\\nattacks while utilizing machine learning. When it comes to the analysis of\\nheterogeneous data derived from different sources, these tasks are found to be\\ntime-consuming and difficult to be managed efficiently. In this paper, we\\npresent an approach for handling feature extraction and feature selection for\\nsecurity analytics of heterogeneous data derived from different network\\nsensors. The approach is implemented in Apache Spark, using its python API,\\nnamed pyspark.\\n'\n",
      " '  Undoubtedly, the MapReduce is the most powerful programming paradigm in\\ndistributed computing. The enhancement of the MapReduce is essential and it can\\nlead the computing faster. Therefore, here are many scheduling algorithms to\\ndiscuss based on their characteristics. Moreover, there are many shortcoming to\\ndiscover in this field. In this article, we present the state-of-the-art\\nscheduling algorithm to enhance the understanding of the algorithms. The\\nalgorithms are presented systematically such that there can be many future\\npossibilities in scheduling algorithm through this article. In this paper, we\\nprovide in-depth insight on the MapReduce scheduling algorithm. In addition, we\\ndiscuss various issues of MapReduce scheduler developed for large-scale\\ncomputing as well as heterogeneous environment.\\n'\n",
      " '  We present a methodology for generating Ising Hamiltonians of tunable\\ncomplexity and with a priori known ground states based on a decomposition of\\nthe model graph into edge-disjoint subgraphs. The idea is illustrated with a\\nspin-glass model defined on a cubic lattice, where subproblems, whose couplers\\nare restricted to the two values {-1,+1}, are specified on unit cubes and are\\nparametrized by their local degeneracy. The construction is shown to be\\nequivalent to a type of three-dimensional constraint satisfaction problem known\\nas the tiling puzzle. By varying the proportions of subproblem types, the\\nHamiltonian can span a dramatic range of typical computational complexity, from\\nfairly easy to many orders of magnitude more difficult than prototypical\\nbimodal and Gaussian spin glasses in three space dimensions. We corroborate\\nthis behavior via experiments with different algorithms and discuss\\ngeneralizations and extensions to different types of graphs.\\n'\n",
      " '  The Lobula Giant Movement Detector (LGMD) is a an identified neuron of the\\nlocust that detects looming objects and triggers its escape responses.\\nUnderstanding the neural principles and networks that lead to these fast and\\nrobust responses can lead to the design of efficient facilitate obstacle\\navoidance strategies in robotic applications. Here we present a neuromorphic\\nspiking neural network model of the LGMD driven by the output of a neuromorphic\\nDynamic Vision Sensor (DVS), which has been optimised to produce robust and\\nreliable responses in the face of the constraints and variability of its mixed\\nsignal analogue-digital circuits. As this LGMD model has many parameters, we\\nuse the Differential Evolution (DE) algorithm to optimise its parameter space.\\nWe also investigate the use of Self-Adaptive Differential Evolution (SADE)\\nwhich has been shown to ameliorate the difficulties of finding appropriate\\ninput parameters for DE. We explore the use of two biological mechanisms:\\nsynaptic plasticity and membrane adaptivity in the LGMD. We apply DE and SADE\\nto find parameters best suited for an obstacle avoidance system on an unmanned\\naerial vehicle (UAV), and show how it outperforms state-of-the-art Bayesian\\noptimisation used for comparison.\\n'\n",
      " '  We developed a new analytical experimental setup called AROMA (Astrochemistry\\nResearch of Organics with Molecular Analyzer) that combines laser\\ndesorption/ionization techniques with ion trap mass spectrometry. We report\\nhere on the ability of the apparatus to detect aromatic species in complex\\nmaterials of astrophysical interests and characterize their structures. A limit\\nof detection of 100 femto-grams has been achieved using pure polycyclic\\naromatic hydrocarbon (PAH) samples, which corresponds to 2x10^8 molecules in\\nthe case of coronene (C24H12). We detected the PAH distribution in the\\nMurchison meteorite, which is made of a complex mixture of extraterrestrial\\norganic compounds. In addition, collision induced dissociation experiments were\\nperformed on selected species detected in Murchison, which led to the first\\nfirm identification of pyrene and its methylated derivatives in this sample.\\n'\n",
      " '  Finite element models without simplifying assumptions can accurately describe\\nthe spatial and temporal distribution of heat in machine tools as well as the\\nresulting deformation. In principle, this allows to correct for displacements\\nof the Tool Centre Point and enables high precision manufacturing. However, the\\ncomputational cost of FEM models and restriction to generic algorithms in\\ncommercial tools like ANSYS prevents their operational use since simulations\\nhave to run faster than real-time. For the case where heat diffusion is slow\\ncompared to machine movement, we introduce a tailored implicit-explicit\\nmulti-rate time stepping method of higher order based on spectral deferred\\ncorrections. Using the open-source FEM library DUNE, we show that fully coupled\\nsimulations of the temperature field are possible in real-time for a machine\\nconsisting of a stock sliding up and down on rails attached to a stand.\\n'\n",
      " '  We present SCUBA-2 follow-up of 61 candidate high-redshift Planck sources. Of\\nthese, 10 are confirmed strong gravitational lenses and comprise some of the\\nbrightest such submm sources on the observed sky, while 51 are candidate\\nproto-cluster fields undergoing massive starburst events. With the accompanying\\nHerschel-SPIRE observations and assuming an empirical dust temperature prior of\\n$34^{+13}_{-9}$ K, we provide photometric redshift and far-IR luminosity\\nestimates for 172 SCUBA-2-selected sources within these Planck overdensity\\nfields. The redshift distribution of the sources peak between a redshift of 2\\nand 4, with one third of the sources having $S_{500}$/$S_{350} > 1$. For the\\nmajority of the sources, we find far-IR luminosities of approximately\\n$10^{13}\\\\,\\\\mathrm{L}_\\\\odot$, corresponding to star-formation rates of around\\n$1000$ M$_\\\\odot \\\\mathrm{yr}^{-1}$. For $S_{850}>8$ mJy sources, we show that\\nthere is up to an order of magnitude increase in star-formation rate density\\nand an increase in uncorrected number counts of $6$ for $S_{850}>8$ mJy when\\ncompared to typical cosmological survey fields. The sources detected with\\nSCUBA-2 account for only approximately $5$ per cent of the Planck flux at 353\\nGHz, and thus many more fainter sources are expected in these fields.\\n'\n",
      " \"  Unraveling the stratigraphic record is the key to understanding ancient\\nclimate and past climate changes on Mars. River deposits when placed in\\nstratigraphic order could constrain the number, magnitudes, and durations of\\nthe wettest climates in Mars history. We establish the stratigraphic context of\\nriver deposits in Aeolis Dorsa sedimentary basin, 10E of Gale crater. Here,\\nwind has exhumed a stratigraphic section of >=4 unconformity-bounded\\nsedimentary rock packages, recording >=3 distinct episodes of surface runoff.\\nEarly deposits (>700m thick) are embayed by river deposits (>400m), which are\\nin turn unconformably draped by fan-shaped deposits (<100m) which we interpret\\nas alluvial fans. Yardang-forming deposits (>900 m) unconformably drape all\\nprevious deposits. River deposits embay a dissected sedimentary-rock landscape,\\nand comprise >=2 distinguishable units. The total interval spanned by river\\ndeposits is >(1x10^6-2x10^7) yr; more if we include alluvial-fan deposits.\\nAlluvial-fan deposits unconformably postdate thrust faults which crosscut river\\ndeposits. We infer a relatively dry interval of >4x10^7 yr after river deposits\\nformed and before fan-shaped deposits formed. The time gap between the end of\\nriver deposition and the onset of yardang-forming deposits is constrained to\\n>10^8 yr by the density of impact craters embedded at the unconformity. We\\ncorrelate yardang-forming deposits to the upper layers of Gale crater's mound\\n(Mt. Sharp/Aeolis Mons), and fan-shaped deposits to Peace Vallis fan.\\nAlternations between periods of low vs. high mean obliquity may have modulated\\nerosion-deposition cycling in Aeolis. This is consistent with results from an\\nensemble of simulations of Solar System orbital evolution and the resulting\\nhistory of Mars obliquity. Almost all simulations yield intervals of\\ncontinuously low mean Mars obliquity that are long enough to match our\\nunconformity data.\\n\"\n",
      " '  Domestic Violence (DV) is considered as big social issue and there exists a\\nstrong relationship between DV and health impacts of the public. Existing\\nresearch studies have focused on social media to track and analyse real world\\nevents like emerging trends, natural disasters, user sentiment analysis,\\npolitical opinions, and health care. However there is less attention given on\\nsocial welfare issues like DV and its impact on public health. Recently, the\\nvictims of DV turned to social media platforms to express their feelings in the\\nform of posts and seek the social and emotional support, for sympathetic\\nencouragement, to show compassion and empathy among public. But, it is\\ndifficult to mine the actionable knowledge from large conversational datasets\\nfrom social media due to the characteristics of high dimensions, short, noisy,\\nhuge volume, high velocity, and so on. Hence, this paper will propose a novel\\nframework to model and discover the various themes related to DV from the\\npublic domain. The proposed framework would possibly provide unprecedentedly\\nvaluable information to the public health researchers, national family health\\norganizations, government and public with data enrichment and consolidation to\\nimprove the social welfare of the community. Thus provides actionable knowledge\\nby monitoring and analysing continuous and rich user generated content.\\n'\n",
      " \"  The edge partition model (EPM) is a fundamental Bayesian nonparametric model\\nfor extracting an overlapping structure from binary matrix. The EPM adopts a\\ngamma process ($\\\\Gamma$P) prior to automatically shrink the number of active\\natoms. However, we empirically found that the model shrinkage of the EPM does\\nnot typically work appropriately and leads to an overfitted solution. An\\nanalysis of the expectation of the EPM's intensity function suggested that the\\ngamma priors for the EPM hyperparameters disturb the model shrinkage effect of\\nthe internal $\\\\Gamma$P. In order to ensure that the model shrinkage effect of\\nthe EPM works in an appropriate manner, we proposed two novel generative\\nconstructions of the EPM: CEPM incorporating constrained gamma priors, and DEPM\\nincorporating Dirichlet priors instead of the gamma priors. Furthermore, all\\nDEPM's model parameters including the infinite atoms of the $\\\\Gamma$P prior\\ncould be marginalized out, and thus it was possible to derive a truly infinite\\nDEPM (IDEPM) that can be efficiently inferred using a collapsed Gibbs sampler.\\nWe experimentally confirmed that the model shrinkage of the proposed models\\nworks well and that the IDEPM indicated state-of-the-art performance in\\ngeneralization ability, link prediction accuracy, mixing efficiency, and\\nconvergence speed.\\n\"\n",
      " '  Human beings cannot be happy with any kind of tiredness based work, so they\\nfocused on machines to work on behalf of humans. The Internet-based latest\\ntechnology provides the platforms for human beings to relax and unburden\\nfeeling. The Internet of Things (IoT) field efficiently helps human beings with\\nsmart decisions through Machine-to-Machine (M2M) communication all over the\\nworld. It has been difficult to ignore the importance of the IoT field with the\\nnew development of applications such as a smartphone in the present era. The\\nIoT field sensor plays a vital role in sensing the intelligent object/things\\nand making an intelligent decision after sensing the objects. The rapid\\ndevelopment of new applications using smartphones in the world caused all users\\nof the IoT community to be faced with one major challenge of security in the\\nform of side channel attacks against highly intensive 3D printing systems. The\\nsmartphone formulated Intellectual property (IP) of side channel attacks\\ninvestigate against 3D printer in the physical domain through reconstructed\\nG-code file through primitive operations. The smartphone (Nexus 5) solved the\\nmain problems such as orientation fixing, model accuracy of frame size and\\nvalidate the feasibility and effectiveness in real case studies against the 3D\\nprinter. The 3D printing estimated value reached 20.2 billion of dollars in\\n2021. The thermal camera is used for exploring the side channel attacks after\\nreconstructing the objects against 3D printers. The researcher analyzed IoT\\nsecurity relevant issues which were avoided in future by enhanced strong\\nsecurity mechanism strategy, encryption, and machine learning-based algorithms,\\nlatest technologies, schemes and protocols utilized in an efficient way.\\nKeywords: - Internet of Things (IoT), Machine-to-Machine (M2M), Security, 3D\\nprinter, smartphone\\n'\n",
      " \"  We propose DeepBreath, a deep learning model which automatically recognises\\npeople's psychological stress level (mental overload) from their breathing\\npatterns. Using a low cost thermal camera, we track a person's breathing\\npatterns as temperature changes around his/her nostril. The paper's technical\\ncontribution is threefold. First of all, instead of creating hand-crafted\\nfeatures to capture aspects of the breathing patterns, we transform the\\nuni-dimensional breathing signals into two dimensional respiration variability\\nspectrogram (RVS) sequences. The spectrograms easily capture the complexity of\\nthe breathing dynamics. Second, a spatial pattern analysis based on a deep\\nConvolutional Neural Network (CNN) is directly applied to the spectrogram\\nsequences without the need of hand-crafting features. Finally, a data\\naugmentation technique, inspired from solutions for over-fitting problems in\\ndeep learning, is applied to allow the CNN to learn with a small-scale dataset\\nfrom short-term measurements (e.g., up to a few hours). The model is trained\\nand tested with data collected from people exposed to two types of cognitive\\ntasks (Stroop Colour Word Test, Mental Computation test) with sessions of\\ndifferent difficulty levels. Using normalised self-report as ground truth, the\\nCNN reaches 84.59% accuracy in discriminating between two levels of stress and\\n56.52% in discriminating between three levels. In addition, the CNN\\noutperformed powerful shallow learning methods based on a single layer neural\\nnetwork. Finally, the dataset of labelled thermal images will be open to the\\ncommunity.\\n\"\n",
      " '  The Bayesian expected power (BEP) has become increasingly popular in sample\\nsize determination and assessment of the probability of success (POS) for a\\nfuture trial. The BEP takes into consideration the uncertainty around the\\nparameters assumed by a power analysis and is thus more robust compared to the\\ntraditional power that assumes a single set of parameters. Current methods for\\nassessing BEP are often based in a parametric framework by imposing a model on\\nthe pilot data to derive and sample from the posterior distributions of the\\nparameters. Implementation of the model-based approaches can be analytically\\nchallenging and computationally costly especially for multivariate data sets;\\nit also runs the risk of generating misleading BEP if the model is\\nmis-specified. We propose an approach based on the Bayesian bootstrap technique\\n(BBS) to simulate future trials in the presence of individual-level pilot data,\\nbased on which the empirical BEP can be calculated. The BBS approach is\\nmodel-free with no assumptions about the distribution of the prior data and\\ncircumvents the analytical and computational complexity associated with\\nobtaining the posterior distribution of the parameters. Information from\\nmultiple pilot studies is also straightforward to combine. We also propose the\\ndouble bootstrap (BS2), a frequentist counterpart to the BBS, that shares\\nsimilar properties and achieves the same goal as the BBS for BEP assessment.\\nSimulation studies and case studies are presented to demonstrate the\\nimplementation of the BBS and BS2 techniques and to compare the BEP results\\nwith model-based approaches.\\n'\n",
      " '  In their precedent work, the authors constructed closed oriented hyperbolic\\nsurfaces with pseudo-Anosov homeomorphisms from certain class of integral\\nmatrices. In this paper, we present a very simple algorithm to compute the\\nTeichmueller polynomial corresponding to those surface homeomorphisms by first\\nconstructing an invariant track whose first homology group can be naturally\\nidentified with the first homology group of the surface, and computing its\\nAlexander polynomial.\\n'\n",
      " '  This paper presents a new 3D point cloud classification benchmark data set\\nwith over four billion manually labelled points, meant as input for data-hungry\\n(deep) learning methods. We also discuss first submissions to the benchmark\\nthat use deep convolutional neural networks (CNNs) as a work horse, which\\nalready show remarkable performance improvements over state-of-the-art. CNNs\\nhave become the de-facto standard for many tasks in computer vision and machine\\nlearning like semantic segmentation or object detection in images, but have no\\nyet led to a true breakthrough for 3D point cloud labelling tasks due to lack\\nof training data. With the massive data set presented in this paper, we aim at\\nclosing this data gap to help unleash the full potential of deep learning\\nmethods for 3D labelling tasks. Our semantic3D.net data set consists of dense\\npoint clouds acquired with static terrestrial laser scanners. It contains 8\\nsemantic classes and covers a wide range of urban outdoor scenes: churches,\\nstreets, railroad tracks, squares, villages, soccer fields and castles. We\\ndescribe our labelling interface and show that our data set provides more dense\\nand complete point clouds with much higher overall number of labelled points\\ncompared to those already available to the research community. We further\\nprovide baseline method descriptions and comparison between methods submitted\\nto our online system. We hope semantic3D.net will pave the way for deep\\nlearning methods in 3D point cloud labelling to learn richer, more general 3D\\nrepresentations, and first submissions after only a few months indicate that\\nthis might indeed be the case.\\n'\n",
      " '  We compute the Upsilon invariant of L-space cable knots $K_{p,q}$ in terms of\\n$p,\\\\Upsilon_K$ and $\\\\Upsilon_{T_{p,q}}$. The integral value of the Upsilon\\ninvariant gives a ${\\\\mathbb Q}$-valued knot concordance invariant. We also\\ncompute the integral values of the Upsilon of L-space cable knots.\\n'\n",
      " '  News reports shape the public perception of the critical social, political\\nand economical events around the world. Yet, the way in which emergent\\nphenomena are reported in the news makes the early prediction of such phenomena\\na challenging task. We propose a scalable community-based probabilistic\\nframework to model the spreading of news about events in online media. Our\\napproach exploits the latent community structure in the global news media and\\nuses the affiliation of the early adopters with a variety of communities to\\nidentify the events widely reported in the news at the early stage of their\\nspread. The time complexity of our approach is linear in the number of news\\nreports. It is also amenable to efficient parallelization. To demonstrate these\\nfeatures, the inference algorithm is parallelized for message passing paradigm\\nand tested on RPI Advanced Multiprocessing Optimized System (AMOS), one of the\\nfastest Blue Gene/Q supercomputers in the world. Thanks to the community-level\\nfeatures of the early adopters, the model gains an improvement of 20% in the\\nearly detection of the most massively reported events compared to the\\nfeature-based machine learning algorithm. Its parallelization scheme achieves\\norders of magnitude speedup.\\n'\n",
      " '  Global magnetic fields of flare stars can evolve rapidly, in time scale of\\nhundreds or dozens of days. We believe, that such changes result from rapid\\nsuperposition of local magnetic fields generated by differential rotation of\\nthose stars. We discuss possible mechanisms of generation and dissipation of\\nlocal and global magnetic fields in sample flare stars OT Ser and YZ CMi. We\\npropose mechanism of magnetic braking of these stars, in which differential\\nrotation generates local magnetic fields, and eventually energy accumulated in\\nlocal fields is radiated away by flares. We obtained estimates of the\\nrotational energy and the energy of the global magnetic field of OT Ser and YZ\\nCMi. We also show that the energy of the local magnetic fields dissipated\\nduring superflare of YZ CMi on 9 February 2008 (UT 20:22:00) did not influence\\nthe global magnetic field of this star.\\n'\n",
      " '  In this paper, we propose a convergent parallel best-response algorithm with\\nthe exact line search for the nondifferentiable nonconvex sparsity-regularized\\nrank minimization problem. On the one hand, it exhibits a faster convergence\\nthan subgradient algorithms and block coordinate descent algorithms. On the\\nother hand, its convergence to a stationary point is guaranteed, while ADMM\\nalgorithms only converge for convex problems. Furthermore, the exact line\\nsearch procedure in the proposed algorithm is performed efficiently in\\nclosed-form to avoid the meticulous choice of stepsizes, which is however a\\ncommon bottleneck in subgradient algorithms and successive convex approximation\\nalgorithms. Finally, the proposed algorithm is numerically tested.\\n'\n",
      " \"  A subfamily $\\\\{F_1,F_2,\\\\dots,F_{|P|}\\\\}\\\\subseteq {\\\\cal F}$ of sets is a copy\\nof a poset $P$ in ${\\\\cal F}$ if there exists a bijection $\\\\phi:P\\\\rightarrow\\n\\\\{F_1,F_2,\\\\dots,F_{|P|}\\\\}$ such that whenever $x \\\\le_P x'$ holds, then so does\\n$\\\\phi(x)\\\\subseteq \\\\phi(x')$. For a family ${\\\\cal F}$ of sets, let $c(P,{\\\\cal\\nF})$ denote the number of copies of $P$ in ${\\\\cal F}$, and we say that ${\\\\cal\\nF}$ is $P$-free if $c(P,{\\\\cal F})=0$ holds. For any two posets $P,Q$ let us\\ndenote by $La(n,P,Q)$ the maximum number of copies of $Q$ over all $P$-free\\nfamilies ${\\\\cal F} \\\\subseteq 2^{[n]}$, i.e. $\\\\max\\\\{c(Q,{\\\\cal F}): {\\\\cal F}\\n\\\\subseteq 2^{[n]}, c(P,{\\\\cal F})=0 \\\\}$.\\nThis generalizes the well-studied parameter $La(n,P)=La(n,P,P_1)$ where $P_1$\\nis the one element poset. The quantity $La(n,P)$ has been determined (precisely\\nor asymptotically) for many posets $P$, and in all known cases an\\nasymptotically best construction can be obtained by taking as many middle\\nlevels as possible without creating a copy of $P$.\\nIn this paper we consider the first instances of the problem of determining\\n$La(n,P,Q)$. We find its value when $P$ and $Q$ are small posets, like chains,\\nforks, the $N$ poset and diamonds. Already these special cases show that the\\nextremal families are completely different from those in the original $P$-free\\ncases: sometimes not middle or consecutive levels maximize $La(n,P,Q)$ and\\nsometimes no asymptotically extremal family is the union of levels.\\nFinally, we determine the maximum number of copies of complete multi-level\\nposets in $k$-Sperner families. The main tools for this are the profile\\npolytope method and two extremal set system problems that are of independent\\ninterest: we maximize the number of $r$-tuples $A_1,A_2,\\\\dots, A_r \\\\in {\\\\cal\\nA}$ over all antichains ${\\\\cal A}\\\\subseteq 2^{[n]}$ such that (i)\\n$\\\\cap_{i=1}^rA_i=\\\\emptyset$, (ii) $\\\\cap_{i=1}^rA_i=\\\\emptyset$ and\\n$\\\\cup_{i=1}^rA_i=[n]$.\\n\"\n",
      " \"  In reinforcement learning, it is common to let an agent interact for a fixed\\namount of time with its environment before resetting it and repeating the\\nprocess in a series of episodes. The task that the agent has to learn can\\neither be to maximize its performance over (i) that fixed period, or (ii) an\\nindefinite period where time limits are only used during training to diversify\\nexperience. In this paper, we provide a formal account for how time limits\\ncould effectively be handled in each of the two cases and explain why not doing\\nso can cause state-aliasing and invalidation of experience replay, leading to\\nsuboptimal policies and training instability. In case (i), we argue that the\\nterminations due to time limits are in fact part of the environment, and thus a\\nnotion of the remaining time should be included as part of the agent's input to\\navoid violation of the Markov property. In case (ii), the time limits are not\\npart of the environment and are only used to facilitate learning. We argue that\\nthis insight should be incorporated by bootstrapping from the value of the\\nstate at the end of each partial episode. For both cases, we illustrate\\nempirically the significance of our considerations in improving the performance\\nand stability of existing reinforcement learning algorithms, showing\\nstate-of-the-art results on several control tasks.\\n\"\n",
      " '  Existing nonconvex statistical optimization theory and methods crucially rely\\non the correct specification of the underlying \"true\" statistical models. To\\naddress this issue, we take a first step towards taming model misspecification\\nby studying the high-dimensional sparse phase retrieval problem with\\nmisspecified link functions. In particular, we propose a simple variant of the\\nthresholded Wirtinger flow algorithm that, given a proper initialization,\\nlinearly converges to an estimator with optimal statistical accuracy for a\\nbroad family of unknown link functions. We further provide extensive numerical\\nexperiments to support our theoretical findings.\\n'\n",
      " '  We present multi-wavelength radio observations obtained with the VLA of the\\nprotoplanetary disk surrounding the young brown dwarf 2MASS J04442713+2512164\\n(2M0444) in the Taurus star forming region. 2M0444 is the brightest known brown\\ndwarf disk at millimeter wavelengths, making this an ideal target to probe\\nradio emission from a young brown dwarf. Thermal emission from dust in the disk\\nis detected at 6.8 and 9.1 mm, whereas the 1.36 cm measured flux is dominated\\nby ionized gas emission. We combine these data with previous observations at\\nshorter sub-mm and mm wavelengths to test the predictions of dust evolution\\nmodels in gas-rich disks after adapting their parameters to the case of 2M0444.\\nThese models show that the radial drift mechanism affecting solids in a gaseous\\nenvironment has to be either completely made inefficient, or significantly\\nslowed down by very strong gas pressure bumps in order to explain the presence\\nof mm/cm-sized grains in the outer regions of the 2M0444 disk. We also discuss\\nthe possible mechanisms for the origin of the ionized gas emission detected at\\n1.36 cm. The inferred radio luminosity for this emission is in line with the\\nrelation between radio and bolometric luminosity valid for for more massive and\\nluminous young stellar objects, and extrapolated down to the very low\\nluminosity of the 2M0444 brown dwarf.\\n'\n",
      " \"  While Generative Adversarial Networks (GANs) have empirically produced\\nimpressive results on learning complex real-world distributions, recent work\\nhas shown that they suffer from lack of diversity or mode collapse. The\\ntheoretical work of Arora et al. suggests a dilemma about GANs' statistical\\nproperties: powerful discriminators cause overfitting, whereas weak\\ndiscriminators cannot detect mode collapse.\\nIn contrast, we show in this paper that GANs can in principle learn\\ndistributions in Wasserstein distance (or KL-divergence in many cases) with\\npolynomial sample complexity, if the discriminator class has strong\\ndistinguishing power against the particular generator class (instead of against\\nall possible generators). For various generator classes such as mixture of\\nGaussians, exponential families, and invertible neural networks generators, we\\ndesign corresponding discriminators (which are often neural nets of specific\\narchitectures) such that the Integral Probability Metric (IPM) induced by the\\ndiscriminators can provably approximate the Wasserstein distance and/or\\nKL-divergence. This implies that if the training is successful, then the\\nlearned distribution is close to the true distribution in Wasserstein distance\\nor KL divergence, and thus cannot drop modes. Our preliminary experiments show\\nthat on synthetic datasets the test IPM is well correlated with KL divergence,\\nindicating that the lack of diversity may be caused by the sub-optimality in\\noptimization instead of statistical inefficiency.\\n\"\n",
      " '  This paper brings together C*-algebras and algebraic topology in terms of\\nviewing a C*-algebraic invariant in terms of a topological spectrum. E-theory,\\nE(A,B), is a bivariant functor in the sense that is a cohomology functor in the\\nfirst variable and a homology functor in the second variable but underlying\\ngoes from the category of separable C*-algebras and *-homomorphisms to the\\ncategory of abelian groups and group homomorphisms. Here we create a\\ngeneralisation of a orthogonal spectrum to quasi-topological spaces for\\nE-theory. This includes a rich product structure in the context of graded\\nseparable C*-algebras.\\n'\n",
      " \"  In this paper, we present observations of cold (0-70 eV) plasma density in\\nthe magnetotail lobes. The observations and results are based on 16 years of\\nCluster observation of spacecraft potential measurements converted into local\\nplasma densities. Measurements from all four Cluster spacecraft have been used,\\nand the survey indicates a persistent asymmetry in lobe density, with\\nconsistently higher cold plasma densities in the northern lobe. External\\ninfluences, such as daily and seasonal variations in the Earth's tilt angle,\\ncan introduce temporary north-south asymmetries through asymmetric ionization\\nof the two hemispheres. Likewise, external drivers, such as the orientation of\\nthe interplanetary magnetic field can set up additional spatial asymmetries in\\noutflow and lobe filling. The persistent asymmetry reported in this paper is\\nalso influenced by these external factors but is mainly caused by differences\\nin magnetic field configuration in the Northern and Southern Hemisphere\\nionospheres.\\n\"\n",
      " \"  To satisfy increasing storage demands in both capacity and performance,\\nindustry has turned to multiple storage technologies, including Flash SSDs and\\nSMR disks. These devices employ a translation layer that conceals the\\nidiosyncrasies of their mediums and enables random access. Device translation\\nlayers are, however, inherently constrained: resources on the drive are scarce,\\nthey cannot be adapted to application requirements, and lack visibility across\\nmultiple devices. As a result, performance and durability of many storage\\ndevices is severely degraded.\\nIn this paper, we present SALSA: a translation layer that executes on the\\nhost and allows unmodified applications to better utilize commodity storage.\\nSALSA supports a wide range of single- and multi-device optimizations and,\\nbecause is implemented in software, can adapt to specific workloads. We\\ndescribe SALSA's design, and demonstrate its significant benefits using\\nmicrobenchmarks and case studies based on three applications: MySQL, the Swift\\nobject store, and a video server.\\n\"\n",
      " '  We present a survey of results on profinite semigroups and their link with\\nsymbolic dynamics. We develop a series of results, mostly due to Almeida and\\nCosta and we also include some original results on the Schützenberger groups\\nassociated to a uniformly recurrent set.\\n'\n",
      " '  We study ensembles of Rydberg atoms in a confined electromagnetic environment\\nsuch as provided by a microwave cavity. The competition between standard free\\nspace Ising type and cavity-mediated interactions leads to the emergence of\\ndifferent regimes where the particle-particle couplings range from the typical\\nvan der Waals $r^{-6}$ behavior to $r^{-3}$ and to $r$-independence. We apply a\\nRamsey spectroscopic technique to map the two-body interactions into a\\ncharacteristic signal such as intensity and contrast decay curves. As opposed\\nto previous treatments requiring high-densities for considerable contrast and\\nphase decay, the cavity scenario can exhibit similar behavior at much lower\\ndensities.\\n'\n",
      " '  In this paper, the idea of a new artificial intelligence based optimization\\nalgorithm, which is inspired from the nature of vortex, has been provided\\nbriefly. As also a bio-inspired computation algorithm, the idea is generally\\nfocused on a typical vortex flow / behavior in nature and inspires from some\\ndynamics that are occurred in the sense of vortex nature. Briefly, the\\nalgorithm is also a swarm-oriented evolutional problem solution approach;\\nbecause it includes many methods related to elimination of weak swarm members\\nand trying to improve the solution process by supporting the solution space via\\nnew swarm members. In order have better idea about success of the algorithm; it\\nhas been tested via some benchmark functions. At this point, the obtained\\nresults show that the algorithm can be an alternative to the literature in\\nterms of single-objective optimization solution ways. Vortex Optimization\\nAlgorithm (VOA) is the name suggestion by the authors; for this new idea of\\nintelligent optimization approach.\\n'\n",
      " '  Analogy completion has been a popular task in recent years for evaluating the\\nsemantic properties of word embeddings, but the standard methodology makes a\\nnumber of assumptions about analogies that do not always hold, either in recent\\nbenchmark datasets or when expanding into other domains. Through an analysis of\\nanalogies in the biomedical domain, we identify three assumptions: that of a\\nSingle Answer for any given analogy, that the pairs involved describe the Same\\nRelationship, and that each pair is Informative with respect to the other. We\\npropose modifying the standard methodology to relax these assumptions by\\nallowing for multiple correct answers, reporting MAP and MRR in addition to\\naccuracy, and using multiple example pairs. We further present BMASS, a novel\\ndataset for evaluating linguistic regularities in biomedical embeddings, and\\ndemonstrate that the relationships described in the dataset pose significant\\nsemantic challenges to current word embedding methods.\\n'\n",
      " '  Robot-assisted laparoscopic prostatectomy (RALP) is a treatment for prostate\\ncancer that involves complete or nerve sparing removal prostate tissue that\\ncontains cancer. After removal the bladder neck is successively sutured\\ndirectly with the urethra. The procedure is called urethrovesical anastomosis\\nand is one of the most dexterity demanding tasks during RALP. Two suturing\\ninstruments and a pair of needles are used in combination to perform a running\\nstitch during urethrovesical anastomosis. While robotic instruments provide\\nenhanced dexterity to perform the anastomosis, it is still highly challenging\\nand difficult to learn. In this paper, we presents a vision-guided needle\\ngrasping method for automatically grasping the needle that has been inserted\\ninto the patient prior to anastomosis. We aim to automatically grasp the\\nsuturing needle in a position that avoids hand-offs and immediately enables the\\nstart of suturing. The full grasping process can be broken down into: a needle\\ndetection algorithm; an approach phase where the surgical tool moves closer to\\nthe needle based on visual feedback; and a grasping phase through path planning\\nbased on observed surgical practice. Our experimental results show examples of\\nsuccessful autonomous grasping that has the potential to simplify and decrease\\nthe operational time in RALP by assisting a small component of urethrovesical\\nanastomosis.\\n'\n",
      " \"  In this document, the technical details of the JSNS$^2$ (J-PARC Sterile\\nNeutrino Search at J-PARC Spallation Neutron Source) experiment are described.\\nThe search for sterile neutrinos is currently one of the hottest topics in\\nneutrino physics. The JSNS$^2$ experiment aims to search for the existence of\\nneutrino oscillations with $\\\\Delta m^2$ near 1 eV$^2$ at the J-PARC Materials\\nand Life Science Experimental Facility (MLF). A 1 MW beam of 3 GeV protons\\nincident on a spallation neutron target produces an intense neutrino beam from\\nmuon decay at rest. Neutrinos come predominantly from $\\\\mu^+$ decay: $\\\\mu^{+}\\n\\\\to e^{+} + \\\\bar{\\\\nu}_{\\\\mu} + \\\\nu_{e}$. The experiment will search for\\n$\\\\bar{\\\\nu}_{\\\\mu}$ to $\\\\bar{\\\\nu}_{e}$ oscillations which are detected by the\\ninverse beta decay interaction $\\\\bar{\\\\nu}_{e} + p \\\\to e^{+} + n$, followed by\\ngammas from neutron capture on Gd. The detector has a fiducial volume of 17\\ntons and is located 24 meters away from the mercury target. JSNS$^2$ offers the\\nultimate direct test of the LSND anomaly.\\nIn addition to the sterile neutrino search, the physics program includes\\ncross section measurements with neutrinos with a few 10's of MeV from muon\\ndecay at rest and with monochromatic 236 MeV neutrinos from kaon decay at rest.\\nThese cross sections are relevant for our understanding of supernova explosions\\nand nuclear physics.\\n\"\n",
      " '  The warping sum $e(K)$ of a knot $K$ is the minimal value of the sum of the\\nwarping degrees of a minimal diagram of $K$ with both orientations. In this\\npaper, knots $K$ with $e(K) \\\\le 3$ are characterized, and some knots $K$ with\\n$e(K)=4$ are given.\\n'\n",
      " '  We deconstruct the performance of GANs into three components:\\n1. Formulation: we propose a perturbation view of the population target of\\nGANs. Building on this interpretation, we show that GANs can be viewed as a\\ngeneralization of the robust statistics framework, and propose a novel GAN\\narchitecture, termed as Cascade GANs, to provably recover meaningful\\nlow-dimensional generator approximations when the real distribution is\\nhigh-dimensional and corrupted by outliers.\\n2. Generalization: given a population target of GANs, we design a systematic\\nprinciple, projection under admissible distance, to design GANs to meet the\\npopulation requirement using finite samples. We implement our principle in\\nthree cases to achieve polynomial and sometimes near-optimal sample\\ncomplexities: (1) learning an arbitrary generator under an arbitrary\\npseudonorm; (2) learning a Gaussian location family under total variation\\ndistance, where we utilize our principle provide a new proof for the optimality\\nof Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian\\napproximation of a high-dimensional arbitrary distribution under Wasserstein\\ndistance. We demonstrate a fundamental trade-off in the approximation error and\\nstatistical error in GANs, and show how to apply our principle with empirical\\nsamples to predict how many samples are sufficient for GANs in order not to\\nsuffer from the discriminator winning problem.\\n3. Optimization: we demonstrate alternating gradient descent is provably not\\neven locally stable in optimizating the GAN formulation of PCA. We diagnose the\\nproblem as the minimax duality gap being non-zero, and propose a new GAN\\narchitecture whose duality gap is zero, where the value of the game is equal to\\nthe previous minimax value (not the maximin value). We prove the new GAN\\narchitecture is globally stable in optimization under alternating gradient\\ndescent.\\n'\n",
      " '  A connection, which shows the dependence of norming constants on boundary\\nconditions, was found using the Gelfand-Levitan method for the solution of\\ninverse Sturm-Liouville problem.\\n'\n",
      " '  Diffusion maps are a nonlinear manifold learning technique based on harmonic\\nanalysis of a diffusion process over the data. Out-of-sample extensions with\\ncomputational complexity $\\\\mathcal{O}(N)$, where $N$ is the number of points\\ncomprising the manifold, frustrate applications to online learning applications\\nrequiring rapid embedding of high-dimensional data streams. We propose landmark\\ndiffusion maps (L-dMaps) to reduce the complexity to $\\\\mathcal{O}(M)$, where $M\\n\\\\ll N$ is the number of landmark points selected using pruned spanning trees or\\nk-medoids. Offering $(N/M)$ speedups in out-of-sample extension, L-dMaps\\nenables the application of diffusion maps to high-volume and/or high-velocity\\nstreaming data. We illustrate our approach on three datasets: the Swiss roll,\\nmolecular simulations of a C$_{24}$H$_{50}$ polymer chain, and biomolecular\\nsimulations of alanine dipeptide. We demonstrate up to 50-fold speedups in\\nout-of-sample extension for the molecular systems with less than 4% errors in\\nmanifold reconstruction fidelity relative to calculations over the full\\ndataset.\\n'\n",
      " '  In this study, we analyzed the activity of monkey V1 neurons responding to\\ngrating stimuli of different orientations using inference methods for a\\ntime-dependent Ising model. The method provides optimal estimation of\\ntime-dependent neural interactions with credible intervals according to the\\nsequential Bayes estimation algorithm. Furthermore, it allows us to trace\\ndynamics of macroscopic network properties such as entropy, sparseness, and\\nfluctuation. Here we report that, in all examined stimulus conditions, pairwise\\ninteractions contribute to increasing sparseness and fluctuation. We then\\ndemonstrate that the orientation of the grating stimulus is in part encoded in\\nthe pairwise interactions of the neural populations. These results demonstrate\\nthe utility of the state-space Ising model in assessing contributions of neural\\ninteractions during stimulus processing.\\n'\n",
      " '  We prove the equivalence of two presentations of the Yangian\\n$Y(\\\\mathfrak{g})$ of a simple Lie algebra $\\\\mathfrak{g}$ and we also show the\\nequivalence with a third presentation when $\\\\mathfrak{g}$ is either an\\northogonal or a symplectic Lie algebra. As an application, we obtain an\\nexplicit correspondence between two versions of the classification theorem of\\nfinite-dimensional irreducible modules for orthogonal and symplectic Yangians.\\n'\n",
      " '  Recent breakthroughs in computer vision make use of large deep neural\\nnetworks, utilizing the substantial speedup offered by GPUs. For applications\\nrunning on limited hardware, however, high precision real-time processing can\\nstill be a challenge. One approach to solving this problem is training networks\\nwith binary or ternary weights, thus removing the need to calculate\\nmultiplications and significantly reducing memory size. In this work, we\\nintroduce LR-nets (Local reparameterization networks), a new method for\\ntraining neural networks with discrete weights using stochastic parameters. We\\nshow how a simple modification to the local reparameterization trick,\\npreviously used to train Gaussian distributed weights, enables the training of\\ndiscrete weights. Using the proposed training we test both binary and ternary\\nmodels on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art\\nresults on most experiments.\\n'\n",
      " '  Convolutional Neural Network is known as ConvNet have been extensively used\\nin many complex machine learning tasks. However, hyperparameters optimization\\nis one of a crucial step in developing ConvNet architectures, since the\\naccuracy and performance are reliant on the hyperparameters. This multilayered\\narchitecture parameterized by a set of hyperparameters such as the number of\\nconvolutional layers, number of fully connected dense layers & neurons, the\\nprobability of dropout implementation, learning rate. Hence the searching the\\nhyperparameter over the hyperparameter space are highly difficult to build such\\ncomplex hierarchical architecture. Many methods have been proposed over the\\ndecade to explore the hyperparameter space and find the optimum set of\\nhyperparameter values. Reportedly, Gird search and Random search are said to be\\ninefficient and extremely expensive, due to a large number of hyperparameters\\nof the architecture. Hence, Sequential model-based Bayesian Optimization is a\\npromising alternative technique to address the extreme of the unknown cost\\nfunction. The recent study on Bayesian Optimization by Snoek in nine\\nconvolutional network parameters is achieved the lowerest error report in the\\nCIFAR-10 benchmark. This article is intended to provide the overview of the\\nmathematical concept behind the Bayesian Optimization over a Gaussian prior.\\n'\n",
      " '  The local electronic states around a single As (Te, Se) vacancy are\\ninvestigated in order to shed light on the role of ligands in a series of\\niron-based superconductors. Such a vacancy can produce a local hopping\\ncorrection ranging from $-0.22$ eV to 0.12 eV and always induce two in-gap\\nresonance peaks in the local density of states (LDOS) at the fixed symmetrical\\nbias voltages, which are rather robust and irrelevant to the phase of\\nsuperconducting order parameter. The LDOS images near the defect predominantly\\npossess $0^o$ and $45^o$ stripes. These energy-dependent charge modulations\\ncreated by quasiparticle interference are originated in the nesting effect\\nbetween the inner (outer) hole Fermi surface around $\\\\Gamma$ point and the\\ninner (outer) electron Fermi surface around $M$ point.\\n'\n",
      " '  Quantum spin liquids (QSLs) are long-range entangled states of quantum\\nmagnets which lie beyond the Landau paradigm of classifying phases of matter\\nvia broken symmetries. A physical route to arriving at QSLs is via\\nfrustration-induced quantum melting of ordered states such as valence bond\\ncrystals or magnetic orders. Here, we show, using extensive exact\\ndiagonalization (ED) and density-matrix renormalization group (DMRG) studies of\\nconcrete $SU(2)$ invariant spin models on honeycomb, triangular and square\\nlattices, that chiral spin liquids (CSLs) emerge as descendants of triple-$Q$\\nspin crystals with tetrahedral magnetic order and a large scalar spin\\nchirality. Such ordered-to-CSL melting transitions may yield lattice\\nrealizations of effective Chern-Simons-Higgs field theories. Our work provides\\na distinct unifying perspective on the emergence of CSLs, and suggests that\\nmaterials with magnetic skyrmion crystal order might provide a good starting\\npoint to search for CSLs.\\n'\n",
      " \"  In the present article we introduce two new combinatorial interpretations of\\nthe $r$-Whitney numbers of the second kind obtained from the combinatorics of\\nthe differential operators associated to the grammar $G:=\\\\{ y\\\\rightarrow\\nyx^{m}, x\\\\rightarrow x\\\\}$. By specializing $m=1$ we obtain also a new\\ncombinatorial interpretation of the $r$-Stirling numbers of the second kind.\\nAgain, by specializing to the case $r=0$ we introduce a new generalization of\\nthe Stirling number of the second kind and through them a binomial type family\\nof polynomials that generalizes Touchard's. Moreover, we show several\\nwell-known identities involving the $r$-Dowling polynomials and the $r$-Whitney\\nnumbers using the combinatorial differential calculus. Finally we prove that\\nthe $r$-Dowling polynomials are a Sheffer family relative to the generalized\\nTouchard binomial family, study their umbral inverses, and introduce\\n$[m]$-Stirling numbers of the first kind. From the relation between umbral\\ncalculus and the Riordan matrices we give several new combinatorial identities\\ninvolving the $r$-Whitney number of both kinds, Bernoulli and Euler\\npolynomials.\\n\"\n",
      " '  Measuring the magnetoresistance (MR) of ultraclean {\\\\it GaAs} two-dimensional\\nholes in a large $r_s$ range of 20-50, two striking behaviors in relation to\\nthe spin-orbit coupling (SOC) emerge in response to strong electron-electron\\ninteraction. First, in exact correspondence to the zero-field\\nmetal-to-insulator transition (MIT), the sign of the MR switches from being\\npositive in the metallic regime to being negative in the insulating regime when\\nthe carrier density crosses the critical density $p_c$ of MIT ($r_s\\\\sim 39$).\\nSecond, as the SOC-driven correction $\\\\Delta\\\\rho$ to the MR decreases with\\nreducing carrier density (or the in-plane wave vector), it exhibits an upturn\\nin the close proximity just above $p_c$ where $r_s$ is beyond 30, indicating a\\nsubstantially enhanced SOC effect. This peculiar behavior echoes with a trend\\nof delocalization long suspected for the SOC-interaction interplay. Meanwhile,\\nfor $p<p_c$ or $r_s>40$, in contrast to the common belief that a magnet field\\nenhances Wigner crystallization, the negative MR is likely linked to enhanced\\ninteraction.\\n'\n",
      " '  Community detection is a challenging, yet crucial, problem while mining\\nlarge-scale graph structured data. Most existing approaches solve this problem\\nby mapping nodes into a vector space and performing unsupervised learning with\\nthe resulting embeddings. In cases where multiple types of connectivity\\npatterns exist for the set of nodes, commonly modeled as multilayer graphs, new\\nstrategies are required to model the inter-layer dependencies in order to\\nperform effective inferencing. In this paper, we focus on learning embeddings\\nfor each node of a multilayer graph through neural modeling techniques, such\\nthat the complex dependencies can be concisely encoded into low-dimensional\\nrepresentations. Referred to as multilayer graph embeddings, these\\nrepresentations can be utilized for discovering community structure in a\\nscalable fashion, even with a large number of layers. Furthermore, in order to\\nensure that the semantics that persist over a longer range in the network are\\nwell modeled, we propose to refine the multilayer embeddings via a proxy\\nclustering loss and a graph modularity measure. Using real-world datasets, we\\ndemonstrate that this algorithm generates scalable and robust representations,\\nand outperforms existing multilayer community detection approaches.\\n'\n",
      " '  We consider the framework of average aggregative games, where the cost\\nfunction of each agent depends on his own strategy and on the average\\npopulation strategy. We focus on the case in which the agents are coupled not\\nonly via their cost functions, but also via constraints coupling their\\nstrategies. We propose a distributed algorithm that achieves an almost Nash\\nequilibrium by requiring only local communications of the agents, as specified\\nby a sparse communication network. The proof of convergence of the algorithm\\nrelies on the auxiliary class of network aggregative games and exploits a novel\\nresult of parametric convergence of variational inequalities, which is\\napplicable beyond the context of games. We apply our theoretical findings to a\\nmulti-market Cournot game with transportation costs and maximum market\\ncapacity.\\n'\n",
      " '  Validation experiments of the two-dimensional inverse algorithm are performed\\nin a pulsed Poiseuille flow exposing shear reversal phases. The method is\\napplied to the three-segment electrodiffusion (ED) probe for which a specific\\nnondimensionalization process is suggested, allowing to better link\\nmeasurements from a real ED probe to the modeled one in the inverse problem.\\nThis approach provided a two-component wall shear rate in good agreement with\\nthe one obtained from laser Doppler anemometry (LDA) measurements, thus\\nvalidating the ability of ED probes to deal with high-amplitude unsteady flows.\\nThe classic linear velocity approximation ($u=sy$) in the probe vicinity is\\nalso investigated in such a flow.\\n'\n",
      " '  The chiral anomaly in Weyl semimetals states that the left- and right-handed\\nWeyl fermions, constituting the low energy description, are not individually\\nconserved, resulting, for example, in a negative magnetoresistance in such\\nmaterials. Recent experiments see strong indications of such an anomalous\\nresistance response; however, with a response that at strong fields is more\\nsharply peaked for parallel magnetic and electric fields than expected from\\nsimple theoretical considerations. Here, we uncover a mechanism, arising from\\nthe interplay between the angle-dependent Landau level structure and long-range\\nscalar disorder, that has the same phenomenology. In particular, we ana-\\nlytically show, and numerically confirm, that the internode scattering time\\ndecreases exponentially with the angle between the magnetic field and the Weyl\\nnode separation in the large field limit, while it is insensitive to this angle\\nat weak magnetic fields. Since, in the simplest approximation, the internode\\nscattering time is proportional to the anomaly-related conductivity, this\\nfeature may be related to the experimental observations of a sharply peaked\\nmagnetoresistance.\\n'\n",
      " \"  Sand seas on Titan may reflect the present and past climatic conditions.\\nUnderstanding the morphodynamics and physico-chemical properties of Titan's\\ndunes is therefore essential for a better comprehension of the climatic and\\ngeological history of the largest Saturn's moon. We derived quantitatively\\nsurface properties (texture, composition) from the modelling of microwave\\nbackscattered signal and Monte-Carlo inversion of despeckled Cassini/SAR data\\nover sand sea. We show that dunes and interdunes have significantly different\\nphysical properties. Dunes are globally more microwave absorbent than the\\ninterdunes. The inter-dunes present multi-scale roughness with a higher\\ndielectric constant than the dunes. Considering the composition, the interdunes\\nare in between the dunes and the radar bright inselbergs, suggesting the\\npresence of a shallow layer of non-mobilized sediment in between the dunes.\\nAdditionally potential secondary bedforms, such as ripples and avalanches, may\\nhave been detected. Our findings strongly suggest that sand seas evolve under\\ncurrent multi-directional wind regimes. Consequently sediment inventory and\\nclimatic conditions are being re-evaluated.\\n\"\n",
      " '  Different linguistic perspectives causes many diverse segmentation criteria\\nfor Chinese word segmentation (CWS). Most existing methods focus on improve the\\nperformance for each single criterion. However, it is interesting to exploit\\nthese different criteria and mining their common underlying knowledge. In this\\npaper, we propose adversarial multi-criteria learning for CWS by integrating\\nshared knowledge from multiple heterogeneous segmentation criteria. Experiments\\non eight corpora with heterogeneous segmentation criteria show that the\\nperformance of each corpus obtains a significant improvement, compared to\\nsingle-criterion learning. Source codes of this paper are available on Github.\\n'\n",
      " '  Image segmentation is the process of partitioning an image into a set of\\nmeaningful regions according to some criteria. Hierarchical segmentation has\\nemerged as a major trend in this regard as it favors the emergence of important\\nregions at different scales. On the other hand, many methods allow us to have\\nprior information on the position of structures of interest in the images. In\\nthis paper, we present a versatile hierarchical segmentation method that takes\\ninto account any prior spatial information and outputs a hierarchical\\nsegmentation that emphasizes the contours or regions of interest while\\npreserving the important structures in the image. An application of this method\\nto the weakly-supervised segmentation problem is presented.\\n'\n",
      " '  Genetic algorithms have been widely used in many practical optimization\\nproblems. Inspired by natural selection, operators, including mutation,\\ncrossover and selection, provide effective heuristics for search and black-box\\noptimization. However, they have not been shown useful for deep reinforcement\\nlearning, possibly due to the catastrophic consequence of parameter crossovers\\nof neural networks. Here, we present Genetic Policy Optimization (GPO), a new\\ngenetic algorithm for sample-efficient deep policy optimization. GPO uses\\nimitation learning for policy crossover in the state space and applies policy\\ngradient methods for mutation. Our experiments on MuJoCo tasks show that GPO as\\na genetic algorithm is able to provide superior performance over the\\nstate-of-the-art policy gradient methods and achieves comparable or higher\\nsample efficiency.\\n'\n",
      " '  The purpose of this paper is to advance the understanding of the conditions\\nthat give rise to flash crash contagion, particularly with respect to\\noverlapping asset portfolio crowding. To this end, we designed, implemented,\\nand assessed a hybrid micro-macro agent-based model, where price impact arises\\nendogenously through the limit order placement activity of algorithmic traders.\\nOur novel hybrid microscopic and macroscopic model allows us to quantify\\nsystemic risk not just in terms of system stability, but also in terms of the\\nspeed of financial distress propagation over intraday timescales. We find that\\nsystemic risk is strongly dependent on the behaviour of algorithmic traders, on\\nleverage management practices, and on network topology. Our results demonstrate\\nthat, for high-crowding regimes, contagion speed is a non-monotone function of\\nportfolio diversification. We also find the surprising result that, in certain\\ncircumstances, increased portfolio crowding is beneficial to systemic\\nstability. We are not aware of previous studies that have exhibited this\\nphenomenon, and our results establish the importance of considering non-uniform\\nasset allocations in future studies. Finally, we characterise the time window\\navailable for regulatory interventions during the propagation of flash crash\\ndistress, with results suggesting ex ante precautions may have higher efficacy\\nthan ex post reactions.\\n'\n",
      " '  Given a bounded strongly pseudoconvex domain $D$ in $\\\\mathbb{C}^n$ with\\nsmooth boundary, we give a characterization through products of functions in\\nweighted Bergman spaces of $(\\\\lambda,\\\\gamma)$-skew Carleson measures on $D$,\\nwith $\\\\lambda>0$ and $\\\\gamma>1-\\\\frac{1}{n+1}$.\\n'\n",
      " '  The superior temporal gyrus (STG) region of cortex critically contributes to\\nspeech recognition. In this work, we show that a proposed WaveNet, with limited\\navailable data, is able to reconstruct speech stimuli from STG intracranial\\nrecordings. We further investigate the impulse response of the fitted model for\\neach recording electrode and observe phoneme level temporospectral tuning\\nproperties for the recorded area of cortex. This discovery is consistent with\\nprevious studies implicating the posterior STG (pSTG) in a phonetic\\nrepresentation of speech and provides detailed acoustic features that certain\\nelectrode sites possibly extract during speech recognition.\\n'\n",
      " '  We calculate ionization energies and fundamental vibrational transitions for\\nH$_2^+$, D$_2^+$, and HD$^+$ molecular ions. The NRQED expansion for the energy\\nin terms of the fine structure constant $\\\\alpha$ is used. Previous calculations\\nof orders $m\\\\alpha^6$ and $m\\\\alpha^7$ are improved by including second-order\\ncontributions due to the vibrational motion of nuclei. Furthermore, we evaluate\\nthe largest corrections at the order $m\\\\alpha^8$. That allows to reduce the\\nfractional uncertainty to the level of $7\\\\cdot10^{-12}$ for fundamental\\ntransitions and to $4\\\\cdot10^{-12}$ for the ionization energies.\\n'\n",
      " \"  This work deals with the Mann's stochastic iteration algorithm under strong\\nmixing random errors. We establish the Fuk-Nagaev's inequalities that enable us\\nto prove the almost complete convergence with its corresponding rate of\\nconvergence. Moreover, these inequalities give us the possibility of\\nconstructing a confidence interval for the unique fixed point. Finally, to\\ncheck the feasibility and validity of our theoretical results, we consider some\\nnumerical examples, namely a classical example from astronomy.\\n\"\n",
      " '  To select the best algorithm for a new problem is an expensive and difficult\\ntask. However, there are automatic solutions to address this problem: using\\nMetalearning, which takes advantage of problem characteristics (i.e.\\nmetafeatures), one is able to predict the relative performance of algorithms.\\nIn the Collaborative Filtering scope, recent works have proposed diverse\\nmetafeatures describing several dimensions of this problem. Despite interesting\\nand effective findings, it is still unknown whether these are the most\\neffective metafeatures. Hence, this work proposes a new set of graph\\nmetafeatures, which approach the Collaborative Filtering problem from a Graph\\nTheory perspective. Furthermore, in order to understand whether metafeatures\\nfrom multiple dimensions are a better fit, we investigate the effects of\\ncomprehensive metafeatures. These metafeatures are a selection of the best\\nmetafeatures from all existing Collaborative Filtering metafeatures. The impact\\nof the most representative metafeatures is investigated in a controlled\\nexperimental setup. Another contribution we present is the use of a\\nPareto-Efficient ranking procedure to create multicriteria metatargets. These\\nnew rankings of algorithms, which take into account multiple evaluation\\nmeasures, allow to explore the algorithm selection problem in a fairer and more\\ndetailed way. According to the experimental results, the graph metafeatures are\\na good alternative to related work metafeatures. However, the results have\\nshown that the feature selection procedure used to create the comprehensive\\nmetafeatures is is not effective, since there is no gain in predictive\\nperformance. Finally, an extensive metaknowledge analysis was conducted to\\nidentify the most influential metafeatures.\\n'\n",
      " \"  Trigonometric formulas are derived for certain families of associated\\nLegendre functions of fractional degree and order, for use in approximation\\ntheory. These functions are algebraic, and when viewed as Gauss hypergeometric\\nfunctions, belong to types classified by Schwarz, with dihedral, tetrahedral,\\nor octahedral monodromy. The dihedral Legendre functions are expressed in terms\\nof Jacobi polynomials. For the last two monodromy types, an underlying\\n`octahedral' polynomial, indexed by the degree and order and having a\\nnon-classical kind of orthogonality, is identified, and recurrences for it are\\nworked out. It is a (generalized) Heun polynomial, not a hypergeometric one.\\nFor each of these families of algebraic associated Legendre functions, a\\nrepresentation of the rank-2 Lie algebra so(5,C) is generated by the ladder\\noperators that shift the degree and order of the corresponding solid harmonics.\\nAll such representations of so(5,C) are shown to have a common value for each\\nof its two Casimir invariants. The Dirac singleton representations of so(3,2)\\nare included.\\n\"\n",
      " '  This papers consists of two parts. The first is a critical review of prior\\nart on adversarial learning, identifying some significant limitations of\\nprevious works. The second part is an experimental study considering\\nadversarial active learning and an investigation of the efficacy of a mixed\\nsample selection strategy for combating an adversary who attempts to disrupt\\nthe classifier learning.\\n'\n",
      " '  Unintentional falls can cause severe injuries and even death, especially if\\nno immediate assistance is given. The aim of Fall Detection Systems (FDSs) is\\nto detect an occurring fall. This information can be used to trigger the\\nnecessary assistance in case of injury. This can be done by using either\\nambient-based sensors, e.g. cameras, or wearable devices. The aim of this work\\nis to study the technical aspects of FDSs based on wearable devices and\\nartificial intelligence techniques, in particular Deep Learning (DL), to\\nimplement an effective algorithm for on-line fall detection. The proposed\\nclassifier is based on a Recurrent Neural Network (RNN) model with underlying\\nLong Short-Term Memory (LSTM) blocks. The method is tested on the publicly\\navailable SisFall dataset, with extended annotation, and compared with the\\nresults obtained by the SisFall authors.\\n'\n",
      " '  Rule-based techniques to extract relational entities from documents allow\\nusers to specify desired entities with natural language questions, finite state\\nautomata, regular expressions and structured query language. They require\\nlinguistic and programming expertise and lack support for Arabic morphological\\nanalysis. We present a morphology-based entity and relational entity extraction\\nframework for Arabic (MERF). MERF requires basic knowledge of linguistic\\nfeatures and regular expressions, and provides the ability to interactively\\nspecify Arabic morphological and synonymity features, tag types associated with\\nregular expressions, and relations and code actions defined over matches of\\nsubexpressions. MERF constructs entities and relational entities from matches\\nof the specifications. We evaluated MERF with several case studies. The results\\nshow that MERF requires shorter development time and effort compared to\\nexisting application specific techniques and produces reasonably accurate\\nresults within a reasonable overhead in run time.\\n'\n",
      " '  Recent work in unsupervised representation learning has focused on learning\\ndeep directed latent-variable models. Fitting these models by maximizing the\\nmarginal likelihood or evidence is typically intractable, thus a common\\napproximation is to maximize the evidence lower bound (ELBO) instead. However,\\nmaximum likelihood training (whether exact or approximate) does not necessarily\\nresult in a good latent representation, as we demonstrate both theoretically\\nand empirically. In particular, we derive variational lower and upper bounds on\\nthe mutual information between the input and the latent variable, and use these\\nbounds to derive a rate-distortion curve that characterizes the tradeoff\\nbetween compression and reconstruction accuracy. Using this framework, we\\ndemonstrate that there is a family of models with identical ELBO, but different\\nquantitative and qualitative characteristics. Our framework also suggests a\\nsimple new method to ensure that latent variable models with powerful\\nstochastic decoders do not ignore their latent code.\\n'\n",
      " '  The original research question here is given by marketers in general, i.e.,\\nhow to explain the changes in the desired timescale of the market. Tangled\\nString, a sequence visualization tool based on the metaphor where contexts in a\\nsequence are compared to tangled pills in a string, is here extended and\\ndiverted to detecting stocks that trigger changes in the market and to\\nexplaining the scenario of contextual shifts in the market. Here, the\\nsequential data on the stocks of top 10 weekly increase rates in the First\\nSection of the Tokyo Stock Exchange for 12 years are visualized by Tangled\\nString. The changing in the prices of stocks is a mixture of various timescales\\nand can be explained in the time-scale set as desired by using TS. Also, it is\\nfound that the change points found by TS coincided by high precision with the\\nreal changes in each stock price. As TS has been created from the data-driven\\ninnovation platform called Innovators Marketplace on Data Jackets and is\\nextended to satisfy data users, this paper is as evidence of the contribution\\nof the market of data to data-driven innovations.\\n'\n",
      " \"  We consider a multi-adversary version of the supervisory control problem for\\ndiscrete-event systems, in which an adversary corrupts the observations\\navailable to the supervisor. The supervisor's goal is to enforce a specific\\nlanguage in spite of the opponent's actions and without knowing which adversary\\nit is playing against. This problem is motivated by applications to computer\\nsecurity in which a cyber defense system must make decisions based on reports\\nfrom sensors that may have been tampered with by an attacker. We start by\\nshowing that the problem has a solution if and only if the desired language is\\ncontrollable (in the Discrete event system classical sense) and observable in a\\n(novel) sense that takes the adversaries into account. For the particular case\\nof attacks that insert symbols into or remove symbols from the sequence of\\nsensor outputs, we show that testing the existence of a supervisor and building\\nthe supervisor can be done using tools developed for the classical DES\\nsupervisory control problem, by considering a family of automata with modified\\noutput maps, but without expanding the size of the state space and without\\nincurring on exponential complexity on the number of attacks considered., we\\nconstruct observers that are robust against attacks and lead to an automaton\\nrepresentation of the supervisor. We also develop a test for observability\\nunder such replacement-removal attacks by using the so-called product automata.\\n\"\n",
      " '  We present the design, characterization, and testing of a laboratory\\nprototype radiological search and localization system. The system, based on\\ntime-encoded imaging, uses the attenuation signature of neutrons in time,\\ninduced by the geometrical layout and motion of the system. We have\\ndemonstrated the ability to detect a ~1 mCi Cf-252 radiological source at 100 m\\nstandoff with 90% detection efficiency and 10% false positives against\\nbackground in 12 min. This same detection efficiency is met at 15 s for a 40 m\\nstandoff, and 1.2 s for a 20 m standoff.\\n'\n",
      " \"  Hashing is a basic tool for dimensionality reduction employed in several\\naspects of machine learning. However, the perfomance analysis is often carried\\nout under the abstract assumption that a truly random unit cost hash function\\nis used, without concern for which concrete hash function is employed. The\\nconcrete hash function may work fine on sufficiently random input. The question\\nis if it can be trusted in the real world when faced with more structured\\ninput.\\nIn this paper we focus on two prominent applications of hashing, namely\\nsimilarity estimation with the one permutation hashing (OPH) scheme of Li et\\nal. [NIPS'12] and feature hashing (FH) of Weinberger et al. [ICML'09], both of\\nwhich have found numerous applications, i.e. in approximate near-neighbour\\nsearch with LSH and large-scale classification with SVM.\\nWe consider mixed tabulation hashing of Dahlgaard et al.[FOCS'15] which was\\nproved to perform like a truly random hash function in many applications,\\nincluding OPH. Here we first show improved concentration bounds for FH with\\ntruly random hashing and then argue that mixed tabulation performs similar for\\nsparse input. Our main contribution, however, is an experimental comparison of\\ndifferent hashing schemes when used inside FH, OPH, and LSH.\\nWe find that mixed tabulation hashing is almost as fast as the\\nmultiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work\\nwell on sufficiently random data, but we demonstrate that in the above\\napplications, it can lead to bias and poor concentration on both real-world and\\nsynthetic data. We also compare with the popular MurmurHash3, which has no\\nproven guarantees. Mixed tabulation and MurmurHash3 both perform similar to\\ntruly random hashing in our experiments. However, mixed tabulation is 40%\\nfaster than MurmurHash3, and it has the proven guarantee of good performance on\\nall possible input.\\n\"\n",
      " \"  This paper corrects the proof of the Theorem 2 from the Gower's paper\\n\\\\cite[page 5]{Gower:1982} as well as corrects the Theorem 7 from Gower's paper\\n\\\\cite{Gower:1986}. The first correction is needed in order to establish the\\nexistence of the kernel function used commonly in the kernel trick e.g. for\\n$k$-means clustering algorithm, on the grounds of distance matrix. The\\ncorrection encompasses the missing if-part proof and dropping unnecessary\\nconditions. The second correction deals with transformation of the kernel\\nmatrix into a one embeddable in Euclidean space.\\n\"\n",
      " '  Cosmic growth of large scale structure probes the entire history of cosmic\\nexpansion and gravitational coupling. To get a clear picture of the effects of\\nmodification of gravity we consider a deviation in the coupling strength\\n(effective Newton\\'s constant) at different redshifts, with different durations\\nand amplitudes. We derive, analytically and numerically, the impact on the\\ngrowth rate and growth amplitude. Galaxy redshift surveys can measure a product\\nof these through redshift space distortions and we connect the modified gravity\\nto the observable in a way that may provide a useful parametrization of the\\nability of future surveys to test gravity. In particular, modifications during\\nthe matter dominated era can be treated by a single parameter, the \"area\" of\\nthe modification, to an accuracy of $\\\\sim0.3\\\\%$ in the observables. We project\\nconstraints on both early and late time gravity for the Dark Energy\\nSpectroscopic Instrument and discuss what is needed for tightening tests of\\ngravity to better than 5% uncertainty.\\n'\n",
      " '  In this article, we study the Higgs $G$-bundles $(E,\\\\theta)$ on a compact\\nCalabi-Yau manifolds $X$. Our main result is that there is non-existence Higgs\\nfields $\\\\theta$ on a semistable Higgs $G$-bundle over a compact connected\\nCalabi-Yau surface. The vanish theorem can extends to higher dimensional\\nCalabi-Yau compact $n$-folds, but we should addition the principal $E$ with\\nvanishing Chern-classes. In particular, the $G$-bundle $E$ must be a semistable\\nbundle in both cases.\\n'\n",
      " '  In adversarial training, a set of models learn together by pursuing competing\\ngoals, usually defined on single data instances. However, in relational\\nlearning and other non-i.i.d domains, goals can also be defined over sets of\\ninstances. For example, a link predictor for the is-a relation needs to be\\nconsistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3)\\nhold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for\\nderiving an inconsistency loss, measuring the degree to which the model\\nviolates the assumptions on an adversarially-generated set of examples. The\\ntraining objective is defined as a minimax problem, where an adversary finds\\nthe most offending adversarial examples by maximising the inconsistency loss,\\nand the model is trained by jointly minimising a supervised loss and the\\ninconsistency loss on the adversarial examples. This yields the first method\\nthat can use function-free Horn clauses (as in Datalog) to regularise any\\nneural link predictor, with complexity independent of the domain size. We show\\nthat for several link prediction models, the optimisation problem faced by the\\nadversary has efficient closed-form solutions. Experiments on link prediction\\nbenchmarks indicate that given suitable prior knowledge, our method can\\nsignificantly improve neural link predictors on all relevant metrics.\\n'\n",
      " '  In this paper, the estimation problem for sparse reduced rank regression\\n(SRRR) model is considered. The SRRR model is widely used for dimension\\nreduction and variable selection with applications in signal processing,\\neconometrics, etc. The problem is formulated to minimize the least squares loss\\nwith a sparsity-inducing penalty considering an orthogonality constraint.\\nConvex sparsity-inducing functions have been used for SRRR in literature. In\\nthis work, a nonconvex function is proposed for better sparsity inducing. An\\nefficient algorithm is developed based on the alternating minimization (or\\nprojection) method to solve the nonconvex optimization problem. Numerical\\nsimulations show that the proposed algorithm is much more efficient compared to\\nthe benchmark methods and the nonconvex function can result in a better\\nestimation accuracy.\\n'\n",
      " '  The spin structure of wave functions is reflected in the magnetic structure\\nof the one-particle density matrix. Indeed, for single determinants we can use\\neither one to determine the other. In this work we discuss how one can simply\\nexamine the one-particle density matrix to faithfully determine whether the\\nspin magnetization density vector field is collinear, coplanar, or noncoplanar.\\nFor single determinants, this test suffices to distinguish collinear\\ndeterminants which are eigenfunctions of $\\\\hat{S}_{\\\\hat{n}}$ from noncollinear\\ndeterminants which are not. We also point out the close relationship between\\nnoncoplanar magnetism on the one hand and complex conjugation symmetry breaking\\non the other. Finally, we use these ideas to classify the various ways single\\ndeterminant wave functions break and respect symmetries of the Hamiltonian in\\nterms of their one-particle density matrix.\\n'\n",
      " '  We consider a group-theoretic analogue of the classic subset sum problem. It\\nis known that every virtually nilpotent group has polynomial time decidable\\nsubset sum problem. In this paper we use subgroup distortion to show that every\\npolycyclic non-virtually-nilpotent group has NP-complete subset sum problem.\\n'\n",
      " '  To shed light on the time evolution of local star formation episodes in M33,\\nwe study the association between 566 Giant Molecular Clouds (GMCs), identified\\nthrough the CO (J=2-1) IRAM-all-disk survey, and 630 Young Stellar Cluster\\nCandidates (YSCCs), selected via Spitzer-24~$\\\\mu$m emission. The spatial\\ncorrelation between YSCCs and GMCs is extremely strong, with a typical\\nseparation of 17~pc, less than half the CO(2--1) beamsize, illustrating the\\nremarkable physical link between the two populations. GMCs and YSCCs follow the\\nHI filaments, except in the outermost regions where the survey finds fewer GMCs\\nthan YSCCs, likely due to undetected, low CO-luminosity clouds. The GMCs have\\nmasses between 2$\\\\times 10^4$ and 2$\\\\times 10^6$ M$_\\\\odot$ and are classified\\naccording to different cloud evolutionary stages: inactive clouds are 32$\\\\%$ of\\nthe total, classified clouds with embedded and exposed star formation are\\n16$\\\\%$ and 52$\\\\%$ of the total respectively. Across the regular southern spiral\\narm, inactive clouds are preferentially located in the inner part of the arm,\\npossibly suggesting a triggering of star formation as the cloud crosses the\\narm. Some YSCCs are embedded star-forming sites while the majority have\\nGALEX-UV and H$\\\\alpha$ counterparts with estimated cluster masses and ages. The\\ndistribution of the non-embedded YSCC ages peaks around 5~Myrs with only a few\\nbeing as old as 8--10~Myrs. These age estimates together with the number of\\nGMCs in the various evolutionary stages lead us to conclude that 14~Myrs is a\\ntypical lifetime of a GMC in M33, prior to cloud dispersal. The inactive and\\nembedded phases are short, lasting about 4 and 2~Myrs respectively. This\\nunderlines that embedded YSCCs rapidly break out from the clouds and become\\npartially visible in H$\\\\alpha$ or UV long before cloud dispersal.\\n'\n",
      " \"  Compositor attribution, the clustering of pages in a historical printed\\ndocument by the individual who set the type, is a bibliographic task that\\nrelies on analysis of orthographic variation and inspection of visual details\\nof the printed page. In this paper, we introduce a novel unsupervised model\\nthat jointly describes the textual and visual features needed to distinguish\\ncompositors. Applied to images of Shakespeare's First Folio, our model predicts\\nattributions that agree with the manual judgements of bibliographers with an\\naccuracy of 87%, even on text that is the output of OCR.\\n\"\n",
      " '  We study the substructure content of the strong gravitational lens\\nRXJ1131-1231 through a forward modelling approach that relies on generating an\\nextensive suite of realistic simulations. We use a semi-analytic merger tree\\nprescription that allows us to stochastically generate substructure populations\\nwhose properties depend on the dark matter particle mass. These synthetic halos\\nare then used as lenses to produce realistic mock images that have the same\\nfeatures, e.g. luminous arcs, quasar positions, instrumental noise and PSF, as\\nthe data. We then analyse the data and the simulations in the same way with\\nsummary statistics that are sensitive to the signal being targeted and are able\\nto constrain models of dark matter statistically using Approximate Bayesian\\nComputing (ABC) techniques. In this work, we focus on the thermal relic mass\\nestimate and fix the semi-analytic descriptions of the substructure evolution\\nbased on recent literature. We are able, based on the HST data for\\nRXJ1131-1231, to rule out a warm dark matter thermal relic mass below 2 keV at\\nthe 2$\\\\sigma$ confidence level.\\n'\n",
      " '  When analyzing programs, large libraries pose significant challenges to\\nstatic points-to analysis. A popular solution is to have a human analyst\\nprovide points-to specifications that summarize relevant behaviors of library\\ncode, which can substantially improve precision and handle missing code such as\\nnative code. We propose ATLAS, a tool that automatically infers points-to\\nspecifications. ATLAS synthesizes unit tests that exercise the library code,\\nand then infers points-to specifications based on observations from these\\nexecutions. ATLAS automatically infers specifications for the Java standard\\nlibrary, and produces better results for a client static information flow\\nanalysis on a benchmark of 46 Android apps compared to using existing\\nhandwritten specifications.\\n'\n",
      " '  We find the exact Bloch oscillations in zigzag arrays of curved optical\\nwaveguides under the influence of arbitrary long-range coupling. The curvature\\ninduces a linear transverse potential gradient in the equations of the light\\nevolution. In the case of arrays with second-order coupling, steady states can\\nbe obtained as linear combinations of Bessel functions of integer index. The\\ncorresponding eigenvalues are equally spaced and form the well-known\\nWannier-Stark ladder, the spacing being independent of the second-order\\ncoupling. We also solve exactly the wave packet dynamics and compare it with\\nexperimental results. Accordingly we find that a broad optical pulse performs\\nBloch oscillations. Frequency doubling of the fundamental Bloch frequency sets\\nup at finite values of the second-order coupling. On the contrary when a single\\nwaveguide is initially excited, a breathing mode is activated with no signature\\nof Bloch oscillations. We present a generalization of our results to waveguide\\narrays subject to long-range coupling. In the general case the centroid of the\\nwave packet shows the occurrence of multiples of the Bloch frequency up to the\\norder of the interaction.\\n'\n",
      " '  We present and analyze three-dimensional data cubes of Neptune from the\\nOSIRIS integral-field spectrograph on the 10-m Keck telescope, from July 2009.\\nThese data have a spatial resolution of 0.035\"/pixel and spectral resolution of\\nR~3800 in the H and K broad bands. We focus our analysis on regions of\\nNeptune\\'s atmosphere that are near-infrared dark- that is, free of discrete\\nbright cloud features. We use a forward model coupled to a Markov chain Monte\\nCarlo algorithm to retrieve properties of Neptune\\'s aerosol structure and\\nmethane profile above ~4 bar in these near-infrared dark regions.\\nUsing a set of high signal-to-noise spectra in a cloud-free band from 2-12N,\\nwe find that Neptune\\'s cloud opacity is dominated by a compact, optically thick\\ncloud layer with a base near 3 bar and composed of low albedo, forward\\nscattering particles, with an assumed characteristic size of ~1$\\\\mu$m. Above\\nthis cloud, we require a vertically extended haze of smaller (~0.1 $\\\\mu$m)\\nparticles, which reaches from the upper troposphere (~0.6 bar) into the\\nstratosphere. The particles in this haze are brighter and more isotropically\\nscattering than those in the deep cloud. When we extend our analysis to 18\\ncloud-free locations from 20N to 87S, we observe that the optical depth in\\naerosols above 0.5 bar decreases by a factor of 2-3 or more at mid- and\\nhigh-southern latitudes relative to low latitudes.\\nWe also consider Neptune\\'s methane (CH$_4$) profile, and find that our\\nretrievals indicate a strong preference for a low methane relative humidity at\\npressures where methane is expected to condense. Our preferred solution at most\\nlocations is for a methane relative humidity below 10% near the tropopause in\\naddition to methane depletion down to 2.0-2.5 bar. We tentatively identify a\\ntrend of lower CH$_4$ columns above 2.5 bar at mid- and high-southern latitudes\\nover low latitudes.\\n'\n",
      " '  Applying machine learning in the health care domain has shown promising\\nresults in recent years. Interpretable outputs from learning algorithms are\\ndesirable for decision making by health care personnel. In this work, we\\nexplore the possibility of utilizing causal relationships to refine diagnostic\\nprediction. We focus on the task of diagnostic prediction using discomfort\\ndrawings, and explore two ways to employ causal identification to improve the\\ndiagnostic results. Firstly, we use causal identification to infer the causal\\nrelationships among diagnostic labels which, by itself, provides interpretable\\nresults to aid the decision making and training of health care personnel.\\nSecondly, we suggest a post-processing approach where the inferred causal\\nrelationships are used to refine the prediction accuracy of a multi-view\\nprobabilistic model. Experimental results show firstly that causal\\nidentification is capable of detecting the causal relationships among\\ndiagnostic labels correctly, and secondly that there is potential for improving\\npain diagnostics prediction accuracy using the causal relationships.\\n'\n",
      " '  We develop a model to compute the first-passage time of a random walker in a\\ncrowded environment. Hard-core particles with the same size and diffusion\\ncoefficient than the tracer diffuse, and the model allows to compute the first\\npassage time of the tracer on euclidian lattices. The result is compared to\\nclassical Nakazato-Kitahara model, and extends previous results obtained for\\npersistent random walker. The crowding in a confined media acts as a memory\\neffect, and thus lead to a persistent-like behavior.\\n'\n",
      " '  Let $p$ be a prime number. We develop a theory of $p$-adic Mahler measure of\\npolynomials and apply it to the study of $\\\\mathbb{Z}$-covers of rational\\nhomology 3-spheres branched over links. We obtain a $p$-adic analogue of the\\nasymptotic formula of the torsion homology growth and a balance formula among\\nthe leading coefficient of the Alexander polynomial, the $p$-adic entropy, and\\nthe Iwasawa $\\\\mu_p$-invariant. We also apply the purely $p$-adic theory of\\nBesser--Deninger to $\\\\mathbb{Z}$-covers of links. In addition, we study the\\nentropies of profinite cyclic covers of links. We examine various examples\\nthroughout the paper.\\n'\n",
      " '  It has been a long-standing problem to efficiently learn a halfspace using as\\nfew labels as possible in the presence of noise. In this work, we propose an\\nefficient Perceptron-based algorithm for actively learning homogeneous\\nhalfspaces under the uniform distribution over the unit sphere. Under the\\nbounded noise condition~\\\\cite{MN06}, where each label is flipped with\\nprobability at most $\\\\eta < \\\\frac 1 2$, our algorithm achieves a near-optimal\\nlabel complexity of\\n$\\\\tilde{O}\\\\left(\\\\frac{d}{(1-2\\\\eta)^2}\\\\ln\\\\frac{1}{\\\\epsilon}\\\\right)$ in time\\n$\\\\tilde{O}\\\\left(\\\\frac{d^2}{\\\\epsilon(1-2\\\\eta)^3}\\\\right)$. Under the adversarial\\nnoise condition~\\\\cite{ABL14, KLS09, KKMS08}, where at most a $\\\\tilde\\n\\\\Omega(\\\\epsilon)$ fraction of labels can be flipped, our algorithm achieves a\\nnear-optimal label complexity of $\\\\tilde{O}\\\\left(d\\\\ln\\\\frac{1}{\\\\epsilon}\\\\right)$\\nin time $\\\\tilde{O}\\\\left(\\\\frac{d^2}{\\\\epsilon}\\\\right)$. Furthermore, we show that\\nour active learning algorithm can be converted to an efficient passive learning\\nalgorithm that has near-optimal sample complexities with respect to $\\\\epsilon$\\nand $d$.\\n'\n",
      " \"  Massive co-located devices require new paradigms to allow proper network\\nconnectivity. Internet of things (IoT) is the paradigm that offers a solution\\nfor the inter-connectivity of devices, but in dense IoT networks time\\nsynchronization is a critical aspect. Further, the scalability is another\\ncrucial aspect. This paper focuses on synchronization for uncoordinated dense\\nnetworks without any external timing reference. Two synchronization methods are\\nproposed and compared: i) conventional synchronization that copes with the high\\ndensity of nodes by frame collision-avoidance methods (e.g., CSMA/CA) to avoid\\nthe superimposition (or collision) of synchronization signals; and ii)\\ndistributed synchronization that exploits the frames' collision to drive the\\nnetwork to a global synchronization. The distributed synchronization algorithm\\nallows the network to reach a timing synchronization status based on a common\\nbeacon with the same signature broadcasted by every device. The superimposition\\nof beacons from all the other devices enables the network synchronization,\\nrather than preventing it. Numerical analysis evaluates the synchronization\\nperformance based on the convergence time and synchronization dispersion, both\\non collision and non-collision scenario, by investigating the scalability of\\nthe network. Results prove that in dense network the ensemble of signatures\\nprovides remarkable improvements of synchronization performance compared to\\nconventional master-slave reference.\\n\"\n",
      " '  Computer science offers a large set of tools for prototyping, writing,\\nrunning, testing, validating, sharing and reproducing results, however\\ncomputational science lags behind. In the best case, authors may provide their\\nsource code as a compressed archive and they may feel confident their research\\nis reproducible. But this is not exactly true. James Buckheit and David Donoho\\nproposed more than two decades ago that an article about computational results\\nis advertising, not scholarship. The actual scholarship is the full software\\nenvironment, code, and data that produced the result. This implies new\\nworkflows, in particular in peer-reviews. Existing journals have been slow to\\nadapt: source codes are rarely requested, hardly ever actually executed to\\ncheck that they produce the results advertised in the article. ReScience is a\\npeer-reviewed journal that targets computational research and encourages the\\nexplicit replication of already published research, promoting new and\\nopen-source implementations in order to ensure that the original research can\\nbe replicated from its description. To achieve this goal, the whole publishing\\nchain is radically different from other traditional scientific journals.\\nReScience resides on GitHub where each new implementation of a computational\\nstudy is made available together with comments, explanations, and software\\ntests.\\n'\n",
      " '  We present initial results from the first systematic survey of luminous\\n$z\\\\sim 5.5$ quasars. Quasars at $z \\\\sim$ 5.5, the post-reionization epoch, are\\ncrucial tools to explore the evolution of intergalactic medium, quasar\\nevolution and the early super-massive black hole growth. However, it has been\\nvery challenging to select quasars at redshifts 5.3 $\\\\le z \\\\le$ 5.7 using\\nconventional color selections, due to their similar optical colors to late-type\\nstars, especially M dwarfs, resulting in a glaring redshift gap in quasar\\nredshift distributions. We develop a new selection technique for $z \\\\sim$ 5.5\\nquasars based on optical, near-IR and mid-IR photometric data from Sloan\\nDigital Sky Survey (SDSS), UKIRT InfraRed Deep Sky Surveys - Large Area Survey\\n(ULAS), VISTA Hemisphere Survey (VHS) and Wide field Infrared Survey Explorer\\n(WISE). From our pilot observations in SDSS-ULAS/VHS area, we have discovered\\n15 new quasars at 5.3 $\\\\le z \\\\le$ 5.7 and 6 new lower redshift quasars, with\\nSDSS z band magnitude brighter than 20.5. Including other two $z \\\\sim$ 5.5\\nquasars already published in our previous work, we now construct an uniform\\nquasar sample at 5.3 $\\\\le z \\\\le$ 5.7 with 17 quasars in a $\\\\sim$ 4800 square\\ndegree survey area. For further application in a larger survey area, we apply\\nour selection pipeline to do a test selection by using the new wide field J\\nband photometric data from a preliminary version of the UKIRT Hemisphere Survey\\n(UHS). We successfully discover the first UHS selected $z \\\\sim$ 5.5 quasar.\\n'\n",
      " '  Discriminant analysis is a useful classification method. Variable selection\\nfor discriminant analysis is becoming more and more im- portant in a\\nhigh-dimensional setting. This paper is concerned with the binary-class\\nproblems of main and interaction effects selection for the quadratic\\ndiscriminant analysis. We propose a new penalized quadratic discriminant\\nanalysis (QDA) for variable selection in binary classification. Under sparsity\\nassumption on the relevant variables, we conduct a penalized liner regression\\nto derive sparse QDA by plug- ging the main and interaction effects in the\\nmodel. Then the QDA problem is converted to a penalized sparse ordinary least\\nsquares op- timization by using the composite absolute penalties (CAP). Coor-\\ndinate descent algorithm is introduced to solve the convex penalized least\\nsquares. The penalized linear regression can simultaneously se- lect the main\\nand interaction effects, and also conduct classification. Compared with the\\nexisting methods of variable selection in QDA, the extensive simulation studies\\nand two real data analyses demon- strate that our proposed method works well\\nand is robust in the performance of variable selection and classification.\\n'\n",
      " '  In this paper we formulate a four parameter absolute continuous Geometric\\nMarshall-Olkin bivariate Pareto distribution and study its parameter estimation\\nthrough EM algorithm and also explore the bayesian analysis through slice cum\\nGibbs sampler approach. Numerical results are shown to verify the performance\\nof the algorithms. We illustrate the procedures through a real life data\\nanalysis.\\n'\n",
      " '  Let $T\\\\subset{\\\\mathbb R}^n$ be a fixed set. By a scaled copy of $T$ around\\n$x\\\\in{\\\\mathbb R}^n$ we mean a set of the form $x+rT$ for some $r>0$.\\nIn this survey paper we study results about the following type of problems:\\nHow small can a set be if it contains a scaled copy of $T$ around every point\\nof a set of given size? We will consider the cases when $T$ is circle or sphere\\ncentered at the origin, Cantor set in ${\\\\mathbb R}$, the boundary of a square\\ncentered at the origin, or more generally the $k$-skeleton ($0\\\\le k<n$) of an\\n$n$-dimensional cube centered at the origin or the $k$-skeleton of a more\\ngeneral polytope of ${\\\\mathbb R}^n$.\\nWe also study the case when we allow not only scaled copies but also scaled\\nand rotated copies and also the case when we allow only rotated copies.\\n'\n",
      " '  The nonlinear Hausdorff-Young inequality follows from the work of Christ and\\nKiselev. Later Muscalu, Tao, and Thiele asked if the constants can be chosen\\nindependently of the exponent. We show that the nonlinear Hausdorff-Young\\nquotient admits an even better upper bound than the linear one, provided that\\nthe function is sufficiently small in the $L^1$ norm. The proof combines\\nperturbative techniques with the sharpened version of the linear\\nHausdorff-Young inequality due to Christ.\\n'\n",
      " \"  We periodically kick a local region in a one-dimensional lattice and\\ndemonstrate, by studying wave packet dynamics, that the strength and the time\\nperiod of the kicking can be used as tuning parameters to control the\\ntransmission probability across the region. Interestingly, we can tune the\\ntransmission to zero which is otherwise impossible to do in a time-independent\\nsystem. We adapt the non-equilibrium Green's function method to take into\\naccount the effects of periodic driving; the results obtained by this method\\nagree with those found by wave packet dynamics if the time period is small. We\\ndiscover that Floquet bound states can exist in certain ranges of parameters;\\nwhen the driving frequency is decreased, these states get delocalized and turn\\ninto resonances by mixing with the Floquet bulk states. We extend these results\\nto incorporate the effects of local interactions at the driven site, and we\\nfind some interesting features in the transmission and the bound states.\\n\"\n",
      " '  We study superconducting properties of population-imbalanced ultracold Fermi\\nmixtures in the honeycomb lattice that can be effectively described by the\\nspin-imbalanced attractive Hubbard model in the presence of a Zeeman magnetic\\nfield. We use the mean-field theory approach to obtain ground state phase\\ndiagrams including some unconventional superconducting phases such as the\\nFulde--Ferrell--Larkin--Ovchinnikov (FFLO) phase. We show that this phase is\\ncharacterized by atypical behaviour of the Cooper pairs total momentum in the\\nexternal magnetic field. We show that the momentum changes its value as well as\\ndirection with change of the system parameters. We discuss the influence of van\\nHove singularities on the possibility of the reentrant FFLO phase occurrence,\\nwithout a BCS precursor.\\n'\n",
      " '  Context. It is still an open issue whether a self-gravitating accretion disk\\nfragments. There are many different physical and numerical explanations for\\nfragmentation, but simulations often show a non-convergent behavior for ever\\nbetter resolution.\\nAims. We investigate the influence of different numerical limiters in Godunov\\ntype schemes on the fragmentation boundary in self- gravitating disks.\\nMethods. We compare the linear and non-linear outcome in two-dimensional\\nshearingsheet simulations using the VANLEER and the SUPERBEE limiter.\\nResults. We show that choosing inappropriate limiting functions to handle\\nshock-capturing in Godunov type schemes can lead to an overestimation of the\\nsurface density in regions with shallow density gradients. The effect amplifies\\nitself on timescales comparable to the dynamical timescale even at high\\nresolutions. This is exactly the environment, where clumps are expected to\\nform. The effect is present without, but scaled up by, self-gravity and also\\ndoes not depend on cooling. Moreover it can be backtracked to a well known\\neffect called oversteepening. If the effect is also observed in the linear\\ncase, the fragmentation limit is shifted to larger values of the critical\\ncooling timescale.\\n'\n",
      " '  Stochastic optimization of continuous objectives is at the heart of modern\\nmachine learning. However, many important problems are of discrete nature and\\noften involve submodular objectives. We seek to unleash the power of stochastic\\ncontinuous optimization, namely stochastic gradient descent and its variants,\\nto such discrete problems. We first introduce the problem of stochastic\\nsubmodular optimization, where one needs to optimize a submodular objective\\nwhich is given as an expectation. Our model captures situations where the\\ndiscrete objective arises as an empirical risk (e.g., in the case of\\nexemplar-based clustering), or is given as an explicit stochastic model (e.g.,\\nin the case of influence maximization in social networks). By exploiting that\\ncommon extensions act linearly on the class of submodular functions, we employ\\nprojected stochastic gradient ascent and its variants in the continuous domain,\\nand perform rounding to obtain discrete solutions. We focus on the rich and\\nwidely used family of weighted coverage functions. We show that our approach\\nyields solutions that are guaranteed to match the optimal approximation\\nguarantees, while reducing the computational cost by several orders of\\nmagnitude, as we demonstrate empirically.\\n'\n",
      " '  We study a three-wave truncation of the high-order nonlinear Schrödinger\\nequation for deepwater waves (HONLS, also named Dysthe equation). We validate\\nour approach by comparing it to numerical simulation, distinguish the impact of\\nthe different fourth-order terms and classify the solutions according to their\\ntopology. This allows us to properly define the temporary spectral upshift\\noccurring in the nonlinear stage of Benjamin-Feir instability and provides a\\ntool for studying further generalizations of this model.\\n'\n",
      " '  While prior work on context-based music recommendation focused on fixed set\\nof contexts (e.g. walking, driving, jogging), we propose to use multiple\\nsensors and external data sources to describe momentary (ephemeral) context in\\na rich way with a very large number of possible states (e.g. jogging fast along\\nin downtown of Sydney under a heavy rain at night being tired and angry). With\\nour approach, we address the problems which current approaches face: 1) a\\nlimited ability to infer context from missing or faulty sensor data; 2) an\\ninability to use contextual information to support novel content discovery.\\n'\n",
      " '  In this paper we study constant scalar curvature equation (CSCK), a nonlinear\\nfourth order elliptic equation, and its weak solutions on Kähler manifolds.\\nWe first define a notion of weak solution of CSCK for an $L^\\\\infty$ Kähler\\nmetric. The main result is to show that such a weak solution (with uniform\\n$L^\\\\infty$ bound) is smooth. As an application, this answers in part a\\nconjecture of Chen regarding the regularity of $K$-energy minimizers. The new\\ntechnical ingredient is a $W^{2, 2}$ regularity result for the Laplacian\\nequation $\\\\Delta_g u=f$ on Kähler manifolds, where the metric has only\\n$L^\\\\infty$ coefficients. It is well-known that such a $W^{2, 2}$ regularity\\n($W^{2, p}$ regularity for any $p>1$) fails in general (except for dimension\\ntwo) for uniform elliptic equations of the form $a^{ij}\\\\partial^2_{ij}u=f$ for\\n$a^{ij}\\\\in L^\\\\infty$, without certain smallness assumptions on the local\\noscillation of $a^{ij}$. We observe that the Kähler condition plays an\\nessential role to obtain a $W^{2, 2}$ regularity for elliptic equations with\\nonly $L^\\\\infty$ elliptic coefficients on compact manifolds.\\n'\n",
      " '  We prove that a sequence of quasi-Fuchsian representations for which the\\ncritical exponent converges to the topological dimension of the boundary of the\\ngroup (larger than 2), converges up to subsequence and conjugacy to a totally\\ngeodesic representation.\\n'\n",
      " \"  In this contribution we analyze a parties' vote share distribution across the\\npolling stations during the Lithuanian parliamentary elections of 1992, 2008\\nand 2012. We find that the distribution is rather well fitted by the Beta\\ndistribution. To reproduce this empirical observation we propose a simple\\nmulti-state agent-based model of the voting behavior. In the proposed model\\nagents change the party they vote for either idiosyncratically or due to a\\nlinear recruitment mechanism. We use the model to reproduce the vote share\\ndistribution observed during the election of 1992. We discuss model extensions\\nneeded to reproduce the vote share distribution observed during the other\\nelections.\\n\"\n",
      " '  We derive a new formulation of the $3D$ compressible Euler equations with\\ndynamic entropy exhibiting remarkable null structures and regularity\\nproperties. Our results hold for an arbitrary equation of state (which yields\\nthe pressure in terms of the density and the entropy) in non-vacuum regions\\nwhere the speed of sound is positive. Our work is an extension of our prior\\njoint work with J. Luk, in which we derived a similar new formulation in the\\nspecial case of a barotropic fluid, that is, when the equation of state depends\\nonly on the density. The new formulation comprises covariant wave equations for\\nthe Cartesian components of the velocity and the logarithmic density coupled to\\na transport equation for the specific vorticity (defined to be vorticity\\ndivided by density), a transport equation for the entropy, and some additional\\ntransport-divergence-curl-type equations involving special combinations of the\\nderivatives of the solution variables. The good geometric structures in the\\nequations allow one to use the full power of the vectorfield method in treating\\nthe \"wave part\" of the system. In a forthcoming application, we will use the\\nnew formulation to give a sharp, constructive proof of finite-time shock\\nformation, tied to the intersection of acoustic \"wave\" characteristics, for\\nsolutions with nontrivial vorticity and entropy at the singularity. In the\\npresent article, we derive the new formulation and overview the central role\\nthat it plays in the proof of shock formation.\\n'\n",
      " '  Thanks to incredible advances in instrumentation, surveys like the Sloan\\nDigital Sky Survey have been able to find and catalog billions of objects,\\nranging from local M dwarfs to distant quasars. Machine learning algorithms\\nhave greatly aided in the effort to classify these objects; however, there are\\nregimes where these algorithms fail, where interesting oddities may be found.\\nWe present here an X-ray bright quasar misidentified as a red supergiant/X-ray\\nbinary, and a subsequent search of the SDSS quasar catalog for X-ray bright\\nstars misidentified as quasars.\\n'\n",
      " '  Tropical diseases like \\\\textit{Chikungunya} and \\\\textit{Zika} have come to\\nprominence in recent years as the cause of serious, long-lasting,\\npopulation-wide health problems. In large countries like Brasil, traditional\\ndisease prevention programs led by health authorities have not been\\nparticularly effective. We explore the hypothesis that monitoring and analysis\\nof social media content streams may effectively complement such efforts.\\nSpecifically, we aim to identify selected members of the public who are likely\\nto be sensitive to virus combat initiatives that are organised in local\\ncommunities. Focusing on Twitter and on the topic of Zika, our approach\\ninvolves (i) training a classifier to select topic-relevant tweets from the\\nTwitter feed, and (ii) discovering the top users who are actively posting\\nrelevant content about the topic. We may then recommend these users as the\\nprime candidates for direct engagement within their community. In this short\\npaper we describe our analytical approach and prototype architecture, discuss\\nthe challenges of dealing with noisy and sparse signal, and present encouraging\\npreliminary results.\\n'\n",
      " '  In this paper, we propose a generalized Gronwall inequality through the\\nfractional integral with respect to another function. The Cauchy-type problem\\nfor a nonlinear differential equation involving the $\\\\psi$-Hilfer fractional\\nderivative and the existence and uniqueness of solutions are discussed.\\nFinally, through generalized Gronwall inequality, we prove the continuous\\ndependence of data on the Cauchy-type problem.\\n'\n",
      " '  Power grids are undergoing major changes due to rapid growth in renewable\\nenergy resources and improvements in battery technology. While these changes\\nenhance sustainability and efficiency, they also create significant management\\nchallenges as the complexity of power systems increases. To tackle these\\nchallenges, decentralized Internet-of-Things (IoT) solutions are emerging,\\nwhich arrange local communities into transactive microgrids. Within a\\ntransactive microgrid, \"prosumers\" (i.e., consumers with energy generation and\\nstorage capabilities) can trade energy with each other, thereby smoothing the\\nload on the main grid using local supply. It is hard, however, to provide\\nsecurity, safety, and privacy in a decentralized and transactive energy system.\\nOn the one hand, prosumers\\' personal information must be protected from their\\ntrade partners and the system operator. On the other hand, the system must be\\nprotected from careless or malicious trading, which could destabilize the\\nentire grid. This paper describes Privacy-preserving Energy Transactions\\n(PETra), which is a secure and safe solution for transactive microgrids that\\nenables consumers to trade energy without sacrificing their privacy. PETra\\nbuilds on distributed ledgers, such as blockchains, and provides anonymity for\\ncommunication, bidding, and trading.\\n'\n",
      " '  Supervisor reduction procedure can be used to construct the reduced\\nsupervisor with a reduced number of states in discrete-event systems. The main\\nconcepts which are used in this procedure are control consistency of states,\\ncontrol cover, induced supervisor, and normality of the reduced supervisor\\nw.r.t. the original supervisor. In this paper, it is proved that the reduced\\nsupervisor, constructed by the proposed method in [9], preserves the\\nobservation properties, i.e. normality and relative observability, by self\\nlooping corresponding unobservable events at some states of the reduced\\nsupervisor. This property can be applied to find a natural projection, under\\nwhich the supervisor is relative observable.\\n'\n",
      " '  We investigate the influence of particle diffusion in the two-dimension\\ncontact process (CP) with a competitive dynamics in bipartite sublattices,\\nproposed in [Phys. Rev. E 84, 011125 (2011)]. The particle creation depends on\\nits first and second neighbors and the extinction increases according to the\\nlocal density. In contrast to the standard CP model, mean-field theory and\\nnumerical simulations predict three stable phases: inactive (absorbing), active\\nsymmetric and active asymmetric, signed by distinct sublattice particle\\noccupations. Our results from MFT and Monte Carlo simulations reveal that low\\ndiffusion rates do not destroy sublattice ordering, ensuring the maintenance of\\nthe asymmetric phase. On the other hand, for diffusion larger than a threshold\\nvalue Dc, the sublattice ordering is suppressed and only the usual active\\n(symmetric)-inactive transition is presented. We also show the critical\\nbehavior and universality classes are not affected by the diffusion.\\n'\n",
      " '  The Wasserstein probability metric has received much attention from the\\nmachine learning community. Unlike the Kullback-Leibler divergence, which\\nstrictly measures change in probability, the Wasserstein metric reflects the\\nunderlying geometry between outcomes. The value of being sensitive to this\\ngeometry has been demonstrated, among others, in ordinal regression and\\ngenerative modelling. In this paper we describe three natural properties of\\nprobability divergences that reflect requirements from machine learning: sum\\ninvariance, scale sensitivity, and unbiased sample gradients. The Wasserstein\\nmetric possesses the first two properties but, unlike the Kullback-Leibler\\ndivergence, does not possess the third. We provide empirical evidence\\nsuggesting that this is a serious issue in practice. Leveraging insights from\\nprobabilistic forecasting we propose an alternative to the Wasserstein metric,\\nthe Cramér distance. We show that the Cramér distance possesses all three\\ndesired properties, combining the best of the Wasserstein and Kullback-Leibler\\ndivergences. To illustrate the relevance of the Cramér distance in practice\\nwe design a new algorithm, the Cramér Generative Adversarial Network (GAN),\\nand show that it performs significantly better than the related Wasserstein\\nGAN.\\n'\n",
      " '  We study the temperature dependence of the electrical resistivity in a system\\ncomposed of critical spin chains interacting with three dimensional conduction\\nelectrons and driven to criticality via an external magnetic field. The\\nrelevant experimental system is Yb$_2$Pt$_2$Pb, a metal where itinerant\\nelectrons coexist with localized moments of Yb-ions which can be described in\\nterms of effective S = 1/2 spins with dominantly one-dimensional exchange\\ninteraction. The spin subsystem becomes critical in a relatively weak magnetic\\nfield, where it behaves like a Luttinger liquid. We theoretically examine a\\nKondo lattice with different effective space dimensionalities of the two\\ninteracting subsystems. We characterize the corresponding non-Fermi liquid\\nbehavior due to the spin criticality by calculating the electronic relaxation\\nrate and the dc resistivity and establish its quasi linear temperature\\ndependence.\\n'\n",
      " '  Geometry theorem proving forms a major and challenging component in the K-12\\nmathematics curriculum. A particular difficult task is to add auxiliary\\nconstructions (i.e, additional lines or points) to aid proof discovery.\\nAlthough there exist many intelligent tutoring systems proposed for geometry\\nproofs, few teach students how to find auxiliary constructions. And the few\\nexceptions are all limited by their underlying reasoning processes for\\nsupporting auxiliary constructions. This paper tackles these weaknesses of\\nprior systems by introducing an interactive geometry tutor, the Advanced\\nGeometry Proof Tutor (AGPT). It leverages a recent automated geometry prover to\\nprovide combined benefits that any geometry theorem prover or intelligent\\ntutoring system alone cannot accomplish. In particular, AGPT not only can\\nautomatically process images of geometry problems directly, but also can\\ninteractively train and guide students toward discovering auxiliary\\nconstructions on their own. We have evaluated AGPT via a pilot study with 78\\nhigh school students. The study results show that, on training students how to\\nfind auxiliary constructions, there is no significant perceived difference\\nbetween AGPT and human tutors, and AGPT is significantly more effective than\\nthe state-of-the-art geometry solver that produces human-readable proofs.\\n'\n",
      " '  We present the analysis and computational results for the inclination\\nrelative effect of moonlets of triple asteroidal systems. Perturbations on\\nmoonlets due to the primarys non-sphericity gravity, the solar gravity, and\\nmoonlets relative gravity are discussed. The inclination vector for each\\nmoonlet follows a periodic elliptical motion; the motion period depends on the\\nmoonlets semi-major axis and the primarys J2 perturbations. Perturbation on\\nmoonlets from the Solar gravity and moonlets relative gravity makes the motion\\nof the x component of the inclination vector of moonlet 1 and the y component\\nof the inclination vector of moonlet 2 to be periodic.The mean motion of x\\ncomponent and the y component of the inclination vector of each moonlet forms\\nan ellipse. However, the instantaneous motion of x component and the y\\ncomponent of the inclination vector may be an elliptical disc due to the\\ncoupling effect of perturbation forces. Furthermore, the x component of the\\ninclination vector of moonlet 1 and the y component of the inclination vector\\nof moonlet 2 form a quasi-periodic motion. Numerical calculation of dynamical\\nconfigurations of two triple asteroidal systems (216) Kleopatra and (153591)\\n2001 SN263 validates the conclusion.\\n'\n",
      " '  Threshold of the transverse mode coupling instability is calculated in\\nframeworks of the square well model at arbitrary value of space charge tune\\nshift. A new method of calculation is developed beyond the traditional\\nexpansion technique. The square, resistive, and exponential wakes are\\ninvestigated. It is shown that the instability threshold goes up without limit\\nwhen the tune shift increases. A resemblance of the results to conventional\\ncase of the parabolic potential well is demonstrated and explained.\\n'\n",
      " '  We study vector portal dark matter models where the mediator couples only to\\nleptons. In spite of the lack of tree-level couplings to colored states,\\nradiative effects generate interactions with quark fields that could give rise\\nto a signal in current and future experiments. We identify such experimental\\nsignatures: scattering of nuclei in dark matter direct detection; resonant\\nproduction of lepton-antilepton pairs at the Large Hadron Collider; and\\nhadronic final states in dark matter indirect searches. Furthermore, radiative\\neffects also generate an irreducible mass mixing between the vector mediator\\nand the $Z$ boson, severely bounded by ElectroWeak Precision Tests. We use\\ncurrent experimental results to put bounds on this class of models, accounting\\nfor both radiatively induced and tree-level processes. Remarkably, the former\\noften overwhelm the latter.\\n'\n",
      " '  Let $X=(X_t)_{t \\\\ge 0}$ be a stochastic process which has an (not necessarily\\nstationary) independent increment on a probability space $(\\\\Omega,\\n\\\\mathbb{P})$. In this paper, we study the following Cauchy problem related to\\nthe stochastic process $X$:\\n$\\\\label{main eqn} \\\\frac{\\\\partial u}{\\\\partial t}(t,x) = \\\\cA(t)u(t,x) +f(t,x),\\n\\\\quad u(0,\\\\cdot)=0, \\\\quad (t,x) \\\\in (0,T) \\\\times \\\\mathbf{R}^d, \\\\end{align}\\nwhere $f \\\\in L_p( (0,T) ; L_p(\\\\mathbf{R}^d))=L_p( (0,T) ; L_p)$ and\\n\\\\begin{align*} \\\\cA(t)u(t,x) = \\\\lim_{h \\\\downarrow\\n0}\\\\frac{\\\\mathbb{E}\\\\left[u(t,x+X_{t+h}-X_t)-u(t,x)\\\\right]}{h}$. We provide a\\nsufficient condition on $X$ to guarantee the unique solvability of equation\\n(\\\\ref{ab main}) in $L_p\\\\left( [0,T] ; H^\\\\phi_{p}\\\\right)$, where $H^\\\\phi_{p}$ is\\na $\\\\phi$-potential space on $\\\\mathbf{R}^d$ . Furthemore we show that for this\\nsolution, \\\\| u\\\\|_{L_p\\\\left( [0,T] ; H^\\\\phi_{p}\\\\right)} \\\\leq N \\\\|f\\\\|_{L_p\\\\left(\\n[0,T] ; L_p\\\\right)}, where $N$ is independent of $u$ and $f$.\\n'\n",
      " '  Deep learning is a hierarchical inference method formed by subsequent\\nmultiple layers of learning able to more efficiently describe complex\\nrelationships. In this work, Deep Gaussian Mixture Models are introduced and\\ndiscussed. A Deep Gaussian Mixture model (DGMM) is a network of multiple layers\\nof latent variables, where, at each layer, the variables follow a mixture of\\nGaussian distributions. Thus, the deep mixture model consists of a set of\\nnested mixtures of linear models, which globally provide a nonlinear model able\\nto describe the data in a very flexible way. In order to avoid\\noverparameterized solutions, dimension reduction by factor models can be\\napplied at each layer of the architecture thus resulting in deep mixtures of\\nfactor analysers.\\n'\n",
      " '  In this paper, we use variational recurrent neural network to investigate the\\nanomaly detection problem on graph time series. The temporal correlation is\\nmodeled by the combination of recurrent neural network (RNN) and variational\\ninference (VI), while the spatial information is captured by the graph\\nconvolutional network. In order to incorporate external factors, we use feature\\nextractor to augment the transition of latent variables, which can learn the\\ninfluence of external factors. With the target function as accumulative ELBO,\\nit is easy to extend this model to on-line method. The experimental study on\\ntraffic flow data shows the detection capability of the proposed method.\\n'\n",
      " '  In contrast to conventional, univariate analysis, various types of\\nmultivariate analysis have been applied to functional magnetic resonance\\nimaging (fMRI) data. In this paper, we compare two contemporary approaches for\\nmultivariate regression on task-based fMRI data: linear regression with ridge\\nregularization and non-linear symbolic regression using genetic programming.\\nThe data for this project is representative of a contemporary fMRI experimental\\ndesign for visual stimuli. Linear and non-linear models were generated for 10\\nsubjects, with another 4 withheld for validation. Model quality is evaluated by\\ncomparing $R$ scores (Pearson product-moment correlation) in various contexts,\\nincluding single run self-fit, within-subject generalization, and\\nbetween-subject generalization. Propensity for modelling strategies to overfit\\nis estimated using a separate resting state scan. Results suggest that neither\\nmethod is objectively or inherently better than the other.\\n'\n",
      " '  Given a graded $E_1$-module over an $E_2$-algebra in spaces, we construct an\\naugmented semi-simplicial space up to higher coherent homotopy over it, called\\nits canonical resolution, whose graded connectivity yields homological\\nstability for the graded pieces of the module with respect to constant and\\nabelian coefficients. We furthermore introduce a notion of coefficient systems\\nof finite degree in this context and show that, without further assumptions,\\nthe corresponding twisted homology groups stabilize as well. This generalizes a\\nframework of Randal-Williams and Wahl for families of discrete groups.\\nIn many examples, the canonical resolution recovers geometric resolutions\\nwith known connectivity bounds. As a consequence, we derive new twisted\\nhomological stability results for e.g. moduli spaces of high-dimensional\\nmanifolds, unordered configuration spaces of manifolds with labels in a\\nfibration, and moduli spaces of manifolds equipped with unordered embedded\\ndiscs. This in turn implies representation stability for the ordered variants\\nof the latter examples.\\n'\n",
      " '  Connected and autonomous vehicles (CAVs) have recently attracted a\\nsignificant amount of attention both from researchers and industry. Numerous\\nstudies targeting algorithms, software frameworks, and applications on the CAVs\\nscenario have emerged. Meanwhile, several pioneer efforts have focused on the\\nedge computing system and architecture design for the CAVs scenario and\\nprovided various heterogeneous platform prototypes for CAVs. However, a\\nstandard and comprehensive application benchmark for CAVs is missing, hindering\\nthe study of these emerging computing systems. To address this challenging\\nproblem, we present CAVBench, the first benchmark suite for the edge computing\\nsystem in the CAVs scenario. CAVBench is comprised of six typical applications\\ncovering four dominate CAVs scenarios and takes four datasets as standard\\ninput. CAVBench provides quantitative evaluation results via application and\\nsystem perspective output metrics. We perform a series of experiments and\\nacquire three systemic characteristics of the applications in CAVBench. First,\\nthe operation intensity of the applications is polarized, which explains why\\nheterogeneous hardware is important for a CAVs computing system. Second, all\\napplications in CAVBench consume high memory bandwidth, so the system should be\\nequipped with high bandwidth memory or leverage good memory bandwidth\\nmanagement to avoid the performance degradation caused by memory bandwidth\\ncompetition. Third, some applications have worse data/instruction locality\\nbased on the cache miss observation, so the computing system targeting these\\napplications should optimize the cache architecture. Last, we use the CAVBench\\nto evaluate a typical edge computing platform and present the quantitative and\\nqualitative analysis of the benchmarking results.\\n'\n",
      " '  We report on the fragmentation of the water molecule by $1$ MeV H$^{+}$,\\nHe$^{+}$ and 650 keV N$^{+}$ ion impact. The fragment-ion energy spectra were\\nmeasured by an electrostatic spectrometer at different observation angles. The\\nobtained double-differential fragmentation cross sections for N$^{+}$ is found\\nto be more than an order of magnitude higher, than that for H$^{+}$. The\\nrelative ratios of the fragmentation channels are also different for the three\\nprojectiles. Additional fragmentation channels were observed in the spectra for\\nHe$^{+}$ and for N$^{+}$ impact, which are missing in the case of H$^{+}$. From\\nthe analysis of the kinetic energy of the fragments, the maximum observed\\ndegree of ionization was found to be $q\\\\rm{_{max}}=3$, $4$, and $5$ for\\nH${^+}$, He${^+}$ and N${^+}$ impact, respectively. Absolute multiple\\nionization cross sections have been determined. They are compared with the\\npredictions of the classical trajectory Monte Carlo and\\ncontinuum-distorted-wave eikonal-initial-state theories. At lower degrees of\\nionization, theories provide reasonable agreement with experiment. The\\nsystematic overestimation of the cross section by the theories towards higher\\ndegrees of ionization indicates the failure of the independent particle model.\\n'\n",
      " '  This paper is a complement of our recent works on the semilinear Tricomi\\nequations in [8] and[9].\\n'\n",
      " '  We propose a new globalization strategy that can be used in unconstrained\\noptimization algorithms to support rapid convergence from remote starting\\npoints. Our approach is based on using multiple points at each iteration to\\nbuild a representative model of the objective function. Using the new\\ninformation gathered from those multiple points, a local step is gradually\\nimproved by updating its direction as well as its length. We give a global\\nconvergence result and also provide parallel implementation details accompanied\\nwith a numerical study. Our numerical study shows that the proposed algorithm\\nis a promising alternative as a globalization strategy.\\n'\n",
      " '  In this paper, pattern division multiple access with large-scale antenna\\narray (LSA-PDMA) is proposed as a novel non-orthogonal multiple access (NOMA)\\nscheme. In the proposed scheme, pattern is designed in both beam domain and\\npower domain in a joint manner. At the transmitter, pattern mapping utilizes\\npower allocation to improve the system sum rate and beam allocation to enhance\\nthe access connectivity and realize the integration of LSA into multiple access\\nspontaneously. At the receiver, hybrid detection of spatial filter (SF) and\\nsuccessive interference cancellation (SIC) is employed to separate the\\nsuperposed multiple-domain signals. Furthermore, we formulate the sum rate\\nmaximization problem to obtain the optimal pattern mapping policy, and the\\noptimization problem is proved to be convex through proper mathematical\\nmanipulations. Simulation results show that the proposed LSA-PDMA scheme\\nachieves significant performance gain on system sum rate compared to both the\\northogonal multiple access scheme and the power-domain NOMA scheme.\\n'\n",
      " '  Pyramids are the greatest architectural achievement of ancient civilization,\\nso people all over the world are curious as to the purpose of such huge\\nconstructions. No other structure has been studied as thoroughly, nor have so\\nmany books and articles been written about it. We created a computer model of\\nthe pyramid. To validate the model, we compare our calculations with the\\nexperimental data of Luis W. Alvarez. The fact that the Egyptians set up 2.5\\nmillion stone blocks without any purpose seems to be unimaginable. Therefore,\\nwe attempt to examine the internal structure of the pyramid using muon\\ntomography. With our measurements we performed and verified a calibration of\\nthe attenuation of muons for primary beam momenta of 2.5 GeV/c and 3 GeV/c at\\nthe T9 experimental area of CERN.\\n'\n",
      " '  The Bradley-Terry model assigns probabilities for the outcome of paired\\ncomparison experiments based on strength parameters associated with the objects\\nbeing compared. We consider different proposed choices of prior parameter\\ndistributions for Bayesian inference of the strength parameters based on the\\npaired comparison results. We evaluate them according to four desiderata\\nmotivated by the use of inferred Bradley-Terry parameters to rate teams on the\\nbasis of outcomes of a set of games: invariance under interchange of teams,\\ninvariance under interchange of winning and losing, normalizability and\\ninvariance under elimination of teams. We consider various proposals which fail\\nto satisfy one or more of these desiderata, and illustrate two proposals which\\nsatisfy them. Both are one-parameter independent distributions for the\\nlogarithms of the team strengths: 1) Gaussian and 2) Type III generalized\\nlogistic.\\n'\n",
      " '  The methodology of automatic detection of the event basis of information\\noperations, reflected in thematic information flows, is described. The\\npresented methodology is based on the technologies for identifying information\\noperations, the formation of the terminological basis of the subject area, the\\napplication of cluster analysis with cluster centroids, determined by analyzing\\nthe terminology of the information flow. The clusters formed in this way\\nreflect the main events occurring during the information operations and reveal\\nthe technique for their implementation.\\n'\n",
      " '  Active Search has become an increasingly useful tool in information retrieval\\nproblems where the goal is to discover as many target elements as possible\\nusing only limited label queries. With the advent of big data, there is a\\ngrowing emphasis on the scalability of such techniques to handle very large and\\nvery complex datasets.\\nIn this paper, we consider the problem of Active Search where we are given a\\nsimilarity function between data points. We look at an algorithm introduced by\\nWang et al. [2013] for Active Search over graphs and propose crucial\\nmodifications which allow it to scale significantly. Their approach selects\\npoints by minimizing an energy function over the graph induced by the\\nsimilarity function on the data. Our modifications require the similarity\\nfunction to be a dot-product between feature vectors of data points, equivalent\\nto having a linear kernel for the adjacency matrix. With this, we are able to\\nscale tremendously: for $n$ data points, the original algorithm runs in\\n$O(n^2)$ time per iteration while ours runs in only $O(nr + r^2)$ given\\n$r$-dimensional features.\\nWe also describe a simple alternate approach using a weighted-neighbor\\npredictor which also scales well. In our experiments, we show that our method\\nis competitive with existing semi-supervised approaches. We also briefly\\ndiscuss conditions under which our algorithm performs well.\\n'\n",
      " '  A new generator of univariate continuous distributions, with two additional\\nparameters, called the Log-Lindley generated family is introduced. Some special\\ndistributions in the new family are presented. Some mathematical properties of\\nthe new family are studied. The maximum likelihood method to estimate model\\nparameters is employed. The potentiality of the new generator is illustrated\\nusing a real data set.\\n'\n",
      " '  There are (at least) four ways that an agent can acquire information\\nconcerning the state of the universe: via observation, control, prediction, or\\nvia retrodiction, i.e., memory. Each of these four ways of acquiring\\ninformation seems to rely on a different kind of physical device (resp., an\\nobservation device, a control device, etc.). However it turns out that certain\\nmathematical structure is common to those four types of device. Any device that\\npossesses a certain subset of that structure is known as an \"inference device\"\\n(ID).\\nHere I review some of the properties of IDs, including their relation with\\nTuring machines, and (more loosely) quantum mechanics. I also review the bounds\\nof the joint abilities of any set of IDs to know facts about the physical\\nuniverse that contains them. These bounds constrain the possible properties of\\nany universe that contains agents who can acquire information concerning that\\nuniverse.\\nI then extend this previous work on IDs, by adding to the definition of IDs\\nsome of the other mathematical structure that is common to the four ways of\\nacquiring information about the universe but is not captured in the (minimal)\\ndefinition of IDs. I discuss these extensions of IDs in the context of\\nepistemic logic (especially possible worlds formalisms like Kripke structures\\nand Aumann structures). In particular, I show that these extensions of IDs are\\nnot subject to the problem of logical omniscience that plagues many previously\\nstudied forms of epistemic logic.\\n'\n",
      " '  Additive manufacturing of polymer bonded magnets is a recently developed\\ntechnique, for single-unit production, and for structures that have been\\nimpossible to manufacture previously. Also new possibilities to create a\\nspecific stray field around the magnet are triggered. The current work presents\\na method to 3D print polymer bonded magnets with a variable magnetic compound\\ndensity distribution. A low-cost, end-user 3D printer with a mixing extruder is\\nused to mix permanent magnetic filaments with pure PA12 filaments. The magnetic\\nfilaments are compounded, extruded, and characterized for the printing process.\\nTo deduce the quality of the manufactured magnets with a variable compound\\ndensity, an inverse stray field framework is used. The effectiveness of the\\nprinting process and the simulation method is shown. It can also be used to\\nmanufacture magnets that produce a predefined stray field in a given region.\\nExamples for sensor applications are presented. This setup and simulation\\nframework allows the design and manufacturing of polymer bonded permanent\\nmagnets which are impossible to create with conventional methods.\\n'\n",
      " \"  It is currently unclear why adversarial examples are easy to construct for\\ndeep networks that are otherwise successful with respect to their training\\ndomain. However, it is suspected that these adversarial examples lie within\\nsome small perturbation from the network's decision boundaries or exist in\\nlow-density regions with respect to the training distribution. Using persistent\\nhomology, we find that deep networks effectively have ``holes'' in their\\nactivation graphs, making them blind to regions of the input space that can be\\nexploited by adversarial examples. These holes are effectively dense in the\\ninput space, making it easy to find a perturbed image that can be\\nmisclassified. By studying the topology of network activation, we find global\\npatterns in the form of activation subgraphs which can both reliably determine\\nwhether an example is adversarial and can recover the true category of the\\nexample well above chance, implying that semantic information about the input\\nis embedded globally via the activation pattern in deep networks.\\n\"\n",
      " '  The DsTau project proposes to study tau-neutrino production in high-energy\\nproton interactions. The outcome of this experiment are prerequisite for\\nmeasuring the $\\\\nu_\\\\tau$ charged-current cross section that has never been well\\nmeasured. Precisely measuring the cross section would enable testing of lepton\\nuniversality in $\\\\nu_\\\\tau$ scattering and it also has practical implications\\nfor neutrino oscillation experiments and high-energy astrophysical $\\\\nu_\\\\tau$\\nobservations. $D_s$ mesons, the source of tau neutrinos, following high-energy\\nproton interactions will be studied by a novel approach to detect the\\ndouble-kink topology of the decays $D_s \\\\rightarrow \\\\tau\\\\nu_\\\\tau$ and\\n$\\\\tau\\\\rightarrow\\\\nu_\\\\tau X$. Directly measuring $D_s\\\\rightarrow \\\\tau$ decays\\nwill provide an inclusive measurement of the $D_s$ production rate and decay\\nbranching ratio to $\\\\tau$. The momentum reconstruction of $D_s$ will be\\nperformed by combining topological variables. This project aims to detect 1,000\\n$D_s \\\\rightarrow \\\\tau$ decays in $2.3 \\\\times 10^8$ proton interactions in\\ntungsten target to study the differential production cross section of $D_s$\\nmesons. To achieve this, state-of-the-art emulsion detectors with a\\nnanometric-precision readout will be used. The data generated by this project\\nwill enable the $\\\\nu_\\\\tau$ cross section from DONUT to be re-evaluated, and\\nthis should significantly reduce the total systematic uncertainty. Furthermore,\\nthese results will provide essential data for future $\\\\nu_\\\\tau$ experiments\\nsuch as the $\\\\nu_\\\\tau$ program in the SHiP project at CERN. In addition, the\\nanalysis of $2.3 \\\\times 10^8$ proton interactions, combined with the expected\\nhigh yield of $10^5$ charmed decays as by-products, will enable the extraction\\nof additional physical quantities.\\n'\n",
      " '  The variation of spectral subspaces for linear self-adjoint operators under\\nan additive bounded semidefinite perturbation is considered. A variant of the\\nDavis-Kahan $ \\\\sin2\\\\Theta $ theorem from [SIAM J. Numer. Anal. 7 (1970), 1--46]\\nadapted to this situation is proved. Under a certain additional geometric\\nassumption on the separation of the spectrum of the unperturbed operator, this\\nleads to a sharp estimate on the norm of the difference of the spectral\\nprojections associated with isolated components of the spectrum of the\\nperturbed and perturbed operators, respectively. Without this additional\\ngeometric assumption on the isolated components of the spectrum of the\\nunperturbed operator, a corresponding estimate is obtained by transferring the\\noptimization approach for general perturbations in [J. Anal. Math., to appear;\\narXiv:1310.4360 (2013)] to the present situation.\\n'\n",
      " '  By modeling macro-economical indicators using digital traces of human\\nactivities on mobile or social networks, we can provide important insights to\\nprocesses previously assessed via paper-based surveys or polls only. We\\ncollected aggregated workday activity timelines of US counties from the\\nnormalized number of messages sent in each hour on the online social network\\nTwitter. In this paper, we show how county employment and unemployment\\nstatistics are encoded in the daily rhythm of people by decomposing the\\nactivity timelines into a linear combination of two dominant patterns. The\\nmixing ratio of these patterns defines a measure for each county, that\\ncorrelates significantly with employment ($0.46\\\\pm0.02$) and unemployment rates\\n($-0.34\\\\pm0.02$). Thus, the two dominant activity patterns can be linked to\\nrhythms signaling presence or lack of regular working hours of individuals. The\\nanalysis could provide policy makers a better insight into the processes\\ngoverning employment, where problems could not only be identified based on the\\nnumber of officially registered unemployed, but also on the basis of the\\ndigital footprints people leave on different platforms.\\n'\n",
      " '  {Context}. The HIFI instrument on the Herschel Space Observatory performed\\nover 9100 astronomical observations, almost 900 of which were calibration\\nobservations in the course of the nearly four-year Herschel mission. The data\\nfrom each observation had to be converted from raw telemetry into calibrated\\nproducts and were included in the Herschel Science Archive. {Aims}. The HIFI\\npipeline was designed to provide robust conversion from raw telemetry into\\ncalibrated data throughout all phases of the HIFI missions. Pre-launch\\nlaboratory testing was supported as were routine mission operations. {Methods}.\\nA modular software design allowed components to be easily added, removed,\\namended and/or extended as the understanding of the HIFI data developed during\\nand after mission operations. {Results}. The HIFI pipeline processed data from\\nall HIFI observing modes within the Herschel automated processing environment\\nas well as within an interactive environment. The same software can be used by\\nthe general astronomical community to reprocess any standard HIFI observation.\\nThe pipeline also recorded the consistency of processing results and provided\\nautomated quality reports. Many pipeline modules were in use since the HIFI\\npre-launch instrument level testing. {Conclusions}. Processing in steps\\nfacilitated data analysis to discover and address instrument artefacts and\\nuncertainties. The availability of the same pipeline components from pre-launch\\nthroughout the mission made for well-understood, tested, and stable processing.\\nA smooth transition from one phase to the next significantly enhanced\\nprocessing reliability and robustness.\\n'\n",
      " '  New tilings of certain subsets of $\\\\mathbb{R}^{M}$ are studied, tilings\\nassociated with fractal blow-ups of certain similitude iterated function\\nsystems (IFS). For each such IFS with attractor satisfying the open set\\ncondition, our construction produces a usually infinite family of tilings that\\nsatisfy the following properties: (1) the prototile set is finite; (2) the\\ntilings are repetitive (quasiperiodic); (3) each family contains\\nself-similartilings, usually infinitely many; and (4) when the IFS is rigid in\\nan appropriate sense, the tiling has no non-trivial symmetry; in particular the\\ntiling is non-periodic.\\n'\n",
      " '  BaMn$_{2}$As$_{2}$ is an antiferromagnetic insulator where a metal-insulator\\ntransition occurs with hole doping via the substitution of Ba with K. The\\nmetal-insulator transition causes only a small suppression of the Néel\\ntemperature ($T_\\\\mathrm{N}$) and the ordered moment, suggesting that doped\\nholes interact weakly with the Mn spin system. Powder inelastic neutron\\nscattering measurements were performed on three different powder samples of\\nBa$_{1-x}$K$_{x}$Mn$_{2}$As$_{2}$ with $x=$0, 0.125 and 0.25 to study the\\neffect of hole doping and metallization on the spin dynamics of these\\ncompounds. We compare the neutron intensities to a linear spin wave theory\\napproximation to the $J_{1}-J_{2}-J_{c}$ Heisenberg model. Hole doping is found\\nto introduce only minor modifications to the exchange energies and spin gap.\\nThe changes observed in the exchange constants are consistent with the small\\ndrop of $T_\\\\mathrm{N}$ with doping.\\n'\n",
      " '  Low dimensional embeddings that capture the main variations of interest in\\ncollections of data are important for many applications. One way to construct\\nthese embeddings is to acquire estimates of similarity from the crowd. However,\\nsimilarity is a multi-dimensional concept that varies from individual to\\nindividual. Existing models for learning embeddings from the crowd typically\\nmake simplifying assumptions such as all individuals estimate similarity using\\nthe same criteria, the list of criteria is known in advance, or that the crowd\\nworkers are not influenced by the data that they see. To overcome these\\nlimitations we introduce Context Embedding Networks (CENs). In addition to\\nlearning interpretable embeddings from images, CENs also model worker biases\\nfor different attributes along with the visual context i.e. the visual\\nattributes highlighted by a set of images. Experiments on two noisy crowd\\nannotated datasets show that modeling both worker bias and visual context\\nresults in more interpretable embeddings compared to existing approaches.\\n'\n",
      " '  We characterize a close connection between the continuous-time quantum-walk\\nmodel and a discrete-time quantum-walk version, based on the staggered model\\nwith Hamiltonians in a class of Cayley graphs, which can be considered as a\\ndiscretization of continuous-time quantum walks. This connection provides\\nexamples of perfect state transfer and instantaneous uniform mixing in the\\nstaggered model. On the other hand, we provide some more examples of perfect\\nstate transfer and instantaneous uniform mixing in the staggered model that\\ncannot be reproduced by the continuous-time model.\\n'\n",
      " '  This paper explores the uniqueness of ESA Rosetta mission operations from the\\nAlice instrument point of view, documents lessons learned, and suggests\\noperations ideas for future missions. The Alice instrument mounted on the\\nRosetta orbiter is an imaging spectrograph optimized for cometary\\nfar-ultraviolet (FUV) spectroscopy with the scientific objectives of measuring\\nproperties of the escaping gas and dust, and studying the surface properties,\\nincluding searching for exposed ices. We describe the operations processes\\nduring the comet encounter period, the many interfaces to contend with, the\\nconstraints that impacted Alice, and how the Alice science goals of measuring\\nthe cometary gas characteristics and their evolution were achieved. We provide\\ndetails that are relevant to the use and interpretation of Alice data and\\npublished results. All these flight experiences and lessons learned will be\\nuseful for future cometary missions that include ultraviolet spectrographs in\\nparticular, and multi-instrument international payloads in general.\\n'\n",
      " '  The successive projection algorithm (SPA) can quickly solve a nonnegative\\nmatrix factorization problem under a separability assumption. Even if noise is\\nadded to the problem, SPA is robust as long as the perturbations caused by the\\nnoise are small. In particular, robustness against noise should be high when\\nhandling the problems arising from real applications. The preconditioner\\nproposed by Gillis and Vavasis (2015) makes it possible to enhance the noise\\nrobustness of SPA. Meanwhile, an additional computational cost is required. The\\nconstruction of the preconditioner contains a step to compute the top-$k$\\ntruncated singular value decomposition of an input matrix. It is known that the\\ndecomposition provides the best rank-$k$ approximation to the input matrix; in\\nother words, a matrix with the smallest approximation error among all matrices\\nof rank less than $k$. This step is an obstacle to an efficient implementation\\nof the preconditioned SPA.\\nTo address the cost issue, we propose a modification of the algorithm for\\nconstructing the preconditioner. Although the original algorithm uses the best\\nrank-$k$ approximation, instead of it, our modification uses an alternative.\\nIdeally, this alternative should have high approximation accuracy and low\\ncomputational cost. To ensure this, our modification employs a rank-$k$\\napproximation produced by an SPA based algorithm. We analyze the accuracy of\\nthe approximation and evaluate the computational cost of the algorithm. We then\\npresent an empirical study revealing the actual performance of the SPA based\\nrank-$k$ approximation algorithm and the modified preconditioned SPA.\\n'\n",
      " '  Fluorescent paramagnetic defects in solids have become attractive systems for\\nquantum information processing in the recent years. One of the leading\\ncontenders is the negatively charged nitrogen-vacancy defect in diamond with\\nvisible emission but alternative solution in technologically mature host is an\\nimmediate quest for many applications in this field. It has been recently found\\nthat various polytypes of silicon carbide (SiC), that are standard\\nsemiconductors with wafer scale technology, can host nitrogen-vacancy defect\\n(NV) that could be an alternative qubit candidate with emission in the near\\ninfrared region. However, it is much less known about this defect than its\\ncounterpart in diamond. The inequivalent sites within a polytype and the\\npolytype variations offer a family of NV defects. However, there is an\\ninsufficient knowledge on the magneto-optical properties of these\\nconfigurations. Here we carry out density functional theory calculations, in\\norder to characterize the numerous forms of NV defects in the most common\\npolytypes of SiC including 3C, 4H and 6H, and we also provide new experimental\\ndata in 4H SiC. Our calculations mediate the identification of individual NV\\nqubits in SiC polytypes. In addition, we discuss the formation of NV defects in\\nSiC with providing detailed ionization energies of NV defect in SiC which\\nreveals the critical optical excitation energies for ionizing this qubits in\\nSiC. Our calculations unravel the challenges to produce NV defects in SiC with\\na desirable spin bath.\\n'\n",
      " '  We present three-band simultaneous observations of a weak-line T-Tauri star\\nCVSO~30 (PTFO~8-8695), which is one of the youngest objects having a candidate\\ntransiting planet. The data were obtained with the Multicolor Simultaneous\\nCamera for studying Atmospheres of Transiting exoplanets (MuSCAT) on the 188 cm\\ntelescope at Okayama Astrophysical Observatory in Japan. We observed the fading\\nevent in the $g^{\\\\prime}_2$-, $r^{\\\\prime}_2$-, and $z_{\\\\rm s,2}$-bands\\nsimultaneously. As a result, we find a significant wavelength dependence of\\nfading depths of about 3.1\\\\%, 1.7\\\\%, 1.0\\\\% for the $g^{\\\\prime}_2$-,\\n$r^{\\\\prime}_2$-, and $z_{\\\\rm s,2}$-bands, respectively. A cloudless H/He\\ndominant atmosphere of a hot Jupiter cannot explain this large wavelength\\ndependence. Additionally, we rule out a scenario by the occultation of the\\ngravity-darkened host star. Thus our result is in favor of the fading origin as\\ncircumstellar dust clump or occultation of an accretion hotspot.\\n'\n",
      " '  Helical liquids have been experimentally detected in both nanowires and\\nultracold atomic chains as the result of strong spin-orbit interactions. In\\nboth cases the inner degrees of freedom can be considered as an additional\\nspace dimension, providing an interpretation of these systems as synthetic\\nladders, with artificial magnetic fluxes determined by the spin-orbit terms. In\\nthis work, we characterize the helical state which appears at filling\\n$\\\\nu=1/2$: this state is generated by a gap arising in the spin sector of the\\ncorresponding Luttinger liquid and it can be interpreted as the one-dimensional\\n(1D) limit of a fractional quantum Hall state of bosonic pairs of fermions. We\\nstudy its main features, focusing on entanglement properties and correlation\\nfunctions. The techniques developed here provide a key example for the study of\\nsimilar quasi-1D systems beyond the semiclassical approximation commonly\\nadopted in the description of the Laughlin-like states.\\n'\n",
      " '  Starting from a so-called flat exact semisimple bihamiltonian structures of\\nhydrodynamic type, we arrive at a Frobenius manifold structure and a tau\\nstructure for the associated principal hierarchy. We then classify the\\ndeformations of the principal hierarchy which possess tau structures.\\n'\n",
      " '  The mechanisms of localization of Jahn-Teller deformations and vibronic\\nwavefunctions in isotope substituted dynamical Jahn-Teller systems are\\nelucidated. It is found that the localization in the trough is of potential\\ntype in the case of strong vibronic coupling, while it becomes of kinetic type\\nin the case of intermediate and weak coupling. It is shown that the vibronic\\nlevels in the linear $E\\\\otimes e$-problem remain double degenerate upon\\narbitrary isotope substitution on the reasons similar to time reversal symmetry\\nin which the role of spin is played by orbital pseudospin.\\n'\n",
      " '  We present an instance segmentation algorithm trained and applied to a CCTV\\nrecording of beef cattle during a winter finishing period. A fully\\nconvolutional network was transformed into an instance segmentation network\\nthat learns to label each instance of an animal separately. We introduce a\\nconceptually simple framework that the network uses to output a single\\nprediction for every animal. These results are a contribution towards behaviour\\nanalysis in winter finishing beef cattle for early detection of animal\\nwelfare-related problems.\\n'\n",
      " '  We consider the hash function $h(x) = ((ax+b) \\\\bmod p) \\\\bmod n$ where $a,b$\\nare chosen uniformly at random from $\\\\{0,1,\\\\ldots,p-1\\\\}$. We prove that when we\\nuse $h(x)$ in hashing with chaining to insert $n$ elements into a table of size\\n$n$ the expected length of the longest chain is\\n$\\\\tilde{O}\\\\!\\\\left(n^{1/3}\\\\right)$. The proof also generalises to give the same\\nbound when we use the multiply-shift hash function by Dietzfelbinger et al.\\n[Journal of Algorithms 1997].\\n'\n",
      " '  Given a text and a pattern over two types of symbols called constants and\\nvariables, the parameterized pattern matching problem is to find all\\noccurrences of substrings of the text that the pattern matches by substituting\\na variable in the text for each variable in the pattern, where the substitution\\nshould be injective. The function matching problem is a variant of it that\\nlifts the injection constraint. In this paper, we discuss variants of those\\nproblems, where one can substitute a constant or a variable for each variable\\nof the pattern. We give two kinds of algorithms for both problems, a\\nconvolution-based method and an extended KMP-based method, and analyze their\\ncomplexity.\\n'\n",
      " '  In the time series analysis field, there is not a unique recipe for studying\\nsignal similarities. On the other hand, averaging signals of the same nature is\\nan essential tool in the analysis of different kinds of data. Here we propose a\\nmethod to align and average segments of time series with similar patterns. A\\nsimple implementation based on \\\\textit{python} code is provided for the\\nprocedure. The analysis was inspired by the study of canary sound syllables,\\nbut it is possible to apply it in semi periodic signals of different nature and\\nnot necessarily related to sounds.\\n'\n",
      " '  Many combinatorial optimization problems can be mapped to finding the ground\\nstates of the corresponding Ising Hamiltonians. The physical systems that can\\nsolve optimization problems in this way, namely Ising machines, have been\\nattracting more and more attention recently. Our work shows that Ising machines\\ncan be realized using almost any nonlinear self-sustaining oscillators with\\nlogic values encoded in their phases. Many types of such oscillators are\\nreadily available for large-scale integration, with potentials in high-speed\\nand low-power operation. In this paper, we describe the operation and mechanism\\nof oscillator-based Ising machines. The feasibility of our scheme is\\ndemonstrated through several examples in simulation and hardware, among which a\\nsimulation study reports average solutions exceeding those from state-of-art\\nIsing machines on a benchmark combinatorial optimization problem of size 2000.\\n'\n",
      " '  The growth of data, the need for scalability and the complexity of models\\nused in modern machine learning calls for distributed implementations. Yet, as\\nof today, distributed machine learning frameworks have largely ignored the\\npossibility of arbitrary (i.e., Byzantine) failures. In this paper, we study\\nthe robustness to Byzantine failures at the fundamental level of stochastic\\ngradient descent (SGD), the heart of most machine learning algorithms. Assuming\\na set of $n$ workers, up to $f$ of them being Byzantine, we ask how robust can\\nSGD be, without limiting the dimension, nor the size of the parameter space.\\nWe first show that no gradient descent update rule based on a linear\\ncombination of the vectors proposed by the workers (i.e, current approaches)\\ntolerates a single Byzantine failure. We then formulate a resilience property\\nof the update rule capturing the basic requirements to guarantee convergence\\ndespite $f$ Byzantine workers. We finally propose Krum, an update rule that\\nsatisfies the resilience property aforementioned. For a $d$-dimensional\\nlearning problem, the time complexity of Krum is $O(n^2 \\\\cdot (d + \\\\log n))$.\\n'\n",
      " '  We study the general and connected stable ranks for C*-algebras. We estimate\\nthese ranks for pullbacks of C*-algebras, and for tensor products by\\ncommutative C*-algebras. Finally, we apply these results to determine these\\nranks for certain commutative C*-algebras, and non-commutative CW-complexes.\\n'\n",
      " '  Given simple undirected graph G = (V, E), the Maximum Clique Problem(MCP) is\\nthat of finding a maximum-cardinality subset Q of V such that any two vertices\\nin Q are adjacent. We present a modified local search algorithm for this\\nproblem. Our algorithm build some maximal solution and can determine in\\npolynomial time if a maximal solution can be improved by replacing a single\\nvertex with k, k > 1, others. We test our algorithms on DIMACS[5], Sloane[15],\\nBHOSLIB[1], Iovanella[8] and our random instances.\\n'\n",
      " '  In this paper the conditions are investigated for the occurrence of the\\nso-called macroscopic irreversibility property and the related phenomenon of\\ndecay to kinetic equilibrium which may characterize the $1-$body probability\\ndensity function (PDF) associated with hard-sphere systems. The problem is set\\nin the framework of the axiomatic \"ab initio\" approach to classical statistical\\nmechanics recently developed [Tessarotto \\\\textit{et al}., 2013-2017] and the\\nrelated establishment of an exact kinetic equation realized by Master equation\\nfor the same kinetic PDF. As shown in the paper the task involves the\\nintroduction of a suitable functional of the $1-$body PDF here identified with\\nthe \\\\textit{Master kinetic information}. The goal is to show that, provided the\\nsame PDF is realized in terms of an arbitrary suitably-smooth particular\\nsolution of the Master kinetic equation the two properties indicated above are\\nindeed realized and that the same functional is unrelated either with the\\nBoltzmann-Shannon entropy and the Fisher information.\\n'\n",
      " '  In this paper we analyze the gate activation signals inside the gated\\nrecurrent neural networks, and find the temporal structure of such signals is\\nhighly correlated with the phoneme boundaries. This correlation is further\\nverified by a set of experiments for phoneme segmentation, in which better\\nresults compared to standard approaches were obtained.\\n'\n",
      " '  In this paper, we provide for the first time an automated,\\ncorrect-by-construction, controller synthesis scheme for a class of infinite\\ndimensional stochastic systems, namely, retarded jump-diffusion systems. First,\\nwe construct finite dimensional abstractions approximately bisimilar to\\noriginal retarded jump-diffusion systems having some stability property,\\nnamely, incremental input-to-state stability. Second, we construct finite\\nabstractions approximately bisimilar to constructed finite dimensional\\nabstractions. Both types of abstractions are derived without any state-space\\ndiscretization. By using the transitivity property of approximate bisimulation\\nrelations, we establish that the constructed finite abstractions are also\\napproximately bisimilar to original retarded jump-diffusion systems with a\\nprecision that can be chosen a-priori. Given those finite abstractions, one can\\nsynthesize controllers for original systems satisfying high-level logic\\nrequirements in a systematic way. Moreover, we provide sufficient conditions\\nfor the proposed notion of incremental stability in terms of the existence of\\nincremental Lyapunov functions which reduce to linear matrix inequalities (LMI)\\nfor the linear systems. Finally, the effectiveness of the results is\\nillustrated by synthesizing a controller regulating the temperatures in a\\nten-room building modeled as a delayed jump-diffusion system.\\n'\n",
      " \"  On October 2016 the South Korean cyber military unit was the victim of a\\nsuccessful cyber attack that allowed access to internal networks. Per usual\\nwith large scale attacks against South Korean entities, the hack was\\nimmediately attributed to North Korea. Also, per other large-scale cyber\\nsecurity incidents, the same types of 'evidence' were used for attribution\\npurposes. Disclosed methods of attribution provide weak evidence, and the\\nprocedure Korean organizations tend to use for information disclosure lead many\\nto question any conclusions. We will analyze and discuss a number of issues\\nwith the current way that South Korean organizations disclose cyber attack\\ninformation to the public. A time line of events and disclosures will be\\nconstructed and analyzed in the context of appropriate measures for cyber\\nwarfare. Finally, we will examine the South Korean cyber military attack in\\nterms previously proposed cyber warfare response guidelines. Specifically,\\nwhether any of the guidelines can be applied to this real-world case, and if\\nso, is South Korea justified in declaring war based on the most recent cyber\\nattack.\\n\"\n",
      " '  We carried out the deep spectroscopic observations of the nearby cluster\\nA2151 with AF2/WYFFOS@WHT. The caustic technique enables us to identify 360\\nmembers brighter than $M_r = -16$ and within 1.3$R_{200}$. We separated the\\nmembers into subsamples according to photometrical and dynamical properties\\nsuch as colour, local environment and infall time. The completeness of the\\ncatalogue and our large sample allow us to analyse the velocity dispersion and\\nthe luminosity functions of the identified populations. We found evidence of a\\ncluster still in its collapsing phase. The LF of the red population of A2151\\nshows a deficit of dwarf red galaxies. Moreover, the normalized LFs of the red\\nand blue populations of A2151 are comparable to the red and blue LFs of the\\nfield, even if the blue galaxies start dominating one magnitude fainter and the\\nred LF is well represented by a single Schechter function rather than a double\\nSchechter function. We discuss how the evolution of cluster galaxies depends on\\ntheir mass: bright and intermediate galaxies are mainly affected by dynamical\\nfriction and internal/mass quenching, while the evolution of dwarfs is driven\\nby environmental processes which need time and a hostile cluster environment to\\nremove the gas reservoirs and halt the star formation.\\n'\n",
      " '  What do we really mean by a \"good\" scientific journal? Do we care more about\\nthe short-time impact of our papers, or about the chance that they will still\\nbe read and cited on the long run? Here I show that, by regarding a journal as\\na \"virtual scientist\" that can be attributed a time-dependent Hirsch h-index,\\nwe can introduce a parameter that, arguably, better captures the \"persistency\"\\nof a scientific publication. Curiously, however, this parameter seems to depend\\nabove all on the \"thickness\" of a journal.\\n'\n",
      " '  This work presents and compares efficient implementations of high-order\\ndiscontinuous Galerkin methods: a modal matrix-free discontinuous Galerkin (DG)\\nmethod, a hybridizable discontinuous Galerkin (HDG) method, and a primal\\nformulation of HDG, applied to the implicit solution of unsteady compressible\\nflows. The matrix-free implementation allows for a reduction of the memory\\nfootprint of the solver when dealing with implicit time-accurate\\ndiscretizations. HDG reduces the number of globally-coupled degrees of freedom\\nrelative to DG, at high order, by statically condensing element-interior\\ndegrees of freedom from the system in favor of face unknowns. The primal\\nformulation further reduces the element-interior degrees of freedom by\\neliminating the gradient as a separate unknown. This paper introduces a\\n$p$-multigrid preconditioner implementation for these discretizations and\\npresents results for various flow problems. Benefits of the $p$-multigrid\\nstrategy relative to simpler, less expensive, preconditioners are observed for\\nstiff systems, such as those arising from low-Mach number flows at high-order\\napproximation. The $p$-multigrid preconditioner also shows excellent\\nscalability for parallel computations. Additional savings in both speed and\\nmemory occur with a matrix-free/reduced version of the preconditioner.\\n'\n",
      " '  The fast-paced evolution of Android APIs has posed a challenging task for\\nAndroid app developers. To leverage the newly and frequently released APIs from\\nAndroid, developers often must spend considerable effort on API migrations.\\nPrior research work and Android official documentation typically provide enough\\ninformation to guide developers in identifying both the changed API calls that\\nneed to be migrated and the corresponding API calls in the new version of\\nAndroid (what to migrate). However, the API migration task is still challenging\\nsince developers lack the knowledge of how to migrate the API calls. In\\naddition to the official documentation, there exist code examples, such as\\nGoogle Samples, that illustrate the usage of APIs. We posit that by analyzing\\nthe changes of API usage in code examples, we may be able to learn API\\nmigration patterns to assist developers with API migrations.\\nIn this paper, we propose an approach that automatically learns API migration\\npatterns from code examples and applies these patterns to the source code of\\nAndroid apps for API migration. To evaluate our approach, we migrate API calls\\nin open source Android apps by learning API migration patterns from both public\\nand manually generated code examples. We find that our approach can\\nsuccessfully learn API migration patterns and provide API migration assistance\\nin 71 out of 80 cases. In particular, our approach can either automatically\\nmigrate API calls with little to no extra modifications needed or provide\\nguidance to assist with the migrations. Our approach can be adopted by Android\\ndevelopers to reduce the effort they spend on regularly migrating Android APIs.\\n'\n",
      " '  Non-rigid registration is challenging because it is ill-posed with high\\ndegrees of freedom and is thus sensitive to noise and outliers. We propose a\\nrobust non-rigid registration method using reweighted sparsities on position\\nand transformation to estimate the deformations between 3-D shapes. We\\nformulate the energy function with dual sparsities on both the data term and\\nthe smoothness term, and define the smoothness constraint using local rigidity.\\nThe dual-sparsity based non-rigid registration model is enhanced with a\\nreweighting scheme, and solved by transferring the model into some alternating\\noptimized subproblems which have exact solutions and guaranteed convergence.\\nExperimental results on both public datasets and real scanned datasets show\\nthat our method outperforms the state-of-the-art methods and is more robust to\\nnoise and outliers than conventional non-rigid registration methods.\\n'\n",
      " \"  We use the large deviation approach to sum rules pioneered by Gamboa, Nagel\\nand Rouault to prove higher order sum rules for orthogonal polynomials on the\\nunit circle. In particular, we prove one half of a conjectured sum rule of\\nLukic in the case of two singular points, one simple and one double. This is\\nimportant because it is known that the conjecture of Simon fails in exactly\\nthis case, so this paper provides support for the idea that Lukic's replacement\\nfor Simon's conjecture might be true.\\n\"\n",
      " '  Unconventional superconductivity frequently emerges as the transition\\ntemperature of a magnetic phase, typically antiferromagnetic, is suppressed\\ncontinuously toward zero temperature. Here, we report contrary behavior in\\npressurized CeRhGe3, a non-centrosymmetric heavy fermion compound. We find that\\nits pressure-tuned antiferromagnetic transition temperature (TN) appears to\\navoid a continuous decrease to zero temperature by terminating abruptly above a\\ndome of pressure-induced superconductivity. Near 21.5 GPa, evidence for TN\\nsuddenly vanishes, the electrical resistance becomes linear in temperature and\\nthe superconducting transition reaches a maximum. In light of X-ray absorption\\nspectroscopy measurements, these characteristics appear to be related to a\\npressured-induced Ce valence instability, which reveals as a sharp increase in\\nthe rate of change of Ce valence with applied pressure.\\n'\n",
      " '  With an abundance of research papers in deep learning, reproducibility or\\nadoption of the existing works becomes a challenge. This is due to the lack of\\nopen source implementations provided by the authors. Further, re-implementing\\nresearch papers in a different library is a daunting task. To address these\\nchallenges, we propose a novel extensible approach, DLPaper2Code, to extract\\nand understand deep learning design flow diagrams and tables available in a\\nresearch paper and convert them to an abstract computational graph. The\\nextracted computational graph is then converted into execution ready source\\ncode in both Keras and Caffe, in real-time. An arXiv-like website is created\\nwhere the automatically generated designs is made publicly available for 5,000\\nresearch papers. The generated designs could be rated and edited using an\\nintuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our\\napproach, we create a simulated dataset with over 216,000 valid design\\nvisualizations using a manually defined grammar. Experiments on the simulated\\ndataset show that the proposed framework provide more than $93\\\\%$ accuracy in\\nflow diagram content extraction.\\n'\n",
      " '  The adoption of automated, data-driven decision making in an ever expanding\\nrange of applications has raised concerns about its potential unfairness\\ntowards certain social groups. In this context, a number of recent studies have\\nfocused on defining, detecting, and removing unfairness from data-driven\\ndecision systems. However, the existing notions of fairness, based on parity\\n(equality) in treatment or outcomes for different social groups, tend to be\\nquite stringent, limiting the overall decision making accuracy. In this paper,\\nwe draw inspiration from the fair-division and envy-freeness literature in\\neconomics and game theory and propose preference-based notions of fairness --\\ngiven the choice between various sets of decision treatments or outcomes, any\\ngroup of users would collectively prefer its treatment or outcomes, regardless\\nof the (dis)parity as compared to the other groups. Then, we introduce\\ntractable proxies to design margin-based classifiers that satisfy these\\npreference-based notions of fairness. Finally, we experiment with a variety of\\nsynthetic and real-world datasets and show that preference-based fairness\\nallows for greater decision accuracy than parity-based fairness.\\n'\n",
      " '  In an era where accumulating data is easy and storing it inexpensive, feature\\nselection plays a central role in helping to reduce the high-dimensionality of\\nhuge amounts of otherwise meaningless data. In this paper, we propose a\\ngraph-based method for feature selection that ranks features by identifying the\\nmost important ones into arbitrary set of cues. Mapping the problem on an\\naffinity graph-where features are the nodes-the solution is given by assessing\\nthe importance of nodes through some indicators of centrality, in particular,\\nthe Eigen-vector Centrality (EC). The gist of EC is to estimate the importance\\nof a feature as a function of the importance of its neighbors. Ranking central\\nnodes individuates candidate features, which turn out to be effective from a\\nclassification point of view, as proved by a thoroughly experimental section.\\nOur approach has been tested on 7 diverse datasets from recent literature\\n(e.g., biological data and object recognition, among others), and compared\\nagainst filter, embedded and wrappers methods. The results are remarkable in\\nterms of accuracy, stability and low execution time.\\n'\n",
      " '  Recurrent Neural Networks (RNNs), which are a powerful scheme for modeling\\ntemporal and sequential data need to capture long-term dependencies on datasets\\nand represent them in hidden layers with a powerful model to capture more\\ninformation from inputs. For modeling long-term dependencies in a dataset, the\\ngating mechanism concept can help RNNs remember and forget previous\\ninformation. Representing the hidden layers of an RNN with more expressive\\noperations (i.e., tensor products) helps it learn a more complex relationship\\nbetween the current input and the previous hidden layer information. These\\nideas can generally improve RNN performances. In this paper, we proposed a\\nnovel RNN architecture that combine the concepts of gating mechanism and the\\ntensor product into a single model. By combining these two concepts into a\\nsingle RNN, our proposed models learn long-term dependencies by modeling with\\ngating units and obtain more expressive and direct interaction between input\\nand hidden layers using a tensor product on 3-dimensional array (tensor) weight\\nparameters. We use Long Short Term Memory (LSTM) RNN and Gated Recurrent Unit\\n(GRU) RNN and combine them with a tensor product inside their formulations. Our\\nproposed RNNs, which are called a Long-Short Term Memory Recurrent Neural\\nTensor Network (LSTMRNTN) and Gated Recurrent Unit Recurrent Neural Tensor\\nNetwork (GRURNTN), are made by combining the LSTM and GRU RNN models with the\\ntensor product. We conducted experiments with our proposed models on word-level\\nand character-level language modeling tasks and revealed that our proposed\\nmodels significantly improved their performance compared to our baseline\\nmodels.\\n'\n",
      " '  Universal Dependencies (UD) offer a uniform cross-lingual syntactic\\nrepresentation, with the aim of advancing multilingual applications. Recent\\nwork shows that semantic parsing can be accomplished by transforming syntactic\\ndependencies to logical forms. However, this work is limited to English, and\\ncannot process dependency graphs, which allow handling complex phenomena such\\nas control. In this work, we introduce UDepLambda, a semantic interface for UD,\\nwhich maps natural language to logical forms in an almost language-independent\\nfashion and can process dependency graphs. We perform experiments on question\\nanswering against Freebase and provide German and Spanish translations of the\\nWebQuestions and GraphQuestions datasets to facilitate multilingual evaluation.\\nResults show that UDepLambda outperforms strong baselines across languages and\\ndatasets. For English, it achieves a 4.9 F1 point improvement over the\\nstate-of-the-art on GraphQuestions. Our code and data can be downloaded at\\nthis https URL.\\n'\n",
      " '  This paper considers online convex optimization with time-varying constraint\\nfunctions. Specifically, we have a sequence of convex objective functions\\n$\\\\{f_t(x)\\\\}_{t=0}^{\\\\infty}$ and convex constraint functions\\n$\\\\{g_{t,i}(x)\\\\}_{t=0}^{\\\\infty}$ for $i \\\\in \\\\{1, ..., k\\\\}$. The functions are\\ngradually revealed over time. For a given $\\\\epsilon>0$, the goal is to choose\\npoints $x_t$ every step $t$, without knowing the $f_t$ and $g_{t,i}$ functions\\non that step, to achieve a time average at most $\\\\epsilon$ worse than the best\\nfixed-decision that could be chosen with hindsight, subject to the time average\\nof the constraint functions being nonpositive. It is known that this goal is\\ngenerally impossible. This paper develops an online algorithm that solves the\\nproblem with $O(1/\\\\epsilon^2)$ convergence time in the special case when all\\nconstraint functions are nonpositive over a common subset of $\\\\mathbb{R}^n$.\\nSimilar performance is shown in an expected sense when the common subset\\nassumption is removed but the constraint functions are assumed to vary\\naccording to a random process that is independent and identically distributed\\n(i.i.d.) over time slots $t \\\\in \\\\{0, 1, 2, \\\\ldots\\\\}$. Finally, in the special\\ncase when both the constraint and objective functions are i.i.d. over time\\nslots $t$, the algorithm is shown to come within $\\\\epsilon$ of optimality with\\nrespect to the best (possibly time-varying) causal policy that knows the full\\nprobability distribution.\\n'\n",
      " '  Image classification datasets are often imbalanced, characteristic that\\nnegatively affects the accuracy of deep-learning classifiers. In this work we\\npropose balancing GAN (BAGAN) as an augmentation tool to restore balance in\\nimbalanced datasets. This is challenging because the few minority-class images\\nmay not be enough to train a GAN. We overcome this issue by including during\\nthe adversarial training all available images of majority and minority classes.\\nThe generative model learns useful features from majority classes and uses\\nthese to generate images for minority classes. We apply class conditioning in\\nthe latent space to drive the generation process towards a target class. The\\ngenerator in the GAN is initialized with the encoder module of an autoencoder\\nthat enables us to learn an accurate class-conditioning in the latent space. We\\ncompare the proposed methodology with state-of-the-art GANs and demonstrate\\nthat BAGAN generates images of superior quality when trained with an imbalanced\\ndataset.\\n'\n",
      " '  Non-invasive magnetic field sensing using optically - detected magnetic\\nresonance of nitrogen-vacancy (NV) centers in diamond was used to study spatial\\ndistribution of the magnetic induction upon penetration and expulsion of weak\\nmagnetic fields in several representative superconductors. Vector magnetic\\nfields were measured on the surface of conventional, Pb and Nb, and\\nunconventional, LuNi$_2$B$_2$C, Ba$_{0.6}$K$_{0.4}$Fe$_2$As$_2$,\\nBa(Fe$_{0.93}$Co$_{0.07}$)$_2$As$_2$, and CaKFe$_4$As$_4$, superconductors,\\nwith diffraction - limited spatial resolution using variable - temperature\\nconfocal system. Magnetic induction profiles across the crystal edges were\\nmeasured in zero-field-cooled (ZFC) and field-cooled (FC) conditions. While all\\nsuperconductors show nearly perfect screening of magnetic fields applied after\\ncooling to temperatures well below the superconducting transition, $T_c$, a\\nrange of very different behaviors was observed for Meissner expulsion upon\\ncooling in static magnetic field from above $T_c$. Substantial conventional\\nMeissner expulsion is found in LuNi$_2$B$_2$C, paramagnetic Meissner effect\\n(PME) is found in Nb, and virtually no expulsion is observed in iron-based\\nsuperconductors. In all cases, good correlation with macroscopic measurements\\nof total magnetic moment is found. Our measurements of the spatial distribution\\nof magnetic induction provide insight into microscopic physics of the Meissner\\neffect.\\n'\n",
      " \"  In a standard cluster analysis, such as k-means, in addition to clusters\\nlocations and distances between them, it's important to know if they are\\nconnected or well separated from each other. The main focus of this paper is\\ndiscovering the relations between the resulting clusters. We propose a new\\nmethod which is based on pairwise overlapping k-means clustering, that in\\naddition to means of clusters provides the graph structure of their relations.\\nThe proposed method has a set of parameters that can be tuned in order to\\ncontrol the sensitivity of the model and the desired relative size of the\\npairwise overlapping interval between means of two adjacent clusters, i.e.,\\nlevel of overlapping. We present the exact formula for calculating that\\nparameter. The empirical study presented in the paper demonstrates that our\\napproach works well not only on toy data but also compliments standard\\nclustering results with a reasonable graph structure on real datasets, such as\\nfinancial indices and restaurants.\\n\"\n",
      " \"  Differences between men and women have intrigued generations of social\\nscientists, who have found that the two sexes behave differently in settings\\nrequiring competition, risk taking, altruism, honesty, as well as many others.\\nYet, little is known about whether there are gender differences in cooperative\\nbehavior. Previous evidence is mixed and inconclusive. Here I shed light on\\nthis topic by analyzing the totality of studies that my research group has\\nconducted since 2013. This is a dataset of 10,951 observations coming from\\n7,322 men and women living in the US, recruited through Amazon Mechanical Turk,\\nand who passed four comprehension questions to make sure they understand the\\ncooperation problem (a one-shot prisoner's dilemma). The analysis demonstrates\\nthat women are more cooperative than men. The effect size is small (about 4\\npercentage points, and this might explain why previous studies failed to detect\\nit) but highly significant (p<.0001).\\n\"\n",
      " '  On an asymptotically flat manifold $M^n$ with nonnegative scalar curvature,\\nwith outer minimizing boundary $\\\\Sigma$, we prove a Penrose-like inequality in\\ndimensions $ n < 8$, under suitable assumptions on the mean curvature and the\\nscalar curvature of $ \\\\Sigma$.\\n'\n",
      " '  We give results and observations which allow the application of the\\nlogarithmic tensor category theory of Lepowsky, Zhang and the author\\n([HLZ1]--[HLZ9]) to more general vertex (operator) algebras and their module\\ncategories than those studied in a paper by the author ([H3]).\\n'\n",
      " '  How big is the risk that a few initial failures of nodes in a network amplify\\nto large cascades that span a substantial share of all nodes? Predicting the\\nfinal cascade size is critical to ensure the functioning of a system as a\\nwhole. Yet, this task is hampered by uncertain or changing parameters and\\nmissing information. In infinitely large networks, the average cascade size can\\noften be well estimated by established approaches building on local tree\\napproximations and mean field approximations. Yet, as we demonstrate, in finite\\nnetworks, this average does not even need to be a likely outcome. Instead, we\\nfind broad and even bimodal cascade size distributions. This phenomenon\\npersists for system sizes up to $10^{7}$ and different cascade models, i.e. it\\nis relevant for most real systems. To show this, we derive explicit closed-form\\nsolutions for the full probability distribution of the final cascade size. We\\nfocus on two topological limit cases, the complete network representing a dense\\nnetwork with a very narrow degree distribution, and the star network\\nrepresenting a sparse network with a inhomogeneous degree distribution. Those\\ntopologies are of great interest, as they either minimize or maximize the\\naverage cascade size and are common motifs in many real world networks.\\n'\n",
      " '  In this paper, we study the cooperative robust output regulation problem for\\ndiscrete-time linear multi-agent systems with both communication and input\\ndelays by distributed internal model approach. We first introduce the\\ndistributed internal model for discrete-time multi-agent systems with both\\ncommunication and input delays. Then, we define so-called auxiliary system and\\nauxiliary augmented system. Finally, we solve our problem by showing, under\\nsome standard assumptions, that if a distributed state feedback control or a\\ndistributed output feedback control solves the robust output regulation problem\\nof the auxiliary system, then the same control law solves the cooperative\\nrobust output regulation problem of the original multi-agent systems.\\n'\n",
      " '  We introduce the Dense Basis method for Spectral Energy Distribution (SED)\\nfitting. It accurately recovers traditional SED parameters, including M$_*$,\\nSFR and dust attenuation, and reveals previously inaccessible information about\\nthe number and duration of star formation episodes and the timing of stellar\\nmass assembly, as well as uncertainties in these quantities. This is done using\\nbasis Star Formation Histories (SFHs) chosen by comparing the goodness-of-fit\\nof mock galaxy SEDs to the goodness-of-reconstruction of their SFHs. We train\\nand validate the method using a sample of realistic SFHs at $z =1$ drawn from\\nstochastic realisations, semi-analytic models, and a cosmological\\nhydrodynamical galaxy formation simulation. The method is then applied to a\\nsample of 1100 CANDELS GOODS-S galaxies at $1<z<1.5$ to illustrate its\\ncapabilities at moderate S/N with 15 photometric bands. Of the six\\nparametrizations of SFHs considered, we adopt linear-exponential,\\nbessel-exponential, lognormal and gaussian SFHs and reject the traditional\\nparametrizations of constant (Top-Hat) and exponential SFHs. We quantify the\\nbias and scatter of each parametrization. $15\\\\%$ of galaxies in our CANDELS\\nsample exhibit multiple episodes of star formation, with this fraction\\ndecreasing above $M_*>10^{9.5}M_\\\\odot$. About $40\\\\%$ of the CANDELS galaxies\\nhave SFHs whose maximum occurs at or near the epoch of observation. The Dense\\nBasis method is scalable and offers a general approach to a broad class of\\ndata-science problems.\\n'\n",
      " '  Attractive Bose-Einstein condensates can host two types of macroscopic\\nself-bound states of different nature: bright solitons and quantum liquid\\ndroplets. Here, we investigate the connection between them with a Bose-Bose\\nmixture confined in an optical waveguide. We develop a simple theoretical model\\nto show that, depending on atom number and interaction strength, solitons and\\ndroplets can be smoothly connected or remain distinct states coexisting only in\\na bi-stable region. We experimentally measure their spin composition, extract\\ntheir density for a broad range of parameters and map out the boundary of the\\nregion separating solitons from droplets.\\n'\n",
      " '  We consider the composition optimization with two expected-value functions in\\nthe form of $\\\\frac{1}{n}\\\\sum\\\\nolimits_{i = 1}^n F_i(\\\\frac{1}{m}\\\\sum\\\\nolimits_{j\\n= 1}^m G_j(x))+R(x)$, { which formulates many important problems in statistical\\nlearning and machine learning such as solving Bellman equations in\\nreinforcement learning and nonlinear embedding}. Full Gradient or classical\\nstochastic gradient descent based optimization algorithms are unsuitable or\\ncomputationally expensive to solve this problem due to the inner expectation\\n$\\\\frac{1}{m}\\\\sum\\\\nolimits_{j = 1}^m G_j(x)$. We propose a duality-free based\\nstochastic composition method that combines variance reduction methods to\\naddress the stochastic composition problem. We apply SVRG and SAGA based\\nmethods to estimate the inner function, and duality-free method to estimate the\\nouter function. We prove the linear convergence rate not only for the convex\\ncomposition problem, but also for the case that the individual outer functions\\nare non-convex while the objective function is strongly-convex. We also provide\\nthe results of experiments that show the effectiveness of our proposed methods.\\n'\n",
      " '  We show time hierarchies for reasonable semantic classes without advice by\\neliminating the constant bits of advice in previous results.The elimination is\\ndone by a contrapositive argument that for any reasonable computational\\nmodel,let $\\\\text{CTIME}(f(n))/{g(n)}$ denote the set of all languages decide by\\nmachines running in time $O(f(n))$ with advice of $g(n)$ bits in that model, if\\n$\\\\text{CTIME}(t(n))\\\\subseteq \\\\text{CTIME}(T(n))/{A(n)}$ then\\n$\\\\text{CTIME}(t(n))/a \\\\subseteq \\\\text{CTIME}(T(n))/{a+2^aA(n)}$ where $a$ is a\\nconstant integer.\\n'\n",
      " \"  When a robot is operating in a dynamic environment, it cannot be assumed that\\na tool required to solve a given task will always be available. In case of a\\nmissing tool, an ideal response would be to find a substitute to complete the\\ntask. In this paper, we present a proof of concept of a grounded\\nknowledge-based approach to tool substitution. In order to validate the\\nsuitability of a substitute, we conducted experiments involving 22 substitution\\nscenarios. The substitutes computed by the proposed approach were validated on\\nthe basis of the experts' choices for each scenario. Our evaluation showed, in\\n20 out of 22 scenarios (91%), the approach identified the same substitutes as\\nexperts.\\n\"\n",
      " '  We present a simple analysis of the design of a passive miniature resonant\\noptical gyroscope. By combining the requirements on the angular random walk and\\nthe bias stability, we end up with simple expressions of the minimum diameter\\nof the ring waveguide cavity and the maximum power that should be used to probe\\nit. Using state-of-the-art performances of photonic integrated circuit and\\nwhispering gallery mode technologies in terms of propagation losses and mode\\nsize, we show that tactical grade gyroscope performances can be achieved with a\\ndiameter of a few cm provided the detrimental influence of Kerr effect is\\nmitigated, using for instance an active control of the unbalance in the\\nintensities. We further extend the analysis to medium performance gyroscope and\\ngive some hints on the efforts to be made to potentially demonstrate a\\nminiature resonant optical gyroscope with this level of performance.\\n'\n",
      " '  Optimal and Learning Control for Autonomous Robots has been taught in the\\nRobotics, Systems and Controls Masters at ETH Zurich with the aim to teach\\noptimal control and reinforcement learning for closed loop control problems\\nfrom a unified point of view. The starting point is the formulation of of an\\noptimal control problem and deriving the different types of solutions and\\nalgorithms from there. These lecture notes aim at supporting this unified view\\nwith a unified notation wherever possible, and a bit of a translation help to\\ncompare the terminology and notation in the different fields. The course\\nassumes basic knowledge of Control Theory, Linear Algebra and Stochastic\\nCalculus.\\n'\n",
      " '  We show that a jammed packing of disks with generic radii, in a generic\\ncontainer, is such that the minimal number of contacts occurs and there is only\\none dimension of equilibrium stresses. We also point out some connections to\\npackings with different radii and results in the theory of circle packings\\nwhose graph forms a triangulation of a given topological surface. We also point\\nout a counterexample, due to F. Nazarov, to a previous conjecture that that\\ntriangulated packings with fixed numbers of disks with fixed numbers of disks\\nfor each radius claiming that such packings were the most dense.\\n'\n",
      " '  An important application of intelligent vehicles is advance detection of\\ndangerous events such as collisions. This problem is framed as a problem of\\noptimal alarm choice given predictive models for vehicle location and motion.\\nTechniques for real-time collision detection are surveyed and grouped into\\nthree classes: random Monte Carlo sampling, faster deterministic\\napproximations, and machine learning models trained by simulation. Theoretical\\nguarantees on the performance of these collision detection techniques are\\nprovided where possible, and empirical analysis is provided for two example\\nscenarios. Results validate Monte Carlo sampling as a robust solution despite\\nits simplicity.\\n'\n",
      " '  DeConvNet, Guided BackProp, LRP, were invented to better understand deep\\nneural networks. We show that these methods do not produce the theoretically\\ncorrect explanation for a linear model. Yet they are used on multi-layer\\nnetworks with millions of parameters. This is a cause for concern since linear\\nmodels are simple neural networks. We argue that explanation methods for neural\\nnets should work reliably in the limit of simplicity, the linear models. Based\\non our analysis of linear models we propose a generalization that yields two\\nexplanation techniques (PatternNet and PatternAttribution) that are\\ntheoretically sound for linear models and produce improved explanations for\\ndeep networks.\\n'\n",
      " '  In this paper we study the behaviour of the Neumann data of Dirichlet\\neigenfunctions on simplices. We prove that the $L^2$ norm of the\\n(semi-classical) Neumann data on each face is equal to $2/n$ times the\\n$(n-1)$-dimensional volume of the face divided by the volume of the simplex.\\nThis is a generalization of \\\\cite{Chr-tri} to higher dimensions. Again it is\\n{\\\\it not} an asymptotic, but an exact formula. The proof is by simple\\nintegrations by parts and linear algebra.\\nWe also consider the following inverse problem: do the {\\\\it norms} of the\\nNeumann data on a simplex determine a constant coefficient elliptic operator?\\nThe answer is yes in dimension 2 and no in higher dimensions.\\n'\n",
      " '  Motivated by theoretical expectations that Nuclear Star Clusters (NSCs) in\\ngalactic centers may provide a favorable environment for super-massive black\\nholes to form and/or efficiently grow, we set out to measure the fraction of\\nnearby nucleated galaxies that also host an Active Galactic Nucleus (AGN). We\\ntargeted a distance-limited sample of 98 objects with the Chandra X-ray\\nTelescope, down to a uniform X-ray luminosity threshold of $\\\\sim$10$^{38}$ erg\\ns$^{-1}$. The sample is composed of 47 late-types and 51 early-types, enabling\\nus to further investigate the active fraction as a function of galactic\\nmorphology. After correcting for contamination to the nuclear X-ray signal from\\nbright X-ray binaries, we measure an active fraction $f$=11.2$\\\\%^{+7.4}_{-4.9}$\\n(1$\\\\sigma$ C.L.) across the whole sample, in agreement with previous estimates\\nbased on an heterogeneous combination of optical, X-ray and radio diagnostics,\\nby Seth et al. (2008). After accounting for the different stellar mass\\ndistributions in our samples, we find no statistically significant difference\\nin the active fraction of early- vs. late-type nucleated galaxies, with\\n$f$=10.6$\\\\%^{+11.9}_{-4.9}$ and 10.8$\\\\%^{+11.3}_{-6.3}$, respectively. For the\\nearly-type nucleated galaxies, we are able to carry out a controlled comparison\\nwith a parent sample of non-nucleated galaxies covering the same stellar mass\\nrange, finding again no statistically significant difference in the active\\nfraction. Taken at face value, our findings suggest that the presence of a NSC\\ndoes not facilitate nor enhance accretion-powered emission from a nuclear\\nsuper-massive black hole. This is true even for late-type nucleated galaxies,\\nhome to bluer NSCs and arguably larger gas reservoirs.\\n'\n",
      " '  Two integrable $U(1)$-invariant peakon equations are derived from the NLS\\nhierarchy through the tri-Hamiltonian splitting method. A Lax pair, a recursion\\noperator, a bi-Hamiltonian formulation, and a hierarchy of symmetries and\\nconservation laws are obtained for both peakon equations. These equations are\\nalso shown to arise as potential flows in the NLS hierarchy by applying the NLS\\nrecursion operator to flows generated by space translations and $U(1)$-phase\\nrotations on a potential variable. Solutions for both equations are derived\\nusing a peakon ansatz combined with an oscillatory temporal phase. This yields\\nthe first known example of a peakon breather. Spatially periodic counterparts\\nof these solutions are also obtained.\\n'\n",
      " \"  This paper presents a quantitative study of the evolution of the ejecta cloud\\nreleased from a hypervelocity impact on a binary asteroid. We performed\\nnumerical simulations of the post-impact dynamics of the ejecta cloud in the\\nframework of the current mission scenario of AIDA mission project. A grid\\nsearch of launching sites of ejecta was defined over the globe of Didymoon, and\\nconsidering a wide range of possible ejection speeds, we determined the\\ndependency of ejecta fate on launching sites (projectile impact sites) and\\nspeeds. This range allows us to track all the complex cases that include\\ndifferent types of dynamical fates. Two major mechanisms are found to be\\nworking broadly during the post-ejection evolution of the ejecta cloud: 1)\\nejecta on mean motion resonance orbits with Didymoon produce long-term\\nquasi-periodic showers onto Didymoon over at least a couple of weeks after the\\nprojectile impact, 2) ejecta on non-resonant orbits produce a rapid and high\\nre-accretion flux. This rapid and high flux occurs just once because ejecta on\\nsuch orbits leave the system unless they experience a collision during their\\nfirst encounter. For the second part of this study, we performed full-scale\\nsimulations of the ejecta cloud released from 6 hypothetical impact sites. We\\nconsidered two kinds of material composing Didymoon's subsurface and then\\ncombined a power-law size distribution of the ejecta with an ejection speed\\ndistribution. We find that the ejecta cloud evolution can be divided in two\\nperiods. It starts with a first violent period (<10 hr) with fast re-accretion\\nor ejection from the system. A second period is found to be more sensitive to\\nthe launching site than the first one. During this second period, ejecta will\\neither re-accrete or being ejected from the system, depending both on their\\nsizes and on their average survival time in close proximity of the binary\\ncomponents.\\n\"\n",
      " '  Since the mid-1920s, different strands of research used stars as \"physics\\nlaboratories\" for investigating the nature of matter under extreme densities\\nand pressures, impossible to realize on Earth. To trace this process this paper\\nis following the evolution of the concept of a dense core in stars, which was\\nimportant both for an understanding of stellar evolution and as a testing\\nground for the fast-evolving field of nuclear physics. In spite of the divide\\nbetween physicists and astrophysicists, some key actors working in the\\ncross-fertilized soil of overlapping but different scientific cultures\\nformulated models and tentative theories that gradually evolved into more\\nrealistic and structured astrophysical objects. These investigations culminated\\nin the first contact with general relativity in 1939, when J. Robert\\nOppenheimer and his students George Volkoff and Hartland Snyder systematically\\napplied the theory to the dense core of a collapsing neutron star. This\\npioneering application of Einstein\\'s theory to an astrophysical compact object\\ncan be regarded as a milestone in the path eventually leading to the emergence\\nof relativistic astrophysics in the early 1960s.\\n'\n",
      " '  In this paper, we consider the usual linear regression model in the case\\nwhere the error process is assumed strictly stationary. We use a result from\\nHannan, who proved a Central Limit Theorem for the usual least square estimator\\nunder general conditions on the design and on the error process. We show that\\nfor a large class of designs, the asymptotic covariance matrix is as simple as\\nthe i.i.d. case. We then estimate the covariance matrix using an estimator of\\nthe spectral density whose consistency is proved under very mild conditions. As\\nan application, we show how to modify the usual Fisher tests in this dependent\\ncontext, in such a way that the type-$I$ error rate remains asymptotically\\ncorrect, and we illustrate the performance of this procedure through different\\nsets of simulations.\\n'\n",
      " '  THz radiation promises breakthrough advances in compact advanced accelerators\\ndue to the high frequency and GV/m fields achievable, orders of magnitude\\nlarger than in conventional radiofrequency (RF) based accelerators. Compared to\\nlaser-driven schemes, the large phase acceptances of THz-driven accelerators\\nare advantageous for operation with sizable charge. Despite burgeoning\\nresearch, THz sources, particularly laser-based ones, cannot yet compete with\\nthe efficiency of RF amplifiers for high average current accelerators.\\nNevertheless, THz-based phase space manipulation is of immediate interest for a\\nvariety of applications, including generation and diagnostics of ultrashort\\nbunches for electron diffraction/microscopy and compact free-electron laser\\napplications.\\nThe challenge of maintaining overlap and synchronism between an electron beam\\nand short laser-generated THz pulse has so far limited interactions to the few\\nmm scale. We discuss a novel scheme for simultaneous group and phase velocity\\nmatching of nearly single-cycle THz radiation with a relativistic electron beam\\nfor meter-scale interaction. We demonstrate energy modulations of up to 150 keV\\nusing modest THz pulse energies (up to 1 uJ). We apply this large and efficient\\nenergy exchange for beam compression and time-stamping of a relativistic beam,\\npaving the way towards realizing the unique opportunities enabled by\\nlaser-based THz accelerators.\\n'\n",
      " \"  The paper presents an investigation of estimating treatment effect using\\ndifferent matching methods. The study proposed a new method which is\\ncomputationally efficient and convenient in implication-'largest caliper\\nmatching' and compared the performance with other five popular matching methods\\nby simulation. The bias, empirical standard deviation and the mean square error\\nof the estimates in the simulation are checked under different treatment\\nprevalence and different distributions of covariates. A Monte Carlo simulation\\nstudy and a real data example are employed to measure the performance of these\\nmethods. It is shown that matched samples improve estimation of the population\\ntreatment effect in a wide range of settings. It reduces the bias if the data\\ncontains the selection on observables and treatment imbalances. Also, findings\\nabout the relative performance of the different matching methods are provided\\nto help practitioners determine which method should be used under certain\\nsituations.\\n\"\n",
      " '  The usual main objection against any attempt in finding a physical cause for\\nthe planet distance distribution is based on the assumption that similar\\ndistance distribution could be obtained by sequences of random numbers. This\\nassumption was stated by Lecar in an old paper (1973). We show here how this\\nassumption is incorrect and how his visual comparison method is inappropriate.\\n'\n",
      " '  Time-resolved angiography with interleaved stochastic trajectories (TWIST)\\nhas been widely used for dynamic contrast enhanced MRI (DCE-MRI). To achieve\\nhighly accelerated acquisitions, TWIST combines the periphery of the k-space\\ndata from several adjacent frames to reconstruct one temporal frame. However,\\nthis view-sharing scheme limits the true temporal resolution of TWIST.\\nMoreover, the k-space sampling patterns have been specially designed for a\\nspecific generalized autocalibrating partial parallel acquisition (GRAPPA)\\nfactor so that it is not possible to reduce the number of view-sharing once the\\nk-data is acquired. To address these issues, this paper proposes a novel\\nk-space deep learning approach for parallel MRI. In particular, we have\\ndesigned our neural network so that accurate k-space interpolations are\\nperformed simultaneously for multiple coils by exploiting the redundancies\\nalong the coils and images. Reconstruction results using in vivo TWIST data set\\nconfirm that the proposed method can immediately generate high-quality\\nreconstruction results with various choices of view- sharing, allowing us to\\nexploit the trade-off between spatial and temporal resolution in time-resolved\\nMR angiography.\\n'\n",
      " '  The theoretical proposal of chiral fermions in topological semimetals has led\\nto a significant effort towards their experimental realization. In particular,\\nthe Fermi surfaces of chiral semimetals carry quantized Chern numbers, making\\nthem an attractive platform for the observation of exotic transport and optical\\nphenomena. While the simplest example of a chiral fermion in condensed matter\\nis a conventional $|C|=1$ Weyl fermion, recent theoretical works have proposed\\na number of unconventional chiral fermions beyond the Standard Model which are\\nprotected by unique combinations of topology and crystalline symmetries.\\nHowever, materials candidates for experimentally probing the transport and\\nresponse signatures of these unconventional fermions have thus far remained\\nelusive. In this paper, we propose the RhSi family in space group (SG) $\\\\#$198\\nas the ideal platform for the experimental examination of unconventional chiral\\nfermions. We find that RhSi is a filling-enforced semimetal that features near\\nits Fermi surface a chiral double six-fold-degenerate spin-1 Weyl node at $R$\\nand a previously uncharacterized four-fold-degenerate chiral fermion at\\n$\\\\Gamma$. Each unconventional fermion displays Chern number $\\\\pm4$ at the Fermi\\nlevel. We also show that RhSi displays the largest possible momentum separation\\nof compensative chiral fermions, the largest proposed topologically nontrivial\\nenergy window, and the longest possible Fermi arcs on its surface. We conclude\\nby proposing signatures of an exotic bulk photogalvanic response in RhSi.\\n'\n",
      " '  In this paper we prove the following. Let $\\\\Sigma$ be an $n$--dimensional\\nclosed hyperbolic manifold and let $g$ be a Riemannian metric on $\\\\Sigma \\\\times\\n\\\\mathbb{S}^1$. Given an upper bound on the volumes of unit balls in the\\nRiemannian universal cover $(\\\\widetilde{\\\\Sigma\\\\times\\n\\\\mathbb{S}^1},\\\\widetilde{g})$, we get a lower bound on the area of the\\n$\\\\mathbb{Z}_2$--homology class $[\\\\Sigma \\\\times \\\\ast]$ on $\\\\Sigma \\\\times\\n\\\\mathbb{S}^1$, proportional to the hyperbolic area of $\\\\Sigma$. The theorem is\\nbased on a theorem of Guth and is analogous to a theorem of Kronheimer and\\nMrowka involving scalar curvature.\\n'\n",
      " '  We use a stochastic birth-death model for a population of cells to estimate\\nthe normal tissue complication probability (NTCP) under a particular\\nradiotherapy protocol. We specifically allow for interaction between cells, via\\na nonlinear logistic growth model. To capture some of the effects of intrinsic\\nnoise in the population we develop several approximations of NTCP, using\\nKramers-Moyal expansion techniques. These approaches provide an approximation\\nto the first and second moments of a general first-passage time problem in the\\nlimit of large, but finite populations. We use this method to study NTCP in a\\nsimple model of normal cells and in a model of normal and damaged cells. We\\nalso study a combined model of normal tissue cells and tumour cells. Based on\\nexisting methods to calculate tumour control probabilities, and our procedure\\nto approximate NTCP, we estimate the probability of complication free tumour\\ncontrol.\\n'\n",
      " '  Three new infrared bands of the weakly-bound He-OCS complex are studied,\\nusing tunable lasers to probe a pulsed supersonic slit jet expansion. They\\ncorrespond to the (0400) <-- (0000), (1001)<-- (0000), and (0401) <-- (0000)\\ntransitions of OCS at 2105, 2918, and 2937 cm-1, respectively. The latter band\\nis about 7900 times weaker than the previously studied OCS nu1 fundamental.\\nVibrational shifts relative to the free OCS monomer are found to be additive.\\nSince carbonyl sulfide has previously been shown to be a valuable probe of\\nsuperfluid quantum solvation effects in helium clusters and droplets, the\\npresent results could be useful for future studies of vibrational effects in\\nsuch systems.\\n'\n",
      " '  Polarimetric observations of celestial sources in the hard X-ray band stand\\nto provide new information on emission mechanisms and source geometries. PoGO+\\nis a Compton scattering polarimeter (20-150 keV) optimised for the observation\\nof the Crab (pulsar and wind nebula) and Cygnus X-1 (black hole binary), from a\\nstratospheric balloon-borne platform launched from the Esrange Space Centre in\\nsummer 2016. Prior to flight, the response of the polarimeter has been studied\\nwith polarised and unpolarised X-rays allowing a Geant4-based simulation model\\nto be validated. The expected modulation factor for Crab observations is found\\nto be $M_{\\\\mathrm{Crab}}=(41.75\\\\pm0.85)\\\\%$, resulting in an expected Minimum\\nDetectable Polarisation (MDP) of $7.3\\\\%$ for a 7 day flight. This will allow a\\nmeasurement of the Crab polarisation parameters with at least $5\\\\sigma$\\nstatistical significance assuming a polarisation fraction $\\\\sim20\\\\%$ $-$ a\\nsignificant improvement over the PoGOLite Pathfinder mission which flew in 2013\\nand from which the PoGO+ design is developed.\\n'\n",
      " '  Esports has emerged as a popular genre for players as well as spectators,\\nsupporting a global entertainment industry. Esports analytics has evolved to\\naddress the requirement for data-driven feedback, and is focused on\\ncyber-athlete evaluation, strategy and prediction. Towards the latter, previous\\nwork has used match data from a variety of player ranks from hobbyist to\\nprofessional players. However, professional players have been shown to behave\\ndifferently than lower ranked players. Given the comparatively limited supply\\nof professional data, a key question is thus whether mixed-rank match datasets\\ncan be used to create data-driven models which predict winners in professional\\nmatches and provide a simple in-game statistic for viewers and broadcasters.\\nHere we show that, although there is a slightly reduced accuracy, mixed-rank\\ndatasets can be used to predict the outcome of professional matches, with\\nsuitably optimized configurations.\\n'\n",
      " '  Universal characteristics of road networks and traffic patterns can help to\\nforecast and control traffic congestion. The antipersistence of traffic flow\\ntime series has been found for many data sets, but its relevance for congestion\\nhas been overseen. Based on empirical data from motorways in Germany, we study\\nhow antipersistence of traffic flow time-series impacts the duration of traffic\\ncongestion on a wide range of time scales. We find a large number of short\\nlasting traffic jams, which implies a large risk for rear-end collisions.\\n'\n",
      " '  Fast radio bursts are astronomical radio flashes of unknown physical nature\\nwith durations of milliseconds. Their dispersive arrival times suggest an\\nextragalactic origin and imply radio luminosities orders of magnitude larger\\nthan any other kind of known short-duration radio transient. Thus far, all FRBs\\nhave been detected with large single-dish telescopes with arcminute\\nlocalizations, and attempts to identify their counterparts (source or host\\ngalaxy) have relied on contemporaneous variability of field sources or the\\npresence of peculiar field stars or galaxies. These attempts have not resulted\\nin an unambiguous association with a host or multi-wavelength counterpart. Here\\nwe report the sub-arcsecond localization of FRB 121102, the only known\\nrepeating burst source, using high-time-resolution radio interferometric\\nobservations that directly image the bursts themselves. Our precise\\nlocalization reveals that FRB 121102 originates within 100 mas of a faint 180\\nuJy persistent radio source with a continuum spectrum that is consistent with\\nnon-thermal emission, and a faint (25th magnitude) optical counterpart. The\\nflux density of the persistent radio source varies by tens of percent on day\\ntimescales, and very long baseline radio interferometry yields an angular size\\nless than 1.7 mas. Our observations are inconsistent with the fast radio burst\\nhaving a Galactic origin or its source being located within a prominent\\nstar-forming galaxy. Instead, the source appears to be co-located with a\\nlow-luminosity active galactic nucleus or a previously unknown type of\\nextragalactic source. [Truncated] If other fast radio bursts have similarly\\nfaint radio and optical counterparts, our findings imply that direct\\nsub-arcsecond localizations of FRBs may be the only way to provide reliable\\nassociations.\\n'\n",
      " '  We design a non-commutative version of the Peterson-Gorenstein-Zierler\\ndecoding algorithm for a class of codes that we call skew RS codes. These codes\\nare left ideals of a quotient of a skew polynomial ring, which endow them of a\\nsort of non-commutative cyclic structure. Since we work over an arbitrary\\nfield, our techniques may be applied both to linear block codes and\\nconvolutional codes. In particular, our decoding algorithm applies for block\\ncodes beyond the classical cyclic case.\\n'\n",
      " '  A multivariable measurement error model $AX \\\\approx B$ is considered. Here\\n$A$ and $B$ are input and output matrices of measurements and $X$ is a\\nrectangular matrix of fixed size to be estimated. The errors in $[A,B]$ are\\nrow-wise independent, but within each row the errors may be correlated. Some of\\nthe columns are observed without errors and the error covariance matrices may\\ndiffer from row to row. The total covariance structure of the errors is known\\nup to a scalar factor. The fully weighted total least squares estimator of $X$\\nis studied. We give conditions for asymptotic normality of the estimator, as\\nthe number of rows in $A$ is increasing. We provide that the covariance\\nstructure of the limiting Gaussian random matrix is nonsingular.\\n'\n",
      " '  The recovery of structured signals from a few linear measurements is a\\ncentral point in both compressed sensing (CS) and discrete tomography. In CS\\nthe signal structure is described by means of a low complexity model e.g.\\nco-/sparsity. The CS theory shows that any signal/image can be undersampled at\\na rate dependent on its intrinsic complexity. Moreover, in such undersampling\\nregimes, the signal can be recovered by sparsity promoting convex\\nregularization like $\\\\ell_1$- or total variation (TV-) minimization. Precise\\nrelations between many low complexity measures and the sufficient number of\\nrandom measurements are known for many sparsity promoting norms. However, a\\nprecise estimate of the undersampling rate for the TV seminorm is still\\nlacking. We address this issue by: a) providing dual certificates testing\\nuniqueness of a given cosparse signal with bounded signal values, b)\\napproximating the undersampling rates via the statistical dimension of the TV\\ndescent cone and c) showing empirically that the provided rates also hold for\\ntomographic measurements.\\n'\n",
      " '  The paper proposes an on-line monitoring framework for continuous real-time\\nsafety/security in learning-based control systems (specifically application to\\na unmanned ground vehicle). We monitor validity of mappings from sensor inputs\\nto actuator commands, controller-focused anomaly detection (CFAM), and from\\nactuator commands to sensor inputs, system-focused anomaly detection (SFAM).\\nCFAM is an image conditioned energy based generative adversarial network\\n(EBGAN) in which the energy based discriminator distinguishes between proper\\nand anomalous actuator commands. SFAM is based on an action condition video\\nprediction framework to detect anomalies between predicted and observed\\ntemporal evolution of sensor data. We demonstrate the effectiveness of the\\napproach on our autonomous ground vehicle for indoor environments and on\\nUdacity dataset for outdoor environments.\\n'\n",
      " '  We investigate the effects of the in-plane biaxial strain and charge doping\\non the charge density wave (CDW) order of monolayer $1T$-TiSe$_2$ by using the\\nfirst-principles calculations. Our results show that the tensile strain can\\nsignificantly enhance the CDW order, while both compressive strain and charge\\ndoping (electrons and holes) suppress the CDW instability. The tensile strain\\nmay provide an effective method for obtaining higher CDW transition temperature\\non the basis of monolayer $1T$-TiSe$_2$. We also discuss the potential\\nsuperconductivity in charge-doped monolayer $1T$-TiSe$_2$. Controllable\\nelectronic phase transition from CDW state to metallic state or even\\nsuperconducting state can be realized in monolayer $1T$-TiSe$_2$, which makes\\n$1T$-TiSe$_2$ possess a promising application in controllable switching\\nelectronic devices based on CDW.\\n'\n",
      " '  A suitable piece of software is presented to connect Abaqus, a sophisticated\\nfinite element package, with Matlab, the most comprehensive program for\\nmathematical analysis. This interface between these well-known codes not only\\nbenefits from the image processing and the integrated graph-plotting features\\nof Matlab but also opens up new opportunities in results post-processing,\\nstatistical analysis and mathematical optimization, among many other\\npossibilities. The software architecture and usage are appropriately described\\nand two problems of particular engineering significance are addressed to\\ndemonstrate its capabilities. Firstly, the software is employed to assess\\ncleavage fracture through a novel 3-parameter Weibull probabilistic framework.\\nThen, its potential to create and train neural networks is used to identify\\ndamage parameters through a hybrid experimental-numerical scheme, and model\\ncrack propagation in structural materials by means of a cohesive zone approach.\\nThe source code, detailed documentation and a large number of tutorials can be\\nfreely downloaded from www.abaqus2matlab.com.\\n'\n",
      " '  The spin Hall effect (SHE), which converts a charge current into a transverse\\nspin current, has long been believed to be a phenomenon induced by the\\nspin--orbit coupling. Here, we propose an alternative mechanism to realize the\\nintrinsic SHE through a chiral magnetic structure that breaks the spin rotation\\nsymmetry. No spin--orbit coupling is needed even when the scalar spin chirality\\nvanishes, different from the case of the topological Hall effect. In known\\nchiral antiferromagnetic compounds Mn$_3X$ ($X=$ Ga, Ge, and Sn), for example,\\nwe indeed obtain large spin Hall conductivities based on \\\\textit{ab initio}\\ncalculations. Apart further developing the conceptual understanding of the SHE,\\nour work suggests an alternative strategy to design spin Hall materials without\\ninvolving heavy elements, which may be advantageous for technological\\napplications.\\n'\n",
      " '  Motivated by the forensic problem of determining the strength of evidence of\\na continuously distributed measurement of evidence, in the situation of\\ncomposite hypotheses of the prosecutor and the defence concerning a parameter\\nof a parametric model, we consider empirical Bayes methods with a prescribed\\nquantile value for the prior distribution.\\nFirstly we derive the strength of evidence for nonparametric priors. It turns\\nout that we get the by now more or less accepted strength of evidence as the\\nratio of two suprema,\\n$\\\\sup_{\\\\theta\\\\geq\\\\theta_0}f(x|\\\\theta)/\\\\sup_{\\\\theta<\\\\theta_0}f(x|\\\\theta)$. Here\\nthe hypotheses of the prosecutor and defence are given by $H_p: \\\\theta\\\\geq\\n\\\\theta_0$ and $H_d:\\\\theta<\\\\theta_0$. The evidence is seen as a measurement $x$\\nwhich is a realization of a random variable with a density $f(x|\\\\theta)$.\\nSecondly we consider a similar parametric empirical Bayes method with a\\nquantile restriction on the prior where the prior distribution is assumed to be\\nnormal. Some interesting strength of evidence functions are derived for this\\nsituation.\\n'\n",
      " '  Let $\\\\{X_n: n\\\\in \\\\mathbb{N}\\\\}$ be a linear process with bounded probability\\ndensity function $f(x)$. We study the estimation of the quadratic functional\\n$\\\\int_{\\\\mathbb{R}} f^2(x)\\\\, dx$. With a Fourier transform on the kernel\\nfunction and the projection method, it is shown that, under certain mild\\nconditions, the estimator \\\\[ \\\\frac{2}{n(n-1)h_n} \\\\sum_{1\\\\le i<j\\\\le\\nn}K\\\\left(\\\\frac{X_i-X_j}{h_n}\\\\right) \\\\] has similar asymptotical properties as\\nthe i.i.d. case studied in Giné and Nickl (2008) if the linear process\\n$\\\\{X_n: n\\\\in \\\\mathbb{N}\\\\}$ has the defined short range dependence. We also\\nprovide an application to $L^2_2$ divergence and the extension to multivariate\\nlinear processes. The simulation study for linear processes with Gaussian and\\n$\\\\alpha$-stable innovations confirms our theoretical results. As an\\nillustration, we estimate the $L^2_2$ divergences among the density functions\\nof average annual river flows for four rivers and obtain promising results.\\n'\n",
      " '  In this paper, we propose the primal-dual method of multipliers (PDMM) for\\ndistributed optimization over a graph. In particular, we optimize a sum of\\nconvex functions defined over a graph, where every edge in the graph carries a\\nlinear equality constraint. In designing the new algorithm, an augmented\\nprimal-dual Lagrangian function is constructed which smoothly captures the\\ngraph topology. It is shown that a saddle point of the constructed function\\nprovides an optimal solution of the original problem. Further under both the\\nsynchronous and asynchronous updating schemes, PDMM has the convergence rate of\\nO(1/K) (where K denotes the iteration index) for general closed, proper and\\nconvex functions. Other properties of PDMM such as convergence speeds versus\\ndifferent parameter- settings and resilience to transmission failure are also\\ninvestigated through the experiments of distributed averaging.\\n'\n",
      " '  The ^1{\\\\Sigma}^+ electronic ground states of MgLi^+ and CaLi^+ molecular ions\\nare investigated for their spectroscopic constants and properties such as the\\ndipole- and quadrupole moments, and static dipole polarizabilities. The\\nquadrupole moments and the static dipole polarizabilities for these ions have\\nbeen calculated and reported here, for the first time. The maximum possible\\nerror bars, arising due to the finite basis set and the exclusion of higher\\ncorrelation effects beyond partial triples, are quoted for reliability.\\nFurther, the adiabatic effects such as diagonal Born-Oppenheimer corrections\\nare also calculated for these molecules. The vibrational energies, the\\nwavefunctions, and the relevant vibrational parameters are obtained by solving\\nthe vibrational Schrödinger equation using the potential energy curve and the\\npermanent dipole moment curve of the molecular electronic ground state.\\nThereafter, spontaneous and black-body radiation induced transition rates are\\ncalculated to obtain the lifetimes of the vibrational states. The lifetime of\\nrovibronic ground state for MgLi^+ , at room temperature, is found to be 2.81 s\\nand for CaLi^+ it is 3.19 s. It has been observed that the lifetime of the\\nhighly excited vibrational state is several times larger than (comparable to)\\nthat of the vibrational ground state of MgLi^+ (CaLi^+ ). In addition, a few\\nlow-lying electronic excited states of {\\\\Sigma} and {\\\\Pi} symmetries have been\\ninvestigated for their electronic and vibrational properties, using EOM-CCSD\\nmethod together with the QZ basis sets.\\n'\n",
      " '  Deep Convolutional Neural Networks (DCNNs) are showing impressive\\nperformances in biomedical semantic segmentation. However, current DCNNs\\nusually use down-sampling layers to achieve significant receptive field\\nincreasing and to gain abstract semantic information. These down-sampling\\nlayers decrease the spatial dimension of feature maps as well, which is harmful\\nfor semantic segmentation. Atrous convolution is an alternative for the\\ndown-sampling layer. It could increase the receptive field significantly but\\nalso maintain the spatial dimension of feature maps. In this paper, firstly, an\\natrous rate setting is proposed to achieve the largest and fully-covered\\nreceptive field with a minimum number of layers. Secondly, six atrous blocks,\\nthree shortcut connections and four normalization methods are explored to\\nselect the optimal atrous block, shortcut connection and normalization method.\\nFinally, a new and dimensionally lossless DCNN - Atrous Convolutional Neural\\nNetwork (ACNN) is proposed with using cascaded atrous II-blocks, residual\\nlearning and Fine Group Normalization (FGN). The Right Ventricle (RV), Left\\nVentricle (LV) and aorta data are used for the validation. The results show\\nthat the proposed ACNN achieves comparable segmentation Dice Similarity\\nCoefficients (DSCs) with U-Net, optimized U-Net and the hybrid network, but\\nuses much less parameters. This advantage is considered to benefit from the\\ndimensionally lossless feature maps.\\n'\n",
      " '  For long wavelengths three-dimensional connected metallic wire meshes are\\nimpenetrable by light and have an electromagnetic response similar to that of\\nan electron gas below the plasma frequency. Surprisingly, here it is shown that\\nwhen two opaque metallic meshes are spatially-interlaced the combined structure\\nenables an anomalous light tunneling in the long wavelength regime. The effect\\nis due to the destructive interference of the waves scattered by the two wire\\nmeshes, which leads to a Fano-type resonance.\\n'\n",
      " '  In this paper, we consider a finite network of unmanned aerial vehicles\\n(UAVs) serving a given region. Modeling this network as a uniform binomial\\npoint process (BPP), we derive the downlink coverage probability of a reference\\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\\nfading for all wireless links. The reference receiver is assumed to connect to\\nits closest transmitting node as is usually the case in cellular systems. After\\nderiving the distribution of distances from the reference receiver to the\\nserving and interfering nodes, we derive an exact expression for downlink\\ncoverage probability in terms of the derivative of Laplace transform of\\ninterference power distribution. In the downlink of this system, it is not\\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\\nsignificantly stronger than the reflected multipath components. To emulate such\\nscenarios, we also derive the coverage probability in the absence of fading\\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\\\to \\\\infty$.\\nUsing asymptotic expansion of incomplete gamma function, we concretely show\\nthat this limit reduces to a redundant condition. Consequently, we derive an\\naccurate coverage probability approximation for this case using dominant\\ninterferer-based approach in which the effect of dominant interferer is exactly\\ncaptured and the residual interference from other interferers is carefully\\napproximated. We then derive the bounds of the approximate coverage probability\\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\\ncoverage probability as a function of height of the transmitting nodes and the\\nlocation of reference receiver on the ground.\\n'\n",
      " '  We present a linear time algorithm for computing a cycle separator in a\\nplanar graph that is (arguably) simpler than previously known algorithms. Our\\nalgorithm builds on, and is somewhat similar to, previous algorithms for\\ncomputing separators. The main new ingredient is a specific layered\\ndecomposition of the planar graph constructed differently from previous\\nBFS-based layerings.\\n'\n",
      " '  An NP-hard graph problem may be intractable for general graphs but it could\\nbe efficiently solvable using dynamic programming for graphs with bounded width\\n(or depth or some other structural parameter). Dynamic programming is a\\nwell-known approach used for finding exact solutions for NP-hard graph problems\\nbased on tree decompositions. It has been shown that there exist algorithms\\nusing linear time in the number of vertices and single exponential time in the\\nwidth (depth or other parameters) of a given tree decomposition for many\\nconnectivity problems. Employing dynamic programming on a tree decomposition\\nusually uses exponential space. In 2010, Lokshtanov and Nederlof introduced an\\nelegant framework to avoid exponential space by algebraization. Later, Fürer\\nand Yu modified the framework in a way that even works when the underlying set\\nis dynamic, thus applying it to tree decompositions. In this work, we design\\nspace-efficient algorithms to solve the Hamiltonian Cycle and the Traveling\\nSalesman problems, using polynomial space while the time complexity is only\\nslightly increased. This might be inevitable since we are reducing the space\\nusage from an exponential amount (in dynamic programming solution) to\\npolynomial. We give an algorithm to solve Hamiltonian cycle in time\\n$\\\\mathcal{O}((4w)^d\\\\, nM(n\\\\log{n}))$ using $\\\\mathcal{O}(dn\\\\log{n})$ space,\\nwhere $M(r)$ is the time complexity to multiply two integers, each of which\\nbeing represented by at most $r$ bits. Then, we solve the more general\\nTraveling Salesman problem in time $\\\\mathcal{O}((4w)^d poly(n))$ using space\\n$\\\\mathcal{O}(\\\\mathcal{W}dn\\\\log{n})$, where $w$ and $d$ are the width and the\\ndepth of the given tree decomposition and $\\\\mathcal{W}$ is the sum of weights.\\nFurthermore, this algorithm counts the number of Hamiltonian Cycles.\\n'\n",
      " '  This paper introduces a fast and numerically stable algorithm for the\\nsolution of fourth-order linear boundary value problems on an interval. This\\ntype of equation arises in a variety of settings in physics and signal\\nprocessing. However, current methods of solution involve discretizing the\\ndifferential equation directly by finite elements or finite differences, and\\nconsequently suffer from the poor conditioning introduced by such schemes. Our\\nnew method instead reformulates the equation as a collection of second-kind\\nintegral equations defined on local subdomains. Each such equation can be\\nstably discretized. The boundary values of these local solutions are matched by\\nsolving a banded linear system. The method of deferred corrections is then used\\nto increase the accuracy of the scheme. Deferred corrections requires applying\\nthe integral operator to a function on the entire domain, for which we provide\\nan algorithm with linear cost. We illustrate the performance of our method on\\nseveral numerical examples.\\n'\n",
      " '  The full development of mono- or multi-dimensional time-resolved spectroscopy\\ntechniques incorporating optical activity signals has been strongly hampered by\\nthe challenge of identifying the small chiral signals over the large achiral\\nbackground. Here we propose a new methodology to isolate chiral signals\\nremoving the achiral background from two commonly used configurations for\\nperforming two dimensional optical spectroscopy, known as BOXCARS and GRadient\\nAssisted Photon Echo Spectroscopy (GRAPES). It is found that in both cases an\\nachiral signal from an isotropic system can be completely eliminated by small\\nmanipulations of the relative angles between the linear polarizations of the\\nfour input laser pulses. Starting from the formulation of a perturbative\\nexpansion of the signal in the angle between the beams and the propagation\\naxis, we derive analytic expressions that can be used to estimate how to change\\nthe polarization angles of the four pulses to minimize achiral contributions in\\nthe studied configurations. The generalization to any other possible\\nexperimental configurations has also been discussed. %We derive analytic\\nexpressions to changes required to the polarizations in terms of a perturbative\\nexpansion in the angle between the beams and the colinear axis. We also\\nnumerically estimate higher order coefficients which cover arbitrarily large\\nangles and thus any experimental configuration.\\n'\n",
      " '  With a growing number of social apps, people have become increasingly willing\\nto share their everyday photos and events on social media platforms, such as\\nFacebook, Instagram, and WeChat. In social media data mining, post popularity\\nprediction has received much attention from both data scientists and\\npsychologists. Existing research focuses more on exploring the post popularity\\non a population of users and including comprehensive factors such as temporal\\ninformation, user connections, number of comments, and so on. However, these\\nframeworks are not suitable for guiding a specific user to make a popular post\\nbecause the attributes of this user are fixed. Therefore, previous frameworks\\ncan only answer the question \"whether a post is popular\" rather than \"how to\\nbecome famous by popular posts\". In this paper, we aim at predicting the\\npopularity of a post for a specific user and mining the patterns behind the\\npopularity. To this end, we first collect data from Instagram. We then design a\\nmethod to figure out the user environment, representing the content that a\\nspecific user is very likely to post. Based on the relevant data, we devise a\\nnovel dual-attention model to incorporate image, caption, and user environment.\\nThe dual-attention model basically consists of two parts, explicit attention\\nfor image-caption pairs and implicit attention for user environment. A\\nhierarchical structure is devised to concatenate the explicit attention part\\nand implicit attention part. We conduct a series of experiments to validate the\\neffectiveness of our model and investigate the factors that can influence the\\npopularity. The classification results show that our model outperforms the\\nbaselines, and a statistical analysis identifies what kind of pictures or\\ncaptions can help the user achieve a relatively high \"likes\" number.\\n'\n",
      " '  The impact of liquid drops on a heated solid surface is of great importance\\nin many engineering applications. This paper describes the simulation of the\\ndrop-wall interaction using the smoothed particle hydrodynamics (SPH) method.\\nThe SPH method is a Lagrangian mesh-free method that can be used to solve the\\nfluid equations. A vaporization model based on the SPH formulation was also\\ndeveloped and implemented. A parametric study was conducted to characterize the\\neffects of impact velocity and wall temperature on the impact outcome. The\\npresent numerical method was able to predict different outcomes, such as\\ndeposition, splash, breakup, and rebound (i.e., Leidenfrost phenomenon). The\\npresent numerical method was used to construct a regime diagram for describing\\nthe impact of an iso-octane drop on a heated surface at various Weber numbers\\nand wall temperatures.\\n'\n",
      " '  In this paper we apply active learning algorithms for dynamic pricing in a\\nprominent e-commerce website. Dynamic pricing involves changing the price of\\nitems on a regular basis, and uses the feedback from the pricing decisions to\\nupdate prices of the items. Most popular approaches to dynamic pricing use a\\npassive learning approach, where the algorithm uses historical data to learn\\nvarious parameters of the pricing problem, and uses the updated parameters to\\ngenerate a new set of prices. We show that one can use active learning\\nalgorithms such as Thompson sampling to more efficiently learn the underlying\\nparameters in a pricing problem. We apply our algorithms to a real e-commerce\\nsystem and show that the algorithms indeed improve revenue compared to pricing\\nalgorithms that use passive learning.\\n'\n",
      " '  We give a characterisation of Bieberbach manifolds which are geodesic\\nboundaries of a compact flat manifold, and discuss the low dimensional cases,\\nup to dimension 4.\\n'\n",
      " '  Neural samplers such as variational autoencoders (VAEs) or generative\\nadversarial networks (GANs) approximate distributions by transforming samples\\nfrom a simple random source---the latent space---to samples from a more complex\\ndistribution represented by a dataset. While the manifold hypothesis implies\\nthat the density induced by a dataset contains large regions of low density,\\nthe training criterions of VAEs and GANs will make the latent space densely\\ncovered. Consequently points that are separated by low-density regions in\\nobservation space will be pushed together in latent space, making stationary\\ndistances poor proxies for similarity. We transfer ideas from Riemannian\\ngeometry to this setting, letting the distance between two points be the\\nshortest path on a Riemannian manifold induced by the transformation. The\\nmethod yields a principled distance measure, provides a tool for visual\\ninspection of deep generative models, and an alternative to linear\\ninterpolation in latent space. In addition, it can be applied for robot\\nmovement generalization using previously learned skills. The method is\\nevaluated on a synthetic dataset with known ground truth; on a simulated robot\\narm dataset; on human motion capture data; and on a generative model of\\nhandwritten digits.\\n'\n",
      " '  For a commutative Noetherian ring R of dimension d and a commutative\\ncancellative monoid M, the elementary action on unimodular n-rows over the\\nmonoid ring R[M] is transitive for n>=max(d+2,3). The starting point is the\\ncase of polynomial rings, considered by A. Suslin in the 1970s. The main result\\ncompletes a project, initiated in the early 1990s, and suggests a new direction\\nin the study of K-theory of monoid rings.\\n'\n",
      " \"  In this paper, we establish existence and multiplicity of solutions for the\\nfollowing class of quasilinear field equation $$ -\\\\Delta\\nu+V(x)u-\\\\Delta_{p}u+W'(u)=0, \\\\,\\\\,\\\\, \\\\mbox{in} \\\\,\\\\,\\\\, \\\\mathbb{R}^{N}, \\\\eqno{(P)}\\n$$ where $u=(u_1,u_2,...,u_{N+1})$, $p>N \\\\geq 2$, $W$ is a singular function\\nand $V$ is a positive continuous function.\\n\"\n",
      " '  The t-distribution has many useful applications in robust statistical\\nanalysis. The parameter estimation of the t-distribution is carried out using\\nML estimation method, and the ML estimates are obtained via the EM algorithm.\\nIn this study, we consider an alternative estimation method for all the\\nparameters of the multivariate-t distribution using the MLq estimation method.\\nWe adapt the EM algorithm to obtain the MLq estimates for all the parameters.\\nWe provide a small simulation study to illustrate the performance of the MLq\\nestimators over the ML estimators and observe that the MLq estimators have\\nconsiderable superiority over the ML estimators.\\n'\n",
      " '  The paper is a suggested experiment in effectively teaching subjects in\\nComputer Science. The paper addresses effective content-delivery with the help\\nof a university intranet. The proposal described herein is for teaching a\\nsubject like Combinatorics and Graph Theory - the main idea is to supplement\\nlectures with a teacher-moderated online forum against an associated intranet\\nportal.\\nKeywords and phrases -computer-assisted learning; learning portal; active\\nlearning; OEIS; intranet portal; undergraduate teaching; Combinatorics and\\nGraph theory\\n'\n",
      " '  In this paper, we will look at actions on complex flag varieties $G/P$ of the\\ntorus $\\\\hat{T}=\\\\bigcap\\\\limits_{\\\\alpha\\\\in\\\\Delta\\\\setminus\\\\Delta_P}\\\\ker(\\\\alpha)$,\\nand under reasonable assumptions, we will give a description of the set\\n$X^{us}$ of unstable points for $\\\\hat{T}$-linearized invertible sheaves. We\\nwill investigate the case where $P$ is a maximal parabolic subgroup, and show\\nthat $X^{us}$ can be written as a disjoint union of a Schubert variety and an\\nopposite Schubert variety, and we deduce the vanishing of cohomology groups\\n$H^i(Y,{\\\\cal M})$ for invertible sheaves ${\\\\cal M}$ on the quotient variety $Y$\\nfor $i$ in a range given by the codimension of $X^{us}$.\\n'\n",
      " '  The probability that a user will click a search result depends both on its\\nrelevance and its position on the results page. The position based model\\nexplains this behavior by ascribing to every item an attraction probability,\\nand to every position an examination probability. To be clicked, a result must\\nbe both attractive and examined. The probabilities of an item-position pair\\nbeing clicked thus form the entries of a rank-$1$ matrix. We propose the\\nlearning problem of a Bernoulli rank-$1$ bandit where at each step, the\\nlearning agent chooses a pair of row and column arms, and receives the product\\nof their Bernoulli-distributed values as a reward. This is a special case of\\nthe stochastic rank-$1$ bandit problem considered in recent work that proposed\\nan elimination based algorithm Rank1Elim, and showed that Rank1Elim\\'s regret\\nscales linearly with the number of rows and columns on \"benign\" instances.\\nThese are the instances where the minimum of the average row and column rewards\\n$\\\\mu$ is bounded away from zero. The issue with Rank1Elim is that it fails to\\nbe competitive with straightforward bandit strategies as $\\\\mu \\\\rightarrow 0$.\\nIn this paper we propose Rank1ElimKL which simply replaces the (crude)\\nconfidence intervals of Rank1Elim with confidence intervals based on\\nKullback-Leibler (KL) divergences, and with the help of a novel result\\nconcerning the scaling of KL divergences we prove that with this change, our\\nalgorithm will be competitive no matter the value of $\\\\mu$. Experiments with\\nsynthetic data confirm that on benign instances the performance of Rank1ElimKL\\nis significantly better than that of even Rank1Elim, while experiments with\\nmodels derived from real data confirm that the improvements are significant\\nacross the board, regardless of whether the data is benign or not.\\n'\n",
      " '  We prove that all endo-$p$-permutation modules for a finite group are\\nliftable from characteristic $p>0$ to characteristic $0$.\\n'\n",
      " \"  Capturing the temporal dynamics of user preferences over items is important\\nfor recommendation. Existing methods mainly assume that all time steps in\\nuser-item interaction history are equally relevant to recommendation, which\\nhowever does not apply in real-world scenarios where user-item interactions can\\noften happen accidentally. More importantly, they learn user and item dynamics\\nseparately, thus failing to capture their joint effects on user-item\\ninteractions. To better model user and item dynamics, we present the\\nInteracting Attention-gated Recurrent Network (IARN) which adopts the attention\\nmodel to measure the relevance of each time step. In particular, we propose a\\nnovel attention scheme to learn the attention scores of user and item history\\nin an interacting way, thus to account for the dependencies between user and\\nitem dynamics in shaping user-item interactions. By doing so, IARN can\\nselectively memorize different time steps of a user's history when predicting\\nher preferences over different items. Our model can therefore provide\\nmeaningful interpretations for recommendation results, which could be further\\nenhanced by auxiliary features. Extensive validation on real-world datasets\\nshows that IARN consistently outperforms state-of-the-art methods.\\n\"\n",
      " '  When solving k-in-a-Row games, the Hales-Jewett pairing strategy [4] is a\\nwell-known strategy to prove that specific positions are (at most) a draw. It\\nrequires two empty squares per possible winning line (group) to be marked,\\ni.e., with a coverage ratio of 2.0. In this paper we present a new strategy,\\ncalled Set Matching. A matching set consists of a set of nodes (the markers), a\\nset of possible winning lines (the groups), and a coverage set indicating how\\nall groups are covered after every first initial move. This strategy needs less\\nthan two markers per group. As such it is able to prove positions in k-in-a-Row\\ngames to be draws, which cannot be proven using the Hales-Jewett pairing\\nstrategy. We show several efficient configurations with their matching sets.\\nThese include Cycle Configurations, BiCycle Configurations, and PolyCycle\\nConfigurations involving more than two cycles. Depending on configuration, the\\ncoverage ratio can be reduced to 1.14. Many examples in the domain of solving\\nk-in-a-Row games are given, including the direct proof (without further\\ninvestigation) that the empty 4 x 4 board is a draw for 4-in-a-Row.\\n'\n",
      " '  The increase in the number of researchers coupled with the ease of publishing\\nand distribution of scientific papers (due to technological advancements) has\\nresulted in a dramatic increase in astronomy literature. This has likely led to\\nthe predicament that the body of the literature is too large for traditional\\nhuman consumption and that related and crucial knowledge is not discovered by\\nresearchers. In addition to the increased production of astronomical\\nliterature, recent decades have also brought several advancements in\\ncomputational linguistics. Especially, the machine-aided processing of\\nliterature dissemination might make it possible to convert this stream of\\npapers into a coherent knowledge set. In this paper, we present the application\\nof computational linguistics techniques to astronomy literature. In particular,\\nwe developed a tool that will find similar articles purely based on text\\ncontent from an input paper. We find that our technique performs robustly in\\ncomparison with other tools recommending articles given a reference paper\\n(known as recommender system). Our novel tool shows the great power in\\ncombining computational linguistics with astronomy literature and suggests that\\nadditional research in this endeavor will likely produce even better tools that\\nwill help researchers cope with the vast amounts of knowledge being produced.\\n'\n",
      " \"  In this paper, we study the notion of admissibility for randomised strategies\\nin concurrent games. Intuitively, an admissible strategy is one where the\\nplayer plays `as well as possible', because there is no other strategy that\\ndominates it, i.e., that wins (almost surely) against a super set of\\nadversarial strategies. We prove that admissible strategies always exist in\\nconcurrent games, and we characterise them precisely. Then, when the objectives\\nof the players are omega-regular, we show how to perform assume-admissible\\nsynthesis, i.e., how to compute admissible strategies that win (almost surely)\\nunder the hypothesis that the other players play admissible\\n\"\n",
      " '  In this paper the sensor noise of two geophone configurations (L-22D and L-4C\\ngeophones from Sercel with custom built amplifiers) was measured by performing\\ntwo huddle tests. It is shown that the accuracy of the results can be\\nsignificantly improved by performing the huddle test in a seismically quiet\\nenvironment and by using a large number of reference sensors to remove the\\nseismic foreground signal from the data. Using these two techniques, the\\nmeasured sensor noise of the two geophone configurations matched calculated\\npredictions remarkably well in the bandwidth of interest (0.01 Hz to 100 Hz).\\nLow noise operational amplifiers OPA188 were utilized to amplify the L-4C\\ngeophone to give a sensor that was characterized to be near Johnson noise\\nlimited in the bandwidth of interest with a noise value of $10^{-11}\\n\\\\text{m}/\\\\sqrt{\\\\text{Hz}}$ at 1 Hz.\\n'\n",
      " '  We propose a new audio signal encryption scheme based on the chaotic Hénon\\nmap. The scheme mainly comprises two phases: one is the preprocessing stage\\nwhere the audio signal is transformed into a data by the lifting wavelet scheme\\nand the other in which the transformed data is encrypted by chaotic data set\\nand hyperbolic functions. Furthermore, we use dynamic keys and consider the key\\nspace size to be large enough to resist any kind of cryptographic attacks. A\\nstatistical investigation is also made to test the security and the efficiency\\nof the proposed scheme.\\n'\n",
      " '  We employ random geometric digraphs to construct semi-parametric classifiers.\\nThese data-random digraphs are from parametrized random digraph families called\\nproximity catch digraphs (PCDs). A related geometric digraph family, class\\ncover catch digraph (CCCD), has been used to solve the class cover problem by\\nusing its approximate minimum dominating set. CCCDs showed relatively good\\nperformance in the classification of imbalanced data sets, and although CCCDs\\nhave a convenient construction in $\\\\mathbb{R}^d$, finding minimum dominating\\nsets is NP-hard and its probabilistic behaviour is not mathematically tractable\\nexcept for $d=1$. On the other hand, a particular family of PCDs, called\\n\\\\emph{proportional-edge} PCDs (PE-PCDs), has mathematical tractable minimum\\ndominating sets in $\\\\mathbb{R}^d$; however their construction in higher\\ndimensions may be computationally demanding. More specifically, we show that\\nthe classifiers based on PE-PCDs are prototype-based classifiers such that the\\nexact minimum number of prototypes (equivalent to minimum dominating sets) are\\nfound in polynomial time on the number of observations. We construct two types\\nof classifiers based on PE-PCDs. One is a family of hybrid classifiers depend\\non the location of the points of the training data set, and another type is a\\nfamily of classifiers solely based on class covers. We assess the\\nclassification performance of our PE-PCD based classifiers by extensive Monte\\nCarlo simulations, and compare them with that of other commonly used\\nclassifiers. We also show that, similar to CCCD classifiers, our classifiers\\nare relatively better in classification in the presence of class imbalance.\\n'\n",
      " '  We study the interplay of spin-orbit coupling (SOC) and strong p-wave\\ninteraction to the scattering property of spin-1/2 ultracold Fermi gases. Based\\non a two-channel square-well potential generating p-wave resonance, we show\\nthat the presence of an isotropic SOC, even for its length much longer than the\\npotential range, can greatly modify the p-wave short-range boundary\\ncondition(BC). As a result, the conventional p-wave BC cannot predict the\\ninduced molecules near p-wave resonance, which can be fully destroyed to vanish\\ndue to strong interference between s- and p-wave channels. By analyzing the\\nintrinsic reasons for the breakdown of conventional BC, we propose a new p-wave\\nBC that can excellently reproduce the exact molecule solutions and also equally\\napply for a wide class of single-particle potentials besides SOC. This work\\nreveals the significant effect of SOC to both the short- and long-range\\nproperties of fermions near p-wave resonance, paving the way for future\\nexploring interesting few- and many-body physics in such system.\\n'\n",
      " '  The partial information decomposition (PID) is perhaps the leading proposal\\nfor resolving information shared between a set of sources and a target into\\nredundant, synergistic, and unique constituents. Unfortunately, the PID\\nframework has been hindered by a lack of a generally agreed-upon, multivariate\\nmethod of quantifying the constituents. Here, we take a step toward rectifying\\nthis by developing a decomposition based on a new method that quantifies unique\\ninformation. We first develop a broadly applicable method---the dependency\\ndecomposition---that delineates how statistical dependencies influence the\\nstructure of a joint distribution. The dependency decomposition then allows us\\nto define a measure of the information about a target that can be uniquely\\nattributed to a particular source as the least amount which the source-target\\nstatistical dependency can influence the information shared between the sources\\nand the target. The result is the first measure that satisfies the core axioms\\nof the PID framework while not satisfying the Blackwell relation, which depends\\non a particular interpretation of how the variables are related. This makes a\\nkey step forward to a practical PID.\\n'\n",
      " '  We propose a deep learning based method, the Deep Ritz Method, for\\nnumerically solving variational problems, particularly the ones that arise from\\npartial differential equations. The Deep Ritz method is naturally nonlinear,\\nnaturally adaptive and has the potential to work in rather high dimensions. The\\nframework is quite simple and fits well with the stochastic gradient descent\\nmethod used in deep learning. We illustrate the method on several problems\\nincluding some eigenvalue problems.\\n'\n",
      " \"  In this exploratory study we assessed how attitudes of children with autism\\nspectrum disorder (ASD) towards robots together with children's autism-related\\nsocial impairments are linked to indicators of children's preference of an\\ninteraction with a robot over an interaction with a person. We found that\\nchildren with ASD have overall positive attitudes towards robots and that they\\noften prefer interacting with a robot than with a person. Several of children's\\nattitudes were linked to children's longer gazes towards a robot compared to a\\nperson. Autism-related social impairments were linked to more repetitive and\\nstereotyped behaviors and to a shorter gaze duration in the interaction with\\nthe robot compared to the person. These preliminary results contribute to\\nbetter understand factors that might help determine sub-groups of children with\\nASD for whom robots could be particularly useful.\\n\"\n",
      " '  It is shown that the finite-dimensional simple representations of the super\\nJordan plane $B$ are one-dimensional. The indecomposable representations of\\ndimension $2$ and $3$ of $B$ are classified. Two families of indecomposable\\nrepresentations of $B$ of arbitrary dimension are presented.\\n'\n",
      " '  In this work, we use the numerical renormalization group (NRG) theory to\\nstudy the thermodynamics of the two-impurity Anderson model. Two different\\nmethods are used to estimate the effect of the Dzyaloshiskii-Moriya (DM)\\ninteraction on the variation of the Kondo temperature. When the\\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction is vanishing, the two\\ndifferent estimations give different tendency. If we use the peak of the\\nspecific heat to identify the variation of the Kondo temperature versus the\\nDzyaloshiskii-Moriya interaction, we get an almost linear function. However, if\\nwe use the low temperature universal curve of the impurity entropy, we get a\\nquadratic function. These results indicate that the previous debates about the\\ninfluence of the spin-orbit coupling on the Kondo temperature may come from the\\ndifferent definitions of the Kondo temperature. When the RKKY interaction is\\nferromagnetic, there are two stages of the Kondo screening. Both the two\\nestimations demonstrate that the second stage of the Kondo temperature is\\nexponentially dependent on the DM interaction. There results are dramatically\\ndifferent from those calculated via perturbation theory.\\n'\n",
      " \"  The discovery of radionuclides like 60Fe with half-lives of million years in\\ndeep-sea crusts and sediments offers the unique possibility to date and locate\\nnearby supernovae. We want to quantitatively establish that the 60Fe\\nenhancement is the result of several supernovae which are also responsible for\\nthe formation of the Local Bubble, our Galactic habitat. We performed\\nthree-dimensional hydrodynamic adaptive mesh refinement simulations (with\\nresolutions down to subparsec scale) of the Local Bubble and the neighbouring\\nLoop I superbubble in different homogeneous, self-gravitating environments. For\\nsetting up the Local and Loop I superbubble, we took into account the time\\nsequence and locations of the generating core-collapse supernova explosions,\\nwhich were derived from the mass spectrum of the perished members of certain\\nstellar moving groups. The release of 60Fe and its subsequent turbulent mixing\\nprocess inside the superbubble cavities was followed via passive scalars, where\\nthe yields of the decaying radioisotope were adjusted according to recent\\nstellar evolution calculations. The models are able to reproduce both the\\ntiming and the intensity of the 60Fe excess observed with rather high\\nprecision, provided that the external density does not exceed 0.3 cm-3 on\\naverage. Thus the two best-fit models presented here were obtained with\\nbackground media mimicking the classical warm ionised and warm neutral medium.\\nWe also found that 60Fe (which is condensed onto dust grains) can be delivered\\nto Earth via two physical mechanisms: either through individual fast-paced\\nsupernova blast waves, which cross the Earth's orbit sometimes even twice as a\\nresult of reflection from the Local Bubble's outer shell, or, alternatively,\\nthrough the supershell of the Local Bubble itself, injecting the 60Fe content\\nof all previous supernovae at once, but over a longer time range.\\n\"\n",
      " \"  Due to the rapid innovation of technology and the desire to find and employ\\nbiomarkers for neurodegenerative disease, high-dimensional data classification\\nproblems are routinely encountered in neuroimaging studies. To avoid\\nover-fitting and to explore relationships between disease and potential\\nbiomarkers, feature learning and selection plays an important role in\\nclassifier construction and is an important area in machine learning. In this\\narticle, we review several important feature learning and selection techniques\\nincluding lasso-based methods, PCA, the two-sample t-test, and stacked\\nauto-encoders. We compare these approaches using a numerical study involving\\nthe prediction of Alzheimer's disease from Magnetic Resonance Imaging.\\n\"\n",
      " '  Spectral decomposition of the Koopman operator is attracting attention as a\\ntool for the analysis of nonlinear dynamical systems. Dynamic mode\\ndecomposition is a popular numerical algorithm for Koopman spectral analysis;\\nhowever, we often need to prepare nonlinear observables manually according to\\nthe underlying dynamics, which is not always possible since we may not have any\\na priori knowledge about them. In this paper, we propose a fully data-driven\\nmethod for Koopman spectral analysis based on the principle of learning Koopman\\ninvariant subspaces from observed data. To this end, we propose minimization of\\nthe residual sum of squares of linear least-squares regression to estimate a\\nset of functions that transforms data into a form in which the linear\\nregression fits well. We introduce an implementation with neural networks and\\nevaluate performance empirically using nonlinear dynamical systems and\\napplications.\\n'\n",
      " '  We apply the vectorized Non-negative Matrix Factorization (NMF) method to\\npost-processing of direct imaging data for exoplanetary systems such as\\ncircumstellar disks. NMF is an iterative approach, which first creates a\\nnon-orthogonal and non-negative basis of components using given reference\\nimages, then models a target with the components. The constructed model is then\\nrescaled with a factor to compensate for the contribution from a disk. We\\ncompare NMF with existing methods (classical reference differential imaging\\nmethod, and the Karhunen-Loève image projection algorithm) using synthetic\\ncircumstellar disks, and demonstrate the superiority of NMF: with no need for\\nprior selection of references, NMF can detect fainter circumstellar disks,\\nbetter preserve low order disk morphology, and does not require forward\\nmodeling. As an application to a well-known disk example, we process the\\narchival Hubble Space Telescope (HST) STIS coronagraphic observations of\\nHD~181327 with different methods and compare them. NMF is able to extract some\\ncircumstellar material inside the primary ring for the first time. In the\\nappendix, we mathematically investigate the stability of NMF components during\\niteration, and the linearity of NMF modeling.\\n'\n",
      " '  Traditionally, multi-layer neural networks use dot product between the output\\nvector of previous layer and the incoming weight vector as the input to\\nactivation function. The result of dot product is unbounded, thus increases the\\nrisk of large variance. Large variance of neuron makes the model sensitive to\\nthe change of input distribution, thus results in poor generalization, and\\naggravates the internal covariate shift which slows down the training. To bound\\ndot product and decrease the variance, we propose to use cosine similarity or\\ncentered cosine similarity (Pearson Correlation Coefficient) instead of dot\\nproduct in neural networks, which we call cosine normalization. We compare\\ncosine normalization with batch, weight and layer normalization in\\nfully-connected neural networks as well as convolutional networks on the data\\nsets of MNIST, 20NEWS GROUP, CIFAR-10/100 and SVHN. Experiments show that\\ncosine normalization achieves better performance than other normalization\\ntechniques.\\n'\n",
      " '  Recently, Recurrent Neural Networks (RNNs) have been applied to the task of\\nsession-based recommendation. These approaches use RNNs to predict the next\\nitem in a user session based on the previ- ously visited items. While some\\napproaches consider additional item properties, we argue that item dwell time\\ncan be used as an implicit measure of user interest to improve session-based\\nitem recommen- dations. We propose an extension to existing RNN approaches that\\ncaptures user dwell time in addition to the visited items and show that\\nrecommendation performance can be improved. Additionally, we investigate the\\nusefulness of a single validation split for model selection in the case of\\nminor improvements and find that in our case the best model is not selected and\\na fold-like study with different validation sets is necessary to ensure the\\nselection of the best model.\\n'\n",
      " '  Recently, Deshpande et al. introduced a new measure of the complexity of a\\nBoolean function. We call this measure the \"goal value\" of the function. The\\ngoal value of $f$ is defined in terms of a monotone, submodular utility\\nfunction associated with $f$. As shown by Deshpande et al., proving that a\\nBoolean function $f$ has small goal value can lead to a good approximation\\nalgorithm for the Stochastic Boolean Function Evaluation problem for $f$. Also,\\nif $f$ has small goal value, it indicates a close relationship between two\\nother measures of the complexity of $f$, its average-case decision tree\\ncomplexity and its average-case certificate complexity. In this paper, we\\nexplore the goal value measure in detail. We present bounds on the goal values\\nof arbitrary and specific Boolean functions, and present results on properties\\nof the measure. We compare the goal value measure to other, previously studied,\\nmeasures of the complexity of Boolean functions. Finally, we discuss a number\\nof open questions provoked by our work.\\n'\n",
      " '  By analyzing a paradigmatic example of the theory of dissipative systems --\\nthe classical and quantum dissipative standard map -- we are able to explain\\nthe main features of the decay to the quantum equilibrium state. The classical\\nisoperiodic stable structures typically present in the parameter space of these\\nkind of systems play a fundamental role. In fact, we have found that the period\\nof stable structures that are near in this space determines the phase of the\\nleading eigenstates of the corresponding quantum superoperator. Moreover, the\\neigenvectors show a strong localization on the corresponding periodic orbits\\n(limit cycles). We show that this sort of scarring phenomenon (an established\\nproperty of Hamiltonian and projectively open systems) is present in the\\ndissipative case and it is of extreme simplicity.\\n'\n",
      " '  A novel semantic approach to data selection and compression is presented for\\nthe dynamic adaptation of IoT data processing and transmission within \"wireless\\nislands\", where a set of sensing devices (sensors) are interconnected through\\none-hop wireless links to a computational resource via a local access point.\\nThe core of the proposed technique is a cooperative framework where local\\nclassifiers at the mobile nodes are dynamically crafted and updated based on\\nthe current state of the observed system, the global processing objective and\\nthe characteristics of the sensors and data streams. The edge processor plays a\\nkey role by establishing a link between content and operations within the\\ndistributed system. The local classifiers are designed to filter the data\\nstreams and provide only the needed information to the global classifier at the\\nedge processor, thus minimizing bandwidth usage. However, the better the\\naccuracy of these local classifiers, the larger the energy necessary to run\\nthem at the individual sensors. A formulation of the optimization problem for\\nthe dynamic construction of the classifiers under bandwidth and energy\\nconstraints is proposed and demonstrated on a synthetic example.\\n'\n",
      " '  The electron-cyclotron maser is a process that generates intense and coherent\\nradio emission in plasma. In this paper, we present a comprehensive parametric\\ninvestigation on the electron-cyclotron-maser instability driven by non-thermal\\nring-beam electrons with intrinsic Alfvén waves which pervade the solar\\natmosphere and interplanetary space. It is found that both forward propagating\\nand backward propagating waves can be excited in the fast ordinary (O) and\\nextraordinary (X) electromagnetic modes. The growth rates of X1 mode are almost\\nalways weakened by Alfvén waves. The average pitch-angle $\\\\phi_0$ of\\nelectrons is a key parameter for the effect of Alfvén waves on the growth\\nrate of modes O1, O2 and X2. For a beam-dominated electron distribution\\n($\\\\phi_0 \\\\lesssim 30^\\\\circ$ ), the growth rates of the maser instability for\\nO1, O2 and X2 modes are enhanced with the increase of Alfvén wave energy\\ndensity. In other conditions, the growth rates of O1, O2 and X2 modes weakened\\nwith increasing Alfvén wave intensity, except that the growth of O1 mode may\\nalso be enhanced by Alfvén waves for a ring distribution. The results may be\\nimportant for us in analyzing the mechanism of radio bursts with various fine\\nstructures observed in space and astrophysical plasmas.\\n'\n",
      " '  News reports in media contain records of a wide range of socio-economic and\\npolitical events in time. Using a publicly available, large digital database of\\nnews records, and aggregating them over time, we study the network of ethnic\\nconflicts and human rights violations. Complex network analyses of the events\\nand the involved actors provide important insights on the engaging actors,\\ngroups, establishments and sometimes nations, pointing at their long range\\neffect over space and time. We find power law decays in distributions of actor\\nmentions, co-actor mentions and degrees and dominance of influential actors and\\ngroups. Most influential actors or groups form a giant connected component\\nwhich grows in time, and is expected to encompass all actors globally in the\\nlong run. We demonstrate how targeted removal of actors may help stop spreading\\nunruly events. We study the cause-effect relation between types of events, and\\nour quantitative analysis confirm that ethnic conflicts lead to human rights\\nviolations, while it does not support the converse.\\n'\n",
      " '  We consider a general stationary solution and derive the general laws for\\naccretion of rotating perfect fluids. For non-degenerate and degenerate Fermi\\nand Bose fluids we derive new effects that mimic the center-of-mass-energy\\neffect of two colliding particle in the vicinity of horizons. Non-degenerate\\nfluids see their chemical potential grow arbitrarily and ultra-relativistic\\nFermi fluids see their specific enthalpy and Fermi momentum grow arbitrarily\\ntoo while the latter vanishes gradually for non-relativistic Fermi fluids. For\\ndegenerate Bose fluids two scenarios remain possible as the fluid approaches a\\nhorizon: a) The Bose-Einstein condensation ceases or b) the temperature drops\\ngradually down to zero.\\n'\n",
      " \"  In online communities, antisocial behavior such as trolling disrupts\\nconstructive discussion. While prior work suggests that trolling behavior is\\nconfined to a vocal and antisocial minority, we demonstrate that ordinary\\npeople can engage in such behavior as well. We propose two primary trigger\\nmechanisms: the individual's mood, and the surrounding context of a discussion\\n(e.g., exposure to prior trolling behavior). Through an experiment simulating\\nan online discussion, we find that both negative mood and seeing troll posts by\\nothers significantly increases the probability of a user trolling, and together\\ndouble this probability. To support and extend these results, we study how\\nthese same mechanisms play out in the wild via a data-driven, longitudinal\\nanalysis of a large online news discussion community. This analysis reveals\\ntemporal mood effects, and explores long range patterns of repeated exposure to\\ntrolling. A predictive model of trolling behavior shows that mood and\\ndiscussion context together can explain trolling behavior better than an\\nindividual's history of trolling. These results combine to suggest that\\nordinary people can, under the right circumstances, behave like trolls.\\n\"\n",
      " '  The design of IoT systems could benefit from the combination of two different\\nanalyses. We perform a first analysis to approximate how data flow across the\\nsystem components, while the second analysis checks their communication\\nsoundness. We show how the combination of these two analyses yields further\\nbenefits hardly achievable by separately using each of them. We exploit two\\nindependently developed tools for the analyses.\\nFirstly, we specify IoT systems in IoT-LySa, a simple specification language\\nfeaturing asynchronous multicast communication of tuples. The values carried by\\nthe tuples are drawn from a term-algebra obtained by a parametric signature.\\nThe analysis of communication soundness is supported by ChorGram, a tool\\ndeveloped to verify the compatibility of communicating finite-state machines.\\nIn order to combine the analyses we implement an encoding of IoT-LySa processes\\ninto communicating machines. This encoding is not completely straightforward\\nbecause IoT-LySa has multicast communications with data, while communication\\nmachines are based on point-to-point communications where only finitely many\\nsymbols can be exchanged. To highlight the benefits of our approach we appeal\\nto a simple yet illustrative example.\\n'\n",
      " '  Expression quantitative trait loci (eQTL) analysis identifies genetic markers\\nassociated with the expression of a gene. Most existing eQTL analyses and\\nmethods investigate association in a single, readily available tissue, such as\\nblood. Joint analysis of eQTL in multiple tissues has the potential to improve,\\nand expand the scope of, single-tissue analyses. Large-scale collaborative\\nefforts such as the Genotype-Tissue Expression (GTEx) program are currently\\ngenerating high quality data in a large number of tissues. However,\\ncomputational constraints limit genome-wide multi-tissue eQTL analysis. We\\ndevelop an integrative method under a hierarchical Bayesian framework for eQTL\\nanalysis in a large number of tissues. The model fitting procedure is highly\\nscalable, and the computing time is a polynomial function of the number of\\ntissues. Multi-tissue eQTLs are identified through a local false discovery rate\\napproach, which rigorously controls the false discovery rate. Using simulation\\nand GTEx real data studies, we show that the proposed method has superior\\nperformance to existing methods in terms of computing time and the power of\\neQTL discovery. We provide a scalable method for eQTL analysis in a large\\nnumber of tissues. The method enables the identification of eQTL with different\\nconfigurations and facilitates the characterization of tissue specificity.\\n'\n",
      " '  The MOLLER experiment proposed at the Thomas Jefferson National Accelerator\\nFacility plans a precision low energy determination of the weak mixing angle\\nvia the measurement of the parity-violating asymmetry in the scattering of high\\nenergy longitudinally polarized electrons from electrons bound in a liquid\\nhydrogen target (M{\\\\o}ller scattering). A relative measure of the scattering\\nrate is planned to be obtained by intercepting the M{\\\\o}ller scattered\\nelectrons with a circular array of thin fused silica tiles attached to air\\nlight guides, which facilitate the transport of Cherenkov photons generated\\nwithin the tiles to photomultiplier tubes (PMTs). The scattered flux will also\\npass through the light guides of downstream tiles, generating additional\\nCherenkov as well as scintillation light and is a potential background. In\\norder to estimate the rate of these backgrounds, a gas-filled tube detector was\\ndesigned and deployed in an electron beam at the MAMI facility at Johannes\\nGutenberg University, Mainz, Germany. Described in this paper is the design of\\na detector to measure separately the scintillation and Cherenkov responses of\\ngas mixtures from relativistic electrons, the results of studies of several gas\\nmixtures with comparisons to simulations, and conclusions about the\\nimplications for the design of the MOLLER detector apparatus.\\n'\n",
      " '  ALICE (Adaptive Learning for Interdisciplinary Collaborative Environments) is\\nan open-source web based adaptive learning system designed for\\ninterdisciplinary instruction. ALICE has the potential to transform education\\nby empowering transdisciplinary knowledge acquisition. This is particularly\\nimportant in fields that accept newcomers with diverse scholastic backgrounds,\\ne.g. Systems Biology. With traditional interdisciplinary instruction, the\\ninstructor must cover pre-requisite information from multiple disciplines to\\nensure all students begin at a common baseline - slowing the learning process.\\nWith ALICE, students follow a personalized syllabus based on their previous\\nknowledge and work towards individual goals. Implementing an adaptive learning\\nsystem in an interdisciplinary course requires careful considerations of the\\ninstructional design. Structuring material, formulating assessments, and other\\ninstructional design aspects must be carefully considered. These considerations\\nare detailed through the exploration of a case study implementing ALICE in a\\ngraduate level Systems Biology course.\\n'\n",
      " '  Generalizing the classical work of Atiyah and Hirzebruch on non-algebraic\\nclasses, recently Quick proved the existence of torsion non-algebraic elements\\nin the Brown-Peterson tower. We construct non-torsion non-algebraic elements in\\nthe Brown-Peterson tower for the prime number 2.\\n'\n",
      " '  The analysis of log data generated by online educational systems is an\\nimportant task for improving the systems, and furthering our knowledge of how\\nstudents learn. This paper uses previously unseen log data from Edulab, the\\nlargest provider of digital learning for mathematics in Denmark, to analyse the\\nsessions of its users, where 1.08 million student sessions are extracted from a\\nsubset of their data. We propose to model students as a distribution of\\ndifferent underlying student behaviours, where the sequence of actions from\\neach session belongs to an underlying student behaviour. We model student\\nbehaviour as Markov chains, such that a student is modelled as a distribution\\nof Markov chains, which are estimated using a modified k-means clustering\\nalgorithm. The resulting Markov chains are readily interpretable, and in a\\nqualitative analysis around 125,000 student sessions are identified as\\nexhibiting unproductive student behaviour. Based on our results this student\\nrepresentation is promising, especially for educational systems offering many\\ndifferent learning usages, and offers an alternative to common approaches like\\nmodelling student behaviour as a single Markov chain often done in the\\nliterature.\\n'\n",
      " '  This paper studies the zero error capacity of the Nearest Neighbor Error\\n(NNE) channels with a multilevel alphabet. In the NNE channels, a transmitted\\nsymbol is a $d$-tuple of elements in $\\\\{0,1,2,\\\\dots, n-1 \\\\}$. It is assumed\\nthat only one element error to a nearest neighbor element in a transmitted\\nsymbol can occur. The NNE channels can be considered as a special type of\\nlimited magnitude error channels, and it is closely related to error models for\\nflash memories. In this paper, we derive a lower bound of the zero error\\ncapacity of the NNE channels based on a result of the perfect Lee codes. An\\nupper bound of the zero error capacity of the NNE channels is also derived from\\na feasible solution of a linear programming problem defined based on the\\nconfusion graphs of the NNE channels. As a result, a concise formula of the\\nzero error capacity is obtained using the lower and upper bounds.\\n'\n",
      " '  FinFETs have replaced the conventional bulk CMOS transistors in the sub-20nm\\ntechnology. One of the key issues to consider is, the vulnerability of FinFET\\nbased circuits to multiple node charge collection due to neutron-induced\\nstrikes. In this paper, we perform a device simulation based characterization\\nstudy on representative layouts of 14nm bulk FinFETs in order to study the\\nextent to which multiple transistors are affected. We find that multiple\\ntransistors do get affected and the impact can last up to five transistors away\\n(~200nm). We show that the potential of source/drain regions in the\\nneighborhood of the strike is a significant contributing factor. In the case of\\nmulti-fin FinFETs, the charge collected per fin is seen to reduce as the number\\nof fins increase. Thus, smaller FinFETs are susceptible to high amounts of\\ncharge collection.\\n'\n",
      " \"  Recently, the idea of taking ensemble average over gravity models has been\\nintroduced. Based on this idea, we study the ensemble average over\\n(effectively) all the gravity models (constructed from Ricci scalar) dubbing\\nthe name über-gravity which is a {\\\\it{fixed point}} in the model space. The\\nüber-gravity has interesting universal properties, independent from the\\nchoice of basis: $i)$ it mimics Einstein-Hilbert gravity for high-curvature\\nregime, $ii)$ it predicts stronger gravitational force for an\\nintermediate-curvature regime, $iii)$ surprisingly, for low-curvature regime,\\ni.e. $R<R_0$ where $R$ is Ricci scalar and $R_0$ is a given scale, the\\nLagrangian vanishes automatically and $iiii)$ there is a sharp transition\\nbetween low- and intermediate-curvature regimes at $R=R_0$. We show that the\\nüber-gravity response is robust to all values of vacuum energy, $\\\\rho_{vac}$\\nwhen there is no other matter. So as a toy model, über-gravity, gives a way\\nto think about the hierarchy problems e.g. the cosmological constant problem.\\nDue to the transition at $R=R_0$ there is a chance for über-gravity to bypass\\nWeinberg's no-go theorem. The cosmology of this model is also promising because\\nof its non-trivial predictions for small curvature scales in comparison to\\n$\\\\Lambda$CDM model.\\n\"\n",
      " '  We introduce a novel data-driven approach to discover and decode features in\\nthe neural code coming from large population neural recordings with minimal\\nassumptions, using cohomological feature extraction. We apply our approach to\\nneural recordings of mice moving freely in a box, where we find a circular\\nfeature. We then observe that the decoded value corresponds well to the head\\ndirection of the mouse. Thus we capture head direction cells and decode the\\nhead direction from the neural population activity without having to process\\nthe behaviour of the mouse. Interestingly, the decoded values convey more\\ninformation about the neural activity than the tracked head direction does,\\nwith differences that have some spatial organization. Finally, we note that the\\nresidual population activity, after the head direction has been accounted for,\\nretains some low-dimensional structure which is correlated with the speed of\\nthe mouse.\\n'\n",
      " \"  We propose an under-approximate reachability analysis algorithm for programs\\nrunning under the POWER memory model, in the spirit of the work on\\ncontext-bounded analysis intitiated by Qadeer et al. in 2005 for detecting bugs\\nin concurrent programs (supposed to be running under the classical SC model).\\nTo that end, we first introduce a new notion of context-bounding that is\\nsuitable for reasoning about computations under POWER, which generalizes the\\none defined by Atig et al. in 2011 for the TSO memory model. Then, we provide a\\npolynomial size reduction of the context-bounded state reachability problem\\nunder POWER to the same problem under SC: Given an input concurrent program P,\\nour method produces a concurrent program P' such that, for a fixed number of\\ncontext switches, running P' under SC yields the same set of reachable states\\nas running P under POWER. The generated program P' contains the same number of\\nprocesses as P, and operates on the same data domain. By leveraging the\\nstandard model checker CBMC, we have implemented a prototype tool and applied\\nit on a set of benchmarks, showing the feasibility of our approach.\\n\"\n",
      " '  We consider a finite-horizon linear-quadratic optimal control problem where\\nonly a limited number of control messages are allowed for sending from the\\ncontroller to the actuator. To restrict the number of control actions computed\\nand transmitted by the controller, we employ a threshold-based event-triggering\\nmechanism that decides whether or not a control message needs to be calculated\\nand delivered. Due to the nature of threshold-based event-triggering\\nalgorithms, finding the optimal control sequence requires minimizing a\\nquadratic cost function over a non-convex domain. In this paper, we firstly\\nprovide an exact solution to the non-convex problem mentioned above by solving\\nan exponential number of quadratic programs. To reduce computational\\ncomplexity, we, then, propose two efficient heuristic algorithms based on\\ngreedy search and the Alternating Direction Method of Multipliers (ADMM)\\nmethod. Later, we consider a receding horizon control strategy for linear\\nsystems controlled by event-triggered controllers, and we also provide a\\ncomplete stability analysis of receding horizon control that uses finite\\nhorizon optimization in the proposed class. Numerical examples testify to the\\nviability of the presented design technique.\\n'\n",
      " '  Ensembling multiple predictions is a widely-used technique to improve the\\naccuracy of various machine learning tasks. One obvious drawback of the\\nensembling is its higher execution cost during inference. In this paper, we\\nfirst describe our insights on relationship between the probability of the\\nprediction and the effect of ensembling with current deep neural networks;\\nensembling does not help mispredictions for inputs predicted with a high\\nprobability even when there is a non-negligible number of mispredicted inputs.\\nThis finding motivates us to develop a new technique called adaptive ensemble\\nprediction, which achieves the benefits of ensembling with much smaller\\nadditional execution costs. If the prediction for an input reaches a high\\nenough probability on the basis of the confidence level, we stop ensembling for\\nthis input to avoid wasting computation power. We evaluated the adaptive\\nensembling by using various datasets and showed that it reduces the computation\\ncost significantly while achieving similar accuracy to the naive ensembling. We\\nalso showed that our statistically rigorous confidence-level-based termination\\ncondition reduces the burden of the task-dependent parameter tuning compared to\\nthe naive termination based on the pre-defined threshold in addition to\\nyielding a better accuracy with the same cost.\\n'\n",
      " \"  Robot-assisted dressing offers an opportunity to benefit the lives of many\\npeople with disabilities, such as some older adults. However, robots currently\\nlack common sense about the physical implications of their actions on people.\\nThe physical implications of dressing are complicated by non-rigid garments,\\nwhich can result in a robot indirectly applying high forces to a person's body.\\nWe present a deep recurrent model that, when given a proposed action by the\\nrobot, predicts the forces a garment will apply to a person's body. We also\\nshow that a robot can provide better dressing assistance by using this model\\nwith model predictive control. The predictions made by our model only use\\nhaptic and kinematic observations from the robot's end effector, which are\\nreadily attainable. Collecting training data from real world physical\\nhuman-robot interaction can be time consuming, costly, and put people at risk.\\nInstead, we train our predictive model using data collected in an entirely\\nself-supervised fashion from a physics-based simulation. We evaluated our\\napproach with a PR2 robot that attempted to pull a hospital gown onto the arms\\nof 10 human participants. With a 0.2s prediction horizon, our controller\\nsucceeded at high rates and lowered applied force while navigating the garment\\naround a persons fist and elbow without getting caught. Shorter prediction\\nhorizons resulted in significantly reduced performance with the sleeve catching\\non the participants' fists and elbows, demonstrating the value of our model's\\npredictions. These behaviors of mitigating catches emerged from our deep\\npredictive model and the controller objective function, which primarily\\npenalizes high forces.\\n\"\n",
      " \"  The triad census is an important approach to understand local structure in\\nnetwork science, providing comprehensive assessments of the observed relational\\nconfigurations between triples of actors in a network. However, researchers are\\noften interested in combinations of relational and categorical nodal\\nattributes. In this case, it is desirable to account for the label, or color,\\nof the nodes in the triad census. In this paper, we describe an efficient\\nalgorithm for constructing the colored triad census, based, in part, on\\nexisting methods for the classic triad census. We evaluate the performance of\\nthe algorithm using empirical and simulated data for both undirected and\\ndirected graphs. The results of the simulation demonstrate that the proposed\\nalgorithm reduces computational time many-fold over the naive approach. We also\\napply the colored triad census to the Zachary karate club network dataset. We\\nsimultaneously show the efficiency of the algorithm, and a way to conduct a\\nstatistical test on the census by forming a null distribution from 1,000\\nrealizations of a mixing-matrix conditioned graph and comparing the observed\\ncolored triad counts to the expected. From this, we demonstrate the method's\\nutility in our discussion of results about homophily, heterophily, and\\nbridging, simultaneously gained via the colored triad census. In sum, the\\nproposed algorithm for the colored triad census brings novel utility to social\\nnetwork analysis in an efficient package.\\n\"\n",
      " '  The millimeter-wave (mmWave) communication is envisioned to provide orders of\\nmagnitude capacity improvement. However, it is challenging to realize a\\nsufficient link margin due to high path loss and blockages. To address this\\ndifficulty, in this paper, we explore the potential gain of ultra-densification\\nfor enhancing mmWave communications from a network-level perspective. By\\ndeploying the mmWave base stations (BSs) in an extremely dense and amorphous\\nfashion, the access distance is reduced and the choice of serving BSs is\\nenriched for each user, which are intuitively effective for mitigating the\\npropagation loss and blockages. Nevertheless, co-channel interference under\\nthis model will become a performance-limiting factor. To solve this problem, we\\npropose a large-scale channel state information (CSI) based interference\\ncoordination approach. Note that the large-scale CSI is highly\\nlocation-dependent, and can be obtained with a quite low cost. Thus, the\\nscalability of the proposed coordination framework can be guaranteed.\\nParticularly, using only the large-scale CSI of interference links, a\\ncoordinated frequency resource block allocation problem is formulated for\\nmaximizing the minimum achievable rate of the users, which is uncovered to be a\\nNP-hard integer programming problem. To circumvent this difficulty, a greedy\\nscheme with polynomial-time complexity is proposed by adopting the bisection\\nmethod and linear integer programming tools. Simulation results demonstrate\\nthat the proposed coordination scheme based on large-scale CSI only can still\\noffer substantial gains over the existing methods. Moreover, although the\\nproposed scheme is only guaranteed to converge to a local optimum, it performs\\nwell in terms of both user fairness and system efficiency.\\n'\n",
      " '  We study the problem of sampling from a distribution where the negative\\nlogarithm of the target density is $L$-smooth everywhere and $m$-strongly\\nconvex outside a ball of radius $R$, but potentially non-convex inside this\\nball. We study both overdamped and underdamped Langevin MCMC and prove upper\\nbounds on the time required to obtain a sample from a distribution that is\\nwithin $\\\\epsilon$ of the target distribution in $1$-Wasserstein distance. For\\nthe first-order method (overdamped Langevin MCMC), the time complexity is\\n$\\\\tilde{\\\\mathcal{O}}\\\\left(e^{cLR^2}\\\\frac{d}{\\\\epsilon^2}\\\\right)$, where $d$ is\\nthe dimension of the underlying space. For the second-order method (underdamped\\nLangevin MCMC), the time complexity is\\n$\\\\tilde{\\\\mathcal{O}}\\\\left(e^{cLR^2}\\\\frac{\\\\sqrt{d}}{\\\\epsilon}\\\\right)$ for some\\nexplicit positive constant $c$. Surprisingly, the convergence rate is only\\npolynomial in the dimension $d$ and the target accuracy $\\\\epsilon$. It is\\nhowever exponential in the problem parameter $LR^2$, which is a measure of\\nnon-logconcavity of the target distribution.\\n'\n",
      " '  The Sachdev-Ye-Kitaev (SYK) model has become increasingly of great interest\\nin studying exotic non-fermi liquid states without quasiparticle excitations,\\nholography duality to Einstein gravity, and quantum chaos. However, the\\nunnatural form of its Hamiltonian, including its strong randomness and fully\\nnonlocal fermion interaction, makes its experimental investigation an\\nintractable challenge. A promising solution to overcome this challenge is\\nquantum simulation, whose role will be more pronounced particularly in the\\nfuture when more qubits can be handled. We have enough control to demonstrate a\\nfirst step towards quantum simulation of this system. We observed the fermion\\nparing instability of the non-Fermi liquid state and the chaotic-nonchaotic\\ntransition at simulated temperatures, as was predicted by previous theory.\\nThese results demonstrate the feasibility of experimentally simulating the SYK\\nmodel. It opens a new experimental avenue towards investigating the key\\nfeatures of non-Fermi liquid states, as well as the quantum chaotic systems and\\nthe AdS/CFT duality, thanks to the rich physics of the SYK model.\\n'\n",
      " '  A standard belief on emerging collective behavior is that it emerges from\\nsimple individual rules. Most of the mathematical research on such collective\\nbehavior starts from imperative individual rules, like always go to the center.\\nBut how could an (optimal) individual rule emerge during a short period within\\nthe group lifetime, especially if communication is not available. We argue that\\nsuch rules can actually emerge in a group in a short span of time via\\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\\npunishments. We consider the gathering problem: several agents (social animals,\\nswarming robots...) must gather around a same position, which is not determined\\nin advance. They must do so without communication on their planned decision,\\njust by looking at the position of other agents. We present the first\\nexperimental evidence that a gathering behavior can be learned without\\ncommunication in a partially observable environment. The learned behavior has\\nthe same properties as a self-stabilizing distributed algorithm, as processes\\ncan gather from any initial state (and thus tolerate any transient failure).\\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\\\%\\nof agents without significant impact on the behavior.\\n'\n",
      " '  Smartwatches enable many novel applications and are fast gaining popularity.\\nHowever, the presence of a diverse set of on-board sensors provides an\\nadditional attack surface to malicious software and services on these devices.\\nIn this paper, we investigate the feasibility of key press inference attacks on\\nhandheld numeric touchpads by using smartwatch motion sensors as a\\nside-channel. We consider different typing scenarios, and propose multiple\\nattack approaches to exploit the characteristics of the observed wrist\\nmovements for inferring individual key presses. Experimental evaluation using\\ncommercial off-the-shelf smartwatches and smartphones show that key press\\ninference using smartwatch motion sensors is not only fairly accurate, but also\\ncomparable with similar attacks using smartphone motion sensors. Additionally,\\nhand movements captured by a combination of both smartwatch and smartphone\\nmotion sensors yields better inference accuracy than either device considered\\nindividually.\\n'\n",
      " '  We study the cosmological dynamics of D-BIonic and DBI scalar field, which is\\ncoupled to matter fluid. For the exponential potential and the exponential\\ncouplings, we find a new analytic scaling solution yielding the accelerated\\nexpansion of the Universe. Since it is shown to be an attractor for some range\\nof the coupling parameters, the density parameter of matter fluid can be the\\nobserved value, as in the coupled quintessence with a canonical scalar field.\\nContrary to the usual coupled quintessence, where the value of matter couple\\ngiving observed density parameter is too large to satisfy observational\\nconstraint from CMB, we show that the D-BIonic theory can give similar solution\\nwith much smaller value of matter coupling. As a result, together with the fact\\nthat the D-BIonic theory has a screening mechanism, the D-BIonic theory can\\nsolve the so-called coincidence problem as well as the dark energy problem.\\n'\n",
      " '  In 1932, Paul Erdos asked whether a random walk constructed from a binary\\nsequence can achieve the lowest possible deviation (lowest discrepancy), for\\nthe sequence itself and for all its subsequences formed by homogeneous\\narithmetic progressions. Although avoiding low discrepancy is impossible for\\ninfinite sequences, as recently proven by Terence Tao, attempts were made to\\nconstruct such sequences with finite lengths. We recognize that such\\nconstructed sequences (we call these \"Erdos sequences\") exhibit certain\\nhallmarks of randomness at the local level: they show roughly equal frequencies\\nof subsequences, and at the same time exclude the trivial periodic patterns.\\nFor the human DNA we examine the frequency of a set of Erdos motifs of\\nlength-10 using three nucleotides-to-binary mappings. The particular length-10\\nErdos sequence is derived by the length-11 Mathias sequence and is identical\\nwith the first 10 digits of the Thue-Morse sequence, underscoring the fact that\\nboth are deficient in periodicities. Our calculations indicate that: (1) the\\npurine (A and G)/pyridimine (C and T) based Erdos motifs are greatly\\nunderrepresented in the human genome, (2) the strong(G and C)/weak(A and T)\\nbased Erdos motifs are slightly overrepresented, (3) the densities of the two\\nare negatively correlated, (4) the Erdos motifs based on all three mappings\\nbeing combined are slightly underrepresented, and (5) the strong/weak based\\nErdos motifs are greatly overrepresented in the human messenger RNA sequences.\\n'\n",
      " \"  The appearance of rogue waves in deep sea is investigated using the modified\\nnonlinear Schrödinger (MNLS) equation in one spatial-dimension with random\\ninitial conditions that are assumed to be normally distributed, with a spectrum\\napproximating realistic conditions of a uni-directional sea state. It is shown\\nthat one can use the incomplete information contained in this spectrum as prior\\nand supplement this information with the MNLS dynamics to reliably estimate the\\nprobability distribution of the sea surface elevation far in the tail at later\\ntimes. Our results indicate that rogue waves occur when the system hits\\nunlikely pockets of wave configurations that trigger large disturbances of the\\nsurface height. The rogue wave precursors in these pockets are wave patterns of\\nregular height but with a very specific shape that is identified explicitly,\\nthereby allowing for early detection. The method proposed here combines Monte\\nCarlo sampling with tools from large deviations theory that reduce the\\ncalculation of the most likely rogue wave precursors to an optimization problem\\nthat can be solved efficiently. This approach is transferable to other problems\\nin which the system's governing equations contain random initial conditions\\nand/or parameters.\\n\"\n",
      " '  Given a centrally symmetric convex body $K \\\\subset \\\\mathbb{R}^d$ and a\\npositive number $\\\\lambda$, we consider, among all ellipsoids $E \\\\subset\\n\\\\mathbb{R}^d$ of volume $\\\\lambda$, those that best approximate $K$ with respect\\nto the symmetric difference metric, or equivalently that maximize the volume of\\n$E\\\\cap K$: these are the maximal intersection (MI) ellipsoids introduced by\\nArtstein-Avidan and Katzin. The question of uniqueness of MI ellipsoids (under\\nthe obviously necessary assumption that $\\\\lambda$ is between the volumes of the\\nJohn and the Loewner ellipsoids of $K$) is open in general. We provide a\\npositive answer to this question in dimension $d=2$. Therefore we obtain a\\ncontinuous $1$-parameter family of ellipses interpolating between the John and\\nthe Loewner ellipses of $K$. In order to prove uniqueness, we show that the\\narea $I_K(E)$ of the intersection $K \\\\cap E$ is a strictly quasiconcave\\nfunction of the ellipse $E$, with respect to the natural affine structure on\\nthe set of ellipses of area $\\\\lambda$. The proof relies on smoothening $K$,\\nputting it in general position, and obtaining uniform estimates for certain\\nderivatives of the function $I_K(.)$. Finally, we provide a characterization of\\nmaximal intersection positions, that is, the situation where the MI ellipse of\\n$K$ is the unit disk, under the assumption that the two boundaries are\\ntransverse.\\n'\n",
      " '  We offer an alternative and shorter proof to a result by Jan J.Ub{\\\\o}e about\\nmonotonicity properties of a one-dimensional function that appeared in the\\nMathematical Intelligencer in 2015. Our proof is based on reducing the problem\\nto symmetry properties of a two-dimensional surface.\\n'\n",
      " '  We investigate residue-type indices for germs of holomorphic foliations in\\nthe plane and characterize second type foliations - those not containing\\ntangent saddle-nodes in the reduction of singularities - by an expression\\ninvolving the Baum-Bott, variation and polar excess indices. These local\\nresults are applied in the study of logarithmic foliations on compact complex\\nsurfaces.\\n'\n",
      " '  We count the number of distinct (scattered) subwords occurring in the base-b\\nexpansion of the non-negative integers. More precisely, we consider the\\nsequence $(S_b(n))_{n\\\\ge 0}$ counting the number of positive entries on each\\nrow of a generalization of the Pascal triangle to binomial coefficients of\\nbase-$b$ expansions. By using a convenient tree structure, we provide\\nrecurrence relations for $(S_b(n))_{n\\\\ge 0}$ leading to the $b$-regularity of\\nthe latter sequence. Then we deduce the asymptotics of the summatory function\\nof the sequence $(S_b(n))_{n\\\\ge 0}$.\\n'\n",
      " '  A modern notion of integrability is that of multidimensional consistency\\n(MDC), which classically implies the coexistence of (commuting) dynamical flows\\nin several independent variables for one and the same dependent variable. This\\nproperty holds for both continuous dynamical systems as well as for discrete\\nones defined in discrete space-time. Possibly the simplest example in the\\ndiscrete case is that of a linear quadrilateral lattice equation, which can be\\nviewed as a linearised version of the well-known lattice potential Korteweg-de\\nVries (KdV) equation. In spite of the linearity, the MDC property is\\nnon-trivial in terms of the parameters of the system. The Lagrangian aspects of\\nsuch equations, and their nonlinear analogues, has led to the notion of\\nLagrangian multiform structures, where the Lagrangians are no longer scalar\\nfunctions (or volume forms) but genuine forms in a multidimensional space of\\nindependent variables. The variational principle involves variations not only\\nwith respect to the field variables, but also with respect to the geometry in\\nthe space of independent variables. In this paper we consider a quantum\\nanalogue of this new variational principle by means of quantum propagators (or\\nequivalently Feynman path integrals). In the case of quadratic Lagrangians\\nthese can be evaluated in terms of Gaussian integrals. We study also periodic\\nreductions of the lattice leading to discrete multi-time dynamical commuting\\nmappings, the simplest example of which is the discrete harmonic oscillator,\\nwhich surprisingly reveals a rich integrable structure behind it. On the basis\\nof this study we propose a new quantum variational principle in terms of\\nmultiform path integrals.\\n'\n",
      " '  An inner de Sitter region is glued smoothly and consistently with an outer\\nReissner-Nordström (RN) spacetime on a spherical thin-shell. Mass and\\ncharge of the outer RN spacetime are defined by the de Sitter and shell\\nparameters. Radius of the shell plays the role of a cut-off which by virtue of\\nregular de Sitter inside removes the singularity at $r=0.$ The topology of\\ninner de Sitter with the radius of the thin-shell becomes compact. For\\nstability the perturbed shell is shown to satisfy a modified polytropic\\nequation of state which has vanishing mass and pressure on the unperturbed\\nshell as dictated by the junction conditions.\\n'\n",
      " '  The Class 0 protostar, L483, has been observed in various molecular lines in\\nthe 1.2 mm band at a sub-arcsecond resolution with ALMA. An infalling-rotating\\nenvelope is traced by the CS line, while a very compact component with a broad\\nvelocity width is observed for the CS, SO, HNCO, NH$_2$CHO, and HCOOCH$_3$\\nlines. Although this source is regarded as the warm carbon-chain chemistry\\n(WCCC) candidate source at a 1000 au scale, complex organic molecules\\ncharacteristic of hot corinos such as NH$_2$CHO and HCOOCH$_3$ are detected in\\nthe vicinity of the protostar. Thus, both hot corino chemistry and WCCC are\\nseen in L483. Although such a mixed chemical character source has been\\nrecognized as an intermediate source in previous single-dish observations, we\\nhere report the first spatially-resolved detection. A kinematic structure of\\nthe infalling-rotating envelope is roughly explained by a simple ballistic\\nmodel with the protostellar mass of 0.1--0.2 $M_\\\\odot$ and the radius of the\\ncentrifugal barrier (a half of the centrifugal radius) of 30--200 au, assuming\\nthe inclination angle of 80\\\\degr\\\\ (0\\\\degr\\\\ for a face-on). The broad line\\nemission observed in the above molecules most likely comes from the disk\\ncomponent inside the centrifugal barrier. Thus, a drastic chemical change is\\nseen around the centrifugal barrier.\\n'\n",
      " '  In this note we observe that one can contact embed all contact 3-manifolds\\ninto a Stein fillable contact structure on the twisted $S^3$-bundle over $S^2$\\nand also into a unique overtwisted contact structure on $S^3\\\\times S^2$. These\\nresults are proven using \"spun embeddings\" and Lefschetz fibrations.\\n'\n",
      " '  We empirically verify that the market capitalisations of coins and tokens in\\nthe cryptocurrency universe follow power-law distributions with significantly\\ndifferent values, with the tail exponent falling between 0.5 and 0.7 for coins,\\nand between 1.0 and 1.3 for tokens. We provide a rationale for this, based on a\\nsimple proportional growth with birth & death model previously employed to\\ndescribe the size distribution of firms, cities, webpages, etc. We empirically\\nvalidate the model and its main predictions, in terms of proportional growth\\n(Gibrat\\'s law) of the coins and tokens. Estimating the main parameters of the\\nmodel, the theoretical predictions for the power-law exponents of coin and\\ntoken distributions are in remarkable agreement with the empirical estimations,\\ngiven the simplicity of the model. Our results clearly characterize coins as\\nbeing \"entrenched incumbents\" and tokens as an \"explosive immature ecosystem\",\\nlargely due to massive and exuberant Initial Coin Offering activity in the\\ntoken space. The theory predicts that the exponent for tokens should converge\\nto 1 in the future, reflecting a more reasonable rate of new entrants\\nassociated with genuine technological innovations.\\n'\n",
      " '  The spectral radius of the adjacency matrix can impact both algorithmic\\nefficiency as well as the stability of solutions to an underlying dynamical\\nprocess. Although much research has considered the distribution of the spectral\\nradius for undirected random graph models, as symmetric adjacency matrices are\\namenable to spectral analysis, very little work has focused on directed graphs.\\nConsequently, we provide novel concentration results for the spectral radius of\\nthe directed Chung-Lu random graph model. We emphasize that our concentration\\nresults are applicable both asymptotically and to networks of finite size.\\nSubsequently, we extend our concentration results to a generalization of the\\ndirected Chung-Lu model that allows for community structure.\\n'\n",
      " '  Thin films of cerium dioxide (CeO2) were deposited by atomic layer deposition\\n(ALD) at 250 °C on both Si and TiN substrates. The ALD growth produces\\nCeO2 films with polycrystalline cubic phase on both substrates. However, the\\nfilms show a preferential orientation along <200> crystallographic direction\\nfor CeO2/Si or <111> for CeO2/TiN, as revealed by X-ray diffraction.\\nAdditionally, CeO2 films differ in interface roughness depending on the\\nsubstrate. Furthermore, the relative concentration of Ce3+ is 22.0% in CeO2/Si\\nand around 18% in CeO2/TiN, as obtained by X-ray photoelectron spectroscopy\\n(XPS). Such values indicate a ~10% off-stoichiometry and are indicative of the\\npresence of oxygen vacancies in the films. Nonetheless, CeO2 bandgap energy and\\nrefractive index at 550 nm are 3.54+/-0.63 eV and 2.3 for CeO2/Si, and\\n3.63+/-0.18 eV and 2.4 for CeO2/TiN, respectively. Our results extend the\\nknowledge on the structural and chemical properties of ALD-deposited CeO2\\neither on Si or TiN substrates, underlying films differences and similarities,\\nthus contributing to boost the use of CeO2 through ALD deposition as foreseen\\nin a wide number of applications.\\n'\n",
      " '  A method has been developed for the analysis of images of sentinel lymph\\nnodes generated by a spectral scanning device. The aim is to classify the\\nnodes, excised during surgery for breast cancer, as normal or metastatic. The\\ndata from one node constitute spectra at 86 wavelengths for each pixel of a\\n20*20 grid. For the analysis, the spectra are reduced to scores on two factors,\\none derived externally from a linear discriminant analysis using spectra taken\\nmanually from known normal and metastatic tissue, and one derived from the node\\nunder investigation to capture variability orthogonal to the external factor.\\nThen a three-group mixture model (normal, metastatic, non-nodal background)\\nusing multivariate t distributions is fitted to the scores, with external data\\nbeing used to specify informative prior distributions for the parameters of the\\nthree distributions. A Markov random field prior imposes smoothness on the\\nimage generated by the model. Finally, the node is classified as metastatic if\\nany one pixel in this smoothed image is classified as metastatic. The model\\nparameters were tuned on a training set of nodes, and then the tuned model was\\ntested on a separate validation set of nodes, achieving satisfactory\\nsensitivity and specificity. The aim in developing the analysis was to allow\\nflexibility in the way each node is modelled whilst still using external\\ninformation. The Bayesian framework employed is ideal for this.\\n'\n",
      " '  We present a report of the MEG II experiment, the upgrade of MEG, whose goal\\nis to search for the forbidden decay \\\\megc\\\\ with increased precision. After\\nhaving briefly reviewed the motivation for such a search and the current limit\\ndue to MEG, we present the conceptual design of the detector detailing for each\\nsubdetector the motivations and the extent of the upgrade and the expected\\nresolution improvements. Novel subdetectors and calibration hardware are\\nintroduced. We conclude with the expected sensitivity of the MEGII experiment.\\n'\n",
      " '  The Generative Adversarial Networks (GANs) have demonstrated impressive\\nperformance for data synthesis, and are now used in a wide range of computer\\nvision tasks. In spite of this success, they gained a reputation for being\\ndifficult to train, what results in a time-consuming and human-involved\\ndevelopment process to use them.\\nWe consider an alternative training process, named SGAN, in which several\\nadversarial \"local\" pairs of networks are trained independently so that a\\n\"global\" supervising pair of networks can be trained against them. The goal is\\nto train the global pair with the corresponding ensemble opponent for improved\\nperformances in terms of mode coverage. This approach aims at increasing the\\nchances that learning will not stop for the global pair, preventing both to be\\ntrapped in an unsatisfactory local minimum, or to face oscillations often\\nobserved in practice. To guarantee the latter, the global pair never affects\\nthe local ones.\\nThe rules of SGAN training are thus as follows: the global generator and\\ndiscriminator are trained using the local discriminators and generators,\\nrespectively, whereas the local networks are trained with their fixed local\\nopponent.\\nExperimental results on both toy and real-world problems demonstrate that\\nthis approach outperforms standard training in terms of better mitigating mode\\ncollapse, stability while converging and that it surprisingly, increases the\\nconvergence speed as well.\\n'\n",
      " \"  It is widely believed that the backpropagation algorithm is essential for\\nlearning good feature detectors in early layers of artificial neural networks,\\nso that these detectors are useful for the task performed by the higher layers\\nof that neural network. At the same time, the traditional form of\\nbackpropagation is biologically implausible. In the present paper we propose an\\nunusual learning rule, which has a degree of biological plausibility, and which\\nis motivated by Hebb's idea that change of the synapse strength should be local\\n- i.e. should depend only on the activities of the pre and post synaptic\\nneurons. We design a learning algorithm that utilizes global inhibition in the\\nhidden layer, and is capable of learning early feature detectors in a\\ncompletely unsupervised way. These learned lower layer feature detectors can be\\nused to train higher layer weights in a usual supervised way so that the\\nperformance of the full network is comparable to the performance of standard\\nfeedforward networks trained end-to-end with a backpropagation algorithm.\\n\"\n",
      " '  We define an admissibility condition for abstractions expressed using angelic\\nsemantics and show that these conditions allow us to accelerate planning while\\npreserving the ability to find the optimal motion plan. We then derive\\nadmissible abstractions for two motion planning domains with continuous state.\\nWe extract upper and lower bounds on the cost of concrete motion plans using\\nlocal metric and topological properties of the problem domain. These bounds\\nguide the search for a plan while maintaining performance guarantees. We show\\nthat abstraction can dramatically reduce the complexity of search relative to a\\ndirect motion planner. Using our abstractions, we find near-optimal motion\\nplans in planning problems involving $10^{13}$ states without using a separate\\ntask planner.\\n'\n",
      " \"  Internet of Things (IoT) applications typically collect and analyse personal\\ndata that can be used to derive sensitive information about individuals.\\nHowever, thus far, privacy concerns have not been explicitly considered in\\nsoftware engineering processes when designing IoT applications. In this paper,\\nwe explore how a Privacy-by-Design (PbD) framework, formulated as a set of\\nguidelines, can help software engineers to design privacy-aware IoT\\napplications. We studied the utility of our proposed PbD framework by studying\\nhow software engineers use it to design IoT applications. We also explore the\\nchallenges in using set of guidelines to influence the IoT applications design\\nprocess. This paper also highlights the benefits of providing a framework that\\nhelps software engineers explicitly consider privacy for IoT applications and\\nalso surfaced a number of challenges associated with our approach. Our studies\\nshow that PbD framework significantly increase both novice and expert software\\nengineers' ability to design privacy aware IoT applications.\\n\"\n",
      " '  We evaluate two methods of signalling abrupt direction changes of a robotic\\nplatform using a Mixed Reality avatar. The \"Body\" method uses gaze, gesture and\\ntorso direction to point to upcoming waypoints. The \"Path\" method visualises\\nthe change in direction using an angled path on the ground. We compare these\\ntwo methods using a controlled user study and show that each method has its\\nstrengths depending on the situation. Overall the \"Path\" method was slightly\\nmore accurate in communicating the direction change of the robot but\\nparticipants overall preferred the \"Body\" method.\\n'\n",
      " '  The magnetic field response of the Mott-insulating honeycomb iridate\\nNa$_{2}$IrO$_{3}$ is investigated using torque magnetometry measurements in\\nmagnetic fields up to 60 tesla. A peak-dip structure is observed in the torque\\nresponse at magnetic fields corresponding to an energy scale close to the\\nzigzag ordering ($\\\\approx 15~K$) temperature. Using exact diagonalization\\ncalculations, we show that such a distinctive signature in the torque response\\nconstrains the effective spin models for these classes of Kitaev materials to\\nones with dominant ferromagnetic Kitaev interactions, while alternative models\\nwith dominant antiferromagnetic Kitaev interactions are excluded. We further\\nshow that at high magnetic fields, long range spin correlation functions decay\\nrapidly, signaling a transition to a long-sought-after field-induced quantum\\nspin liquid beyond the peak-dip structure. Kitaev systems are thus revealed to\\nbe excellent candidates for field-induced quantum spin liquids, similar physics\\nhaving been suggested in another Kitaev material $\\\\alpha-$RuCl$_{3}$.\\n'\n",
      " '  The spin polarization of electrons from multiphoton ionization of Xe by 395\\nnm circularly polarized laser pulses at $6\\\\cdot10^{13}$ W/cm$^2$ has been\\nmeasured. At this photon energy of 3.14 eV the above threshold ionization peaks\\nconnected to Xe$^+$ ions in the ground state ($J=3/2$, ionization potential\\n$I_p=12.1$ eV) and the first exicted state ($J=1/2$, $I_p=13.4$ eV) are clearly\\nseparated in the electron energy distribution. These two combs of ATI peaks\\nshow opposite spin polarizations. The magnitude of the spin polarization is a\\nfactor of two higher for the $J=1/2$ than for the $J=3/2$ final ionic state. In\\nturn the data show that the ionization probability is strongly dependent on the\\nsign of the magnetic quantum number.\\n'\n",
      " '  It has been demonstrated that deep neural networks are prone to noisy\\nexamples particular adversarial samples during inference process. The gap\\nbetween robust deep learning systems in real world applications and vulnerable\\nneural networks is still large. Current adversarial training strategies improve\\nthe robustness against adversarial samples. However, these methods lead to\\naccuracy reduction when the input examples are clean thus hinders the\\npracticability. In this paper, we investigate an approach that protects the\\nneural network classification from the adversarial samples and improves its\\naccuracy when the input examples are clean. We demonstrate the versatility and\\neffectiveness of our proposed approach on a variety of different networks and\\ndatasets.\\n'\n",
      " '  In this paper, a simple method is proposed to extend the photon energy range\\nof a soft x-ray self-seeding free-electron laser (FEL). A normal monochromator\\nis first applied to purify the FEL spectrum and provide a coherent seeding\\nsignal. This coherent signal then interacts with the electron beam in the\\nfollowing reverse tapered undulator section to generate strong coherent\\nmicrobunchings while maintain the good quality of the electron beam. After\\nthat, the pre-bunched electron beam is sent into the third undulator section\\nwhich resonates at a target high harmonic of the seed to amplify the coherent\\nradiation at shorter wavelength. Three dimensional simulations have been\\nperformed and the results demonstrate that the photon energy gap between 1.5\\nkeV and 4.5 keV of the self-seeding scheme can be fully covered and 100\\nGW-level peak power can be achieved by using the proposed technique.\\n'\n",
      " \"  Nowadays, computation is playing an increasingly more important role in the\\nfuture generation of computer and communication networks, as exemplified by the\\nrecent progress in software defined networking (SDN) for wired networks as well\\nas cloud radio access networks (C-RAN) and mobile cloud computing (MCC) for\\nwireless networks. This paper proposes a unified concept, i.e., computation\\ndiversity, to describe the impact and diverse forms of the computation\\nresources on both wired and wireless communications. By linking the computation\\nresources to the communication networks based on quality of service (QoS)\\nrequirements, we can show how computation resources influence the networks.\\nMoreover, by analyzing the different functionalities of computation resources\\nin SDN, C-RAN, and MCC, we can show diverse and flexible form that the\\ncomputation resources present in different networks. The study of computation\\ndiversity can provide guidance to the future networks design, i.e., how to\\nallocate the resources jointly between computation (e.g., CPU capacity) and\\ncommunication (e.g., bandwidth), and thereby saving system energy and increase\\nusers' experiences.\\n\"\n",
      " '  A central issue in the theory of extreme values focuses on suitable\\nconditions such that the well-known results for the limiting distributions of\\nthe maximum of i.i.d. sequences can be applied to stationary ones. In this\\ncontext, the extremal index appears as a key parameter to capture the effect of\\ntemporal dependence on the limiting distribution of the maxima. The\\nmultivariate extremal index corresponds to a generalization of this concept to\\na multivariate context and affects the tail dependence structure within the\\nmarginal sequences and between them. As it is a function, the inference becomes\\nmore difficult, and it is therefore important to obtain characterizations,\\nnamely bounds based on the marginal dependence that are easier to estimate. In\\nthis work we present two decompositions that emphasize different types of\\ninformation contained in the multivariate extremal index, an upper limit better\\nthan those found in the literature and we analyze its role in dependence on the\\nlimiting model of the componentwise maxima of a stationary sequence. We will\\nillustrate the results with examples of recognized interest in applications.\\n'\n",
      " '  We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for\\nsolving the Gross-Pitaevskii (GP) equation for a Bose-Einstein condensate in\\none, two, and three spatial dimensions, optimized for use with GNU and Intel\\ncompilers. We use the split-step Crank-Nicolson algorithm for imaginary- and\\nreal-time propagation, which enables efficient calculation of stationary and\\nnon-stationary solutions, respectively. The present OpenMP programs are\\ndesigned for computers with multi-core processors and optimized for compiling\\nwith both commercially-licensed Intel Fortran and popular free open-source GNU\\nFortran compiler. The programs are easy to use and are elaborated with helpful\\ncomments for the users. All input parameters are listed at the beginning of\\neach program. Different output files provide physical quantities such as\\nenergy, chemical potential, root-mean-square sizes, densities, etc. We also\\npresent speedup test results for new versions of the programs.\\n'\n",
      " '  We provide precise formulations and proofs of two theorems from Darboux\\'s\\nlectures on orthogonal systems. These results provide local existence and\\nuniqueness of solutions to certain types of first order PDE systems where each\\nequation contains a single derivative for which it is solved: \\\\[\\\\frac{\\\\partial\\nu_i}{\\\\partial x_j}(x)=f_{ij}(x,u(x)).\\\\] The data prescribe values for the\\nunknowns $u_i$ along certain hyperplanes through a given point $\\\\bar x$.\\nThe first theorem applies to determined systems (the number of equations\\nequals the number unknowns), and a unique, local solution is obtained via\\nPicard iteration. While Darboux\\'s statement of the theorem leaves unspecified\\n\"certaines conditions de continuité,\" it is clear from his proof that he\\nassumes Lipschitz continuity of the maps $f_{ij}$. On the other hand, he did\\nnot address the regularity of the data. We provide a precise formulation and\\nproof of his first theorem.\\nThe second theorem is more involved and applies to overdetermined systems of\\nthe same general form. Under the appropriate integrability conditions, Darboux\\nused his first theorem to treat the cases with two and three independent\\nvariables. We provide a proof for any number of independent variables.\\nWhile the systems are rather special, they do appear in applications; e.g.,\\nthe second theorem contains the classical Frobenius theorem on overdetermined\\nsystems as a special case. The key aspect of the proofs is that they apply to\\nnon-analytic situations. In an analytic setup the results are covered by the\\ngeneral Cartan-Kähler theorem.\\n'\n",
      " '  In this paper, we present a method for identifying infeasible, unbounded, and\\npathological conic programs based on Douglas-Rachford splitting, or\\nequivalently ADMM. When an optimization program is infeasible, unbounded, or\\npathological, the iterates of Douglas-Rachford splitting diverge. Somewhat\\nsurprisingly, such divergent iterates still provide useful information, which\\nour method uses for identification. In addition, for strongly infeasible\\nproblems the method produces a separating hyperplane and informs the user on\\nhow to minimally modify the given problem to achieve strong feasibility. As a\\nfirst-order method, the proposed algorithm relies on simple subroutines, and\\ntherefore is simple to implement and has low per-iteration cost.\\n'\n",
      " '  This paper studies identification, estimation, and inference of quantile\\ntreatment effects in the fuzzy regression kink design with a binary treatment\\nvariable. We first show the identification of conditional quantile treatment\\neffects given the event of local compliance. We then propose a bootstrap method\\nof uniform inference for the local quantile process. This bootstrap method is\\nfast and is robust against common optimal choices of bandwidth parameters. We\\nprovide practical guidelines as well as a formal theory. Simulation studies\\nshow accurate coverage probabilities for tests of uniform treatment\\nsignificance and treatment heterogeneity.\\n'\n",
      " '  Generalized linear models (GLMs) arise in high-dimensional machine learning,\\nstatistics, communications and signal processing. In this paper we analyze GLMs\\nwhen the data matrix is random, as relevant in problems such as compressed\\nsensing, error-correcting codes or benchmark models in neural networks. We\\nevaluate the mutual information (or \"free entropy\") from which we deduce the\\nBayes-optimal estimation and generalization errors. Our analysis applies to the\\nhigh-dimensional limit where both the number of samples and the dimension are\\nlarge and their ratio is fixed. Non-rigorous predictions for the optimal errors\\nexisted for special cases of GLMs, e.g. for the perceptron, in the field of\\nstatistical physics based on the so-called replica method. Our present paper\\nrigorously establishes those decades old conjectures and brings forward their\\nalgorithmic interpretation in terms of performance of the generalized\\napproximate message-passing algorithm. Furthermore, we tightly characterize,\\nfor many learning problems, regions of parameters for which this algorithm\\nachieves the optimal performance, and locate the associated sharp phase\\ntransitions separating learnable and non-learnable regions. We believe that\\nthis random version of GLMs can serve as a challenging benchmark for\\nmulti-purpose algorithms. This paper is divided in two parts that can be read\\nindependently: The first part (main part) presents the model and main results,\\ndiscusses some applications and sketches the main ideas of the proof. The\\nsecond part (supplementary informations) is much more detailed and provides\\nmore examples as well as all the proofs.\\n'\n",
      " \"  Recommendation is the task of improving customer experience through\\npersonalized recommendation based on users' past feedback. In this paper, we\\ninvestigate the most common scenario: the user-item (U-I) matrix of implicit\\nfeedback. Even though many recommendation approaches are designed based on\\nimplicit feedback, they attempt to project the U-I matrix into a low-rank\\nlatent space, which is a strict restriction that rarely holds in practice. In\\naddition, although misclassification costs from imbalanced classes are\\nsignificantly different, few methods take the cost of classification error into\\naccount. To address aforementioned issues, we propose a robust framework by\\ndecomposing the U-I matrix into two components: (1) a low-rank matrix that\\ncaptures the common preference, and (2) a sparse matrix that detects the\\nuser-specific preference of individuals. A cost-sensitive learning model is\\nembedded into the framework. Specifically, this model exploits different costs\\nin the loss function for the observed and unobserved instances. We show that\\nthe resulting non-smooth convex objective can be optimized efficiently by an\\naccelerated projected gradient method with closed-form solutions. Morever, the\\nproposed algorithm can be scaled up to large-sized datasets after a relaxation.\\nThe theoretical result shows that even with a small fraction of 1's in the U-I\\nmatrix $M\\\\in\\\\mathbb{R}^{n\\\\times m}$, the cost-sensitive error of the proposed\\nmodel is upper bounded by $O(\\\\frac{\\\\alpha}{\\\\sqrt{mn}})$, where $\\\\alpha$ is a\\nbias over imbalanced classes. Finally, empirical experiments are extensively\\ncarried out to evaluate the effectiveness of our proposed algorithm.\\nEncouraging experimental results show that our algorithm outperforms several\\nstate-of-the-art algorithms on benchmark recommendation datasets.\\n\"\n",
      " \"  When modeling network data using a latent position model, it is typical to\\nassume that all nodes' latent positions are independently and identically\\ndistributed. However, this assumption implies the average node degree grows\\nlinearly with the number of nodes, which is inappropriate when the graph is\\nthought to be sparse. We propose an alternative assumption--- that the latent\\npositions are generated according to a Poisson point process--- and show that\\nit is compatible with various levels of sparsity. Unlike other sparse latent\\nposition models, our approach also defines a projective family of probability\\ndistributions, ensuring statistical inference and prediction are well-defined\\nfor networks of different sizes. We establish conditions for consistently\\ninferring the latent positions in a latent position network model, and compare\\nour results to those of existing frameworks for modeling sparse graphs.\\n\"\n",
      " '  This work is about recognizing human activities occurring in videos at\\ndistinct semantic levels, including individual actions, interactions, and group\\nactivities. The recognition is realized using a two-level hierarchy of Long\\nShort-Term Memory (LSTM) networks, forming a feed-forward deep architecture,\\nwhich can be trained end-to-end. In comparison with existing architectures of\\nLSTMs, we make two key contributions giving the name to our approach as\\nConfidence-Energy Recurrent Network -- CERN. First, instead of using the common\\nsoftmax layer for prediction, we specify a novel energy layer (EL) for\\nestimating the energy of our predictions. Second, rather than finding the\\ncommon minimum-energy class assignment, which may be numerically unstable under\\nuncertainty, we specify that the EL additionally computes the p-values of the\\nsolutions, and in this way estimates the most confident energy minimum. The\\nevaluation on the Collective Activity and Volleyball datasets demonstrates: (i)\\nadvantages of our two contributions relative to the common softmax and\\nenergy-minimization formulations and (ii) a superior performance relative to\\nthe state-of-the-art approaches.\\n'\n",
      " '  A diverse white matter network and finely tuned neuronal membrane properties\\nallow the brain to transition seamlessly between cognitive states. However, it\\nremains unclear how static structural connections guide the temporal\\nprogression of large-scale brain activity patterns in different cogni- tive\\nstates. Here, we deploy an unsupervised machine learning algorithm to define\\nbrain states as time point level activity patterns from functional magnetic\\nresonance imaging data acquired dur- ing passive visual fixation (rest) and an\\nn-back working memory task. We find that brain states are composed of\\ninterdigitated functional networks and exhibit context-dependent dynamics.\\nUsing diffusion-weighted imaging acquired from the same subjects, we show that\\nstructural connectivity constrains the temporal progression of brain states. We\\nalso combine tools from network control theory with geometrically conservative\\nnull models to demonstrate that brains are wired to sup- port states of high\\nactivity in default mode areas, while requiring relatively low energy. Finally,\\nwe show that brain state dynamics change throughout development and explain\\nworking mem- ory performance. Overall, these results elucidate the structural\\nunderpinnings of cognitively and developmentally relevant spatiotemporal brain\\ndynamics.\\n'\n",
      " '  The polyhedron projection for 360-degree video is becoming more and more\\npopular since it can lead to much less geometry distortion compared with the\\nequirectangular projection. However, in the polyhedron projection, we can\\nobserve very obvious texture discontinuity in the area near the face boundary.\\nSuch a texture discontinuity may lead to serious quality degradation when\\nmotion compensation crosses the discontinuous face boundary. To solve this\\nproblem, in this paper, we first propose to fill the corresponding neighboring\\nfaces in the suitable positions as the extension of the current face to keep\\napproximated texture continuity. Then a co-projection-plane based 3-D padding\\nmethod is proposed to project the reference pixels in the neighboring face to\\nthe current face to guarantee exact texture continuity. Under the proposed\\nscheme, the reference pixel is always projected to the same plane with the\\ncurrent pixel when performing motion compensation so that the texture\\ndiscontinuity problem can be solved. The proposed scheme is implemented in the\\nreference software of High Efficiency Video Coding. Compared with the existing\\nmethod, the proposed algorithm can significantly improve the rate-distortion\\nperformance. The experimental results obviously demonstrate that the texture\\ndiscontinuity in the face boundary can be well handled by the proposed\\nalgorithm.\\n'\n",
      " '  Interbank lending and borrowing occur when financial institutions seek to\\nsettle and refinance their mutual positions over time and circumstances. This\\ninteractive process involves money creation at the aggregate level.\\nCoordination mismatch on interbank credit may trigger systemic crises. This\\nhappened when, since summer 2007, interbank credit coordination did not longer\\nwork smoothly across financial institutions, eventually requiring exceptional\\nmonetary policies by central banks, and guarantee and bailout interventions by\\ngovernments. Our article develops an interacting heterogeneous agents-based\\nmodel of interbank credit coordination under minimal institutions. First, we\\nexplore the link between interbank credit coordination and the money generation\\nprocess. Contrary to received understanding, interbank credit has the capacity\\nto make the monetary system unbound. Second, we develop simulation analysis on\\nimperfect interbank credit coordination, studying impact of interbank dynamics\\non financial stability and resilience at individual and aggregate levels.\\nSystemically destabilizing forces prove to be related to the working of the\\nbanking system over time, especially interbank coordination conditions and\\ncircumstances.\\n'\n",
      " '  A $k$-ranking of a directed graph $G$ is a labeling of the vertex set of $G$\\nwith $k$ positive integers such that every directed path connecting two\\nvertices with the same label includes a vertex with a larger label in between.\\nThe rank number of $G$ is defined to be the smallest $k$ such that $G$ has a\\n$k$-ranking. We find the largest possible directed graph that can be obtained\\nfrom a directed path or a directed cycle by attaching new edges to the vertices\\nsuch that the new graphs have the same rank number as the original graphs. The\\nadjacency matrix of the resulting graph is embedded in the Sierpiński\\ntriangle.\\nWe present a connection between the number of edges that can be added to\\npaths and the Stirling numbers of the second kind. These results are\\ngeneralized to create directed graphs which are unions of directed paths and\\ndirected cycles that maintain the rank number of a base graph of a directed\\npath or a directed cycle.\\n'\n",
      " '  Chondrules in primitive meteorites likely formed by recrystallisation of dust\\naggregates that were flash-heated to nearly complete melting. Chondrules may\\nrepresent the building blocks of rocky planetesimals and protoplanets in the\\ninner regions of protoplanetary discs, but the source of ubiquitous thermal\\nprocessing of their dust aggregate precursors remains elusive. Here we\\ndemonstrate that escape of positrons released in the decay of the short-lived\\nradionuclide $^{26}$Al leads to a large-scale charging of dense pebble\\nstructures, resulting in neutralisation by lightning discharge and\\nflash-heating of dust and pebbles. This charging mechanism is similar to a\\nnuclear battery where a radioactive source charges a capacitor. We show that\\nthe nuclear battery effect operates in circumplanetesimal pebble discs. The\\nextremely high pebble densities in such discs are consistent with conditions\\nduring chondrule heating inferred from the high abundance of sodium within\\nchondrules. The sedimented mid-plane layer of the protoplanetary disc may also\\nbe prone to charging by the emission of positrons, if the mass density of small\\ndust there is at least an order of magnitude above the gas density. Our results\\nimply that the decay energy of $^{26}$Al can be harvested to drive intense\\nlightning activity in protoplanetary discs. The total energy stored in positron\\nemission is comparable to the energy needed to melt all solids in the\\nprotoplanetary disc. The efficiency of transferring the positron energy to the\\nelectric field nevertheless depends on the relatively unknown distribution and\\nscale-dependence of pebble density gradients in circumplanetesimal pebble discs\\nand in the protoplanetary disc mid-plane layer.\\n'\n",
      " '  Despite years of research, understanding of the space radiation environment\\nand the risk it poses to long-duration astronauts remains limited. There is a\\ndisparity between research results and observed empirical effects seen in human\\nastronaut crews, likely due to the numerous factors that limit terrestrial\\nsimulation of the complex space environment and extrapolation of human clinical\\nconsequences from varied animal models. Given the intended future of human\\nspaceflight, with efforts now to rapidly expand capabilities for human missions\\nto the moon and Mars, there is a pressing need to improve upon the\\nunderstanding of the space radiation risk, predict likely clinical outcomes of\\ninterplanetary radiation exposure, and develop appropriate and effective\\nmitigation strategies for future missions. To achieve this goal, the space\\nradiation and aerospace community must recognize the historical limitations of\\nradiation research and how such limitations could be addressed in future\\nresearch endeavors. We have sought to highlight the numerous factors that limit\\nunderstanding of the risk of space radiation for human crews and to identify\\nways in which these limitations could be addressed for improved understanding\\nand appropriate risk posture regarding future human spaceflight.\\n'\n",
      " '  We describe the Customer LifeTime Value (CLTV) prediction system deployed at\\nASOS.com, a global online fashion retailer. CLTV prediction is an important\\nproblem in e-commerce where an accurate estimate of future value allows\\nretailers to effectively allocate marketing spend, identify and nurture high\\nvalue customers and mitigate exposure to losses. The system at ASOS provides\\ndaily estimates of the future value of every customer and is one of the\\ncornerstones of the personalised shopping experience. The state of the art in\\nthis domain uses large numbers of handcrafted features and ensemble regressors\\nto forecast value, predict churn and evaluate customer loyalty. Recently,\\ndomains including language, vision and speech have shown dramatic advances by\\nreplacing handcrafted features with features that are learned automatically\\nfrom data. We detail the system deployed at ASOS and show that learning feature\\nrepresentations is a promising extension to the state of the art in CLTV\\nmodelling. We propose a novel way to generate embeddings of customers, which\\naddresses the issue of the ever changing product catalogue and obtain a\\nsignificant improvement over an exhaustive set of handcrafted features.\\n'\n",
      " '  In this paper, we propose a solution of fractional logistic equation by using\\nproperties of Mittag-Leffler function.\\n'\n",
      " \"  Let $(M,g)$ be a compact, 2-dimensional Riemannian manifold with nonpositive\\nsectional curvature. Let $\\\\Delta_g$ be the Laplace-Beltrami operator\\ncorresponding to the metric $g$ on $M$, and let $e_\\\\lambda$ be $L^2$-normalized\\neigenfunctions of $\\\\Delta_g$ with eigenvalue $\\\\lambda$, i.e. \\\\[ -\\\\Delta_g\\ne_\\\\lambda = \\\\lambda^2 e_\\\\lambda. \\\\] We prove \\\\[ \\\\left| \\\\int_{\\\\mathbb R} b(t)\\ne_\\\\lambda (\\\\gamma(t)) \\\\, dt \\\\right| = o(1) \\\\quad \\\\text{ as } \\\\lambda \\\\to \\\\infty\\n\\\\] where $b$ is a smooth, compactly supported function on $\\\\mathbb R$ and\\n$\\\\gamma$ is a curve parametrized by arc-length whose geodesic curvature\\n$\\\\kappa(\\\\gamma(t))$ avoids two critical curvatures $\\\\mathbf\\nk(\\\\gamma'^\\\\perp(t))$ and $\\\\mathbf k(-\\\\gamma'^{\\\\perp}(t))$ for each $t \\\\in\\n\\\\operatorname{supp} b$. $\\\\mathbf k(v)$ denotes the curvature of a circle with\\ncenter taken to infinity along the geodesic ray in direction $-v$.\\n\"\n",
      " '  We study the problem of identifying a probability distribution for some given\\nrandomly sampled data in the limit, in the context of algorithmic learning\\ntheory as proposed recently by Vinanyi and Chater. We show that there exists a\\ncomputable partial learner for the computable probability measures, while by\\nBienvenu, Monin and Shen it is known that there is no computable learner for\\nthe computable probability measures. Our main result is the characterization of\\nthe oracles that compute explanatory learners for the computable (continuous)\\nprobability measures as the high oracles. This provides an analogue of a\\nwell-known result of Adleman and Blum in the context of learning computable\\nprobability distributions. We also discuss related learning notions such as\\nbehaviorally correct learning and orther variations of explanatory learning, in\\nthe context of learning probability distributions from data.\\n'\n",
      " '  In this paper we consider the $15$-dimensional homogeneous variety of Picard\\nnumber one ${\\\\rm F}_4(4)$, and provide a characterization of it in terms of its\\nvarieties of minimal rational tangents.\\n'\n",
      " '  This paper presents a new result on strong-consistency, in the trace norm, of\\na diagonal componentwise parameter estimator of the autocorrelation operator of\\nan autoregressive process of order one (ARH(1) process), allowing\\nstrong-consistency of the associated plug-in predictor. These results are\\nderived, when the eigenvectors of the autocovariance operator are unknown, and\\nthe autocorrelation operator does not admit a diagonal spectral representation\\nwith respect to the eigenvectors of the autocovariance operator.\\n'\n",
      " '  From what is known today about the elementary particles of matter, and the\\nforces that control their behavior, it may be observed that still a host of\\nobstacles must be overcome that are standing in the way of further progress of\\nour understanding. Most researchers conclude that drastically new concepts must\\nbe investigated, new starting points are needed, older structures and theories,\\nin spite of their successes, will have to be overthrown, and new,\\nsuperintelligent questions will have to be asked and investigated. In short,\\nthey say that we shall need new physics. Here, we argue in a different manner.\\nToday, no prototype, or toy model, of any so-called Theory of Everything\\nexists, because the demands required of such a theory appear to be conflicting.\\nThe demands that we propose include locality, special and general relativity,\\ntogether with a fundamental finiteness not only of the forces and amplitudes,\\nbut also of the set of Nature\\'s dynamical variables. We claim that the two\\nremaining ingredients that we have today, Quantum Field Theory and General\\nRelativity, indeed are coming a long way towards satisfying such elementary\\nrequirements. Putting everything together in a Grand Synthesis is like solving\\na gigantic puzzle. We argue that we need the correct analytical tools to solve\\nthis puzzle. Finally, it seems to be obvious that this solution will give room\\nneither for \"Divine Intervention\", nor for \"Free Will\", an observation that,\\nall by itself, can be used as a clue. We claim that this reflects on our\\nunderstanding of the deeper logic underlying quantum mechanics.\\n'\n",
      " '  Short term unpredictability is discovered numerically for high Reynolds\\nnumber fluid flows under periodic boundary conditions. Furthermore, the\\nabundance of the short term unpredictability is also discovered. These\\ndiscoveries support our theory that fully developed turbulence is constantly\\ndriven by such short term unpredictability.\\n'\n",
      " '  We present a new Bayesian algorithm making use of Markov Chain Monte Carlo\\nsampling that allows us to simultaneously estimate the unknown continuum level\\nof each quasar in an ensemble of high-resolution spectra, as well as their\\ncommon probability distribution function (PDF) for the transmitted Ly$\\\\alpha$\\nforest flux. This fully automated PDF regulated continuum fitting method models\\nthe unknown quasar continuum with a linear Principal Component Analysis (PCA)\\nbasis, with the PCA coefficients treated as nuisance parameters. The method\\nallows one to estimate parameters governing the thermal state of the\\nintergalactic medium (IGM), such as the slope of the temperature-density\\nrelation $\\\\gamma-1$, while marginalizing out continuum uncertainties in a fully\\nBayesian way. Using realistic mock quasar spectra created from a simplified\\nsemi-numerical model of the IGM, we show that this method recovers the\\nunderlying quasar continua to a precision of $\\\\simeq7\\\\%$ and $\\\\simeq10\\\\%$ at\\n$z=3$ and $z=5$, respectively. Given the number of principal component spectra,\\nthis is comparable to the underlying accuracy of the PCA model itself. Most\\nimportantly, we show that we can achieve a nearly unbiased estimate of the\\nslope $\\\\gamma-1$ of the IGM temperature-density relation with a precision of\\n$\\\\pm8.6\\\\%$ at $z=3$, $\\\\pm6.1\\\\%$ at $z=5$, for an ensemble of ten mock\\nhigh-resolution quasar spectra. Applying this method to real quasar spectra and\\ncomparing to a more realistic IGM model from hydrodynamical simulations would\\nenable precise measurements of the thermal and cosmological parameters\\ngoverning the IGM, albeit with somewhat larger uncertainties given the\\nincreased flexibility of the model.\\n'\n",
      " '  Age-dependent dynamics is an important characteristic of many infectious\\ndiseases. Age-group epidemic models describe the infection dynamics in\\ndifferent age-groups by allowing to set distinct parameter values for each.\\nHowever, such models are highly nonlinear and may have a large number of\\nunknown parameters. Thus, parameter estimation of age-group models, while\\nbecoming a fundamental issue for both the scientific study and policy making in\\ninfectious diseases, is not a trivial task in practice. In this paper, we\\nexamine the estimation of the so called next-generation matrix using incidence\\ndata of a single entire outbreak, and extend the approach to deal with\\nrecurring outbreaks. Unlike previous studies, we do not assume any constraints\\nregarding the structure of the matrix. A novel two-stage approach is developed,\\nwhich allows for efficient parameter estimation from both statistical and\\ncomputational perspectives. Simulation studies corroborate the ability to\\nestimate accurately the parameters of the model for several realistic\\nscenarios. The model and estimation method are applied to real data of\\ninfluenza-like-illness in Israel. The parameter estimates of the key relevant\\nepidemiological parameters and the recovered structure of the estimated\\nnext-generation matrix are in line with results obtained in previous studies.\\n'\n",
      " '  We interpret the construction of relative Cuntz-Pimsner algebras of\\ncorrespondences in terms of the correspondence bicategory, as a reflector into\\na certain sub-bicategory. This generalises a previous characterisation of\\nabsolute Cuntz-Pimsner algebras of proper correspondences as colimits in the\\ncorrespondence bicategory.\\n'\n",
      " '  We study the dynamical thermal conductivity of the two-dimensional Kitaev\\nspin-model on the honeycomb lattice. We find a strongly temperature dependent\\nlow-frequency spectral intensity as a direct consequence of fractionalization\\nof spins into mobile Majorana matter and a static $\\\\mathbb{Z}_{2}$ gauge field.\\nThe latter acts as an emergent thermally activated disorder, leading to the\\nappearance of a pseudogap which partially closes in the thermodynamic limit,\\nindicating a dissipative heat conductor. Our analysis is based on complementary\\ncalculations of the current correlation function, comprising exact\\ndiagonalization by means of a complete summation over all gauge sectors, as\\nwell as a phenomenological mean-field treatment of thermal gauge fluctuations,\\nvalid at intermediate and high temperatures. The results will also be\\ncontrasted against the conductivity discarding gauge fluctuations.\\n'\n",
      " '  Let $M$ be a compact complex manifold admitting a Kähler structure. A\\nconformally Kähler, Einstein-Maxwell metric (cKEM metric for short) is a\\nHermitian metric $\\\\tilde{g}$ on $M$ with constant scalar curvature such that\\nthere is a positive smooth function $f$ with $g = f^2 \\\\tilde{g}$ being a\\nKähler metric and $f$ being a Killing Hamiltonian potential with respect to\\n$g$. Fixing a Kähler class, we characterize such Killing vector fields whose\\nHamiltonian function $f$ with respect to some Kähler metric $g$ in the fixed\\nKähler class gives a cKEM metric $\\\\tilde{g} = f^{-2}g$. The characterization\\nis described in terms of critical points of certain volume functional. The\\nconceptual idea is similar to the cases of Kähler-Ricci solitons and\\nSasaki-Einstein metrics in that the derivative of the volume functional gives\\nrise to a natural obstruction to the existence of cKEM metrics. However, unlike\\nthe Kähler-Ricci soliton case and Sasaki-Einstein case, the functional is\\nneither convex nor proper in general, and often has more than one critical\\npoints. The last observation matches well with the ambitoric examples studied\\nearlier by LeBrun and Apostolov-Maschler.\\n'\n",
      " '  This paper discusses the approach taken by the UWaterloo team to arrive at a\\nsolution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of\\nSemEval 2017. The paper describes the document vectorization and sentiment\\nscore prediction techniques used, as well as the design and implementation\\ndecisions taken while building the system for this task. The system uses text\\nvectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled\\nwith regression model variants to predict the sentiment scores. Amongst the\\nmethods examined, unigrams and bigrams coupled with simple linear regression\\nobtained the best baseline accuracy. The paper also explores data augmentation\\nmethods to supplement the training dataset. This system was designed for\\nSubtask 2 (News Statements and Headlines).\\n'\n",
      " '  We consider the technologically relevant costs of operating a reliable bit\\nthat can be erased rapidly. We find that both erasing and reliability times are\\nnon-monotonic in the underlying friction, leading to a trade-off between\\nerasing speed and bit reliability. Fast erasure is possible at the expense of\\nlow reliability at moderate friction, and high reliability comes at the expense\\nof slow erasure in the underdamped and overdamped limits. Within a given class\\nof bit parameters and control strategies, we define \"optimal\" designs of bits\\nthat meet the desired reliability and erasing time requirements with the lowest\\noperational work cost. We find that optimal designs always saturate the bound\\non the erasing time requirement, but can exceed the required reliability time\\nif critically damped. The non-trivial geometry of the reliability and erasing\\ntime-scales allows us to exclude large regions of parameter space as\\nsub-optimal. We find that optimal designs are either critically damped or close\\nto critical damping under the erasing procedure.\\n'\n",
      " \"  We consider the positions and velocities of electrons and spinning nuclei and\\ndemonstrate that these particles harbour hidden momentum when located in an\\nelectromagnetic field. This hidden momentum is present in all atoms and\\nmolecules, however it is ultimately cancelled by the momentum of the\\nelectromagnetic field. We point out that an electron vortex in an electric\\nfield might harbour a comparatively large hidden momentum and recognise the\\nphenomenon of 'hidden hidden momentum'.\\n\"\n",
      " '  Software Engineering as an industry is highly diverse in terms of development\\nmethods and practices. Practitioners employ a myriad of methods and tend to\\nfurther tailor them by e.g. omitting some practices or rules. This diversity in\\ndevelopment methods poses a challenge for software engineering education,\\ncreating a gap between education and industry. General theories such as the\\nEssence Theory of Software Engineering can help bridge this gap by presenting\\nsoftware engineering students with higher-level frameworks upon which to build\\nan understanding of software engineering methods and practical project work. In\\nthis paper, we study Essence in an educational setting to evaluate its\\nusefulness for software engineering students while also investigating barriers\\nto its adoption in this context. To this end, we observe 102 student teams\\nutilize Essence in practical software engineering projects during a semester\\nlong, project-based course.\\n'\n",
      " '  Labeling training data is increasingly the largest bottleneck in deploying\\nmachine learning systems. We present Snorkel, a first-of-its-kind system that\\nenables users to train state-of-the-art models without hand labeling any\\ntraining data. Instead, users write labeling functions that express arbitrary\\nheuristics, which can have unknown accuracies and correlations. Snorkel\\ndenoises their outputs without access to ground truth by incorporating the\\nfirst end-to-end implementation of our recently proposed machine learning\\nparadigm, data programming. We present a flexible interface layer for writing\\nlabeling functions based on our experience over the past year collaborating\\nwith companies, agencies, and research labs. In a user study, subject matter\\nexperts build models 2.8x faster and increase predictive performance an average\\n45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in\\nthis new setting and propose an optimizer for automating tradeoff decisions\\nthat gives up to 1.8x speedup per pipeline execution. In two collaborations,\\nwith the U.S. Department of Veterans Affairs and the U.S. Food and Drug\\nAdministration, and on four open-source text and image data sets representative\\nof other deployments, Snorkel provides 132% average improvements to predictive\\nperformance over prior heuristic approaches and comes within an average 3.60%\\nof the predictive performance of large hand-curated training sets.\\n'\n",
      " '  Autoignition experiments for n-butanol have been performed using a heated\\nrapid compression machine at compressed pressures of 15 and 30 bar, in the\\ncompressed temperature range of 675-925 K, and for equivalence ratios of 0.5,\\n1.0, and 2.0. Over the conditions studied, the ignition delay decreases\\nmonotonically as temperature increases, and the autoignition response exhibits\\nsingle-stage characteristics. A non-linear fit to the experimental data is\\nperformed and the reactivity, in terms of the inverse of ignition delay, shows\\nnearly second order dependence on the initial oxygen mole fraction and slightly\\ngreater than first order dependence on initial fuel mole fraction and\\ncompressed pressure. Experimentally measured ignition delays are also compared\\nto simulations using several reaction mechanisms available in the literature.\\nAgreement between simulated and experimental ignition delay is found to be\\nunsatisfactory. Sensitivity analysis is performed on one recent mechanism and\\nindicates that uncertainties in the rate coefficients of parent fuel\\ndecomposition reactions play a major role in causing the poor agreement. Path\\nanalysis of the fuel decomposition reactions supports this conclusion and also\\nhighlights the particular importance of certain pathways. Further experimental\\ninvestigations of the fuel decomposition, including speciation measurements,\\nare required.\\n'\n",
      " '  It has been shown in recent years that the stochastic block model (SBM) is\\nsometimes undetectable in the sparse limit, i.e., that no algorithm can\\nidentify a partition correlated with the partition used to generate an\\ninstance, if the instance is sparse enough and infinitely large. In this\\ncontribution, we treat the finite case explicitly, using arguments drawn from\\ninformation theory and statistics. We give a necessary condition for\\nfinite-size detectability in the general SBM. We then distinguish the concept\\nof average detectability from the concept of instance-by-instance detectability\\nand give explicit formulas for both definitions. Using these formulas, we prove\\nthat there exist large equivalence classes of parameters, where widely\\ndifferent network ensembles are equally detectable with respect to our\\ndefinitions of detectability. In an extensive case study, we investigate the\\nfinite-size detectability of a simplified variant of the SBM, which encompasses\\na number of important models as special cases. These models include the\\nsymmetric SBM, the planted coloring model, and more exotic SBMs not previously\\nstudied. We conclude with three appendices, where we study the interplay of\\nnoise and detectability, establish a connection between our\\ninformation-theoretic approach and random matrix theory, and provide proofs of\\nsome of the more technical results.\\n'\n",
      " '  With ever growing data volume and model size, an error-tolerant,\\ncommunication efficient, yet versatile distributed algorithm has become vital\\nfor the success of many large-scale machine learning applications. In this work\\nwe propose m-PAPG, an implementation of the flexible proximal gradient\\nalgorithm in model parallel systems equipped with the partially asynchronous\\ncommunication protocol. The worker machines communicate asynchronously with a\\ncontrolled staleness bound $s$ and operate at different frequencies. We\\ncharacterize various convergence properties of m-PAPG: 1) Under a general\\nnon-smooth and non-convex setting, we prove that every limit point of the\\nsequence generated by m-PAPG is a critical point of the objective function; 2)\\nUnder an error bound condition, we prove that the function value decays\\nlinearly for every $s$ steps; 3) Under the Kurdyka-${\\\\L}$ojasiewicz inequality,\\nwe prove that the sequences generated by m-PAPG converge to the same critical\\npoint, provided that a proximal Lipschitz condition is satisfied.\\n'\n",
      " '  The \"digital Michelangelo project\" was a seminal computer vision project in\\nthe early 2000\\'s that pushed the capabilities of acquisition systems and\\ninvolved multiple people from diverse fields, many of whom are now leaders in\\nindustry and academia. Reviewing this project with modern eyes provides us with\\nthe opportunity to reflect on several issues, relevant now as then to the field\\nof computer vision and research in general, that go beyond the technical\\naspects of the work.\\nThis article was written in the context of a reading group competition at the\\nweek-long International Computer Vision Summer School 2017 (ICVSS) on Sicily,\\nItaly. To deepen the participants understanding of computer vision and to\\nfoster a sense of community, various reading groups were tasked to highlight\\nimportant lessons which may be learned from provided literature, going beyond\\nthe contents of the paper. This report is the winning entry of this guided\\ndiscourse (Fig. 1). The authors closely examined the origins, fruits and most\\nimportantly lessons about research in general which may be distilled from the\\n\"digital Michelangelo project\". Discussions leading to this report were held\\nwithin the group as well as with Hao Li, the group mentor.\\n'\n",
      " '  We investigate particle production à la Schwinger mechanism in an\\nexpanding, flat de Sitter patch as is relevant for the inflationary epoch of\\nour universe. Defining states and particle content in curved spacetime is\\ncertainly not a unique process. There being different prescriptions on how that\\ncan be done, we have used the Schrödinger formalism to define instantaneous\\nparticle content of the state etc. This allows us to go past the adiabatic\\nregime to which the effect has been restricted in the previous studies and\\nbring out its multifaceted nature in different settings. Each of these settings\\ngives rise to contrasting features and behaviour as per the effect of electric\\nfield and expansion rate on the instantaneous mean particle number. We also\\nquantify the degree of classicality of the process during its evolution using a\\n\"classicality parameter\" constructed out of parameters of the Wigner function\\nto obtain information about the quantum to classical transition in this case.\\n'\n",
      " '  Computing the extensions between Verma modules is in general a very difficult\\nproblem. Using Soergel bimodules, one can construct a graded version of the\\nprincipal block of Category $\\\\mathcal{O}$ for any finite coxeter group. In this\\nsetting, we compute the extensions between Verma modules for dihedral groups.\\n'\n",
      " '  \\\\textbf{GalRotpy} is an educational \\\\verb+Python3+-based visual tool, which\\nis useful to undestand how is the contribution of each mass component to the\\ngravitational potential of disc-like galaxies by means of their rotation curve.\\nBesides, \\\\textbf{GalRotpy} allows the user to perform a parametric fit of a\\ngiven rotation curve, which relies on a MCMC procedure implemented by using\\n\\\\verb+emcee+ package. Here the gravitational potential of disc-like galaxies is\\nbuilt from the contribution of a Miyamoto-Nagai potential model for the\\nbulge/core and the thin/thick disc, an exponential disc, together with the NFW\\n(Navarro-Frenk- White) potential or the Burkert (cored density profile)\\npotential for the Dark Matter halo, where each contribution is implemented by\\nusing \\\\verb+galpy+ package. We summarize the properties of each contribution to\\nthe rotation curve involved, and then describe how \\\\textbf{GalRotpy} is\\nimplemented along with its capabilities. Finally we present the\\ncharacterization of two galaxies, NGC6361 and M33, and show that the results\\nfor M33 provided by \\\\textbf{GalRotpy} are consistent with those found in the\\nliterature.\\n'\n",
      " '  Deep learning hyper-parameter optimization is a tough task. Finding an\\nappropriate network configuration is a key to success, however most of the\\ntimes this labor is roughly done. In this work we introduce a novel library to\\ntackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly\\ndescribe its architecture and present a set of use examples. This is an open\\nsource project developed under the GNU GPL v3 license and it is freely\\navailable at this https URL\\n'\n",
      " '  In previous work the authors introduced a new class of modular quasi-Hopf\\nalgebras $D^{\\\\omega}(G, A)$ associated to a finite group $G$, a central\\nsubgroup $A$, and a $3$-cocycle $\\\\omega\\\\in Z^3(G, C^x)$. In the present paper\\nwe propose a description of the class of orbifold models of rational vertex\\noperator algebras whose module category is tensor equivalent to $D^{\\\\omega}(G,\\nA)$-mod. The paper includes background on quasi-Hopf algebras and a discussion\\nof some relevant orbifolds.\\n'\n",
      " '  Superhydrophobic surfaces demonstrate promising potential for skin friction\\nreduction in naval and hydrodynamic applications. Recent developments of\\nsuperhydrophobic surfaces aiming for scalable applications use random\\ndistribution of roughness, such as spray coating and etched process. However,\\nmost of previous analyses of the interaction between flows and superhydrophobic\\nsurfaces studied periodic geometries that are economically feasible only in\\nlab-scale experiments. We conduct direct numerical simulations of turbulent\\nflows over randomly patterned interfaces considering a range of texture widths\\n$w^+\\\\approx 4-26$, and solid fractions $\\\\phi_s=11\\\\%$ to $25\\\\%$. Slip and\\nno-slip boundary conditions are implemented in a pattern, modeling the presence\\nof gas-liquid interfaces and solid elements. Our results indicate that slip of\\nrandomly distributed textures under turbulent flows are about $30\\\\%$ less than\\nthose of surfaces with aligned features of the same size. In the small texture\\nsize limit $w^+\\\\approx 4$, the slip length of the randomly distributed textures\\nin turbulent flows is well described by a previously introduced Stokes flow\\nsolution of randomly distributed shear-free holes. By comparing DNS results for\\npatterned slip and no-slip boundary against the corresponding homogenized slip\\nlength boundary conditions, we show that turbulent flows over randomly\\ndistributed posts can be represented by an isotropic slip length in streamwise\\nand spanwise direction. The average pressure fluctuation on gas pocket is\\nsimilar to that of the aligned features with the same texture size and gas\\nfraction, but the maximum interface deformation at the leading edge of the\\nroughness element is about twice larger when the textures are randomly\\ndistributed.\\n'\n",
      " '  How cooperation can evolve between players is an unsolved problem of biology.\\nHere we use Hamiltonian dynamics of models of the Ising type to describe\\npopulations of cooperating and defecting players to show that the equilibrium\\nfraction of cooperators is given by the expectation value of a thermal\\nobservable akin to a magnetization. We apply the formalism to the Public Goods\\ngame with three players, and show that a phase transition between cooperation\\nand defection occurs that is equivalent to a transition in one-dimensional\\nIsing crystals with long-range interactions. We then investigate the effect of\\npunishment on cooperation and find that punishment plays the role of a magnetic\\nfield that leads to an \"alignment\" between players, thus encouraging\\ncooperation. We suggest that a thermal Hamiltonian picture of the evolution of\\ncooperation can generate other insights about the dynamics of evolving groups\\nby mining the rich literature of critical dynamics in low-dimensional spin\\nsystems.\\n'\n",
      " '  We present a detailed study of the low temperature and high magnetic field\\nphases in the chemical substitution series URu$_2$Si$_{2-x}$P$_x$ using\\nelectrical transport and magnetization in pulsed magnetic fields up to 65T.\\nWithin the hidden order region (0 $\\\\ x$$\\\\ $ 0.035) the high field ordering is\\nrobust even as the hidden order temperature is suppressed. Earlier work shows\\nthat for 0.035 $\\\\ x$ $\\\\ $ 0.26 there is a Kondo lattice with a no-ordered state\\nthat is replaced by antiferromagnetism for 0.26 $\\\\ x$ 0.5. We observe a\\nsimplified continuation of the high field ordering in the no-order $x$-region\\nand an enhancement of the high field state upon the destruction of the\\nantiferromagnetism with magnetic field. These results closely resemble what is\\nseen for URu$_{2-x}$Rh$_x$Si$_2$\\\\footnote{The concentration in this paper is\\ndefined as URu$_{2-x}$Rh$_x$Si$_2$ while the chemical formula in the literature\\nis given as U(Ru$_{1-x}$Rh$_x$)$_2$Si$_2$ [24-26]}, from which we infer that\\ncharge tuning uniformly controls the ground state of URu$_2$Si$_2$, regardless\\nof whether s/p or d-electrons are replaced. This provides guidance for\\ndetermining the specific factors that lead to hidden order versus magnetism in\\nthis family of materials.\\n'\n",
      " '  The radio-quiet quasar Q2059-360 at redshift $z=3.08$ is known to be close to\\na small Lyman $\\\\alpha$ blob (LAB) and to be absorbed by a proximate damped\\nLy$\\\\alpha$ (PDLA) system.\\nHere, we present the Multi Unit Spectroscopic Explorer (MUSE) integral field\\nspectroscopy follow-up of this quasi-stellar object (QSO). Our primary goal is\\nto characterize this LAB in detail by mapping it both spatially and spectrally\\nusing the Ly$\\\\alpha$ line, and by looking for high-ionization lines to\\nconstrain the emission mechanism.\\nCombining the high sensitivity of the MUSE integral field spectrograph\\nmounted on the Yepun telescope at ESO-VLT with the natural coronagraph provided\\nby the PDLA, we map the LAB down to the QSO position, after robust subtraction\\nof QSO light in the spectral domain.\\nIn addition to confirming earlier results for the small bright component of\\nthe LAB, we unveil a faint filamentary emission protruding to the south over\\nabout 80 pkpc (physical kpc); this results in a total size of about 120 pkpc.\\nWe derive the velocity field of the LAB (assuming no transfer effects) and map\\nthe Ly$\\\\alpha$ line width. Upper limits are set to the flux of the N V $\\\\lambda\\n1238-1242$, C IV $\\\\lambda 1548-1551$, He II $\\\\lambda 1640$, and C III] $\\\\lambda\\n1548-1551$ lines. We have discovered two probable Ly$\\\\alpha$ emitters at the\\nsame redshift as the LAB and at projected distances of 265 kpc and 207 kpc from\\nthe QSO; their Ly$\\\\alpha$ luminosities might well be enhanced by the QSO\\nradiation. We also find an emission line galaxy at $z=0.33$ near the line of\\nsight to the QSO.\\nThis LAB shares the same general characteristics as the 17 others surrounding\\nradio-quiet QSOs presented previously. However, there are indications that it\\nmay be centered on the PDLA galaxy rather than on the QSO.\\n'\n",
      " \"  We demonstrate how methods in Functional Programming can be used to implement\\na computer algebra system. As a proof-of-concept, we present the\\ncomputational-algebra package. It is a computer algebra system implemented as\\nan embedded domain-specific language in Haskell, a purely functional\\nprogramming language. Utilising methods in functional programming and prominent\\nfeatures of Haskell, this library achieves safety, composability, and\\ncorrectness at the same time. To demonstrate the advantages of our approach, we\\nhave implemented advanced Gröbner basis algorithms, such as Faugère's\\n$F_4$ and $F_5$, in a composable way.\\n\"\n",
      " '  Given a convolutional neural network (CNN) that is pre-trained for object\\nclassification, this paper proposes to use active question-answering to\\nsemanticize neural patterns in conv-layers of the CNN and mine part concepts.\\nFor each part concept, we mine neural patterns in the pre-trained CNN, which\\nare related to the target part, and use these patterns to construct an And-Or\\ngraph (AOG) to represent a four-layer semantic hierarchy of the part. As an\\ninterpretable model, the AOG associates different CNN units with different\\nexplicit object parts. We use an active human-computer communication to\\nincrementally grow such an AOG on the pre-trained CNN as follows. We allow the\\ncomputer to actively identify objects, whose neural patterns cannot be\\nexplained by the current AOG. Then, the computer asks human about the\\nunexplained objects, and uses the answers to automatically discover certain CNN\\npatterns corresponding to the missing knowledge. We incrementally grow the AOG\\nto encode new knowledge discovered during the active-learning process. In\\nexperiments, our method exhibits high learning efficiency. Our method uses\\nabout 1/6-1/3 of the part annotations for training, but achieves similar or\\nbetter part-localization performance than fast-RCNN methods.\\n'\n",
      " \"  Despite incredible recent advances in machine learning, building machine\\nlearning applications remains prohibitively time-consuming and expensive for\\nall but the best-trained, best-funded engineering organizations. This expense\\ncomes not from a need for new and improved statistical models but instead from\\na lack of systems and tools for supporting end-to-end machine learning\\napplication development, from data preparation and labeling to\\nproductionization and monitoring. In this document, we outline opportunities\\nfor infrastructure supporting usable, end-to-end machine learning applications\\nin the context of the nascent DAWN (Data Analytics for What's Next) project at\\nStanford.\\n\"\n",
      " '  A linear stochastic continuity equation with non-regular coefficients is\\nconsidered. We prove existence and uniqueness of strong solution, in the\\nprobabilistic sense, to the Cauchy problem when the vector field has low\\nregularity, in which the classical DiPerna-Lions-Ambrosio theory of uniqueness\\nof distributional solutions does not apply. We solve partially the open problem\\nthat is the case when the vector-field has random dependence. In addition, we\\nprove a stability result for the solutions.\\n'\n",
      " '  In determining when a four-dimensional ellipsoid can be symplectically\\nembedded into a ball, McDuff and Schlenk found an infinite sequence of \"ghost\"\\nobstructions that generate an infinite \"ghost staircase\" determined by the even\\nindex Fibonacci numbers. The ghost obstructions are not visible for the\\nfour-dimensional embedding problem because strictly stronger obstructions also\\nexist. We show that in contrast, the embedding constraints associated to the\\nghost obstructions are sharp for the stabilized problem; moreover, the\\ncorresponding optimal embeddings are given by symplectic folding. The proof\\nintroduces several ideas of independent interest, namely: (i) an improved\\nversion of the index inequality familiar from the theory of embedded contact\\nhomology (ECH), (ii) new applications of relative intersection theory in the\\ncontext of neck stretching analysis, (iii) a new approach to estimating the ECH\\ngrading of multiply covered elliptic orbits in terms of areas and continued\\nfractions, and (iv) a new technique for understanding the ECH of ellipsoids by\\nconstructing explicit bijections between certain sets of lattice points.\\n'\n",
      " '  Large-scale networks are widely used to represent object relationships in\\nmany real world applications. The occurrence of large-scale networks presents\\nsignificant computational challenges to process, analyze, and extract\\ninformation from such networks. Network summarization techniques are commonly\\nused to reduce the computational load while attempting to maintain the basic\\nstructural properties of the original network. Previous works have primarily\\nfocused on some type of network partitioning strategies with\\napplication-dependent regularizations, most often resulting in strongly\\nconnected clusters.\\nIn this paper, we introduce a novel perspective regarding the network\\nsummarization problem based on concepts from spectral graph theory. We propose\\na new distance measurement to characterize the spectral differences between the\\noriginal and coarsened networks. We rigorously justify the spectral distance\\nwith the interlacing theorem as well the results from the stochastic block\\nmodel. We provide an efficient algorithm to generate the coarsened networks\\nthat maximally preserves the spectral properties of the original network. Our\\nproposed network summarization framework allows the flexibility to generate a\\nset of coarsened networks with significantly different structures preserved\\nfrom different aspects of the original network, which distinguishes our work\\nfrom others. We conduct extensive experimental tests on a variety of\\nlarge-scale networks, both from real-world applications and the random graph\\nmodel. We show that our proposed algorithms consistently perform better results\\nin terms of the spectral measurements and running time compared to previous\\nnetwork summarization algorithms.\\n'\n",
      " '  This paper presents a method for fitting a copula-driven generalized linear\\nmixed models. For added flexibility, the skew-normal copula is adopted for\\nfitting. The correlation matrix of the skew-normal copula is used to capture\\nthe dependence structure within units, while the fixed and random effects\\ncoefficients are estimated through the mean of the copula. For estimation, a\\nMonte Carlo expectation-maximization algorithm is developed. Simulations are\\nshown alongside a real data example from the Framingham Heart Study.\\n'\n",
      " '  The proven efficacy of learning-based control schemes strongly motivates\\ntheir application to robotic systems operating in the physical world. However,\\nguaranteeing correct operation during the learning process is currently an\\nunresolved issue, which is of vital importance in safety-critical systems. We\\npropose a general safety framework based on Hamilton-Jacobi reachability\\nmethods that can work in conjunction with an arbitrary learning algorithm. The\\nmethod exploits approximate knowledge of the system dynamics to guarantee\\nconstraint satisfaction while minimally interfering with the learning process.\\nWe further introduce a Bayesian mechanism that refines the safety analysis as\\nthe system acquires new evidence, reducing initial conservativeness when\\nappropriate while strengthening guarantees through real-time validation. The\\nresult is a least-restrictive, safety-preserving control law that intervenes\\nonly when (a) the computed safety guarantees require it, or (b) confidence in\\nthe computed guarantees decays in light of new observations. We prove\\ntheoretical safety guarantees combining probabilistic and worst-case analysis\\nand demonstrate the proposed framework experimentally on a quadrotor vehicle.\\nEven though safety analysis is based on a simple point-mass model, the\\nquadrotor successfully arrives at a suitable controller by policy-gradient\\nreinforcement learning without ever crashing, and safely retracts away from a\\nstrong external disturbance introduced during flight.\\n'\n",
      " '  We introduce a geometric property complementary-finite asymptotic dimension\\n(coas- dim). Similar with asymptotic dimension, we prove the corresponding\\ncoarse invariant theorem, union theorem and Hurewicz-type theorem.\\n'\n",
      " '  Phytoplankton plays an important role in marine ecosystem. It is defined as a\\nbiological factor to assess marine quality. The identification of phytoplankton\\nspecies has a high potential for monitoring environmental, climate changes and\\nfor evaluating water quality. However, phytoplankton species identification is\\nnot an easy task owing to their variability and ambiguity due to thousands of\\nmicro and pico-plankton species. Therefore, the aim of this paper is to build a\\nframework for identifying phytoplankton species and to perform a comparison on\\ndifferent features types and classifiers. We propose a new features type\\nextracted from raw signals of phytoplankton species. We then analyze the\\nperformance of various classifiers on the proposed features type as well as two\\nother features types for finding the robust one. Through experiments, it is\\nfound that Random Forest using the proposed features gives the best\\nclassification results with average accuracy up to 98.24%.\\n'\n",
      " '  In this paper, we consider reinforcement learning of Markov Decision\\nProcesses (MDP) with peak constraints, where an agent chooses a policy to\\noptimize an objective and at the same time satisfy additional constraints. The\\nagent has to take actions based on the observed states, reward outputs, and\\nconstraint-outputs, without any knowledge about the dynamics, reward functions,\\nand/or the knowledge of the constraint-functions. We introduce a game theoretic\\napproach to construct reinforcement learning algorithms where the agent\\nmaximizes an unconstrained objective that depends on the simulated action of\\nthe minimizing opponent which acts on a finite set of actions and the output\\ndata of the constraint functions (rewards). We show that the policies obtained\\nfrom maximin Q-learning converge to the optimal policies. To the best of our\\nknowledge, this is the first time learning algorithms guarantee convergence to\\noptimal stationary policies for the MDP problem with peak constraints for both\\ndiscounted and expected average rewards.\\n'\n",
      " \"  GPUs are becoming first-class compute citizens and are being tasked to\\nperform increasingly complex work. Modern GPUs increasingly support\\nprogrammability- enhancing features such as shared virtual memory and hardware\\ncache coherence, enabling them to run a wider variety of programs. But a key\\naspect of general-purpose programming where GPUs are still found lacking is the\\nability to invoke system calls. We explore how to directly invoke generic\\nsystem calls in GPU programs. We examine how system calls should be meshed with\\nprevailing GPGPU programming models where thousands of threads are organized in\\na hierarchy of execution groups: Should a system call be invoked at the\\nindividual GPU task, or at different execution group levels? What are\\nreasonable ordering semantics for GPU system calls across these hierarchy of\\nexecution groups? To study these questions, we implemented GENESYS -- a\\nmechanism to allow GPU pro- grams to invoke system calls in the Linux operating\\nsystem. Numerous subtle changes to Linux were necessary, as the existing kernel\\nassumes that only CPUs invoke system calls. We analyze the performance of\\nGENESYS using micro-benchmarks and three applications that exercise the\\nfilesystem, networking, and memory allocation subsystems of the kernel. We\\nconclude by analyzing the suitability of all of Linux's system calls for the\\nGPU.\\n\"\n",
      " \"  We propose a computational model of neuron, called firing cell (FC),\\nproperties of which cover such phenomena as attenuation of receptors for\\nexternal stimuli, delay and decay of postsynaptic potentials, modification of\\ninternal weights due to propagation of postsynaptic potentials through the\\ndendrite, modification of properties of the analog memory for each input due to\\na pattern of short-time synaptic potentiation or long-time synaptic\\npotentiation (LTP), output-spike generation when the sum of all inputs exceeds\\na threshold, and refraction. The cell may take one of the three forms:\\nexcitatory, inhibitory, and receptory. The computer simulations showed that,\\ndepending on the phase of input signals, the artificial neuron's output\\nfrequency may demonstrate various chaotic behaviors.\\n\"\n",
      " '  This paper demonstrates the use of genetic algorithms for evolving a\\ngrandmaster-level evaluation function for a chess program. This is achieved by\\ncombining supervised and unsupervised learning. In the supervised learning\\nphase the organisms are evolved to mimic the behavior of human grandmasters,\\nand in the unsupervised learning phase these evolved organisms are further\\nimproved upon by means of coevolution.\\nWhile past attempts succeeded in creating a grandmaster-level program by\\nmimicking the behavior of existing computer chess programs, this paper presents\\nthe first successful attempt at evolving a state-of-the-art evaluation function\\nby learning only from databases of games played by humans. Our results\\ndemonstrate that the evolved program outperforms a two-time World Computer\\nChess Champion.\\n'\n",
      " '  We have developed ultra-low-background NaI(Tl) crystals to reproduce the DAMA\\nresults with the ultimate goal of achieving purity levels that are comparable\\nto or better than those of the DAMA/LIBRA crystals. Even though the achieved\\nbackground level does not approach that of DAMA/LIBRA, it is crucial to have a\\nquantitative understanding of the backgrounds. We have studied background\\nsimulations toward a deeper understanding of the backgrounds and developed\\nbackground models for a 9.16-kg NaI(Tl) crystal used in the test arrangement.\\nIn this paper we describe the contributions of background sources\\nquantitatively by performing Geant4 Monte Carlo simulations that are fitted to\\nthe measured data to quantify the unknown fractions of the background\\ncompositions. In the fitted results, the overall simulated background spectrum\\nwell describes the measured data with a 9.16-kg NaI(Tl) crystal and shows that\\nthe background sources are dominated by surface $^{210}$Pb and internal\\n$^{40}$K in the 2 to 6-keV energy interval, which produce 2.4 counts/day/keV/kg\\n(dru) and 0.5 dru, respectively.\\n'\n",
      " '  Gas-solid multiphase flows are prone to develop an instability known as\\nclustering. Two-fluid models, which treat the particulate phase as a continuum,\\nare known to reproduce the qualitative features of this instability, producing\\nhighly-dynamic, spatiotemporal patterns. However, it is unknown whether such\\nsimulations are truly aperiodic or a type of complex periodic behavior. By\\nshowing that the system possesses a sensitive dependence on initial conditions\\nand a positive largest Lyapunov exponent, $\\\\lambda_1 \\\\approx 1/\\\\tau$, we\\nprovide a tentative answer: continuum predictions of clustering are chaotic. We\\nfurther demonstrate that the chaotic behavior is dimensionally dependent, a\\nconclusion which unifies previous results and strongly suggests that the\\nchaotic behavior is not a result of the fundamental kinematic instability, but\\nof the secondary (inherently multidimensional) instability.\\n'\n",
      " '  In the study of Markov chain mixing times, analysis has centered on the\\nperformance from a worst-case starting state. Here, in the context of Glauber\\ndynamics for the one-dimensional Ising model, we show how new ideas from\\ninformation percolation can be used to establish mixing times from other\\nstarting states. At high temperatures we show that the alternating initial\\ncondition is asymptotically the fastest one, and, surprisingly, its mixing time\\nis faster than at infinite temperature, accelerating as the inverse-temperature\\n$\\\\beta$ ranges from 0 to $\\\\beta_0=\\\\frac12\\\\mathrm{arctanh}(\\\\frac13)$. Moreover,\\nthe dominant test function depends on the temperature: at $\\\\beta<\\\\beta_0$ it is\\nautocorrelation, whereas at $\\\\beta>\\\\beta_0$ it is the Hamiltonian.\\n'\n",
      " '  In this paper, we examine the problem of robotic manipulation of granular\\nmedia. We evaluate multiple predictive models used to infer the dynamics of\\nscooping and dumping actions. These models are evaluated on a task that\\ninvolves manipulating the media in order to deform it into a desired shape. Our\\nbest performing model is based on a highly-tailored convolutional network\\narchitecture with domain-specific optimizations, which we show accurately\\nmodels the physical interaction of the robotic scoop with the underlying media.\\nWe empirically demonstrate that explicitly predicting physical mechanics\\nresults in a policy that out-performs both a hand-crafted dynamics baseline,\\nand a \"value-network\", which must otherwise implicitly predict the same\\nmechanics in order to produce accurate value estimates.\\n'\n",
      " '  We show that in Lorentzian manifolds, sectional curvature bounds of the form\\n$\\\\mathcal{R}\\\\le K\\\\,$, as defined by Andersson and Howard, are closely tied to\\nspace-time convex and $\\\\lambda$-convex ($\\\\lambda>0$) functions, as defined by\\nGibbons and Ishibashi. Among the consequences are a natural construction of\\nsuch functions, and an analogue, that applies to domains of a new type, of a\\ntheorem of Alías, Bessa and deLira ruling out trapped submanifolds.\\n'\n",
      " \"  Image denoising techniques are essential to reducing noise levels and\\nenhancing diagnosis reliability in low-dose computed tomography (CT). Machine\\nlearning based denoising methods have shown great potential in removing the\\ncomplex and spatial-variant noises in CT images. However, some residue\\nartifacts would appear in the denoised image due to complexity of noises. A\\ncascaded training network was proposed in this work, where the trained CNN was\\napplied on the training dataset to initiate new trainings and remove artifacts\\ninduced by denoising. A cascades of convolutional neural networks (CNN) were\\nbuilt iteratively to achieve better performance with simple CNN structures.\\nExperiments were carried out on 2016 Low-dose CT Grand Challenge datasets to\\nevaluate the method's performance.\\n\"\n",
      " '  In this paper, we study a dynamic version of the sharing problem, in which a\\ndynamic system cost function composed of time-variant local costs of subsystems\\nand a shared time-variant cost of the whole system is minimized. A dynamic\\nalternating direction method of multipliers (ADMM) is proposed to track the\\nvarying optimal points of the dynamic optimization problem in an online manner.\\nWe analyze the convergence properties of the dynamic ADMM and show that, under\\nseveral standard technical assumptions, the iterations of the dynamic ADMM\\nconverge linearly to some neighborhoods of the time-varying optimal points. The\\nsizes of these neighborhoods depend on the drifts of the dynamic objective\\nfunctions: the more drastically the dynamic objective function evolves across\\ntime, the larger the sizes of these neighborhoods. We also investigate the\\nimpact of the drifts on the steady state convergence behaviors of the dynamic\\nADMM. Finally, two numerical examples, namely a dynamic sharing problem and the\\ndynamic least absolute shrinkage and selection operator (LASSO), are presented\\nto corroborate the effectiveness of the proposed dynamic ADMM. It is observed\\nthat the dynamic ADMM can track the time-varying optimal points quickly and\\naccurately. For the dynamic LASSO, the dynamic ADMM has competitive performance\\ncompared to the benchmark offline optimizor while the former possesses\\nsignificant computational advantage over the latter.\\n'\n",
      " '  We propose a new approach for metric learning by framing it as learning a\\nsparse combination of locally discriminative metrics that are inexpensive to\\ngenerate from the training data. This flexible framework allows us to naturally\\nderive formulations for global, multi-task and local metric learning. The\\nresulting algorithms have several advantages over existing methods in the\\nliterature: a much smaller number of parameters to be estimated and a\\nprincipled way to generalize learned metrics to new testing data points. To\\nanalyze the approach theoretically, we derive a generalization bound that\\njustifies the sparse combination. Empirically, we evaluate our algorithms on\\nseveral datasets against state-of-the-art metric learning methods. The results\\nare consistent with our theoretical findings and demonstrate the superiority of\\nour approach in terms of classification performance and scalability.\\n'\n",
      " '  Neuronal assemblies, loosely defined as subsets of neurons with reoccurring\\nspatio-temporally coordinated activation patterns, or \"motifs\", are thought to\\nbe building blocks of neural representations and information processing. We\\nhere propose LeMoNADe, a new exploratory data analysis method that facilitates\\nhunting for motifs in calcium imaging videos, the dominant microscopic\\nfunctional imaging modality in neurophysiology. Our nonparametric method\\nextracts motifs directly from videos, bypassing the difficult intermediate step\\nof spike extraction. Our technique augments variational autoencoders with a\\ndiscrete stochastic node, and we show in detail how a differentiable\\nreparametrization and relaxation can be used. An evaluation on simulated data,\\nwith available ground truth, reveals excellent quantitative performance. In\\nreal video data acquired from brain slices, with no ground truth available,\\nLeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses\\nfor more focused biological investigations.\\n'\n",
      " '  We show that dispersive propagation of light followed by phase detection has\\nproperties that can be exploited for extracting features from the waveforms.\\nThis discovery is spearheading development of a new class of physics-inspired\\nalgorithms for feature extraction from digital images with unique properties\\nand superior dynamic range compared to conventional algorithms. In certain\\ncases, these algorithms have the potential to be an energy efficient and\\nscalable substitute to synthetically fashioned computational techniques in\\npractice today.\\n'\n",
      " '  This paper proposes Monte Carlo Action Programming, a programming language\\nframework for autonomous systems that act in large probabilistic state spaces\\nwith high branching factors. It comprises formal syntax and semantics of a\\nnondeterministic action programming language. The language is interpreted\\nstochastically via Monte Carlo Tree Search. Effectiveness of the approach is\\nshown empirically.\\n'\n",
      " \"  This article considers two variants of a shortest path problem for a car-like\\nrobot visiting a set of waypoints. The sequence of waypoints to be visited is\\nspecified in the first variant while the robot is allowed to visit the\\nwaypoints in any sequence in the second variant. Field of view constraints are\\nalso placed when the robot arrives at a waypoint, i.e., the orientation of the\\nrobot at any waypoint is restricted to belong to a given interval of angles at\\nthe waypoint. The shortest path problem is first solved for two waypoints with\\nthe field of view constraints using Pontryagin's minimum principle. Using the\\nresults for the two point problem, tight lower and upper bounds on the length\\nof the shortest path are developed for visiting n points by relaxing the\\nrequirement that the arrival angle must be equal to the departure angle of the\\nrobot at each waypoint. Theoretical bounds are also provided on the length of\\nthe feasible solutions obtained by the proposed algorithm. Simulation results\\nverify the performance of the bounds for instances with 20 waypoints.\\n\"\n",
      " \"  The predominant structural protein in vertebrates is collagen, which plays a\\nkey role in extracellular matrix and connective tissue mechanics. Despite its\\nprevalence and physical importance in biology, the mechanical properties of\\nmolecular collagen are far from established. The flexibility of its triple\\nhelix is unresolved, with descriptions from different experimental techniques\\nranging from flexible to semirigid. Furthermore, it is unknown how collagen\\ntype (homo- vs. heterotrimeric) and source (tissue-derived vs. recombinant)\\ninfluence flexibility. Using SmarTrace, a chain tracing algorithm we devised,\\nwe performed statistical analysis of collagen conformations collected with\\natomic force microscopy (AFM) to determine the protein's mechanical properties.\\nOur results show that types I, II and III collagens - the key fibrillar\\nvarieties - exhibit molecular flexibilities that are very similar. However,\\ncollagen conformations are strongly modulated by salt, transitioning from\\ncompact to extended as KCl concentration increases, in both neutral and acidic\\npH. While analysis with a standard worm-like chain model suggests that the\\npersistence length of collagen can attain almost any value within the\\nliterature range, closer inspection reveals that this modulation of collagen's\\nconformational behavior is not due to changes in flexibility, but rather arises\\nfrom the induction of curvature (either intrinsic or induced by interactions\\nwith the mica surface). By modifying standard polymer theory to include innate\\ncurvature, we show that collagen behaves as an equilibrated curved worm-like\\nchain (cWLC) in two dimensions. Analysis within the cWLC model shows that\\ncollagen's curvature depends strongly on pH and salt, while its persistence\\nlength does not. Thus, we find that triple-helical collagen is well described\\nas semiflexible, irrespective of source, type, pH and salt environment.\\n\"\n",
      " '  The goal of this paper is to analyze the geometric properties of deep neural\\nnetwork classifiers in the input space. We specifically study the topology of\\nclassification regions created by deep networks, as well as their associated\\ndecision boundary. Through a systematic empirical investigation, we show that\\nstate-of-the-art deep nets learn connected classification regions, and that the\\ndecision boundary in the vicinity of datapoints is flat along most directions.\\nWe further draw an essential connection between two seemingly unrelated\\nproperties of deep networks: their sensitivity to additive perturbations in the\\ninputs, and the curvature of their decision boundary. The directions where the\\ndecision boundary is curved in fact remarkably characterize the directions to\\nwhich the classifier is the most vulnerable. We finally leverage a fundamental\\nasymmetry in the curvature of the decision boundary of deep nets, and propose a\\nmethod to discriminate between original images, and images perturbed with small\\nadversarial examples. We show the effectiveness of this purely geometric\\napproach for detecting small adversarial perturbations in images, and for\\nrecovering the labels of perturbed images.\\n'\n",
      " \"  Many undergraduate students of engineering and the exact sciences have\\ndifficulty with their mathematics courses due to insufficient proficiency in\\nwhat we in this paper have termed clear thinking. We believe that this lack of\\nproficiency is one of the primary causes underlying the common difficulties\\nstudents face, leading to mistakes like the improper use of definitions and the\\nimproper phrasing of definitions, claimes and proofs. We further argue that\\nclear thinking is not a skill that is acquired easily and naturally - it must\\nbe consciously learned and developed. The paper describes, using concrete\\nexamples, how the examination and analysis of classical paradoxes can be a fine\\ntool for developing students' clear thinking. It also looks closely at the\\nparadoxes themselves, and at the various solutions that have been proposed for\\nthem. We believe that the extensive literature on paradoxes has not always\\ngiven clear thinking its due emphasis as an analytical tool. We therefore\\nsuggest that other discipkunes could also benefit from drawing upon the\\nstrategies employed by mathematicians to describe and examine the foundations\\nof the problems they encounter.\\n\"\n",
      " '  We present the validation of a recent fractional mathematical model for\\nerythrocyte sedimentation proposed by Sharma et al. \\\\cite{GMR}. The model uses\\na Caputo fractional derivative to build a time fractional diffusion equation\\nsuitable to predict blood sedimentation rates. This validation was carried out\\nby means of erythrocyte sedimentation tests in laboratory. Data on\\nsedimentation rates (percentages) were analyzed and compared with the\\nanalytical solution of the time fractional diffusion equation. The behavior of\\nthe analytical solution related to each blood sample sedimentation data was\\ndescribed and analyzed.\\n'\n",
      " '  A tower is a sequence of simplicial complexes connected by simplicial maps.\\nWe show how to compute a filtration, a sequence of nested simplicial complexes,\\nwith the same persistent barcode as the tower. Our approach is based on the\\nconing strategy by Dey et al. (SoCG 2014). We show that a variant of this\\napproach yields a filtration that is asymptotically only marginally larger than\\nthe tower and can be efficiently computed by a streaming algorithm, both in\\ntheory and in practice. Furthermore, we show that our approach can be combined\\nwith a streaming algorithm to compute the barcode of the tower via matrix\\nreduction. The space complexity of the algorithm does not depend on the length\\nof the tower, but the maximal size of any subcomplex within the tower.\\n'\n",
      " \"  We study nonlinear dynamics of the Earth's tropical climate system. For that,\\nwe apply a recently developed technique for feature extraction and mode\\ndecomposition of spatiotemporal data generated by ergodic dynamical systems.\\nThe method relies on constructing low-dimensional representations (temporal\\npatterns) of signals using eigenfunctions of Koopman operators governing the\\nevolution of observables in ergodic dynamical systems. We apply this technique\\nto a variety of tropical climate datasets and extract a multiscale hierarchy of\\nspatiotemporal patterns on diurnal to interannual timescales. In particular, we\\ndetect without prefiltering the input data modes operating on intraseasonal and\\nshorter timescales that correspond to propagation of organized convection. We\\ndiscuss the salient properties of these propagating features and in particular\\nwe focus on how the activity of certain types of these traveling patterns is\\nrelated to lower-frequency dynamics. As an extension of this work, we discuss\\ntheir potential predictability based on a range of nonparametric techniques and\\npotential advances related to understanding the deterministic and stochastic\\naspects of the variability of these modes.\\n\"\n",
      " '  The general formula for the probability of radiation of a twisted photon by a\\nclassical current is derived. The general theory of generation of twisted\\nphotons by undulators is developed. It is proved that the probability to record\\na twisted photon produced by a classical current is equal to the average number\\nof twisted photons in a given state. The general formula for the projection of\\nthe total angular momentum of twisted photons with given the energy, the\\nlongitudinal projection of momentum, and the helicity is obtained. The symmetry\\nproperty of the average number of twisted photons produced by a charged\\nparticle moving along a planar trajectory is found. The explicit formulas for\\nthe average number of twisted photons generated by undulators both in the\\ndipole and wiggler regimes are obtained. It is established that, for the\\nforward radiation of an ideal right-handed helical undulator, the harmonic\\nnumber $n$ of the twisted photon coincides with its projection of the total\\nangular momentum $m$. As for the ideal left-handed helical undulator, we obtain\\nthat $m=-n$. It is found that the forward radiation of twisted photons by a\\nplanar undulator obeys the selection rule that $n+m$ is an even number. It\\nturns out that the average number of twisted photons produced by the undulator\\nand detected off the undulator axis is a periodic function of $m$ in a certain\\nspectral band of the quantum numbers $m$.\\n'\n",
      " '  We study the Stochastic Gradient Descent (SGD) method in nonconvex\\noptimization problems from the point of view of approximating diffusion\\nprocesses. We prove rigorously that the diffusion process can approximate the\\nSGD algorithm weakly using the weak form of master equation for probability\\nevolution. In the small step size regime and the presence of omnidirectional\\nnoise, our weak approximating diffusion process suggests the following dynamics\\nfor the SGD iteration starting from a local minimizer (resp.~saddle point): it\\nescapes in a number of iterations exponentially (resp.~almost linearly)\\ndependent on the inverse stepsize. The results are obtained using the theory\\nfor random perturbations of dynamical systems (theory of large deviations for\\nlocal minimizers and theory of exiting for unstable stationary points). In\\naddition, we discuss the effects of batch size for the deep neural networks,\\nand we find that small batch size is helpful for SGD algorithms to escape\\nunstable stationary points and sharp minimizers. Our theory indicates that one\\nshould increase the batch size at later stage for the SGD to be trapped in flat\\nminimizers for better generalization.\\n'\n",
      " '  We study the effect of non-magnetic Zn$^{2+}$ (spin-$0$) and magnetic\\nNi$^{2+}$ (spin-$1$) impurities on the ground state and low-lying excitations\\nof the quasi-one-dimensional spin-$1/2$ Heisenberg antiferromagnet\\nSr$_{2}$CuO$_{3}$ using inelastic neutron scattering, specific heat and bulk\\nmagnetization measurements. We show that 1 \\\\% Ni$^{2+}$ doping in Sr$_2$CuO$_3$\\nresults in a sizable spin gap in the spinon excitations, analogous to the case\\nof Ni-doped SrCuO$_2$ previously reported [ref. 1]. However, a similar level of\\nZn$^{2+}$ doping in SrCuO$_2$, investigated here for comparison, did not reveal\\nany signs of a spin gap. Magnetic ordering temperature was found to be\\nsuppressed in the presence of both Zn$^{2+}$ and Ni$^{2+}$ impurities, however,\\nthe rate of suppression due to Ni$^{2+}$ was found to be much more pronounced\\nthan for Zn$^{2+}$. Effect of magnetic field on the ordering temperature is\\ninvestigated. We found that with increasing magnetic field, not only the\\nmagnetic ordering temperature gradually increases but the size of specific heat\\nanomaly associated with the magnetic ordering also progressively enhances,\\nwhich can be qualitatively understood as due to the field induced suppression\\nof quantum fluctuations.\\n'\n",
      " '  We construct the electromagnetically induced transparency (EIT) by\\ndynamically coupling a superradiant state with a subradiant state. The\\nsuperradiant and subradiant states with enhanced and inhibited decay rates act\\nas the excited and metastable states in EIT, respectively. Their energy\\ndifference determined by the distance between the atoms can be measured by the\\nEIT spectra, which renders this method useful in subwavelength metrology. The\\nscheme can also be applied to many atoms in nuclear quantum optics, where the\\ntransparency point due to counter-rotating wave terms can be observed.\\n'\n",
      " '  Efficient and automated classification of phases from minimally processed\\ndata is one goal of machine learning in condensed matter and statistical\\nphysics. Supervised algorithms trained on raw samples of microstates can\\nsuccessfully detect conventional phase transitions via learning a bulk feature\\nsuch as an order parameter. In this paper, we investigate whether neural\\nnetworks can learn to classify phases based on topological defects. We address\\nthis question on the two-dimensional classical XY model which exhibits a\\nKosterlitz-Thouless transition. We find significant feature engineering of the\\nraw spin states is required to convincingly claim that features of the vortex\\nconfigurations are responsible for learning the transition temperature. We\\nfurther show a single-layer network does not correctly classify the phases of\\nthe XY model, while a convolutional network easily performs classification by\\nlearning the global magnetization. Finally, we design a deep network capable of\\nlearning vortices without feature engineering. We demonstrate the detection of\\nvortices does not necessarily result in the best classification accuracy,\\nespecially for lattices of less than approximately 1000 spins. For larger\\nsystems, it remains a difficult task to learn vortices.\\n'\n",
      " \"  We establish quantitative estimates for sampling (dominating) sets in model\\nspaces associated with meromorphic inner functions, i.e. those corresponding to\\nde Branges spaces. Our results encompass the Logvinenko-Sereda-Panejah (LSP)\\nTheorem including Kovrijkine's optimal sampling constants for Paley-Wiener\\nspaces. It also extends Dyakonov's LSP theoremfor model spaces associated with\\nbounded derivative inner functions. Considering meromorphic inner functions\\nallows us tointroduce a new geometric density condition, in terms of which the\\nsampling sets are completely characterized. This, incomparison to Volberg's\\ncharacterization of sampling measures in terms of harmonic measure, enables us\\nto obtain explicitestimates on the sampling constants. The methods combine\\nBaranov-Bernstein inequalities, reverse Carleson measures andRemez inequalities .\\n\"\n",
      " \"  The way we perceive a sound depends on many aspects-- its ecological\\nfrequency, acoustic features, typicality, and most notably, its identified\\nsource. In this paper, we present the HCU400: a dataset of 402 sounds ranging\\nfrom easily identifiable everyday sounds to intentionally obscured artificial\\nones. It aims to lower the barrier for the study of aural phenomenology as the\\nlargest available audio dataset to include an analysis of causal attribution.\\nEach sample has been annotated with crowd-sourced descriptions, as well as\\nfamiliarity, imageability, arousal, and valence ratings. We extend existing\\ncalculations of causal uncertainty, automating and generalizing them with word\\nembeddings. Upon analysis we find that individuals will provide less polarized\\nemotion ratings as a sound's source becomes increasingly ambiguous; individual\\nratings of familiarity and imageability, on the other hand, diverge as\\nuncertainty increases despite a clear negative trend on average.\\n\"\n",
      " '  In voxel-based neuroimage analysis, lesion features have been the main focus\\nin disease prediction due to their interpretability with respect to the related\\ndiseases. However, we observe that there exists another type of features\\nintroduced during the preprocessing steps and we call them \"\\\\textbf{Procedural\\nBias}\". Besides, such bias can be leveraged to improve classification accuracy.\\nNevertheless, most existing models suffer from either under-fit without\\nconsidering procedural bias or poor interpretability without differentiating\\nsuch bias from lesion ones. In this paper, a novel dual-task algorithm namely\\n\\\\emph{GSplit LBI} is proposed to resolve this problem. By introducing an\\naugmented variable enforced to be structural sparsity with a variable splitting\\nterm, the estimators for prediction and selecting lesion features can be\\noptimized separately and mutually monitored by each other following an\\niterative scheme. Empirical experiments have been evaluated on the Alzheimer\\'s\\nDisease Neuroimaging Initiative\\\\thinspace(ADNI) database. The advantage of\\nproposed model is verified by improved stability of selected lesion features\\nand better classification results.\\n'\n",
      " '  Online audio advertising is a particular form of advertising used abundantly\\nin online music streaming services. In these platforms, which tend to host tens\\nof thousands of unique audio advertisements (ads), providing high quality ads\\nensures a better user experience and results in longer user engagement.\\nTherefore, the automatic assessment of these ads is an important step toward\\naudio ads ranking and better audio ads creation. In this paper we propose one\\nway to measure the quality of the audio ads using a proxy metric called Long\\nClick Rate (LCR), which is defined by the amount of time a user engages with\\nthe follow-up display ad (that is shown while the audio ad is playing) divided\\nby the impressions. We later focus on predicting the audio ad quality using\\nonly acoustic features such as harmony, rhythm, and timbre of the audio,\\nextracted from the raw waveform. We discuss how the characteristics of the\\nsound can be connected to concepts such as the clarity of the audio ad message,\\nits trustworthiness, etc. Finally, we propose a new deep learning model for\\naudio ad quality prediction, which outperforms the other discussed models\\ntrained on hand-crafted features. To the best of our knowledge, this is the\\nfirst large-scale audio ad quality prediction study.\\n'\n",
      " '  We investigate scaling properties of human brain functional networks in the\\nresting-state. Analyzing network degree distributions, we statistically test\\nwhether their tails scale as power-law or not. Initial studies, based on\\nleast-squares fitting, were shown to be inadequate for precise estimation of\\npower-law distributions. Subsequently, methods based on maximum-likelihood\\nestimators have been proposed and applied to address this question.\\nNevertheless, no clear consensus has emerged, mainly because results have shown\\nsubstantial variability depending on the data-set used or its resolution. In\\nthis study, we work with high-resolution data (10K nodes) from the Human\\nConnectome Project and take into account network weights. We test for the\\npower-law, exponential, log-normal and generalized Pareto distributions. Our\\nresults show that the statistics generally do not support a power-law, but\\ninstead these degree distributions tend towards the thin-tail limit of the\\ngeneralized Pareto model. This may have implications for the number of hubs in\\nhuman brain functional networks.\\n'\n",
      " '  The problem of class imbalance along with class-overlapping has become a\\nmajor issue in the domain of supervised learning. Most supervised learning\\nalgorithms assume equal cardinality of the classes under consideration while\\noptimizing the cost function and this assumption does not hold true for\\nimbalanced datasets which results in sub-optimal classification. Therefore,\\nvarious approaches, such as undersampling, oversampling, cost-sensitive\\nlearning and ensemble based methods have been proposed for dealing with\\nimbalanced datasets. However, undersampling suffers from information loss,\\noversampling suffers from increased runtime and potential overfitting while\\ncost-sensitive methods suffer due to inadequately defined cost assignment\\nschemes. In this paper, we propose a novel boosting based method called\\nLIUBoost. LIUBoost uses under sampling for balancing the datasets in every\\nboosting iteration like RUSBoost while incorporating a cost term for every\\ninstance based on their hardness into the weight update formula minimizing the\\ninformation loss introduced by undersampling. LIUBoost has been extensively\\nevaluated on 18 imbalanced datasets and the results indicate significant\\nimprovement over existing best performing method RUSBoost.\\n'\n",
      " '  We propose the use of Bayesian networks, which provide both a mean value and\\nan uncertainty estimate as output, to enhance the safety of learned control\\npolicies under circumstances in which a test-time input differs significantly\\nfrom the training set. Our algorithm combines reinforcement learning and\\nend-to-end imitation learning to simultaneously learn a control policy as well\\nas a threshold over the predictive uncertainty of the learned model, with no\\nhand-tuning required. Corrective action, such as a return of control to the\\nmodel predictive controller or human expert, is taken when the uncertainty\\nthreshold is exceeded. We validate our method on fully-observable and\\nvision-based partially-observable systems using cart-pole and autonomous\\ndriving simulations using deep convolutional Bayesian neural networks. We\\ndemonstrate that our method is robust to uncertainty resulting from varying\\nsystem dynamics as well as from partial state observability.\\n'\n",
      " '  This study covers an analytical approach to calculate positively invariant\\nsets of dynamical systems. Using Lyapunov techniques and quantifier elimination\\nmethods, an automatic procedure for determining bounds in the state space as an\\nenclosure of attractors is proposed. The available software tools permit an\\nalgorithmizable process, which normally requires a good insight into the\\nsystems dynamics and experience. As a result we get an estimation of the\\nattractor, whose conservatism only results from the initial choice of the\\nLyapunov candidate function. The proposed approach is illustrated on the\\nwell-known Lorenz system.\\n'\n",
      " '  If the electroweak sector of the standard model is described by classically\\nconformal dynamics, the early Universe evolution can be substantially altered.\\nIt is already known that---contrarily to the standard model case---a first\\norder electroweak phase transition may occur. Here we show that, depending on\\nthe model parameters, a dramatically different scenario may happen: A\\nfirst-order, six massless quark QCD phase transition occurs first, which then\\ntriggers the electroweak symmetry breaking. We derive the necessary conditions\\nfor this dynamics to occur, using the specific example of the classically\\nconformal B-L model. In particular, relatively light weakly coupled particles\\nare predicted, with implications for collider searches. This scenario is also\\npotentially rich in cosmological consequences, such as renewed possibilities\\nfor electroweak baryogenesis, altered dark matter production, and gravitational\\nwave production, as we briefly comment upon.\\n'\n",
      " '  In recent years, coverage-based greybox fuzzing has proven itself to be one\\nof the most effective techniques for finding security bugs in practice.\\nParticularly, American Fuzzy Lop (AFL for short) is deemed to be a great\\nsuccess in fuzzing relatively simple test inputs. Unfortunately, when it meets\\nstructured test inputs such as XML and JavaScript, those grammar-blind trimming\\nand mutation strategies in AFL hinder the effectiveness and efficiency.\\nTo this end, we propose a grammar-aware coverage-based greybox fuzzing\\napproach to fuzz programs that process structured inputs. Given the grammar\\n(which is often publicly available) of test inputs, we introduce a\\ngrammar-aware trimming strategy to trim test inputs at the tree level using the\\nabstract syntax trees (ASTs) of parsed test inputs. Further, we introduce two\\ngrammar-aware mutation strategies (i.e., enhanced dictionary-based mutation and\\ntree-based mutation). Specifically, tree-based mutation works via replacing\\nsubtrees using the ASTs of parsed test inputs. Equipped with grammar-awareness,\\nour approach can carry the fuzzing exploration into width and depth.\\nWe implemented our approach as an extension to AFL, named Superion; and\\nevaluated the effectiveness of Superion on real-life large-scale programs (a\\nXML engine libplist and three JavaScript engines WebKit, Jerryscript and\\nChakraCore). Our results have demonstrated that Superion can improve the code\\ncoverage (i.e., 16.7% and 8.8% in line and function coverage) and bug-finding\\ncapability (i.e., 31 new bugs, among which we discovered 21 new vulnerabilities\\nwith 16 CVEs assigned and 3.2K USD bug bounty rewards received) over AFL and\\njsfunfuzz. We also demonstrated the effectiveness of our grammar-aware trimming\\nand mutation.\\n'\n",
      " \"  The Black-Litterman model combines investors' personal views with historical\\ndata and gives optimal portfolio weights. In this paper we will introduce the\\noriginal Black-Litterman model (section 1), we will modify the model such that\\nit fits in a Bayesian framework by considering the investors' personal views to\\nbe a direct prior on the means of the returns and by adding a typical Inverse\\nWishart prior on the covariance matrix of the returns (section 2). Lastly, we\\nwill use Leonard and Hsu's (1992) idea of adding a prior on the logarithm of\\nthe covariance matrix (section 3). Sensitivity simulations for the level of\\nconfidence that the investor has in their own personal views were performed and\\nperformance of the models was assessed on a test data set consisting of returns\\nover the month of January 2018.\\n\"\n",
      " '  This project serves to analyze the behavior of Ricci Flow in five dimensional\\nmanifolds. Ricci Flow was introduced by Richard Hamilton in 1982 and was an\\nessential tool in proving the Geometrization and Poincare Conjectures. In\\ngeneral, Ricci Flow is a nonlinear PDE whose solutions are rather difficult to\\ncalculate; however, in a homogeneous manifold, the Ricci Flow reduces to an\\nODE. The behavior of Ricci Flow in two, three, and four dimensional homogenous\\nmanifolds has been calculated and is well understood. The work presented here\\nwill describe efforts to better understand the behavior of Ricci Flow in a\\ncertain class of five dimensional homogeneous manifolds.\\n'\n",
      " '  The problem of multi-speaker localization is formulated as a multi-class\\nmulti-label classification problem, which is solved using a convolutional\\nneural network (CNN) based source localization method. Utilizing the common\\nassumption of disjoint speaker activities, we propose a novel method to train\\nthe CNN using synthesized noise signals. The proposed localization method is\\nevaluated for two speakers and compared to a well-known steered response power\\nmethod.\\n'\n",
      " \"  In this paper, there are obtained growth estimates of entire in\\n$\\\\mathbb{C}^n$ function of bounded $\\\\mathbf{L}$-index in joint variables. They\\ndescribe the behaviour of maximum modulus of entire function on a skeleton in a\\npolydisc by behaviour of the function $\\\\mathbf{L}(z)=(l_1(z),\\\\ldots,l_n(z)),$\\nwhere for every $j\\\\in\\\\{1,\\\\ldots, n\\\\}$ \\\\ $l_j:\\\\mathbb{C}^n\\\\to \\\\mathbb{R}_+$ is a\\ncontinuous function. We generalised known results of W. K. Hayman, M. M.\\nSheremeta, A. D. Kuzyk, M. T. Borduyak, T. O. Banakh and V. O. Kushnir for a\\nwider class of functions $\\\\mathbf{L}.$ One of our estimates is sharper even for\\nentire in $\\\\mathbb{C}$ functions of bounded $l$-index than Sheremeta's\\nestimate.\\n\"\n",
      " '  The purpose of this paper is to explore a resolution for the Faint Young Sun\\nParadox that has been mostly rejected by the community, namely the possibility\\nof a somewhat more massive young Sun with a large mass loss rate sustained for\\ntwo to three billion years. This would make the young Sun bright enough to keep\\nboth the terrestrial and Martian oceans from freezing, and thus resolve the\\nparadox. It is found that a large and sustained mass loss is consistent with\\nthe well observed spin-down rate of Sun-like stars, and indeed may be required\\nfor it. It is concluded that a more massive young Sun must be considered a\\nplausible hypothesis.\\n'\n",
      " '  We study the statistics of the kinetic (or equivalently potential) energy for\\n$N$ non-interacting fermions in a $1d$ harmonic trap of frequency $\\\\omega$, at\\nfinite temperature $T$. Remarkably, we find an exact solution for the full\\ndistribution of the kinetic energy, at any temperature $T$ and for any $N$,\\nusing a non-trivial mapping to an integrable Calogero-Moser-Sutherland model.\\nAs a function of temperature $T$, and for large $N$, we identify: (i) a quantum\\nregime, for $T \\\\sim \\\\hbar \\\\omega$, where quantum fluctuations dominate and (ii)\\na thermal regime, for $T \\\\sim N \\\\hbar \\\\omega$, governed by thermal\\nfluctuations. We show how the mean, the variance as well as the large deviation\\nfunction associated with the distribution of the kinetic energy cross over from\\nthe quantum to the thermal regime as temperature increases.\\n'\n",
      " '  With the intention of bringing uniformity to Bengali text entry research,\\nhere we present a new approach for calculating the most popular English text\\nentry evaluation metrics for Bengali. To demonstrate our approach, we conducted\\na user study where we evaluated four popular Bengali text entry techniques.\\n'\n",
      " '  Many problems in machine learning are naturally expressed in the language of\\nundirected graphical models. Here, we propose black-box learning and inference\\nalgorithms for undirected models that optimize a variational approximation to\\nthe log-likelihood of the model. Central to our approach is an upper bound on\\nthe log-partition function parametrized by a function q that we express as a\\nflexible neural network. Our bound makes it possible to track the partition\\nfunction during learning, to speed-up sampling, and to train a broad class of\\nhybrid directed/undirected models via a unified variational inference\\nframework. We empirically demonstrate the effectiveness of our method on\\nseveral popular generative modeling datasets.\\n'\n",
      " '  The stability of charge ordered phases is doping dependent, with different\\nmaterials having particularly stable ordered phases. In the half filled charge\\nordered phases of the cuprates this occurs at one eighth doping, whereas in\\ncharge-stripe ordered La2-xSrxNiO4+delta there is enhanced stability at one\\nthird doping. In this paper we discuss the known details of the charge-stripe\\norder in La2-xSrxNiO4+delta, and how these properties lead to the one third\\ndoping stability.\\n'\n",
      " \"  In this paper we develop a novel framework for numerically solving scalar\\nconservation laws in one space dimension. Utilizing the method of\\ncharacteristics in conjunction with the equal area principle we develop an\\napproach where the weak solution is obtained purely as the solution of a\\nparametric interpolation problem. As this framework hinges on the validity of\\nthe equal area principle, we provide a rigorous discussion of the equal area\\nprinciple and show that, indeed, the equal area principle is equivalent to the\\nRankine-Hugoniot condition, within the specific context studied in this paper.\\nCombining these results with properties of the characteristic equations yields\\nthe desired setting to define the equivalent parametric interpolation problem.\\nWe conclude by applying this framework to Burgers' equation and show how one\\nobtains machine precision in the shock position when the initial condition can\\nbe represented exactly in the chosen space of parametric polynomials.\\n\"\n",
      " '  Learning in models with discrete latent variables is challenging due to high\\nvariance gradient estimators. Generally, approaches have relied on control\\nvariates to reduce the variance of the REINFORCE estimator. Recent work (Jang\\net al. 2016, Maddison et al. 2016) has taken a different approach, introducing\\na continuous relaxation of discrete variables to produce low-variance, but\\nbiased, gradient estimates. In this work, we combine the two approaches through\\na novel control variate that produces low-variance, \\\\emph{unbiased} gradient\\nestimates. Then, we introduce a modification to the continuous relaxation and\\nshow that the tightness of the relaxation can be adapted online, removing it as\\na hyperparameter. We show state-of-the-art variance reduction on several\\nbenchmark generative modeling tasks, generally leading to faster convergence to\\na better final log-likelihood.\\n'\n",
      " '  We propose a new reconstruction operator that aims to recover the missing\\nparts of a function given the observed parts. This new operator belongs to a\\nnew, very large class of functional operators which includes the classical\\nregression operators as a special case. We show the optimality of our\\nreconstruction operator and demonstrate that the usually considered regression\\noperators generally cannot be optimal reconstruction operators. Our estimation\\ntheory allows for autocorrelated functional data and considers the practically\\nrelevant situation in which each of the $n$ functions is observed at $m_i$,\\n$i=1,\\\\dots,n$, discretization points. We derive rates of consistency for our\\nnonparametric estimation procedures using a double asymptotic. For data\\nsituations, as in our real data application where $m_i$ is considerably smaller\\nthan $n$, we show that our functional principal components based estimator can\\nprovide better rates of convergence than conventional nonparametric smoothing\\nmethod.\\n'\n",
      " '  The restricted maximum likelihood method enhances popularity of maximum\\nlikelihood methods for variance component analysis on large scale unbalanced\\ndata. As the high throughput biological data sets and the emerged science on\\nuncertainty quantification, such a method receives increasing attention.\\nEstimating the unknown variance parameters with restricted maximum likelihood\\nmethod usually requires an nonlinear iterative method. Therefore proper\\nformulae for the log-likelihood function and its derivatives play an essential\\nrole in practical algorithm design. It is our aim to provide a mathematical\\nintroduction to this method, and supply a self-contained derivation on some\\navailable formulae used in practical algorithms. Some new proof are supplied.\\n'\n",
      " \"  Network analysis has driven key developments in research on animal behaviour\\nby providing quantitative methods to study the social structures of animal\\ngroups and populations. A recent formalism, known as \\\\emph{multilayer network\\nanalysis}, has advanced the study of multifaceted networked systems in many\\ndisciplines. It offers novel ways to study and quantify animal behaviour as\\nconnected 'layers' of interactions. In this article, we review common questions\\nin animal behaviour that can be studied using a multilayer approach, and we\\nlink these questions to specific analyses. We outline the types of behavioural\\ndata and questions that may be suitable to study using multilayer network\\nanalysis. We detail several multilayer methods, which can provide new insights\\ninto questions about animal sociality at individual, group, population, and\\nevolutionary levels of organisation. We give examples for how to implement\\nmultilayer methods to demonstrate how taking a multilayer approach can alter\\ninferences about social structure and the positions of individuals within such\\na structure. Finally, we discuss caveats to undertaking multilayer network\\nanalysis in the study of animal social networks, and we call attention to\\nmethodological challenges for the application of these approaches. Our aim is\\nto instigate the study of new questions about animal sociality using the new\\ntoolbox of multilayer network analysis.\\n\"\n",
      " '  We address the problem of sparse recovery in an online setting, where random\\nlinear measurements of a sparse signal are revealed sequentially and the\\nobjective is to recover the underlying signal. We propose a reweighted least\\nsquares (RLS) algorithm to solve the problem of online sparse reconstruction,\\nwherein a system of linear equations is solved using conjugate gradient with\\nthe arrival of every new measurement. The proposed online algorithm is useful\\nin a setting where one seeks to design a progressive decoding strategy to\\nreconstruct a sparse signal from linear measurements so that one does not have\\nto wait until all measurements are acquired. Moreover, the proposed algorithm\\nis also useful in applications where it is infeasible to process all the\\nmeasurements using a batch algorithm, owing to computational and storage\\nconstraints. It is not needed a priori to collect a fixed number of\\nmeasurements; rather one can keep collecting measurements until the quality of\\nreconstruction is satisfactory and stop taking further measurements once the\\nreconstruction is sufficiently accurate. We provide a proof-of-concept by\\ncomparing the performance of our algorithm with the RLS-based batch\\nreconstruction strategy, known as iteratively reweighted least squares (IRLS),\\non natural images. Experiments on a recently proposed focal plane array-based\\nimaging setup show up to 1 dB improvement in output peak signal-to-noise ratio\\nas compared with the total variation-based reconstruction.\\n'\n",
      " '  A classical theorem of I. Schur states that the degree of any irreducible\\ncomplex representation of a finite group $G$ divides the order of\\n$G/\\\\mathscr{Z} G$, where $\\\\mathscr{Z} G$ is the center $G$. This note discusses\\nsimilar divisibility results for certain classes of Hopf algebras.\\n'\n",
      " '  We present a general technique for approximating bicriteria minimization\\nproblems with positive-valued, polynomially computable objective functions.\\nGiven $0<\\\\epsilon\\\\leq1$ and a polynomial-time $\\\\alpha$-approximation algorithm\\nfor the corresponding weighted sum problem, we show how to obtain a bicriteria\\n$(\\\\alpha\\\\cdot(1+2\\\\epsilon),\\\\alpha\\\\cdot(1+\\\\frac{2}{\\\\epsilon}))$-approximation\\nalgorithm for the budget-constrained problem whose running time is polynomial\\nin the encoding length of the input and linear in $\\\\frac{1}{\\\\epsilon}$.\\nMoreover, we show that our method can be extended to compute an\\n$(\\\\alpha\\\\cdot(1+2\\\\epsilon),\\\\alpha\\\\cdot(1+\\\\frac{2}{\\\\epsilon}))$-approximate\\nPareto curve under the same assumptions. Our technique applies to many\\nminimization problems to which most previous algorithms for computing\\napproximate Pareto curves cannot be applied because the corresponding gap\\nproblem is $\\\\textsf{NP}$-hard to solve. For maximization problems, however, we\\nshow that approximation results similar to the ones presented here for\\nminimization problems are impossible to obtain in polynomial time unless\\n$\\\\textsf{P}=\\\\textsf{NP}$.\\n'\n",
      " '  The theory of renormalized energy spectrum of localized quasi-particle\\ninteracting with polarization phonons at finite temperature is developed within\\nthe Feynman-Pines diagram technique. The created computer program effectively\\ntakes into account multi-phonon processes, exactly defining all diagrams of\\nmass operator together with their analytical expressions in arbitrary order\\nover the coupling constant. Now it is possible to separate the pole and\\nnon-pole mass operator terms and perform a partial summing of their main terms.\\nThe renormalized spectrum of the system is obtained within the solution of\\ndispersion equation in the vicinity of the main state where the high- and\\nlow-energy complexes of bound states are observed. The properties of the\\nspectrum are analyzed depending on the coupling constant and the temperature.\\n'\n",
      " '  A $\\\\mathit{\\\\text{moving frame}}$ at a rational curve is a basis of vectors\\nmoving along the curve. When the rational curve is given parametrically by a\\nrow vector $\\\\mathbf{a}$ of univariate polynomials, a moving frame with\\nimportant algebraic properties can be defined by the columns of an invertible\\npolynomial matrix $P$, such that $\\\\mathbf{a} P=[\\\\gcd(\\\\mathbf{a}),0\\\\ldots,0]$. A\\n$\\\\mathit{\\\\text{degree-optimal moving frame}}$ has column-wise minimal degree,\\nwhere the degree of a column is defined to be the maximum of the degrees of its\\ncomponents. Algebraic moving frames are closely related to the univariate\\nversions of the celebrated Quillen-Suslin problem, effective Nullstellensatz\\nproblem, and syzygy module problem. However, this paper appears to be the first\\ndevoted to finding an efficient algorithm for constructing a degree-optimal\\nmoving frame, a property desirable in various applications. We compare our\\nalgorithm with other possible approaches, based on already available\\nalgorithms, and show that it is more efficient. We also establish several new\\ntheoretical results concerning the degrees of an optimal moving frame and its\\ncomponents. In addition, we show that any deterministic algorithm for computing\\na degree-optimal algebraic moving frame can be augmented so that it assigns a\\ndegree-optimal moving frame in a $GL_n(\\\\mathbb{K})$-equivariant manner. This\\ncrucial property of classical geometric moving frames, in combination with the\\nalgebraic properties, can be exploited in various problems.\\n'\n",
      " '  We characterize the communication complexity of the following distributed\\nestimation problem. Alice and Bob observe infinitely many iid copies of\\n$\\\\rho$-correlated unit-variance (Gaussian or $\\\\pm1$ binary) random variables,\\nwith unknown $\\\\rho\\\\in[-1,1]$. By interactively exchanging $k$ bits, Bob wants\\nto produce an estimate $\\\\hat\\\\rho$ of $\\\\rho$. We show that the best possible\\nperformance (optimized over interaction protocol $\\\\Pi$ and estimator $\\\\hat\\n\\\\rho$) satisfies $\\\\inf_{\\\\Pi,\\\\hat\\\\rho}\\\\sup_\\\\rho \\\\mathbb{E} [|\\\\rho-\\\\hat\\\\rho|^2] =\\n\\\\Theta(\\\\tfrac{1}{k})$. Furthermore, we show that the best possible unbiased\\nestimator achieves performance of $1+o(1)\\\\over {2k\\\\ln 2}$. Curiously, thus,\\nrestricting communication to $k$ bits results in (order-wise) similar minimax\\nestimation error as restricting to $k$ samples. Our results also imply an\\n$\\\\Omega(n)$ lower bound on the information complexity of the Gap-Hamming\\nproblem, for which we show a direct information-theoretic proof.\\nNotably, the protocol achieving (almost) optimal performance is one-way\\n(non-interactive). For one-way protocols we also prove the\\n$\\\\Omega(\\\\tfrac{1}{k})$ bound even when $\\\\rho$ is restricted to any small open\\nsub-interval of $[-1,1]$ (i.e. a local minimax lower bound). %We do not know if\\nthis local behavior remains true in the interactive setting. Our proof\\ntechniques rely on symmetric strong data-processing inequalities, various\\ntensorization techniques from information-theoretic interactive\\ncommon-randomness extraction, and (for the local lower bound) on the\\nOtto-Villani estimate for the Wasserstein-continuity of trajectories of the\\nOrnstein-Uhlenbeck semigroup.\\n'\n",
      " '  A pupil plane wavefront reconstruction procedure is proposed based on\\nanalysis of a sequence of focal plane images corresponding to a sequence of\\nrandom pupil plane phase probes. The developed method provides the unique\\nnontrivial solution of wavefront retrieval problem and shows global convergence\\nto this solution demonstrated using a Gerchberg-Saxton implementation. The\\nmethod is general and can be used in any optical system that includes\\ndeformable mirrors for active/adaptive wavefront correction. The presented\\nnumerical simulation and lab experimental results show low noise sensitivity,\\nhigh reliability and robustness of the proposed approach for high quality\\noptical wavefront restoration. Laboratory experiments have shown $\\\\lambda$/14\\nrms accuracy in retrieval of a poked DM actuator fiducial pattern with spatial\\nresolution of 20-30$~\\\\mu$m that is comparable with accuracy of direct\\nhigh-resolution interferometric measurements.\\n'\n",
      " '  In the present study we analytically investigate the deformation and bulk\\nrheology of a dilute emulsion of surfactant-laden droplets suspended in a\\nlinear flow. We use an asymptotic approach to predict the effect of surfactant\\ndistribution on the deformation of a single droplet as well as the effective\\nshear and extensional viscosity for the dilute emulsion. The non-uniform\\ndistribution of surfactants due to the bulk flow results in the generation of a\\nMarangoni stress which affects both the deformation as well as the bulk\\nrheology of the suspension. The present analysis is done for the limiting case\\nwhen the surfactant transport is dominated by the surface diffusion relative to\\nsurface convection. As an example, we have used two commonly encountered bulk\\nflows, namely, uniaxial extensional flow and simple shear flow. With the\\nassumption of negligible inertial forces present in either of the phases, we\\nare able to show that both the surfactant concentration on the droplet surface\\nas well as the ratio of viscosity of the droplet phase with respect to the\\nsuspending fluid has a significant effect on the droplet deformation as well as\\nthe bulk rheology. It is seen that increase in the non-uniformity in surfactant\\ndistribution on the droplet surface results in a higher droplet deformation and\\na higher effective viscosity for either of linear flows considered. For the\\ncase of simple shear flow, surfactant distribution is found to have no effect\\non the inclination angle, however, a higher viscosity ratio predicts the\\ndroplet to be more aligned towards the direction of flow.\\n'\n",
      " '  Index-less Indexed Flash Code (ILIFC) is a coding scheme for flash memories,\\nin which one bit of a data sequence is stored in a slice consisting of several\\ncells but the index of the bit is stored implicitly. Although several modified\\nILIFC schemes have been proposed, in this research we consider an ILIFC with\\ninversion cells(I-ILIFC). The I-ILIFC reduces the total number of cell level\\nchanges at each writing request. Computer simulation is used to show that the\\nI-ILIFC improves the average performance of the ILIFC in many cases. This paper\\npresents our derivation of the lower bounds on the number of writing operations\\nby I-ILIFC and shows that the worst-case performance of the I-ILIFC is better\\nthan that of the ILIFC if the code length is sufficiently large. Additionally,\\nwe consider the tight lower bounds thereon. The results show that the threshold\\nof the code length that determines whether the I-ILIFC improves the worst-case\\nperformance of the ILIFC is smaller than that in the first lower bounds.\\n'\n",
      " '  In this paper, we introduce the problem of denoting and deriving the\\ncomplexity of workflows (plans, schedules) in collaborative, planner-assisted\\nsettings where humans and agents are trying to jointly solve a task. The\\ninteractions -- and hence the workflows that connect the human and the agents\\n-- may differ according to the domain and the kind of agents. We adapt insights\\nfrom prior work in human-agent teaming and workflow analysis to suggest metrics\\nfor workflow complexity. The main motivation behind this work is to highlight\\nmetrics for human comprehensibility of plans and schedules. The planning\\ncommunity has seen its fair share of work on the synthesis of plans that take\\ndiversity into account -- what value do such plans hold if their generation is\\nnot guided at least in part by metrics that reflect the ease of engaging with\\nand using those plans?\\n'\n",
      " '  The Cherenkov Telescope Array, CTA, will be the major global observatory for\\nvery high energy gamma-ray astronomy over the next decade and beyond. The\\nscientific potential of CTA is extremely broad: from understanding the role of\\nrelativistic cosmic particles to the search for dark matter. CTA is an explorer\\nof the extreme universe, probing environments from the immediate neighbourhood\\nof black holes to cosmic voids on the largest scales. Covering a huge range in\\nphoton energy from 20 GeV to 300 TeV, CTA will improve on all aspects of\\nperformance with respect to current instruments.\\nThe observatory will operate arrays on sites in both hemispheres to provide\\nfull sky coverage and will hence maximize the potential for the rarest\\nphenomena such as very nearby supernovae, gamma-ray bursts or gravitational\\nwave transients. With 99 telescopes on the southern site and 19 telescopes on\\nthe northern site, flexible operation will be possible, with sub-arrays\\navailable for specific tasks. CTA will have important synergies with many of\\nthe new generation of major astronomical and astroparticle observatories.\\nMulti-wavelength and multi-messenger approaches combining CTA data with those\\nfrom other instruments will lead to a deeper understanding of the broad-band\\nnon-thermal properties of target sources.\\nThe CTA Observatory will be operated as an open, proposal-driven observatory,\\nwith all data available on a public archive after a pre-defined proprietary\\nperiod. Scientists from institutions worldwide have combined together to form\\nthe CTA Consortium. This Consortium has prepared a proposal for a Core\\nProgramme of highly motivated observations. The programme, encompassing\\napproximately 40% of the available observing time over the first ten years of\\nCTA operation, is made up of individual Key Science Projects (KSPs), which are\\npresented in this document.\\n'\n",
      " '  Let M be a closed symplectic manifold of volume V. We say that the symplectic\\npackings of M by ellipsoids are unobstructed if any collection of disjoint\\nsymplectic ellipsoids (possibly of different sizes) of total volume less than V\\nadmits a symplectic embedding to M. We show that the symplectic packings by\\nellipsoids are unobstructed for all even-dimensional tori equipped with Kahler\\nsymplectic forms and all closed hyperkahler manifolds of maximal holonomy, or,\\nmore generally, for closed Campana simple manifolds (that is, Kahler manifolds\\nthat are not unions of their complex subvarieties), as well as for any closed\\nKahler manifold which is a limit of Campana simple manifolds in a smooth\\ndeformation. The proof involves the construction of a Kahler resolution of a\\nKahler orbifold with isolated singularities and relies on the results of\\nDemailly-Paun and Miyaoka on Kahler cohomology classes.\\n'\n",
      " '  For generic systems exhibiting power law behaviors, and hence multiscale\\ndependencies, we propose a new, and yet simple, tool to analyze multifractality\\nand intermittency, after noticing that these concepts are directly related to\\nthe deformation of a probability density function from Gaussian at large scales\\nto non-Gaussian at smaller scales. Our framework is based on information\\ntheory, and uses Shannon entropy and Kullback-Leibler divergence. We propose an\\nextensive application to three-dimensional fully developed turbulence, seen\\nhere as a paradigmatic complex system where intermittency was historically\\ndefined. Moreover, the concepts of scale invariance and multifractality were\\nextensively studied in this field and, most importantly, benchmarked. We\\ncompute our measure on experimental Eulerian velocity measurements, as well as\\non synthetic processes and a phenomenological model of fluid turbulence.Our\\napproach is very general and does not require any underlying model of the\\nsystem, although it can probe the relevance of such a model.\\n'\n",
      " '  Circuit QED techniques have been instrumental to manipulate and probe with\\nexquisite sensitivity the quantum state of superconducting quantum bits coupled\\nto microwave cavities. Recently, it has become possible to fabricate new\\ndevices where the superconducting quantum bits are replaced by hybrid\\nmesoscopic circuits combining nanoconductors and metallic reservoirs. This\\nmesoscopic QED provides a new experimental playground to study the light-matter\\ninteraction in electronic circuits. Here, we present the experimental state of\\nthe art of Mesoscopic QED and its theoretical description. A first class of\\nexperiments focuses on the artificial atom limit, where some quasiparticles are\\ntrapped in nanocircuit bound states. In this limit, the Circuit QED techniques\\ncan be used to manipulate and probe electronic degrees of freedom such as\\nconfined charges, spins, or Andreev pairs. A second class of experiments\\nconsists in using cavity photons to reveal the dynamics of electron tunneling\\nbetween a nanoconductor and fermionic reservoirs. For instance, the Kondo\\neffect, the charge relaxation caused by grounded metallic contacts, and the\\nphoto-emission caused by voltage-biased reservoirs have been studied. The\\ntunnel coupling between nanoconductors and fermionic reservoirs also enable one\\nto obtain split Cooper pairs, or Majorana bound states. Cavity photons\\nrepresent a qualitatively new tool to study these exotic condensed matter\\nstates.\\n'\n",
      " '  In the Standard Model (SM) we calculate the decay rate of the neutron\\nradiative beta decay to order \"O(\\\\alpha^2/\\\\pi^2 ~ 10^{-5})\", where \"\\\\alpha$\"is\\nthe fine--structure constant, and radiative corrections to order \"O(\\\\alpha/\\\\pi\\n~ 10^{-3})\". The obtained results together with the recent analysis of the\\nneutron radiative beta decay to next-to-leading order in the large proton-mass\\nexpansion, performed by Ivanov et al. Phys. Rev. D95, 033007 (2017), describe\\nrecent experimental data by the RDK II Collaboration (Bales et al., Phys. Rev.\\nLett. 116, 242501 (2016)) within 1.5 standard deviations. We argue a\\nsubstantial influence of strong low-energy interactions of hadrons coupled to\\nphotons on the properties of the amplitude of the neutron radiative beta decay\\nunder gauge transformations of real and virtual photons.\\n'\n",
      " '  Many important complex networks, including critical infrastructure and\\nemerging industrial automation systems, are becoming increasingly intricate\\nwebs of interacting feedback control loops. A fundamental concern is to\\nquantify the control properties and performance limitations of the network as a\\nfunction of its dynamical structure and control architecture. We study\\nperformance bounds for networks in terms of optimal feedback control costs. We\\nprovide a set of complementary bounds as a function of the system dynamics and\\nactuator structure. For unstable network dynamics, we characterize a tradeoff\\nbetween feedback control performance and the number of control inputs, in\\nparticular showing that optimal cost can increase exponentially with the size\\nof the network. We also derive a bound on the performance of the worst-case\\nactuator subset for stable networks, providing insight into dynamics properties\\nthat affect the potential efficacy of actuator selection. We illustrate our\\nresults with numerical experiments that analyze performance in regular and\\nrandom networks.\\n'\n",
      " '  Diffusion and flow-driven instability, or transport-driven instability, is\\none of the central mechanisms to generate inhomogeneous gradient of\\nconcentrations in spatially distributed chemical systems. However, verifying\\nthe transport-driven instability of reaction-diffusion-advection systems\\nrequires checking the Jacobian eigenvalues of infinitely many Fourier modes,\\nwhich is computationally intractable. To overcome this limitation, this paper\\nproposes mathematical optimization algorithms that determine the\\nstability/instability of reaction-diffusion-advection systems by finite steps\\nof algebraic calculations. Specifically, the stability/instability analysis of\\nFourier modes is formulated as a sum-of-squares (SOS) optimization program,\\nwhich is a class of convex optimization whose solvers are widely available as\\nsoftware packages. The optimization program is further extended for facile\\ncomputation of the destabilizing spatial modes. This extension allows for\\npredicting and designing the shape of concentration gradient without simulating\\nthe governing equations. The streamlined analysis process of self-organized\\npattern formation is demonstrated with a simple illustrative reaction model\\nwith diffusion and advection.\\n'\n",
      " '  We study collective modes in a classical system of particles with repulsive\\ninverse-power-law (IPL) interactions in the fluid phase, near the fluid-solid\\ncoexistence (IPL melts). The IPL exponent is varied from $n=10$ to $n=100$ to\\nmimic the transition from moderately soft to hard-sphere-like interactions. We\\ncompare the longitudinal dispersion relations obtained using molecular dynamic\\n(MD) simulations with those calculated using the quasi-crystalline\\napproximation (QCA) and find that this simple theoretical approach becomes\\ngrossly inaccurate for $n\\\\gtrsim 20$. Similarly, conventional expressions for\\nhigh-frequency (instantaneous) elastic moduli, predicting their divergence as\\n$n$ increases, are meaningless in this regime. Relations of the longitudinal\\nand transverse elastic velocities of the QCA model to the adiabatic sound\\nvelocity, measured in MD simulations, are discussed for the regime where QCA is\\napplicable. Two potentially useful freezing indicators for classical particle\\nsystems with steep repulsive interactions are discussed.\\n'\n",
      " '  Today when many practitioners run basic NLP on the entire web and\\nlarge-volume traffic, faster methods are paramount to saving time and energy\\ncosts. Recent advances in GPU hardware have led to the emergence of\\nbi-directional LSTMs as a standard method for obtaining per-token vector\\nrepresentations serving as input to labeling tasks such as NER (often followed\\nby prediction in a linear-chain CRF). Though expressive and accurate, these\\nmodels fail to fully exploit GPU parallelism, limiting their computational\\nefficiency. This paper proposes a faster alternative to Bi-LSTMs for NER:\\nIterated Dilated Convolutional Neural Networks (ID-CNNs), which have better\\ncapacity than traditional CNNs for large context and structured prediction.\\nUnlike LSTMs whose sequential processing on sentences of length N requires O(N)\\ntime even in the face of parallelism, ID-CNNs permit fixed-depth convolutions\\nto run in parallel across entire documents. We describe a distinct combination\\nof network structure, parameter sharing and training procedures that enable\\ndramatic 14-20x test-time speedups while retaining accuracy comparable to the\\nBi-LSTM-CRF. Moreover, ID-CNNs trained to aggregate context from the entire\\ndocument are even more accurate while maintaining 8x faster test time speeds.\\n'\n",
      " '  The SPARC TSO weak memory model is defined axiomatically, with a\\nnon-compositional formulation that makes modular reasoning about programs\\ndifficult. Our denotational approach uses pomsets to provide a compositional\\nsemantics capturing exactly the behaviours permitted by SPARC TSO. It uses\\nbuffered states and an inductive definition of execution to assign an\\ninput-output meaning to pomsets. We show that our denotational account is sound\\nand complete relative to the axiomatic account, that is, that it captures\\nexactly the behaviours permitted by the axiomatic account. Our compositional\\napproach facilitates the study of SPARC TSO and supports modular analysis of\\nprogram behaviour.\\n'\n",
      " '  We construct a class of non-commutative, non-cocommutative, semisimple Hopf\\nalgebras of dimension $2n^2$ and present conditions to define an inner faithful\\naction of these Hopf algebras on quantum polynomial algebras, providing, in\\nthis way, more examples of semisimple Hopf actions which do not factor through\\ngroup actions. Also, under certain condition, we classify the inner faithful\\nHopf actions of the Kac-Paljutkin Hopf algebra of dimension $8$, $H_8$, on the\\nquantum plane.\\n'\n",
      " '  Defect-free SrTiO3 (STO) is a band insulator but Angle Resolved Photoemission\\nSpectroscopy (ARPES) experiments have demonstrated the existence of a nanometer\\nthin two-dimensional electron liquid (2DEG) at the (001) oriented surface of\\nthis compound. The bulk is a trivial insulator, but our theoretical study\\nreveals that the parity of electronic wavefunctions in this 2DEG is inverted in\\nthe vicinity of special points in reciprocal space where the low-energy\\ndispersion consists of four gapped Dirac cones with a tilted and anisotropic\\nshape. This gives rise to linearly dispersing topological edge states at the\\none-dimensional boundary. We propose to probe these modes by measuring the\\nJosephson radiation from gapless bound Andreev states in STO based junctions,\\nas it is predicted that they display distinctive signatures of topology.\\n'\n",
      " \"  We seek the conditions for a {\\\\it steady} mean field galactic dynamo. The\\nparameter set is reduced to those appearing in the $\\\\alpha^2$ and\\n$\\\\alpha/\\\\omega$ dynamo, namely velocity amplitudes, and the ratio of sub-scale\\nhelicity to diffusivity. The parameters can be allowed to vary on conical\\nspirals. We analyze the mean field dynamo equations in terms of scale invariant\\nlogarithmic spiral modes and special exact solutions. Compatible scale\\ninvariant gravitational spiral arms are introduced and illustrated in an\\nappendix, but the detailed dynamical interaction with the magnetic field is\\nleft for another work. As a result of planar magnetic spirals `lifting' into\\nthe halo, multiple sign changes in average rotation measures forming a regular\\npattern on each side of the galactic minor axis, are predicted. Such changes\\nhave recently been detected in the CHANG-ES survey.\\n\"\n",
      " '  In this paper, we generalize the well-known index coding problem to exploit\\nthe structure in the source-data to improve system throughput. In many\\napplications, the data to be transmitted may lie (or can be well approximated)\\nin a low-dimensional subspace. We exploit this low-dimensional structure of the\\ndata using an algebraic framework to solve the index coding problem (referred\\nto as subspace-aware index coding) as opposed to the traditional index coding\\nproblem which is subspace-unaware. Also, we propose an efficient algorithm\\nbased on the alternating minimization approach to obtain near optimal index\\ncodes for both subspace-aware and -unaware cases. Our simulations indicate that\\nunder certain conditions, a significant throughput gain (about 90%) can be\\nachieved by subspace-aware index codes over conventional subspace-unaware index\\ncodes.\\n'\n",
      " '  We study the impact of thermal hysteresis at the first-order\\nstructural/ferroelectric phase transitions on the electrocaloric response in\\nbulk BaTiO$_3$ by performing molecular dynamics simulations for a\\nfirst-principles-based effective Hamiltonian. We demonstrate that the\\nelectrocaloric response can conceptually be separated in two contributions: a\\ntransitional part, stemming from the discontinuous jump in entropy at the first\\norder phase transition, and a configurational part, due to the continuous\\nchange of polarization and entropy within each phase. This latter part\\nincreases with the strength of the applied field, but for small fields it is\\nvery small. In contrast, we find a large temperature change of $\\\\sim 1$ K\\nresulting from the transition entropy, which is essentially independent of the\\nfield strength. However, due to the coexistence region close to the first order\\nphase transition, this large electrocaloric response depends on the thermal\\nhistory of the sample and is generally not reversible. We show that this\\nirreversibility can be overcome by using larger fields.\\n'\n",
      " '  The Collatz problem is one of many names (the Collatz Problem, the Syracuse\\nProblem, the Hailstone Problem, the 3x+1 problem). Most commonly, however, the\\nproblem goes by either the 3x+1 problem or the Collatz problem. In addition to\\nhaving many names, the Collatz problem has many variations, such as those in\\nthe form introduced by Jeffrey Lagarias in 1985. This writing discusses several\\nvariations of the Collatz function which involve the Mersenne numbers.\\nFollowing that, we observe the convergent cycles of these functions which we\\ncan then relate back to the original Collatz 3x+1 function. Lastly, we give a\\nproof of the No Divergent Trajectories Theorem and show why the same cannot be\\nshown for similar functions.\\n'\n",
      " '  We consider the cohomological Hall algebra Y of a Lagrangian substack of the\\nmoduli stack of representations of the preprojective algebra of an arbitrary\\nquiver Q, and its actions on the cohomology of quiver varieties. We conjecture\\nthat Y is equal, after a suitable extension of scalars, to the Yangian\\nintroduced by Maulik and Okounkov, and we construct an embedding of Y in the\\nYangian, intertwining the respective actions of both algebras on the cohomology\\nof quiver varieties.\\n'\n",
      " '  The basic idea behind information algebras is that information comes in\\npieces, each referring to a certain question, that these pieces can be combined\\nor aggregated and that the part relating to a given question can be extracted.\\nThis algebraic structure can be given different forms. Questions were\\noriginally represented by subsets of variables. Pieces of information were then\\nrepresented by valuations associated with the domains of variables. This leads\\nto an algebraic structure called valuation algebras. The basic axiomatics of\\nthis algebraic structure was in essence proposed by Shenoy and Shafer. Here a\\nmuch more general view of systems of questions is proposed and pieces of\\ninformation are related to the elements of this system of questions. This leads\\nto a new and extended system of axioms for information algebras. Classical\\nvaluation algebras are essentially a special case of this new system. A full\\ndiscussion of the algebraic theory of this new information algebras is given,\\nincluding local computation, duality between labeled and domain-free versions\\nof the algebras, order of information, finiteness of information and\\napproximation, compact and continuous information algebras. Finally a rather\\ncomplete discussion of uncertain information, based on random maps into\\ninformation algebras is presented. This is shown to represent a generalisation\\nof classical Dempster-Shafer theory.\\n'\n",
      " '  Deep neural networks for machine comprehension typically utilizes only word\\nor character embeddings without explicitly taking advantage of structured\\nlinguistic information such as constituency trees and dependency trees. In this\\npaper, we propose structural embedding of syntactic trees (SEST), an algorithm\\nframework to utilize structured information and encode them into vector\\nrepresentations that can boost the performance of algorithms for the machine\\ncomprehension. We evaluate our approach using a state-of-the-art neural\\nattention model on the SQuAD dataset. Experimental results demonstrate that our\\nmodel can accurately identify the syntactic boundaries of the sentences and\\nextract answers that are syntactically coherent over the baseline methods.\\n'\n",
      " '  A major goal in blind source separation to identify and separate sources is\\nto model their inherent characteristics. While most state-of-the-art approaches\\nare supervised methods trained on large datasets, interest in non-data-driven\\napproaches such as Kernel Additive Modelling (KAM) remains high due to their\\ninterpretability and adaptability. KAM performs the separation of a given\\nsource applying robust statistics on the time-frequency bins selected by a\\nsource-specific kernel function, commonly the K-NN function. This choice\\nassumes that the source of interest repeats in both time and frequency. In\\npractice, this assumption does not always hold. Therefore, we introduce a\\nshift-invariant kernel function capable of identifying similar spectral content\\neven under frequency shifts. This way, we can considerably increase the amount\\nof suitable sound material available to the robust statistics. While this leads\\nto an increase in separation performance, a basic formulation, however, is\\ncomputationally expensive. Therefore, we additionally present acceleration\\ntechniques that lower the overall computational complexity.\\n'\n",
      " \"  The National Football League's (NFL) 2011 collective bargaining agreement\\n(CBA) with its players placed a number of contact and quantity limitations on\\npractices and workouts. Some coaches and others have expressed a concern that\\nthis has led to poor conditioning and a subsequent increase in injuries. We\\nsought to assess whether the 2011 CBA's practice restrictions affected the\\nnumber of overall, conditioning-dependent, and/or non-conditioning-dependent\\ninjuries in the NFL or the number of games missed due to those injuries. The\\nstudy population was player-seasons from 2007-2016. We included regular season,\\nnon-illness, non-head, game-loss injuries. Injuries were identified using a\\ndatabase from Football Outsiders. The primary outcomes were overall,\\nconditioning-dependent and non-conditioning-dependent injury counts by season.\\nWe examined time trends in injury counts before (2007-2010) and after\\n(2011-2016) the CBA using a Poisson interrupted time series model. The number\\nof game-loss regular season, non-head, non-illness injuries grew from 701 in\\n2007 to 804 in 2016 (15% increase). The number of regular season weeks missed\\nexhibited a similar increase. Conditioning-dependent injuries increased from\\n197 in 2007 to 271 in 2011 (38% rise), but were lower and remained relatively\\nunchanged at 220-240 injuries per season thereafter. Non-conditioning injuries\\ndecreased by 37% in the first three years of the new CBA before returning to\\nhistoric levels in 2014-2016. Poisson models for all, conditioning-dependent,\\nand non-conditioning-dependent game-loss injury counts did not show\\nstatistically significant or meaningful detrimental changes associated with the\\nCBA. We did not observe an increase in injuries following the 2011 CBA. Other\\nconcurrent injury-related rule and regulation changes limit specific causal\\ninferences about the practice restrictions, however.\\n\"\n",
      " '  TeV photons from extragalactic sources are absorbed in the intergalactic\\nmedium and initiate electromagnetic cascades. These cascades offer a unique\\ntool to probe the properties of the universe at cosmological scales. We present\\na new Monte Carlo code dedicated to the physics of such cascades. This code has\\nbeen tested against both published results and analytical approximations, and\\nis made publicly available. Using this numerical tool, we investigate the main\\ncascade properties (spectrum, halo extension, time delays), and study in detail\\ntheir dependence on the physical parameters (extra-galactic magnetic field,\\nextra-galactic background light, source redshift, source spectrum and beaming\\nemission). The limitations of analytical solutions are emphasised. In\\nparticular, analytical approximations account only for the first generation of\\nphotons and higher branches of the cascade tree are neglected.\\n'\n",
      " '  Attitudes can have a profound impact on socially relevant behaviours, such as\\nvoting. However, this effect is not uniform across situations or individuals,\\nand it is at present difficult to predict whether attitudes will predict\\nbehaviour in any given circumstance. Using a network model, we demonstrate that\\n(a) more strongly connected attitude networks have a stronger impact on\\nbehaviour, and (b) within any given attitude network, the most central attitude\\nelements have the strongest impact. We test these hypotheses using data on\\nvoting and attitudes toward presidential candidates in the US presidential\\nelections from 1980 to 2012. These analyses confirm that the predictive value\\nof attitude networks depends almost entirely on their level of connectivity,\\nwith more central attitude elements having stronger impact. The impact of\\nattitudes on voting behaviour can thus be reliably determined before elections\\ntake place by using network analyses.\\n'\n",
      " '  In a physical neural system, learning rules must be local both in space and\\ntime. In order for learning to occur, non-local information must be\\ncommunicated to the deep synapses through a communication channel, the deep\\nlearning channel. We identify several possible architectures for this learning\\nchannel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges:\\n1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons;\\n4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of\\nlearning rules. Random backpropagation (RBP) addresses the second and third\\nsymmetry, and some of its variations, such as skipped RBP (SRBP) address the\\nfirst and the fourth symmetry. Here we address the last two desirable\\nsymmetries showing through simulations that they can be achieved and that the\\nlearning channel is particularly robust to symmetry variations. Specifically,\\nrandom backpropagation and its variations can be performed with the same\\nnon-linear neurons used in the main input-output forward channel, and the\\nconnections in the learning channel can be adapted using the same algorithm\\nused in the forward channel, removing the need for any specialized hardware in\\nthe learning channel. Finally, we provide mathematical results in simple cases\\nshowing that the learning equations in the forward and backward channels\\nconverge to fixed points, for almost any initial conditions. In symmetric\\narchitectures, if the weights in both channels are small at initialization,\\nadaptation in both channels leads to weights that are essentially symmetric\\nduring and after learning. Biological connections are discussed.\\n'\n",
      " '  Several representation learning and, more broadly, dimensionality reduction\\ntechniques seek to produce representations of the data that are orthogonal\\n(uncorrelated). Examples include PCA, CCA, Kernel/Deep CCA, the ACE algorithm\\nand correspondence analysis (CA). For a fixed data distribution, all finite\\nvariance representations belong to the same function space regardless of how\\nthey are derived. In this work, we present a theoretical framework for\\nanalyzing this function space, and demonstrate how a basis for this space can\\nbe found using neural networks. We show that this framework (i) underlies\\nrecent multi-view representation learning methods, (ii) enables classical\\nexploratory statistical techniques such as CA to be scaled via neural networks,\\nand (iii) can be used to derive new methods for comparing black-box models. We\\nillustrate these applications empirically through different datasets.\\n'\n",
      " \"  This paper presents an intelligent user interface model dedicated to the\\nexploration of complex databases. This model is implemented on a 3D metaphor :\\na virtual museum. In this metaphor, the database elements are embodied as\\nmuseum objects. The objects are grouped in rooms according to their semantic\\nproperties and relationships and the rooms organization forms the museum. Rooms\\norganization is not predefi-ned but defined incrementally by taking into\\naccount not only the relationships between objects, but also the users centers\\nof interest. The latter are evaluated in real-time through user interactions\\nwithin the virtual museum. This interface allows for a personal reading and\\nfavors the discovery of unsuspec-ted links between data. In this paper, we\\npresent our model's formalization as well as its application to the context of\\ncultural heritage.\\n\"\n",
      " '  In this article, we present the Lie transformation algorithm for autonomous\\nBirkhoff systems. Here, we are referring to Hamiltonian systems that obey a\\nsymplectic structure of the general form. Two examples of normalization in the\\nrestricted three-body problem are given to illustrate the application of the\\nalgorithm in perturbation theory. The efficiency of this algorithm for problems\\nof asymptotic integration in dynamics is discussed for the case where there is\\na need to use non-canonical variables in the phase space.\\n'\n",
      " '  Assessing and managing risks in a changing climate requires projections that\\naccount for decision-relevant uncertainties. These deep uncertainties are often\\napproximated by ensembles of Earth-system model runs that sample only a subset\\nof the known uncertainties. Here we demonstrate and quantify how this approach\\ncan cut off the tails of the distributions of projected climate variables such\\nas sea-level rise. As a result, low-probability high-impact events that may\\ndrive risks can be under-represented. Neglecting the tails of this deep\\nuncertainty may lead to overconfident projections and poor decisions when high\\nreliabilities are important.\\n'\n",
      " '  In this paper we present a geometric control law for position and\\nline-of-sight stabilization of the nonholonomic spherical robot actuated by\\nthree independent actuators. A simple configuration error function with an\\nappropriately defined transport map is proposed to extract feedforward and\\nproportional-derivative control law. Simulations are provided to validate the\\ncontroller performance.\\n'\n",
      " '  We study the finite-size spectrum of the O($N$) symmetric Wilson-Fisher\\nconformal field theory (CFT) on the $d=2$ spatial-dimension torus using the\\nexpansion in $\\\\epsilon=3-d$. This is done by deriving a set of universal\\neffective Hamiltonians describing fluctuations of the zero momentum modes. The\\neffective Hamiltonians take the form of $N$-dimensional quantum anharmonic\\noscillators, which are shown to be strongly coupled at the critical point for\\nsmall $\\\\epsilon$. The low-energy spectrum is solved numerically for $N =\\n1,2,3,4$. Using exact diagonalization (ED), we also numerically study explicit\\nlattice models known to be in the O($2$) and O($3$) universality class,\\nobtaining estimates of the low-lying critical spectrum. The analytic and\\nnumerical results show excellent agreement and the critical low energy torus\\nspectra are qualitatively different among the studied CFTs, identifying them as\\na useful fingerprint for detecting the universality class of a quantum critical\\npoint.\\n'\n",
      " '  Visual Domain Adaptation is a problem of immense importance in computer\\nvision. Previous approaches showcase the inability of even deep neural networks\\nto learn informative representations across domain shift. This problem is more\\nsevere for tasks where acquiring hand labeled data is extremely hard and\\ntedious. In this work, we focus on adapting the representations learned by\\nsegmentation networks across synthetic and real domains. Contrary to previous\\napproaches that use a simple adversarial objective or superpixel information to\\naid the process, we propose an approach based on Generative Adversarial\\nNetworks (GANs) that brings the embeddings closer in the learned feature space.\\nTo showcase the generality and scalability of our approach, we show that we can\\nachieve state of the art results on two challenging scenarios of synthetic to\\nreal domain adaptation. Additional exploratory experiments show that our\\napproach: (1) generalizes to unseen domains and (2) results in improved\\nalignment of source and target distributions.\\n'\n",
      " '  Relative smoothness - a notion introduced by Birnbaum et al. (2011) and\\nrediscovered by Bauschke et al. (2016) and Lu et al. (2016) - generalizes the\\nstandard notion of smoothness typically used in the analysis of gradient type\\nmethods. In this work we are taking ideas from well studied field of stochastic\\nconvex optimization and using them in order to obtain faster algorithms for\\nminimizing relatively smooth functions. We propose and analyze two new\\nalgorithms: Relative Randomized Coordinate Descent (relRCD) and Relative\\nStochastic Gradient Descent (relSGD), both generalizing famous algorithms in\\nthe standard smooth setting. The methods we propose can be in fact seen as a\\nparticular instances of stochastic mirror descent algorithms. One of them,\\nrelRCD corresponds to the first stochastic variant of mirror descent algorithm\\nwith linear convergence rate.\\n'\n",
      " '  Network quantization is an effective solution to compress deep neural\\nnetworks for practical usage. Existing network quantization methods cannot\\nsufficiently exploit the depth information to generate low-bit compressed\\nnetwork. In this paper, we propose two novel network quantization approaches,\\nsingle-level network quantization (SLQ) for high-bit quantization and\\nmulti-level network quantization (MLQ) for extremely low-bit quantization\\n(ternary).We are the first to consider the network quantization from both width\\nand depth level. In the width level, parameters are divided into two parts: one\\nfor quantization and the other for re-training to eliminate the quantization\\nloss. SLQ leverages the distribution of the parameters to improve the width\\nlevel. In the depth level, we introduce incremental layer compensation to\\nquantize layers iteratively which decreases the quantization loss in each\\niteration. The proposed approaches are validated with extensive experiments\\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\\n'\n",
      " '  We present the photometric results of the eclipsing cataclysmic variable (CV)\\nWZ Sge near the period minimum ($P_{min}$). Eight new mid-eclipse times were\\ndetermined and the orbital ephemeris was updated. Our result shows that the\\norbital period of WZ Sge is decreasing at a rate of\\n$\\\\dot{P}=-2.72(\\\\pm0.23)\\\\times{10^{-13}}\\\\,s s^{-1}$. This secular decrease,\\ncoupled with previous detection of its donor, suggest that WZ Sge is a\\npre-bounce system. Further analysis indicates that the observed period decrease\\nrate is about $1.53$ times higher than pure gravitational radiation (GR)\\ndriving. We constructed the evolutionary track of WZ Sge, which predicts that\\n$P_{min}$ of WZ Sge is $\\\\sim77.98 (\\\\pm0.90)$ min. If the orbital period\\ndecreases at the current rate, WZ Sge will evolve past its $P_{min}$ after\\n$\\\\sim25.3$ Myr. Based on the period evolution equation we find\\n$\\\\dot{M}_{2}\\\\simeq4.04(\\\\pm0.10)\\\\times10^{-11}M_{\\\\odot}yr^{-1}$, which is\\ncompatible with the current concept of CV evolution at ultrashort orbital\\nperiods.\\n'\n",
      " '  A theoretical analysis of the unfolding pathway of simple modular proteins in\\nlength- controlled pulling experiments is put forward. Within this framework,\\nwe predict the first module to unfold in a chain of identical units,\\nemphasizing the ranges of pulling speeds in which we expect our theory to hold.\\nThese theoretical predictions are checked by means of steered molecular\\ndynamics of a simple construct, specifically a chain composed of two\\ncoiled-coils motives, where anisotropic features are revealed. These\\nsimulations also allow us to give an estimate for the range of pulling\\nvelocities in which our theoretical approach is valid.\\n'\n",
      " \"  In the modern era, each Internet user leaves enormous amounts of auxiliary\\ndigital residuals (footprints) by using a variety of on-line services. All this\\ndata is already collected and stored for many years. In recent works, it was\\ndemonstrated that it's possible to apply simple machine learning methods to\\nanalyze collected digital footprints and to create psycho-demographic profiles\\nof individuals. However, while these works clearly demonstrated the\\napplicability of machine learning methods for such an analysis, created simple\\nprediction models still lacks accuracy necessary to be successfully applied for\\npractical needs. We have assumed that using advanced deep machine learning\\nmethods may considerably increase the accuracy of predictions. We started with\\nsimple machine learning methods to estimate basic prediction performance and\\nmoved further by applying advanced methods based on shallow and deep neural\\nnetworks. Then we compared prediction power of studied models and made\\nconclusions about its performance. Finally, we made hypotheses how prediction\\naccuracy can be further improved. As result of this work, we provide full\\nsource code used in the experiments for all interested researchers and\\npractitioners in corresponding GitHub repository. We believe that applying deep\\nmachine learning for psycho-demographic profiling may have an enormous impact\\non the society (for good or worse) and provides means for Artificial\\nIntelligence (AI) systems to better understand humans by creating their\\npsychological profiles. Thus AI agents may achieve the human-like ability to\\nparticipate in conversation (communication) flow by anticipating human\\nopponents' reactions, expectations, and behavior.\\n\"\n",
      " '  To every convex body $K \\\\subseteq \\\\mathbb{R}^d$, one may associate a minimal\\nmatrix convex set $\\\\mathcal{W}^{\\\\textrm{min}}(K)$, and a maximal matrix convex\\nset $\\\\mathcal{W}^{\\\\textrm{max}}(K)$, which have $K$ as their ground level. The\\nmain question treated in this paper is: under what conditions on a given pair\\nof convex bodies $K,L \\\\subseteq \\\\mathbb{R}^d$ does\\n$\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq \\\\mathcal{W}^{\\\\textrm{min}}(L)$ hold?\\nFor a convex body $K$, we aim to find the optimal constant $\\\\theta(K)$ such\\nthat $\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq \\\\theta(K) \\\\cdot\\n\\\\mathcal{W}^{\\\\textrm{min}}(K)$; we achieve this goal for all the $\\\\ell^p$ unit\\nballs, as well as for other sets. For example, if $\\\\overline{\\\\mathbb{B}}_{p,d}$\\nis the closed unit ball in $\\\\mathbb{R}^d$ with the $\\\\ell^p$ norm, then \\\\[\\n\\\\theta(\\\\overline{\\\\mathbb{B}}_{p,d}) = d^{1-|1/p - 1/2|}. \\\\] This constant is\\nsharp, and it is new for all $p \\\\neq 2$. Moreover, for some sets $K$ we find a\\nminimal set $L$ for which $\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq\\n\\\\mathcal{W}^{\\\\textrm{min}}(L)$. In particular, we obtain that a convex body $K$\\nsatisfies $\\\\mathcal{W}^{\\\\textrm{max}}(K) = \\\\mathcal{W}^{\\\\textrm{min}}(K)$ if\\nand only if $K$ is a simplex.\\nThese problems relate to dilation theory, convex geometry, operator systems,\\nand completely positive maps. We discuss and exploit these connections as well.\\nFor example, our results show that every $d$-tuple of self-adjoint operators of\\nnorm less than or equal to $1$, can be dilated to a commuting family of\\nself-adjoints, each of norm at most $\\\\sqrt{d}$. We also introduce new explicit\\nconstructions of these (and other) dilations.\\n'\n",
      " '  Grasp detection is an essential skill for widespread use of robots. Recent\\nworks demonstrate the advanced performance of Convolutional Neural Network\\n(CNN) on robotic grasp detection. However, a significant shortcoming of\\nexisting grasp detection algorithms is that they all ignore the affiliation\\nbetween grasps and targets. In this paper, we propose a robotic grasp detection\\nalgorithm based on Region of Interest (RoI) to simultaneously detect targets\\nand their grasps in object overlapping scenes. Our proposed algorithm uses\\nRegions of Interest (RoIs) to detect grasps while doing classification and\\nlocation regression of targets. To train the network, we contribute a much\\nbigger multi-object grasp dataset than Cornell Grasp Dataset, which is based on\\nVisual Manipulation Relationship Dataset. Experimental results demonstrate that\\nour algorithm achieves 24.9% miss rate at 1FPPI and 68.2% mAP with grasp on our\\ndataset. Robotic experiments demonstrate that our proposed algorithm can help\\nrobots grasp specified target in multi-object scenes at 84% success rate.\\n'\n",
      " \"  Ceramic is a material frequently used in industry because of its favorable\\nproperties. Common approaches in shape optimization for ceramic structures aim\\nto minimize the tensile stress acting on the component, as it is the main\\ndriver for failure. In contrast to this, we follow a more natural approach by\\nminimizing the component's probability of failure under a given tensile load.\\nSince the fundamental work of Weibull, the probabilistic description of the\\nstrength of ceramics is standard and has been widely applied. Here, for the\\nfirst time, the resulting failure probabilities are used as objective functions\\nin PDE constrained shape optimization.\\nTo minimize the probability of failure, we choose a gradient based method\\ncombined with a first discretize then optimize approach. For discretization\\nfinite elements are used. Using the Lagrangian formalism, the shape gradient\\nvia the adjoint equation is calculated at low computational cost. The\\nimplementation is verified by comparison of it with a finite difference method\\napplied to a minimal 2d example. Furthermore, we construct shape flows towards\\nan optimal / improved shape in the case of a simple beam and a bended joint.\\n\"\n",
      " '  We consider online linear optimization over symmetric positive semi-definite\\nmatrices, which has various applications including the online collaborative\\nfiltering. The problem is formulated as a repeated game between the algorithm\\nand the adversary, where in each round t the algorithm and the adversary choose\\nmatrices X_t and L_t, respectively, and then the algorithm suffers a loss given\\nby the Frobenius inner product of X_t and L_t. The goal of the algorithm is to\\nminimize the cumulative loss. We can employ a standard framework called Follow\\nthe Regularized Leader (FTRL) for designing algorithms, where we need to choose\\nan appropriate regularization function to obtain a good performance guarantee.\\nWe show that the log-determinant regularization works better than other popular\\nregularization functions in the case where the loss matrices L_t are all\\nsparse. Using this property, we show that our algorithm achieves an optimal\\nperformance guarantee for the online collaborative filtering. The technical\\ncontribution of the paper is to develop a new technique of deriving performance\\nbounds by exploiting the property of strong convexity of the log-determinant\\nwith respect to the loss matrices, while in the previous analysis the strong\\nconvexity is defined with respect to a norm. Intuitively, skipping the norm\\nanalysis results in the improved bound. Moreover, we apply our method to online\\nlinear optimization over vectors and show that the FTRL with the Burg entropy\\nregularizer, which is the analogue of the log-determinant regularizer in the\\nvector case, works well.\\n'\n",
      " '  Several auroral events that occurred in the past have not been catalogued as\\nsuch due to fact that they were described in the historical sources with\\ndifferent terminology. Hayakawa et al. (2016) have reviewed historical oriental\\nchronicles and have proposed the terms \"unusual rainbow\" and \"white rainbow\" as\\ncandidates to auroras. In this work, we present three events that took place in\\nthe 18th century in two different settings (the Iberian Peninsula and Brazil)\\nthat were originally described with similar definition/wording used by the\\noriental chronicles, despite the inherent differences in terms associated to\\noriental and Latin languages. We show that these terms are indeed applicable to\\nthe three case studies from Europe and South America. Thus, the auroral\\ncatalogues available can be extended for occidental sources with this new\\nterminology.\\n'\n",
      " '  Convnets have enabled significant progress in pedestrian detection recently,\\nbut there are still open questions regarding suitable architectures and\\ntraining data. We revisit CNN design and point out key adaptations, enabling\\nplain FasterRCNN to obtain state-of-the-art results on the Caltech dataset.\\nTo achieve further improvement from more and better data, we introduce\\nCityPersons, a new set of person annotations on top of the Cityscapes dataset.\\nThe diversity of CityPersons allows us for the first time to train one single\\nCNN model that generalizes well over multiple benchmarks. Moreover, with\\nadditional training with CityPersons, we obtain top results using FasterRCNN on\\nCaltech, improving especially for more difficult cases (heavy occlusion and\\nsmall scale) and providing higher localization quality.\\n'\n",
      " '  We consider matrix completion for recommender systems from the point of view\\nof link prediction on graphs. Interaction data such as movie ratings can be\\nrepresented by a bipartite user-item graph with labeled edges denoting observed\\nratings. Building on recent progress in deep learning on graph-structured data,\\nwe propose a graph auto-encoder framework based on differentiable message\\npassing on the bipartite interaction graph. Our model shows competitive\\nperformance on standard collaborative filtering benchmarks. In settings where\\ncomplimentary feature information or structured data such as a social network\\nis available, our framework outperforms recent state-of-the-art methods.\\n'\n",
      " \"  Clustering consists of grouping together samples giving their similar\\nproperties. The problem of modeling simultaneously groups of samples and\\nfeatures is known as Co-Clustering. This paper introduces ROCCO - a Robust\\nContinuous Co-Clustering algorithm. ROCCO is a scalable, hyperparameter-free,\\neasy and ready to use algorithm to address Co-Clustering problems in practice\\nover massive cross-domain datasets. It operates by learning a graph-based\\ntwo-sided representation of the input matrix. The underlying proposed\\noptimization problem is non-convex, which assures a flexible pool of solutions.\\nMoreover, we prove that it can be solved with a near linear time complexity on\\nthe input size. An exhaustive large-scale experimental testbed conducted with\\nboth synthetic and real-world datasets demonstrates ROCCO's properties in\\npractice: (i) State-of-the-art performance in cross-domain real-world problems\\nincluding Biomedicine and Text Mining; (ii) very low sensitivity to\\nhyperparameter settings; (iii) robustness to noise and (iv) a linear empirical\\nscalability in practice. These results highlight ROCCO as a powerful\\ngeneral-purpose co-clustering algorithm for cross-domain practitioners,\\nregardless of their technical background.\\n\"\n",
      " '  He atom scattering has been shown to be a sensitive probe of electron-phonon\\ninteraction properties at surfaces. Here it is shown that measurements of the\\nthermal attenuation of the specular He atom diffraction peak (the Debye-Waller\\neffect) can determine the electron-phonon coupling constant $\\\\lambda$ for\\nultrathin films of metal overlayers on various close-packed metal substrates.\\nValues of $\\\\lambda$ obtained for single and multiple monolayers of alkali\\nmetals, and for Pb layers on Cu(111), extrapolated to large thicknesses, agree\\nfavorably with known bulk values. This demonstrates that He atom scattering can\\nmeasure the electron-phonon coupling strength as a function of film thickness\\non a layer-by-layer basis.\\n'\n",
      " '  We prove the classification of homomorphisms from the algebra of symmetric\\nfunctions to $\\\\mathbb{R}$ with non-negative values on Macdonald symmetric\\nfunctions $P_{\\\\lambda}$, that was conjectured by S.V. Kerov in 1992.\\n'\n",
      " '  We give a characterization of $n$-cluster tilting subcategories of\\nrepresentation-directed algebras based on the $n$-Auslander-Reiten\\ntranslations. As an application we classify acyclic Nakayama algebras with\\nhomogeneous relations which admit an $n$-cluster tilting subcategory. Finally,\\nwe classify Nakayama algebras of global dimension $d<\\\\infty$ which admit a\\n$d$-cluster tilting subcategory.\\n'\n",
      " '  This paper is concerned with developing a novel distributed Kalman filtering\\nalgorithm over wireless sensor networks based on randomized consensus strategy.\\nCompared with the centralized algorithm, distributed filtering techniques\\nrequire less computation per sensor and lead to more robust estimation since\\nthey simply use the information from the neighboring nodes in the network.\\nHowever, poor local sensor estimation caused by limited observability and\\nnetwork topology changes which interfere the global consensus are challenging\\nissues. Motivated by this observation, we propose a novel randomized\\ngossip-based distributed Kalman filtering algorithm. Information exchange and\\ncomputation in the proposed algorithm can be carried out in an arbitrarily\\nconnected network of nodes. In addition, the computational burden can be\\ndistributed for a sensor which communicates with a stochastically selected\\nneighbor at each clock step under schemes of gossip algorithm. In this case,\\nthe error covariance matrix changes stochastically at every clock step, thus\\nthe convergence is considered in a probabilistic sense. We provide the mean\\nsquare convergence analysis of the proposed algorithm. Under a sufficient\\ncondition, we show that the proposed algorithm is quite appealing as it\\nachieves better mean square error performance theoretically than the\\nnoncooperative decentralized Kalman filtering algorithm. Besides, considering\\nthe limited computation, communication, and energy resources in the wireless\\nsensor networks, we propose an optimization problem which minimizes the average\\nexpected state estimation error based on the proposed algorithm. To solve the\\nproposed problem efficiently, we transform it into a convex optimization\\nproblem. And a sub-optimal solution is attained. Examples and simulations are\\nprovided to illustrate the theoretical results.\\n'\n",
      " '  This work, which extends Squire et al. [ApJL, 830 L25 (2016)], explores the\\neffect of self-generated pressure anisotropy on linearly polarized\\nshear-Alfvén fluctuations in low-collisionality plasmas. Such anisotropies\\nlead to stringent limits on the amplitude of magnetic perturbations in\\nhigh-beta plasmas, above which a fluctuation can destabilize itself through the\\nparallel firehose instability. This causes the wave frequency to approach zero,\\n\"interrupting\" the wave and stopping its oscillation. These effects are\\nexplored in detail in the collisionless and weakly collisional \"Braginskii\"\\nregime, for both standing and traveling waves. The focus is on simplified\\nmodels in one dimension, on scales much larger than the ion gyroradius. The\\neffect has interesting implications for the physics of magnetized turbulence in\\nthe high-beta conditions that are prevalent in many astrophysical plasmas.\\n'\n",
      " \"  We show that the automorphism group of Philip Hall's universal locally finite\\ngroup has ample generics,that is, it admits comeager diagonal conjugacy classes\\nin all dimensions.Consequently, it has the small index property, is not the\\nunion of a countable chain of non-open subgroups, and has the automatic\\ncontinuity property. Also, we discuss some algebraic and topological properties\\nof the automorphism group of Hall universal group. For example, we show that\\nevery generic automorphism of Hall universal group is conjugate to all of its\\npowers, and hence has roots of all orders.\\n\"\n",
      " '  Security enhancement is important in terms of both classical and quantum\\ninformation. The recent development of a quantum storage device is noteworthy,\\nand a coherence time of one second or longer has been demonstrated. On the\\nother hand, although the encryption of a quantum bit or quantum memory has been\\nproposed theoretically, no experiment has yet been carried out. Here we report\\nthe demonstration of a quantum memory with an encryption function that is\\nrealized by scrambling and retrieving the recorded quantum phase. We developed\\ntwo independent Ramsey interferometers on an atomic ensemble trapped below a\\npersistent supercurrent atom chip. By operating the two interferometers with\\nrandom phases, the quantum phase recorded by a pulse of the first\\ninterferometer was modulated by the second interferometer pulse. The scrambled\\nquantum phase was restored by employing another pulse of the second\\ninterferometer with a specific time delay. This technique paves way for\\nimproving the security of quantum information technology.\\n'\n",
      " '  The object of the present paper is to introduce and investigate two new\\ngeneral subclasses ${{S}^{*}}C(\\\\alpha ,\\\\beta ;\\\\gamma )$ and $T{{S}^{*}}C(\\\\alpha\\n,\\\\beta ;\\\\gamma )~~(\\\\alpha, \\\\beta \\\\in [0,1),~\\\\gamma \\\\in [0,1])$ of the analytic\\nfunctions. Here, we give sufficient conditions as well as necessary and\\nsufficient conditions for the functions belonging to the classes.\\n'\n",
      " '  The current models of image representation based on Convolutional Neural\\nNetworks (CNN) have shown tremendous performance in image retrieval. Such\\nmodels are inspired by the information flow along the visual pathway in the\\nhuman visual cortex. We propose that in the field of particular object\\nretrieval, the process of extracting CNN representations from query images with\\na given region of interest (ROI) can also be modelled by taking inspiration\\nfrom human vision. Particularly, we show that by making the CNN pay attention\\non the ROI while extracting query image representation leads to significant\\nimprovement over the baseline methods on challenging Oxford5k and Paris6k\\ndatasets. Furthermore, we propose an extension to a recently introduced\\nencoding method for CNN representations, regional maximum activations of\\nconvolutions (R-MAC). The proposed extension weights the regional\\nrepresentations using a novel saliency measure prior to aggregation. This leads\\nto further improvement in retrieval accuracy.\\n'\n",
      " '  Current astrophysical models of the interstellar medium assume that small\\nscale variation and noise can be modelled as Gaussian random fields or simple\\ntransformations thereof, such as lognormal. We use topological methods to\\ninvestigate this assumption for three regions of the southern sky. We consider\\nGaussian random fields on two-dimensional lattices and investigate the expected\\ndistribution of topological structures quantified through Betti numbers. We\\ndemonstrate that there are circumstances where differences in topology can\\nidentify differences in distributions when conventional marginal or correlation\\nanalyses may not. We propose a non-parametric method for comparing two fields\\nbased on the counts of topological features and the geometry of the associated\\npersistence diagrams. When we apply the methods to the astrophysical data, we\\nfind strong evidence against a Gaussian random field model for each of the\\nthree regions of the interstellar medium that we consider. Further, we show\\nthat there are topological differences at a local scale between these different\\nregions.\\n'\n",
      " '  We present a study of the kinematics of the extraplanar ionized gas around\\nseveral dozen galaxies observed by the Mapping of Nearby Galaxies at the Apache\\nPoint Observatory (MaNGA) survey. We considered a sample of 67 edge-on galaxies\\nout of more than 1400 extragalactic targets observed by MaNGA, in which we\\nfound 25 galaxies (or 37%) with regular lagging of the rotation curve at large\\ndistances from the galactic midplane. We model the observed $H\\\\alpha$ emission\\nvelocity fields in the galaxies, taking projection effects and a simple model\\nfor the dust extinction into the account. We show that the vertical lag of the\\nrotation curve is necessary in the modeling, and estimate the lag amplitude in\\nthe galaxies. We find no correlation between the lag and the star formation\\nrate in the galaxies. At the same time, we report a correlation between the lag\\nand the galactic stellar mass, central stellar velocity dispersion, and axial\\nratio of the light distribution. These correlations suggest a possible higher\\nratio of infalling-to-local gas in early-type disk galaxies or a connection\\nbetween lags and the possible presence of hot gaseous halos, which may be more\\nprevalent in more massive galaxies. These results again demonstrate that\\nobservations of extraplanar gas can serve as a potential probe for accretion of\\ngas.\\n'\n",
      " '  In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of\\nn regions (neighborhoods) and we seek a shortest tour that visits each region.\\nAs a generalization of the classical Euclidean TSP, TSPN is also NP-hard. In\\nthis paper, we present new approximation results for the TSPN, including (1) a\\nconstant-factor approximation algorithm for the case of arbitrary connected\\nneighborhoods having comparable diameters; and (2) a PTAS for the important\\nspecial case of disjoint unit disk neighborhoods (or nearly disjoint,\\nnearly-unit disks). Our methods also yield improved approximation ratios for\\nvarious special classes of neighborhoods, which have previously been studied.\\nFurther, we give a linear-time O(1)-approximation algorithm for the case of\\nneighborhoods that are (infinite) straight lines.\\n'\n",
      " '  This paper implements Simultaneous Localization and Mapping (SLAM) technique\\nto construct a map of a given environment. A Real Time Appearance Based Mapping\\n(RTAB-Map) approach was taken for accomplishing this task. Initially, a 2d\\noccupancy grid and 3d octomap was created from a provided simulated\\nenvironment. Next, a personal simulated environment was created for mapping as\\nwell. In this appearance based method, a process called Loop Closure is used to\\ndetermine whether a robot has seen a location before or not. In this paper, it\\nis seen that RTAB-Map is optimized for large scale and long term SLAM by using\\nmultiple strategies to allow for loop closure to be done in real time and the\\nresults depict that it can be an excellent solution for SLAM to develop robots\\nthat can map an environment in both 2d and 3d.\\n'\n",
      " '  The widespread availability of electronic health records (EHRs) promises to\\nusher in the era of personalized medicine. However, the problem of extracting\\nuseful clinical representations from longitudinal EHR data remains challenging.\\nIn this paper, we explore deep neural network models with learned medical\\nfeature embedding to deal with the problems of high dimensionality and\\ntemporality. Specifically, we use a multi-layer convolutional neural network\\n(CNN) to parameterize the model and is thus able to capture complex non-linear\\nlongitudinal evolution of EHRs. Our model can effectively capture local/short\\ntemporal dependency in EHRs, which is beneficial for risk prediction. To\\naccount for high dimensionality, we use the embedding medical features in the\\nCNN model which hold the natural medical concepts. Our initial experiments\\nproduce promising results and demonstrate the effectiveness of both the medical\\nfeature embedding and the proposed convolutional neural network in risk\\nprediction on cohorts of congestive heart failure and diabetes patients\\ncompared with several strong baselines.\\n'\n",
      " '  Automatic assembly has broad applications in industries. Traditional assembly\\ntasks utilize predefined trajectories or tuned force control parameters, which\\nmake the automatic assembly time-consuming, difficult to generalize, and not\\nrobust to uncertainties. In this paper, we propose a learning framework for\\nhigh precision industrial assembly. The framework combines both the supervised\\nlearning and the reinforcement learning. The supervised learning utilizes\\ntrajectory optimization to provide the initial guidance to the policy, while\\nthe reinforcement learning utilizes actor-critic algorithm to establish the\\nevaluation system when the supervisor is not accurate. The proposed learning\\nframework is more efficient compared with the reinforcement learning and\\nachieves better stability performance than the supervised learning. The\\neffectiveness of the method is verified by both the simulation and experiment.\\nExperimental videos are available at~\\\\cite{website}.\\n'\n",
      " '  Business process models describe the way of working in an organization.\\nTypically, business process models distinguish between the normal flow of work\\nand exceptions to that normal flow. However, they often present an idealized\\nview. This means that unexpected exceptions - exceptions that are not modelled\\nin the business process model - can also occur in practice. This has an effect\\non the efficiency of the organization, because information systems are not\\ndeveloped to handle unexpected exceptions. This paper studies the relation\\nbetween the occurrence of exceptions and operational performance. It does this\\nby analyzing the execution logs of business processes from five organizations,\\nclassifying execution paths as normal or exceptional. Subsequently, it analyzes\\nthe differences between normal and exceptional paths. The results show that\\nexceptions are related to worse operational performance in terms of a longer\\nthroughput time and that unexpected exceptions relate to a stronger increase in\\nthroughput time than expected exceptions.\\n'\n",
      " '  We build simple computational models of belief dynamics within the framework\\nof discrete-spin statistical physics models, and explore how suitable they are\\nfor understanding and predicting real-world belief change on both the\\nindividual and group levels. We find that accurate modeling of real-world\\npatterns requires attending to social interaction rules that people use,\\nnetwork structures in which they are embedded, distributions of initial beliefs\\nand intrinsic preferences, and the relative importance of social information\\nand intrinsic preferences. We demonstrate that these model parameters can be\\nconstrained by empirical measurement, and the resulting models can be used to\\ninvestigate the mechanisms underlying belief dynamics in actual societies. We\\nuse data from two longitudinal studies of belief change, one on 80~individuals\\nliving in an MIT dorm during the 2008 presidential election season, and another\\non 94~participants recruited from Mechanical Turk during the 2016 presidential\\nelection primary season. We find that simple statistical physics-based models\\ncontain predictive value for real-world belief dynamics and enable empirical\\ntests of different assumptions about the underlying network structure and the\\nsocial interaction rules.\\n'\n",
      " '  Dropout is a simple yet effective algorithm for regularizing neural networks\\nby randomly dropping out units through Bernoulli multiplicative noise, and for\\nsome restricted problem classes, such as linear or logistic regression, several\\ntheoretical studies have demonstrated the equivalence between dropout and a\\nfully deterministic optimization problem with data-dependent Tikhonov\\nregularization. This work presents a theoretical analysis of dropout for matrix\\nfactorization, where Bernoulli random variables are used to drop a factor,\\nthereby attempting to control the size of the factorization. While recent work\\nhas demonstrated the empirical effectiveness of dropout for matrix\\nfactorization, a theoretical understanding of the regularization properties of\\ndropout in this context remains elusive. This work demonstrates the equivalence\\nbetween dropout and a fully deterministic model for matrix factorization in\\nwhich the factors are regularized by the sum of the product of the norms of the\\ncolumns. While the resulting regularizer is closely related to a variational\\nform of the nuclear norm, suggesting that dropout may limit the size of the\\nfactorization, we show that it is possible to trivially lower the objective\\nvalue by doubling the size of the factorization. We show that this problem is\\ncaused by the use of a fixed dropout rate, which motivates the use of a rate\\nthat increases with the size of the factorization. Synthetic experiments\\nvalidate our theoretical findings.\\n'\n",
      " '  Research on vehicular networking (V2X) security has produced a range of\\nsecurity mechanisms and protocols tailored for this domain, addressing both\\nsecurity and privacy. Typically, the security analysis of these proposals has\\nlargely been informal. However, formal analysis can be used to expose flaws and\\nultimately provide a higher level of assurance in the protocols.\\nThis paper focusses on the formal analysis of a particular element of\\nsecurity mechanisms for V2X found in many proposals: the revocation of\\nmalicious or misbehaving vehicles from the V2X system by invalidating their\\ncredentials. This revocation needs to be performed in an unlinkable way for\\nvehicle privacy even in the context of vehicles regularly changing their\\npseudonyms. The REWIRE scheme by Forster et al. and its subschemes BASIC and\\nRTOKEN aim to solve this challenge by means of cryptographic solutions and\\ntrusted hardware.\\nFormal analysis using the TAMARIN prover identifies two flaws with some of\\nthe functional correctness and authentication properties in these schemes. We\\nthen propose Obscure Token (OTOKEN), an extension of REWIRE to enable\\nrevocation in a privacy preserving manner. Our approach addresses the\\nfunctional and authentication properties by introducing an additional key-pair,\\nwhich offers a stronger and verifiable guarantee of successful revocation of\\nvehicles without resolving the long-term identity. Moreover OTOKEN is the first\\nV2X revocation protocol to be co-designed with a formal model.\\n'\n",
      " '  Group factor analysis (GFA) methods have been widely used to infer the common\\nstructure and the group-specific signals from multiple related datasets in\\nvarious fields including systems biology and neuroimaging. To date, most\\navailable GFA models require Gibbs sampling or slice sampling to perform\\ninference, which prevents the practical application of GFA to large-scale data.\\nIn this paper we present an efficient collapsed variational inference (CVI)\\nalgorithm for the nonparametric Bayesian group factor analysis (NGFA) model\\nbuilt upon an hierarchical beta Bernoulli process. Our CVI algorithm proceeds\\nby marginalizing out the group-specific beta process parameters, and then\\napproximating the true posterior in the collapsed space using mean field\\nmethods. Experimental results on both synthetic and real-world data demonstrate\\nthe effectiveness of our CVI algorithm for the NGFA compared with\\nstate-of-the-art GFA methods.\\n'\n",
      " '  Single-cell RNA sequencing (scRNA-seq) is a fast growing approach to measure\\nthe genome-wide transcriptome of many individual cells in parallel, but results\\nin noisy data with many dropout events. Existing methods to learn molecular\\nsignatures from bulk transcriptomic data may therefore not be adapted to\\nscRNA-seq data, in order to automatically classify individual cells into\\npredefined classes. We propose a new method called DropLasso to learn a\\nmolecular signature from scRNA-seq data. DropLasso extends the dropout\\nregularisation technique, popular in neural network training, to esti- mate\\nsparse linear models. It is well adapted to data corrupted by dropout noise,\\nsuch as scRNA-seq data, and we clarify how it relates to elastic net\\nregularisation. We provide promising results on simulated and real scRNA-seq\\ndata, suggesting that DropLasso may be better adapted than standard regularisa-\\ntions to infer molecular signatures from scRNA-seq data.\\n'\n",
      " '  Using supporting backchannel (BC) cues can make human-computer interaction\\nmore social. BCs provide a feedback from the listener to the speaker indicating\\nto the speaker that he is still listened to. BCs can be expressed in different\\nways, depending on the modality of the interaction, for example as gestures or\\nacoustic cues. In this work, we only considered acoustic cues. We are proposing\\nan approach towards detecting BC opportunities based on acoustic input features\\nlike power and pitch. While other works in the field rely on the use of a\\nhand-written rule set or specialized features, we made use of artificial neural\\nnetworks. They are capable of deriving higher order features from input\\nfeatures themselves. In our setup, we first used a fully connected feed-forward\\nnetwork to establish an updated baseline in comparison to our previously\\nproposed setup. We also extended this setup by the use of Long Short-Term\\nMemory (LSTM) networks which have shown to outperform feed-forward based setups\\non various tasks. Our best system achieved an F1-Score of 0.37 using power and\\npitch features. Adding linguistic information using word2vec, the score\\nincreased to 0.39.\\n'\n",
      " '  We consider the $(n,k,d,\\\\ell)$ secure exact-repair regenerating code problem,\\nwhich generalizes the $(n,k,d)$ exact-repair regenerating code problem with the\\nadditional constraint that the stored file needs to be kept\\ninformation-theoretically secure against an eavesdropper, who can access the\\ndata transmitted to regenerate a total of $\\\\ell$ different failed nodes. For\\nall known results on this problem, the achievable tradeoff regions between the\\nnormalized storage capacity and repair bandwidth have a single corner point,\\nachieved by a scheme proposed by Shah, Rashmi and Kumar (the SRK point). Since\\nthe achievable tradeoff regions of the exact-repair regenerating code problem\\nwithout any secrecy constraints are known to have multiple corner points in\\ngeneral, these existing results suggest a phase-change-like behavior, i.e.,\\nenforcing a secrecy constraint ($\\\\ell\\\\geq 1$) immediately reduces the tradeoff\\nregion to one with a single corner point. In this work, we first show that when\\nthe secrecy parameter $\\\\ell$ is sufficiently large, the SRK point is indeed the\\nonly corner point of the tradeoff region. However, when $\\\\ell$ is small, we\\nshow that the tradeoff region can in fact have multiple corner points. In\\nparticular, we establish a precise characterization of the tradeoff region for\\nthe $(7,6,6,1)$ problem, which has exactly two corner points. Thus, a smooth\\ntransition, instead of a phase-change-type of transition, should be expected as\\nthe secrecy constraint is gradually strengthened.\\n'\n",
      " \"  Link prediction is a key problem for network-structured data. Link prediction\\nheuristics use some score functions, such as common neighbors and Katz index,\\nto measure the likelihood of links. They have obtained wide practical uses due\\nto their simplicity, interpretability, and for some of them, scalability.\\nHowever, every heuristic has a strong assumption on when two nodes are likely\\nto link, which limits their effectiveness on networks where these assumptions\\nfail. In this regard, a more reasonable way should be learning a suitable\\nheuristic from a given network instead of using predefined ones. By extracting\\na local subgraph around each target link, we aim to learn a function mapping\\nthe subgraph patterns to link existence, thus automatically learning a\\n`heuristic' that suits the current network. In this paper, we study this\\nheuristic learning paradigm for link prediction. First, we develop a novel\\n$\\\\gamma$-decaying heuristic theory. The theory unifies a wide range of\\nheuristics in a single framework, and proves that all these heuristics can be\\nwell approximated from local subgraphs. Our results show that local subgraphs\\nreserve rich information related to link existence. Second, based on the\\n$\\\\gamma$-decaying theory, we propose a new algorithm to learn heuristics from\\nlocal subgraphs using a graph neural network (GNN). Its experimental results\\nshow unprecedented performance, working consistently well on a wide range of\\nproblems.\\n\"\n",
      " '  Shifted combinatorial optimization is a new nonlinear optimization framework,\\nwhich is a broad extension of standard combinatorial optimization, involving\\nthe choice of several feasible solutions at a time. It captures well studied\\nand diverse problems ranging from congestive to partitioning problems. In\\nparticular, every standard combinatorial optimization problem has its shifted\\ncounterpart, which is typically much harder. Here we initiate a study of\\napproximation algorithms for this broad optimization framework.\\n'\n",
      " '  We define the notion $\\\\phi(x,y)$ has $NIP$ in $A$, where $A$ is a subset of a\\nmodel, and give some equivalences by translating results from [1]. Using\\nadditional material from [11] we discuss the number of coheirs when $A$ is not\\nnecessarily countable. We also revisit the notion \"$\\\\phi(x,y)$ has $NOP$ in a\\nmodel $M$\" from [8].\\n'\n",
      " '  We study in this paper a class of constrained linear-quadratic (LQ) optimal\\ncontrol problem formulations for the scalar-state stochastic system with\\nmultiplicative noise, which has various applications, especially in the\\nfinancial risk management. The linear constraint on both the control and state\\nvariables considered in our model destroys the elegant structure of the\\nconventional LQ formulation and has blocked the derivation of an explicit\\ncontrol policy so far in the literature. We successfully derive in this paper\\nthe analytical control policy for such a class of problems by utilizing the\\nstate separation property induced from its structure. We reveal that the\\noptimal control policy is a piece-wise affine function of the state and can be\\ncomputed off-line efficiently by solving two coupled Riccati equations. Under\\nsome mild conditions, we also obtain the stationary control policy for infinite\\ntime horizon. We demonstrate the implementation of our method via some\\nillustrative examples and show how to calibrate our model to solve dynamic\\nconstrained portfolio optimization problems.\\n'\n",
      " '  We study a class of stably projectionless simple C*-algebras which may be\\nviewed as having generalized tracial rank one in analogy with the unital case.\\nSome structural question concerning these simple C*-algebras are studied. The\\npaper also serves as a technical support for the classification of separable\\nstably projectionless simple amenable Jiang-Su stable C*-algebras.\\n'\n",
      " '  In this paper, we study a model of opinion dynamics in a social network in\\nthe presence increasing interpersonal influence, i.e., increasing peer\\npressure. Each agent in the social network has a distinct social stress\\nfunction given by a weighted sum of internal and external behavioral pressures.\\nWe assume a weighted average update rule and prove conditions under which a\\nconnected group of agents converge to a fixed opinion distribution, and under\\nwhich conditions the group reaches consensus. We show that the update rule is a\\ngradient descent and explain its transient and asymptotic convergence\\nproperties. Through simulation, we study the rate of convergence on a\\nscale-free network and then validate the assumption of increasing peer pressure\\nin a simple empirical model.\\n'\n",
      " '  We construct the error distributions for the galactic rotation speed\\n($\\\\Theta_0$) using 137 data points from measurements compiled in De Grijs et\\nal. (arXiv:1709.02501), with all observations normalized to the galactocentric\\ndistance of 8.3 kpc. We then checked (using the same procedures as in works by\\nRatra et al) if the errors constructed using the weighted mean and the median\\nas the estimate, obey Gaussian statistics. We find using both these estimates\\nthat they have much wider tails than a Gaussian distribution. We also tried to\\nfit the data to three other distributions: Cauchy, double-exponential, and\\nStudents-t. The best fit is obtained using the Students-$t$ distribution for\\n$n=2$ using the median value as the central estimate, corresponding to a\\n$p$-value of 0.1. We also calculate the median value of $\\\\Theta_0$ using all\\nthe data as well as using the median of each set of measurements based on the\\ntracer population used. Because of the non-gaussianity of the residuals, we\\npoint out that the subgroup median value, given by $\\\\Theta_{med}=219.65$ km/sec\\nshould be used as the central estimate for $\\\\Theta_0$.\\n'\n",
      " '  We use deep HI observations obtained as part of the extended GALEX Arecibo\\nSDSS survey (xGASS) to study the cold gas properties of central galaxies across\\nenvironments. We find that, below stellar masses of 10^10.2 Msun, central\\ngalaxies in groups have an average atomic hydrogen gas fraction ~0.3dex higher\\nthan those in isolation at the same stellar mass. At these stellar masses,\\ngroup central galaxies are usually found in small groups of N=2 members. The\\nhigher HI content in these low mass group central galaxies is mirrored by their\\nhigher average star formation activity and molecular hydrogen content. At\\nlarger stellar masses, this difference disappears and central galaxies in\\ngroups have similar (or even smaller) gas reservoirs and star formation\\nactivity compared to those in isolation. We discuss possible scenarios able to\\nexplain our findings and suggest that the higher gas content in low mass group\\ncentral galaxies is likely due to contributions from the cosmic web or HI-rich\\nminor mergers, which also fuel their enhanced star formation activity.\\n'\n",
      " '  In this paper, we study almost regular Landsberg general\\n$(\\\\alpha,\\\\beta)$-metrics in Finsler geometry. The corresponding equivalent\\nequations are given. By solving the equations, we give the classification of\\nLandsberg general $(\\\\alpha,\\\\beta)$-metrics under the conditon that $\\\\beta$ is\\nclosed and conformal to $\\\\alpha$. Under this condition, we prove that regular\\nLandsberg general $(\\\\alpha,\\\\beta)$-metrics must be Berwaldian when the\\ndimension is greater than two. For the almost regular case, the classification\\nalso is given and some new non-Berwaldian Landsberg metrics are found.\\n'\n",
      " '  In this note, the attitude and inertial sensors drift biases estimation for\\nStrapdown inertial navigation system is investigated. A semi-analytic method is\\nproposed, which contains two interlaced solution procedures. Specifically, the\\nattitude encoding the body frame changes and gyroscopes drift biases are\\nestimated through attitude estimation while the attitude encoding the constant\\nvalue at the very start and accelerometers drift biases are determined through\\nonline optimization.\\n'\n",
      " '  Regulators require financial institutions to estimate counterparty default\\nrisks from liquid CDS quotes for the valuation and risk management of OTC\\nderivatives. However, the vast majority of counterparties do not have liquid\\nCDS quotes and need proxy CDS rates. Existing methods cannot account for\\ncounterparty-specific default risks; we propose to construct proxy CDS rates by\\nassociating to illiquid counterparty liquid CDS Proxy based on Machine Learning\\nTechniques. After testing 156 classifiers from 8 most popular classifier\\nfamilies, we found that some classifiers achieve highly satisfactory accuracy\\nrates. Furthermore, we have rank-ordered the performances and investigated\\nperformance variations amongst and within the 8 classifier families. This paper\\nis, to the best of our knowledge, the first systematic study of CDS Proxy\\nconstruction by Machine Learning techniques, and the first systematic\\nclassifier comparison study based entirely on financial market data. Its\\nfindings both confirm and contrast existing classifier performance literature.\\nGiven the typically highly correlated nature of financial data, we investigated\\nthe impact of correlation on classifier performance. The techniques used in\\nthis paper should be of interest for financial institutions seeking a CDS Proxy\\nmethod, and can serve for proxy construction for other financial variables.\\nSome directions for future research are indicated.\\n'\n",
      " '  We present results on simplifying an acting group preserving properties of\\nactions: transitivity, being a coset space and preserving a fixed\\nequiuniformity in case of a $G$-Tychonoff space.\\n'\n",
      " '  The nearest neighbor method together with the dynamic time warping (DTW)\\ndistance is one of the most popular approaches in time series classification.\\nThis method suffers from high storage and computation requirements for large\\ntraining sets. As a solution to both drawbacks, this article extends learning\\nvector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ\\nscheme uses asymmetric weighted averaging as update rule. Empirical results\\nexhibited superior performance of asymmetric generalized LVQ (GLVQ) over other\\nstate-of-the-art prototype generation methods for nearest neighbor\\nclassification.\\n'\n",
      " '  Two-dimensional transition metal dichalcogenides (TMDCs), as promising\\nalternative plasmonics supporting materials to graphene, exhibit potential\\napplications in sensing. Here, we propose an ultrasensitive, accurate\\nlong-range surface plasmon resonance (LRSPR) imaging biosensor with\\ntwo-dimensional TMDC layers, which shows higher detection accuracy than that of\\nconventional SPR biosensor. It is found that the imaging sensitivity of the\\nproposed LRSPR biosensor can be enhanced by the integration of TMDC layers,\\nwhich is different from the previous graphene-based LRSPR or SPR imaging\\nsensor, whose imaging sensitivity usually decreases with the number of graphene\\nlayers. The sensitivity enhancement or degradation effect for the proposed\\nchalcogenide-cytop-gold-TMDCs based biosensor depends on the thickness of gold\\nthin film and cytop layer. Imaging sensitivity of more than 4000\\n$\\\\text{RIU}^{-1}$ can be obtained with a high detection accuracy of more than\\n120 $\\\\text{deg}^{-1}$. We expect that the proposed TMDCs mediated LRSPR imaging\\nsensor could provide potential applications in chemical sensing and biosensing\\nfor a highly sensitive and accurate simultaneous detection of multiple\\nbiomolecular interactions.\\n'\n",
      " \"  We present tilting rates for galaxies comparable to the Milky Way (MW) in a\\n$\\\\Lambda$ cold dark matter cosmological hydrodynamical simulation, and compare\\nthese with the predicted tilting rate detection limit of the {\\\\it Gaia}\\nsatellite $0.28\\\\degrees$Gyr$^{-1}$. We first identify galaxies with mass\\ncomparable to the MW ($9 \\\\times 10^{11} \\\\le M_{200} \\\\le 1.2 \\\\times 10^{12}\\n\\\\Msun $) and consider the tilting rates between $z=0.3$ and $0$. This sample\\nyields a tilting rate of $7.6\\\\degrees \\\\pm 4.5\\\\degrees$Gyr$^{-1}$. We constrain\\nour sample further to exclude any galaxies that have high stellar accretion\\nduring the same time. We still find significant tilting, with an average rate\\nof $6.3\\\\degrees$Gyr$^{-1}$. Both subsamples tilt with rates significantly above\\n{\\\\it Gaia}'s predicted detection limit. We show that our sample of galaxies\\ncovers a wide range of environments, including some similar to the MW's. We\\nfind galaxies in denser regions tilt with higher rates then galaxies in less\\ndense regions. We also find correlations between the angular misalignment of\\nthe hot gas corona, and the tilting rate. {\\\\it Gaia} is likely to be able to\\ndirectly measure tilting in the MW. Such a detection will provide an important\\nconstraint on the environment of the MW, including the rate of gas cooling onto\\nthe disc, the shape and orientation of its dark matter halo, and the mass of\\nthe Large Magellanic Cloud. Conversely, failure to detect tilting may suggest\\nthe MW is in a very quiet configuration.\\n\"\n",
      " '  We review two important non-perturbative approaches for extracting the\\nphysics of low-dimensional strongly correlated quantum systems. Firstly, we\\nstart by providing a comprehensive review of non-Abelian bosonization. This\\nincludes an introduction to the basic elements of conformal field theory as\\napplied to systems with a current algebra, and we orient the reader by\\npresenting a number of applications of non-Abelian bosonization to models with\\nlarge symmetries. We then tie this technique into recent advances in the\\nability of cold atomic systems to realize complex symmetries. Secondly, we\\ndiscuss truncated spectrum methods for the numerical study of systems in one\\nand two dimensions. For one-dimensional systems we provide the reader with\\nconsiderable insight into the methodology by reviewing canonical applications\\nof the technique to the Ising model (and its variants) and the sine-Gordon\\nmodel. Following this we review recent work on the development of\\nrenormalization groups, both numerical and analytical, that alleviate the\\neffects of truncating the spectrum. Using these technologies, we consider a\\nnumber of applications to one-dimensional systems: properties of carbon\\nnanotubes, quenches in the Lieb-Liniger model, 1+1D quantum chromodynamics, as\\nwell as Landau-Ginzburg theories. In the final part we move our attention to\\nconsider truncated spectrum methods applied to two-dimensional systems. This\\ninvolves combining truncated spectrum methods with matrix product state\\nalgorithms. We describe applications of this method to two-dimensional systems\\nof free fermions and the quantum Ising model, including their non-equilibrium\\ndynamics.\\n'\n",
      " \"  In this paper an extension of the spectral Lanczos' tau method to systems of\\nnonlinear integro-differential equations is proposed. This extension includes\\n(i) linearization coefficients of orthogonal polynomials products issued from\\nnonlinear terms and (ii) recursive relations to implement matrix inversion\\nwhenever a polynomial change of basis is required and (iii) orthogonal\\npolynomial evaluations directly on the orthogonal basis. All these improvements\\nensure numerical stability and accuracy in the approximate solution. Exposed in\\ndetail, this novel approach is able to significantly outperform numerical\\napproximations with other methods as well as different tau implementations.\\nNumerical results on a set of problems illustrate the impact of the\\nmathematical techniques introduced.\\n\"\n",
      " '  The ferroelectric to paraelectric phase transition of multiferroic\\nCaMnTi$_2$O$_6$ has been investigated at high pressures and ambient temperature\\nby second harmonic generation (SHG), Raman spectroscopy, and powder and\\nsingle-crystal x-ray diffraction. We have found that CaMnTi$_2$O$_6$ undergoes\\na pressure-induced structural phase transition ($P4_2mc \\\\rightarrow P4_2/nmc$)\\nat $\\\\sim$7 GPa to the same paraelectric structure found at ambient pressure and\\n$T_c$ = 630 K. The continuous linear decrease of the SHG intensity that\\ndisappears at 7 GPa and the existence of a Raman active mode at 244 cm$^{-1}$\\nthat first softens up to 7 GPa and then hardens with pressure, are used to\\ndiscuss the nature of the phase transition of CaMnTi$_2$O$_6$ for which a\\nd$T_c$/d$P = -48$ K/GPa has been found. Neither a volume contraction nor a\\nchange of the normalized pressure on the eulerian strain are observed across\\nthe phase transition with all the unit-cell volume data following a second\\norder Birch-Murnaghan equation of state with a bulk modulus of $B_0$ =\\n182.95(2) GPa.\\n'\n",
      " \"  We introduce a family of factorisable ribbon quasi-Hopf algebras $Q(N)$ for\\n$N$ a positive integer: as an algebra, $Q(N)$ is the semidirect product of\\n$\\\\mathbb{C}\\\\mathbb{Z}_2$ with the direct sum of a Grassmann and a Clifford\\nalgebra in $2N$ generators. We show that $Rep Q(N)$ is ribbon equivalent to the\\nsymplectic fermion category $SF(N)$ that was computed by the third author from\\nconformal blocks of the corresponding logarithmic conformal field theory. The\\nlatter category in turn is conjecturally ribbon equivalent to representations\\nof $V_{ev}$, the even part of the symplectic fermion vertex operator super\\nalgebra.\\nUsing the formalism developed in our previous paper we compute the projective\\n$SL(2,\\\\mathbb{Z})$-action on the centre of $Q(N)$ as obtained from\\nLyubashenko's general theory of mapping class group actions for factorisable\\nfinite ribbon categories. This allows us to test a conjectural non-semisimple\\nversion of the modular Verlinde formula: we verify that the\\n$SL(2,\\\\mathbb{Z})$-action computed from $Q(N)$ agrees projectively with that on\\npseudo trace functions of $V_{ev}$.\\n\"\n",
      " '  This article introduces a tensor network subspace algorithm for the\\nidentification of specific polynomial state space models. The polynomial\\nnonlinearity in the state space model is completely written in terms of a\\ntensor network, thus avoiding the curse of dimensionality. We also prove how\\nthe block Hankel data matrices in the subspace method can be exactly\\nrepresented by low rank tensor networks, reducing the computational and storage\\ncomplexity significantly. The performance and accuracy of our subspace\\nidentification algorithm are illustrated by numerical experiments, showing that\\nour tensor network implementation is around 20 times faster than the standard\\nmatrix implementation before the latter fails due to insufficient memory, is\\nrobust with respect to noise and can model real-world systems.\\n'\n",
      " '  Optical distortions can significantly deteriorate the measurement accuracy in\\nimaging systems. Such distortions can occur at fluctuating phase boundaries as\\nwell as multiple-phase flows and result from the accompanied refractive index\\nchanges. Due to multiple reflexes arising from a fluid flow setup, the usage of\\na wave front sensor (WFS) can be hindered. In this work we outline a wave front\\nsensor-less approach which includes iterative aberration correction with a fast\\ndeformable mirror (DM). A combination of sharpness metric (SM) image evaluation\\nand iterative optimization is demonstrated. The SM was measured for each image\\nwhile adjusting seven Zernike modes (after Noll index enumeration) in their\\namplitude. The SM is used as an indicator for wave front aberrations without\\nusing a wave front sensor to correct wave front distortions that are generated\\nby the DM. The proposed method allows for the reduction of systematic\\nmeasurement uncertainties in fluid flow measurement techniques as particle\\nimage velocimetry (PIV). Five different sharpness metrics are demonstrated for\\nreliable sharpness maximization with a deformable mirror of 69 elements. A\\nsystematic linear search (LS) algorithm was applied in order to find the\\noptimal mirror shape. The reduction of measurement uncertainty for PIV\\nmeasurements is shown. The iterative approach offers a way to reduce static or\\nslowly changing wave front distortions in a fluid flow setup where a WFS is not\\napplicable.\\n'\n",
      " '  The subject of this work is the shock development problem in fluid mechanics.\\nA shock originates from an acoustically spacelike surface in spacetime at which\\nthe 1st derivatives of the physical variables blow up. The solution requires\\nthe construction of a hypersurface in spacetime which is acoustically timelike\\nas viewed from its future, acoustically spacelike as viewed from its past, the\\nshock hypersurface, across which the physical variables suffer discontinuities\\nobeying jump conditions in accordance with the integral form of the particle\\nand energy-momentum conservation laws. Mathematically, this is a free boundary\\nproblem, with nonlinear conditions at the free boundary, for a 1st order\\nquasilinear hyperbolic system of p.d.e., with characteristic initial data which\\nare singular at the past boundary of the initial characteristic hypersurface,\\nthat boundary being the surface of origin. This work solves, in any number of\\nspatial dimensions, a restricted form of the problem which retains the\\nessential difficulties due to the singular nature of the surface of origin. The\\nsolution is accomplished through the introduction of new geometric and analytic\\nmethods.\\n'\n",
      " '  We work with attracting subshifts generated by substitutions which are also\\nirreducible parageometric automorphisms of free groups. For such a dynamical\\nsystem, we construct a tree substitution to approximate the repelling real tree\\nof the automorphism. We produce images of this tree inside the Rauzy fractal\\nwhen the substitution is irreducible Pisot. We describe the contour of this\\ntree and compute an interval exchange transformation of the circle covering the\\noriginal substitution.\\n'\n",
      " '  Accurate molecular data for the low-lying states of SiO are computed and used\\nto calculate rate constants for radiative association of Si and O. Einstein\\nA-coefficients are also calculated for transitions between all of the bound and\\nquasi-bound levels for each molecular state. The radiative widths are used\\ntogether with elastic tunneling widths to define effective radiative\\nassociation rate constants which include both direct and indirect (inverse\\npredissociation) formation processes. The indirect process is evaluated for two\\nkinetic models which represent limiting cases for astrophysical environments.\\nThe first case scenario assumes an equilibrium distribution of quasi-bound\\nstates and would be applicable whenever collisional and/or radiative excitation\\nmechanisms are able to maintain the population. The second case scenario\\nassumes that no excitation mechanisms are available which corresponds to the\\nlimit of zero radiation temperature and zero atomic density. Rate constants for\\nSiO formation in realistic astrophysical environments would presumably lie\\nbetween these two limiting cases.\\n'\n",
      " \"  We present CROSSGRAD, a method to use multi-domain training data to learn a\\nclassifier that generalizes to new domains. CROSSGRAD does not need an\\nadaptation phase via labeled or unlabeled data, or domain features in the new\\ndomain. Most existing domain adaptation methods attempt to erase domain signals\\nusing techniques like domain adversarial training. In contrast, CROSSGRAD is\\nfree to use domain signals for predicting labels, if it can prevent overfitting\\non training domains. We conceptualize the task in a Bayesian setting, in which\\na sampling step is implemented as data augmentation, based on domain-guided\\nperturbations of input instances. CROSSGRAD parallelly trains a label and a\\ndomain classifier on examples perturbed by loss gradients of each other's\\nobjectives. This enables us to directly perturb inputs, without separating and\\nre-mixing domain signals while making various distributional assumptions.\\nEmpirical evaluation on three different applications where this setting is\\nnatural establishes that (1) domain-guided perturbation provides consistently\\nbetter generalization to unseen domains, compared to generic instance\\nperturbation methods, and that (2) data augmentation is a more stable and\\naccurate method than domain adversarial training.\\n\"\n",
      " '  Fundamental experimental measurements of quantities such as ignition delay\\ntimes, laminar flame speeds, and species profiles (among others) serve\\nimportant roles in understanding fuel chemistry and validating chemical kinetic\\nmodels. However, despite both the importance and abundance of such information\\nin the literature, the community lacks a widely adopted standard format for\\nthis data. This impedes both sharing and wide use by the community. Here we\\nintroduce a new chemical kinetics experimental data format, ChemKED, and the\\nrelated Python-based package for validating and working with ChemKED-formatted\\nfiles called PyKED. We also review past and related efforts, and motivate the\\nneed for a new solution. ChemKED currently supports the representation of\\nautoignition delay time measurements from shock tubes and rapid compression\\nmachines. ChemKED-formatted files contain all of the information needed to\\nsimulate experimental data points, including the uncertainty of the data.\\nChemKED is based on the YAML data serialization language, and is intended as a\\nhuman- and machine-readable standard for easy creation and automated use.\\nDevelopment of ChemKED and PyKED occurs openly on GitHub under the BSD 3-clause\\nlicense, and contributions from the community are welcome. Plans for future\\ndevelopment include support for experimental data from laminar flame, jet\\nstirred reactor, and speciation measurements.\\n'\n",
      " '  The postulate of independence of cause and mechanism (ICM) has recently led\\nto several new causal discovery algorithms. The interpretation of independence\\nand the way it is utilized, however, varies across these methods. Our aim in\\nthis paper is to propose a group theoretic framework for ICM to unify and\\ngeneralize these approaches. In our setting, the cause-mechanism relationship\\nis assessed by comparing it against a null hypothesis through the application\\nof random generic group transformations. We show that the group theoretic view\\nprovides a very general tool to study the structure of data generating\\nmechanisms with direct applications to machine learning.\\n'\n",
      " '  The current exoplanet database includes 5454 confirmed planets and candidate\\nplanets observed with the KEPLER mission. We find 932 planet pairs from which\\nwe extract distance and orbital period ratios. While earlier studies used the\\nTitius-Bode law or a generalized version with logarithmic spacing, which both\\nlack a physical model, we employ here the theory of harmonic orbit resonances,\\nwhich contains quantized ratios instead, to explain the observed planet\\ndistance ratios and to predict undetected exoplanets. We find that the most\\nprevailing harmonic ratios are (2:1), (3:2), and (5:3), in 73\\\\% of the cases,\\nwhile alternative harmonic ratios of (5:4), (4:3), (5:2), (3:1) occur in 27\\\\%\\nof the other cases. Our orbital predictions includes 171 exoplanets, 2 Jupiter\\nmoons, one Saturn moon, 3 Uranus moons, and 4 Neptune moons. The accuracy of\\nthe predicted planet distances amounts to a few percent, which fits the data\\nsignificantly better than the Titius-Bode law or a logarithmic spacing. This\\ninformation may be useful for targeted exoplanet searches with Kepler data and\\nto estimate the number of live-carrying planets in habitable zones.\\n'\n",
      " '  Although the word-popularity based negative sampler has shown superb\\nperformance in the skip-gram model, the theoretical motivation behind\\noversampling popular (non-observed) words as negative samples is still not well\\nunderstood. In this paper, we start from an investigation of the gradient\\nvanishing issue in the skipgram model without a proper negative sampler. By\\nperforming an insightful analysis from the stochastic gradient descent (SGD)\\nlearning perspective, we demonstrate that, both theoretically and intuitively,\\nnegative samples with larger inner product scores are more informative than\\nthose with lower scores for the SGD learner in terms of both convergence rate\\nand accuracy. Understanding this, we propose an alternative sampling algorithm\\nthat dynamically selects informative negative samples during each SGD update.\\nMore importantly, the proposed sampler accounts for multi-dimensional\\nself-embedded features during the sampling process, which essentially makes it\\nmore effective than the original popularity-based (one-dimensional) sampler.\\nEmpirical experiments further verify our observations, and show that our\\nfine-grained samplers gain significant improvement over the existing ones\\nwithout increasing computational complexity.\\n'\n",
      " '  Despite rapid advances in machine learning tools, the majority of neural\\ndecoding approaches still use traditional methods. Improving the performance of\\nneural decoding algorithms allows us to better understand the information\\ncontained in a neural population, and can help advance engineering applications\\nsuch as brain machine interfaces. Here, we apply modern machine learning\\ntechniques, including neural networks and gradient boosting, to decode from\\nspiking activity in 1) motor cortex, 2) somatosensory cortex, and 3)\\nhippocampus. We compare the predictive ability of these modern methods with\\ntraditional decoding methods such as Wiener and Kalman filters. Modern methods,\\nin particular neural networks and ensembles, significantly outperformed the\\ntraditional approaches. For instance, for all of the three brain areas, an LSTM\\ndecoder explained over 40% of the unexplained variance from a Wiener filter.\\nThese results suggest that modern machine learning techniques should become the\\nstandard methodology for neural decoding. We provide a tutorial and code to\\nfacilitate wider implementation of these methods.\\n'\n",
      " '  As network deployments become denser, interference arises as a dominant\\nperformance degradation factor. To confront with this trend, Long Term\\nEvolution (LTE) incorporated features aiming at enabling cooperation among\\ndifferent base stations, a technique termed as Coordinated Multi Point (CoMP).\\nRecent field trial results and theoretical studies of the performance of CoMP\\nschemes revealed, however, that their gains are not as high as initially\\nexpected, despite their large coordination overhead. In this paper, we review\\nrecent advanced Coordinated Beamforming (CB) schemes, a special family of CoMP\\nthat reduces the coordination overhead through a joint choice of transmit and\\nreceive linear filters. We focus on assessing their resilience to uncoordinated\\ninterference and Channel State Information (CSI) imperfections, which both\\nseverely limit the performance gains of all CoMP schemes. We present a simple\\nyet encompassing system model that aims at incorporating different parameters\\nof interest in the relative interference power and CSI errors, and then utilize\\nit for the performance evaluation of the state-of-the-art in CB schemes. It is\\nshown that blindly applying CB in all system scenarios can indeed be\\ncounter-productive.\\n'\n",
      " '  Let $\\\\C$ be a triangulated category with a cluster tilting subcategory $\\\\T$.\\nWe introduce the notion of $\\\\T[1]$-cluster tilting subcategories (also called\\nghost cluster tilting subcategories) of $\\\\C$, which are a generalization of\\ncluster tilting subcategories. We first develop a basic theory on ghost cluster\\ntilting subcategories. Secondly, we study links between ghost cluster tilting\\ntheory and $\\\\tau$-tilting theory: Inspired by the work of Iyama, J{\\\\o}rgensen\\nand Yang \\\\cite{ijy}, we introduce the notion of $\\\\tau$-tilting subcategories\\nand tilting subcategories of $\\\\mod\\\\T$. We show that there exists a bijection\\nbetween weak $\\\\T[1]$-cluster tilting subcategories of $\\\\C$ and support\\n$\\\\tau$-tilting subcategories of $\\\\mod\\\\T$. Moreover, we figure out the\\nsubcategories of $\\\\mod\\\\T$ which correspond to cluster tilting subcategories of\\n$\\\\C$. This generalizes and improves several results by Adachi-Iyama-Reiten\\n\\\\cite{AIR}, Beligiannis \\\\cite{Be2}, and Yang-Zhu \\\\cite{YZ}. Finally, we prove\\nthat the definition of ghost cluster tilting objects is equivalent to the\\ndefinition of relative cluster tilting objects introduced by the first and the\\nthird author in \\\\cite{YZ}.\\n'\n",
      " '  We revisit the classic online bin packing problem. In this problem, items of\\npositive sizes no larger than 1 are presented one by one to be packed into\\nsubsets called \"bins\" of total sizes no larger than 1, such that every item is\\nassigned to a bin before the next item is presented. We use online partitioning\\nof items into classes based on sizes, as in previous work, but we also apply a\\nnew method where items of one class can be packed into more than two types of\\nbins, where a bin type is defined according to the number of such items grouped\\ntogether. Additionally, we allow the smallest class of items to be packed in\\nmultiple kinds of bins, and not only into their own bins. We combine this with\\nthe approach of packing of sufficiently big items according to their exact\\nsizes. Finally, we simplify the analysis of such algorithms, allowing the\\nanalysis to be based on the most standard weight functions. This simplified\\nanalysis allows us to study the algorithm which we defined based on all these\\nideas. This leads us to the design and analysis of the first algorithm of\\nasymptotic competitive ratio strictly below 1.58, specifically, we break this\\nbarrier and provide an algorithm AH (Advanced Harmonic) whose asymptotic\\ncompetitive ratio does not exceed 1.5783.\\n'\n",
      " '  Effective utilization of photovoltaic (PV) plants requires weather\\nvariability robust global solar radiation (GSR) forecasting models. Random\\nweather turbulence phenomena coupled with assumptions of clear sky model as\\nsuggested by Hottel pose significant challenges to parametric & non-parametric\\nmodels in GSR conversion rate estimation. Also, a decent GSR estimate requires\\ncostly high-tech radiometer and expert dependent instrument handling and\\nmeasurements, which are subjective. As such, a computer aided monitoring (CAM)\\nsystem to evaluate PV plant operation feasibility by employing smart grid past\\ndata analytics and deep learning is developed. Our algorithm, SolarisNet is a\\n6-layer deep neural network trained on data collected at two weather stations\\nlocated near Kalyani metrological site, West Bengal, India. The daily GSR\\nprediction performance using SolarisNet outperforms the existing state of art\\nand its efficacy in inferring past GSR data insights to comprehend daily and\\nseasonal GSR variability along with its competence for short term forecasting\\nis discussed.\\n'\n",
      " '  Human motion modelling is a classical problem at the intersection of graphics\\nand computer vision, with applications spanning human-computer interaction,\\nmotion synthesis, and motion prediction for virtual and augmented reality.\\nFollowing the success of deep learning methods in several computer vision\\ntasks, recent work has focused on using deep recurrent neural networks (RNNs)\\nto model human motion, with the goal of learning time-dependent representations\\nthat perform tasks such as short-term motion prediction and long-term human\\nmotion synthesis. We examine recent work, with a focus on the evaluation\\nmethodologies commonly used in the literature, and show that, surprisingly,\\nstate-of-the-art performance can be achieved by a simple baseline that does not\\nattempt to model motion at all. We investigate this result, and analyze recent\\nRNN methods by looking at the architectures, loss functions, and training\\nprocedures used in state-of-the-art approaches. We propose three changes to the\\nstandard RNN models typically used for human motion, which result in a simple\\nand scalable RNN architecture that obtains state-of-the-art performance on\\nhuman motion prediction.\\n'\n",
      " \"  We propose a new simple convergence acceleration method for wide range class\\nof convergent alternating series. It has some common features with Smith's and\\nFord's modification of Levin's and Weniger's sequence transformations, but its\\ncomputational and memory cost is lower. We compare all three methods and give\\nsome common theoretical results. Numerical examples confirm a similar\\nperformance of all of them.\\n\"\n",
      " '  There has been considerable interest in making Bayesian inference more\\nscalable. In big data settings, most literature focuses on reducing the\\ncomputing time per iteration, with less focused on reducing the number of\\niterations needed in Markov chain Monte Carlo (MCMC). This article focuses on\\ndata augmentation MCMC (DA-MCMC), a widely used technique. DA-MCMC samples tend\\nto become highly autocorrelated in large data samples, due to a miscalibration\\nproblem in which conditional posterior distributions given augmented data are\\ntoo concentrated. This makes it necessary to collect very long MCMC paths to\\nobtain acceptably low MC error. To combat this inefficiency, we propose a\\nfamily of calibrated data augmentation algorithms, which appropriately adjust\\nthe variance of conditional posterior distributions. A Metropolis-Hastings step\\nis used to eliminate bias in the stationary distribution of the resulting\\nsampler. Compared to existing alternatives, this approach can dramatically\\nreduce MC error by reducing autocorrelation and increasing the effective number\\nof DA-MCMC samples per computing time. The approach is simple and applicable to\\na broad variety of existing data augmentation algorithms, and we focus on three\\npopular models: probit, logistic and Poisson log-linear. Dramatic gains in\\ncomputational efficiency are shown in applications.\\n'\n",
      " '  We present stacked average far-infrared spectra of a sample of 197 dusty,\\nstar-forming galaxies (DSFGs) at $0.005 < z < 4$ using close to 90% of the\\nSPIRE Fourier Transform Spectrometer (FTS) extragalactic data archive from the\\nHerschel Space Observatory based on 3.5 years of science operations. These\\nspectra explore an observed-frame $\\\\rm 447\\\\,GHz-1568\\\\,GHz$ ($\\\\rm 191\\\\,\\\\mu\\nm-671\\\\,\\\\mu m$) frequency (wavelength) range allowing us to observe the main\\natomic and molecular lines emitted by gas in the interstellar medium. The\\nsample is sub-divided into five redshift bins at $0.005 < z < 0.05$, $0.05 < z\\n< 0.2$, $0.2 < z < 0.5$, $0.8 < z <2$, and $2 < z < 4$. To study the dependence\\nof observed spectral lines on total infrared luminosity, the sources in a\\nsubset of the redshift bins are stacked in luminosity bins. These stacked\\nspectra are used to determine the average properties of the interstellar medium\\nand dense molecular gas properties of DSFGs, in particular, the fine-structure\\nline ([CII] 158 $\\\\mu$m and [OI] 63 $\\\\mu$m) luminosity ratios, and the line to\\nfar-IR luminosity ratios are used to model the gas density and radiation field\\nstrength in the photodissociation regions (PDRs). For the low-redshift sample,\\nwe additionally present the average spectral line energy distributions (SLED)\\nof CO and $\\\\rm{H_2O}$ rotational transitions and also consider PDR conditions\\nbased on a combination of [CI] 370 $\\\\mu$m and 609 $\\\\mu$m and $\\\\rm CO (7-6)$\\nlines. For the high-z ($0.8 < z < 4$) sample PDR models suggest a molecular gas\\ndistribution in the presence of a radiation field that is at least a factor of\\n10$^3$ larger than the Milky-Way and with a neutral gas density of roughly\\n10$^3$ to 10$^5$ cm$^{-3}$. The corresponding PDR models for the low-z sample\\nsuggest a UV radiation field and gas density comparable to those at high-z.\\n'\n",
      " '  We report the first results from a search for transiting warm Jupiter\\nexoplanets - gas giant planets receiving stellar irradiation below about $10^8$\\nerg s$^{-1}$ cm$^{-2}$, equivalent to orbital periods beyond about 10 days\\naround Sun-like stars. We have discovered two transiting warm Jupiter\\nexoplanets initially identified as transiting candidates in ${\\\\it K2}$\\nphotometry. K2-114b has a mass of $1.85^{+0.23}_{-0.22}\\\\ M_J$, a radius of\\n$0.942^{+0.032}_{-0.020}\\\\ R_J$, and an orbital period of 11.4 days. K2-115b has\\na mass of $0.84^{+0.18}_{-0.20}\\\\ M_J$, a radius of $1.115^{+0.057}_{-0.061}\\\\\\nR_J$, and an orbital period of 20.3 days. Both planets are among the longest\\nperiod transiting gas giant planets with a measured mass, and they are orbiting\\nrelatively old host stars. Both planets are not inflated as their radii are\\nconsistent with theoretical expectations. Their position in the planet radius -\\nstellar irradiation diagram is consistent with the scenario where the radius -\\nirradiation correlation levels off below about 10$^8$ erg s$^{-1}$ cm$^{-2}$,\\nsuggesting that for warm Jupiters the stellar irradiation does not play a\\nsignificant role in determining the planet radius. We also report our\\nidentification of another ${\\\\it K2}$ transiting warm Jupiter candidate, EPIC\\n212504617, as a false positive.\\n'\n",
      " \"  Efficient coupling between integrated optical waveguides and optical fibers\\nis essential to the success of integrated photonics. While many solutions\\nexist, perfectly vertical grating couplers which scatter light out of a\\nwaveguide in the direction normal to the waveguide's top surface are an ideal\\ncandidate due to their potential to reduce packaging complexity. Designing such\\ncouplers with high efficiency, however, has proven difficult. In this paper, we\\nuse electromagnetic inverse design techniques to optimize a high efficiency\\ntwo-layer perfectly vertical silicon grating coupler. Our base design achieves\\na chip-to-fiber coupling efficiency of over 99% (-0.04 dB) at 1550 nm. Using\\nthis base design, we apply subsequent constrained optimizations to achieve\\nvertical couplers with over 96% efficiency which are fabricable using a 65 nm\\nprocess.\\n\"\n",
      " '  In this paper we address the problem of developing on-line visual tracking\\nalgorithms. We present a specialized communication protocol that serves as a\\nbridge between a tracker implementation and utilizing application. It decouples\\ndevelopment of algorithms and application, encouraging re-usability. The\\nprimary use case is algorithm evaluation where the protocol facilitates more\\ncomplex evaluation scenarios that are used nowadays thus pushing forward the\\nfield of visual tracking. We present a reference implementation of the protocol\\nthat makes it easy to use in several popular programming languages and discuss\\nwhere the protocol is already used and some usage scenarios that we envision\\nfor the future.\\n'\n",
      " \"  Peakons are special weak solutions of a class of nonlinear partial\\ndifferential equations modelling non-linear phenomena such as the breakdown of\\nregularity and the onset of shocks. We show that the natural concept of weak\\nsolutions in the case of the modified Camassa-Holm equation studied in this\\npaper is dictated by the distributional compatibility of its Lax pair and, as a\\nresult, it differs from the one proposed and used in the literature based on\\nthe concept of weak solutions used for equations of the Burgers type.\\nSubsequently, we give a complete construction of peakon solutions satisfying\\nthe modified Camassa-Holm equation in the sense of distributions; our approach\\nis based on solving certain inverse boundary value problem the solution of\\nwhich hinges on a combination of classical techniques of analysis involving\\nStieltjes' continued fractions and multi-point Padé approximations. We\\npropose sufficient conditions needed to ensure the global existence of peakon\\nsolutions and analyze the large time asymptotic behaviour whose special\\nfeatures include a formation of pairs of peakons which share asymptotic speeds,\\nas well as Toda-like sorting property.\\n\"\n",
      " '  Radiomics aims to extract and analyze large numbers of quantitative features\\nfrom medical images and is highly promising in staging, diagnosing, and\\npredicting outcomes of cancer treatments. Nevertheless, several challenges need\\nto be addressed to construct an optimal radiomics predictive model. First, the\\npredictive performance of the model may be reduced when features extracted from\\nan individual imaging modality are blindly combined into a single predictive\\nmodel. Second, because many different types of classifiers are available to\\nconstruct a predictive model, selecting an optimal classifier for a particular\\napplication is still challenging. In this work, we developed multi-modality and\\nmulti-classifier radiomics predictive models that address the aforementioned\\nissues in currently available models. Specifically, a new reliable classifier\\nfusion strategy was proposed to optimally combine output from different\\nmodalities and classifiers. In this strategy, modality-specific classifiers\\nwere first trained, and an analytic evidential reasoning (ER) rule was\\ndeveloped to fuse the output score from each modality to construct an optimal\\npredictive model. One public data set and two clinical case studies were\\nperformed to validate model performance. The experimental results indicated\\nthat the proposed ER rule based radiomics models outperformed the traditional\\nmodels that rely on a single classifier or simply use combined features from\\ndifferent modalities.\\n'\n",
      " '  In our recent works, we developed a probabilistic framework for structural\\nanalysis in undirected networks and directed networks. The key idea of that\\nframework is to sample a network by a symmetric and asymmetric bivariate\\ndistribution and then use that bivariate distribution to formerly defining\\nvarious notions, including centrality, relative centrality, community, and\\nmodularity. The main objective of this paper is to extend the probabilistic\\ndefinition to attributed networks, where sampling bivariate distributions by\\nexponentially twisted sampling. Our main finding is that we find a way to deal\\nwith the sampling of the attributed network including signed network. By using\\nthe sampling method, we define the various centralities in attributed networks.\\nThe influence centralities and trust centralities correctly show that how to\\nidentify centralities in signed network. The advertisement-specific influence\\ncentralities also perfectly define centralities when the attributed networks\\nthat have node attribute. Experimental results on real-world dataset\\ndemonstrate the different centralities with changing the temperature. Further\\nexperiments are conducted to gain a deeper understanding of the importance of\\nthe temperature.\\n'\n",
      " '  State-of-the-art password guessing tools, such as HashCat and John the\\nRipper, enable users to check billions of passwords per second against password\\nhashes. In addition to performing straightforward dictionary attacks, these\\ntools can expand password dictionaries using password generation rules, such as\\nconcatenation of words (e.g., \"password123456\") and leet speak (e.g.,\\n\"password\" becomes \"p4s5w0rd\"). Although these rules work well in practice,\\nexpanding them to model further passwords is a laborious task that requires\\nspecialized expertise. To address this issue, in this paper we introduce\\nPassGAN, a novel approach that replaces human-generated password rules with\\ntheory-grounded machine learning algorithms. Instead of relying on manual\\npassword analysis, PassGAN uses a Generative Adversarial Network (GAN) to\\nautonomously learn the distribution of real passwords from actual password\\nleaks, and to generate high-quality password guesses. Our experiments show that\\nthis approach is very promising. When we evaluated PassGAN on two large\\npassword datasets, we were able to surpass rule-based and state-of-the-art\\nmachine learning password guessing tools. However, in contrast with the other\\ntools, PassGAN achieved this result without any a-priori knowledge on passwords\\nor common password structures. Additionally, when we combined the output of\\nPassGAN with the output of HashCat, we were able to match 51%-73% more\\npasswords than with HashCat alone. This is remarkable, because it shows that\\nPassGAN can autonomously extract a considerable number of password properties\\nthat current state-of-the art rules do not encode.\\n'\n",
      " '  A method is proposed for solving equality constrained nonlinear optimization\\nproblems involving twice continuously differentiable functions. The method\\nemploys a trust funnel approach consisting of two phases: a first phase to\\nlocate an $\\\\epsilon$-feasible point and a second phase to seek optimality while\\nmaintaining at least $\\\\epsilon$-feasibility. A two-phase approach of this kind\\nbased on a cubic regularization methodology was recently proposed along with a\\nsupporting worst-case iteration complexity analysis. Unfortunately, however, in\\nthat approach, the objective function is completely ignored in the first phase\\nwhen $\\\\epsilon$-feasibility is sought. The main contribution of the method\\nproposed in this paper is that the same worst-case iteration complexity is\\nachieved, but with a first phase that also accounts for improvements in the\\nobjective function. As such, the method typically requires fewer iterations in\\nthe second phase, as the results of numerical experiments demonstrate.\\n'\n",
      " '  Recently, the soft attention mechanism, which was originally proposed in\\nlanguage processing, has been applied in computer vision tasks like image\\ncaptioning. This paper presents improvements to the soft attention model by\\ncombining a convolutional LSTM with a hierarchical system architecture to\\nrecognize action categories in videos. We call this model the Convolutional\\nHierarchical Attention Model (CHAM). The model applies a convolutional\\noperation inside the LSTM cell and an attention map generation process to\\nrecognize actions. The hierarchical architecture of this model is able to\\nexplicitly reason on multi-granularities of action categories. The proposed\\narchitecture achieved improved results on three publicly available datasets:\\nthe UCF sports dataset, the Olympic sports dataset and the HMDB51 dataset.\\n'\n",
      " '  We show that the monodromy for a genus one, fibered knot can have at most two\\nmonodromy equivalence classes of once-unclean arcs. We use this to classify all\\nmonodromies of genus one, fibered knots that possess once-unclean arcs, all\\nmanifolds containing genus one fibered knots with generalized crossing changes\\nresulting in another genus one fibered knot, and all generalized crossing\\nchanges between two genus one, fibered knots.\\n'\n",
      " '  We introduce a trimmed version of the Hill estimator for the index of a\\nheavy-tailed distribution, which is robust to perturbations in the extreme\\norder statistics. In the ideal Pareto setting, the estimator is essentially\\nfinite-sample efficient among all unbiased estimators with a given strict upper\\nbreak-down point. For general heavy-tailed models, we establish the asymptotic\\nnormality of the estimator under second order conditions and discuss its\\nminimax optimal rate in the Hall class. We introduce the so-called trimmed Hill\\nplot, which can be used to select the number of top order statistics to trim.\\nWe also develop an automatic, data-driven procedure for the choice of trimming.\\nThis results in a new type of robust estimator that can {\\\\em adapt} to the\\nunknown level of contamination in the extremes. As a by-product we also obtain\\na methodology for identifying extreme outliers in heavy tailed data. The\\ncompetitive performance of the trimmed Hill and adaptive trimmed Hill\\nestimators is illustrated with simulations.\\n'\n",
      " '  Direct imaging of exoplanet systems requires the use of coronagraphs to reach\\nhigh contrast levels (10^-8 to 10^-11) at small angular separations (0.1\").\\nHowever, the performance of these devices is drastically limited by aberrations\\n(in phase or in amplitude, introduced either by atmosphere or by the optics).\\nCoronagraphs must therefore be combined with extreme adaptive optic systems,\\ncomposed of a focal plane wavefront sensor and of a high order deformable\\nmirror. These adaptive optic systems must reach a residual error in the\\ncorrected wavefront of less than 0.1 nm (RMS) with a rate of 1 kHz. In\\naddition, the surface defects of the deformable mirror, inherent from the\\nfabrication process, must be limited in order to avoid the introduction of\\namplitude aberrations. An experimental high contrast bench has been developed\\nat the Paris Observatory (LESIA). This bench includes a Boston Micromachine\\ndeformable mirror composed of 1024 actuators. For a precise analysis of its\\nsurface and performance, we characterized this mirror on the interferometric\\nbench developed since 2004 at the Marseille Observatory (LAM). In this paper,\\nwe present this interferometric bench as well as the results of the analysis.\\nThis will include a precise surface characterization and a description of the\\nbehavior of the actuators, on a 10 by 10 actuator range (behavior of a single\\nactuator, study of the cross-talk between neighbor actuators, influence of a\\nstuck actuator) and on full mirror scale (general surface shape).\\n'\n",
      " '  In this paper, we use a new partial order, called the f-majorization order.\\nThe new order includes as special cases the majorization , the reciprocal\\nmajorization and the p-larger orders. We provide a comprehensive account of the\\nmathematical properties of the f-majorization order and give applications of\\nthis order in the context of stochastic comparison for extreme order statistics\\nof independent samples following the Frechet distribution and scale model. We\\ndiscuss stochastic comparisons of series systems with independent heterogeneous\\nexponentiated scale components in terms of the usual stochastic order and the\\nhazard rate order. We also derive new result on the usual stochastic order for\\nthe largest order statistics of samples having exponentiated scale marginals\\nand Archimedean copula structure.\\n'\n",
      " \"  The task of determining a speaker's native language based only on his\\nspeeches in a second language is known as Native Language Identification or\\nNLI. Due to its increasing applications in various domains of speech signal\\nprocessing, this has emerged as an important research area in recent times. In\\nthis paper we have proposed an i-vector based approach to develop an automatic\\nNLI system using MFCC and GFCC features. For evaluation of our approach, we\\nhave tested our framework on the 2016 ComParE Native language sub-challenge\\ndataset which has English language speakers from 11 different native language\\nbackgrounds. Our proposed method outperforms the baseline system with an\\nimprovement in accuracy by 21.95% for the MFCC feature based i-vector framework\\nand 22.81% for the GFCC feature based i-vector framework.\\n\"\n",
      " '  In a recent paper, T. Austin has proved an analogous theorem for the\\ncontinuous torus of the original Junta theorem proved by Friedgut in the case\\nof the Boolean cube. Analogous statements have been established recently in\\ndiscrete cases such as the discrete Tori by Ellis et.al., and in the case of\\nslices of the Boolean cube by Wimmer and Filmus. In the continuous case,\\nthrough the notion of geometric influences, a statement has also been\\nestablished by Keller, Mossel and Sen for Boltzmann probability measures. In\\nthis article, we broaden the scope of the arguments of T. Austin to get an\\nunified proof of these results, removing the restriction to Boolean functions.\\nIndeed, the proof of T. Austin relies on semigroup arguments and can be\\nperformed in a general framework that covers both Cayley or Schreier graphs or\\nproduct of log-concave probability measures.\\n'\n",
      " '  Low-quality results have been a long-standing problem on microtask\\ncrowdsourcing platforms, driving away requesters and justifying low wages for\\nworkers. To date, workers have been blamed for low-quality results: they are\\nsaid to make as little effort as possible, do not pay attention to detail, and\\nlack expertise. In this paper, we hypothesize that requesters may also be\\nresponsible for low-quality work: they launch unclear task designs that confuse\\neven earnest workers, under-specify edge cases, and neglect to include\\nexamples. We introduce prototype tasks, a crowdsourcing strategy requiring all\\nnew task designs to launch a small number of sample tasks. Workers attempt\\nthese tasks and leave feedback, enabling the re- quester to iterate on the\\ndesign before publishing it. We report a field experiment in which tasks that\\nunderwent prototype task iteration produced higher-quality work results than\\nthe original task designs. With this research, we suggest that a simple and\\nrapid iteration cycle can improve crowd work, and we provide empirical evidence\\nthat requester \"quality\" directly impacts result quality.\\n'\n",
      " '  In an effort to overcome the data deluge in computational biology and\\nbioinformatics and to facilitate bioinformatics research in the era of big\\ndata, we identify some of the most influential algorithms that have been widely\\nused in the bioinformatics community. These top data mining and machine\\nlearning algorithms cover classification, clustering, regression, graphical\\nmodel-based learning, and dimensionality reduction. The goal of this study is\\nto guide the focus of scalable computing experts in the endeavor of applying\\nnew storage and scalable computation designs to bioinformatics algorithms that\\nmerit their attention most, following the engineering maxim of \"optimize the\\ncommon case\".\\n'\n",
      " '  We show that the symplectic contraction map of Hilgert-Manon-Martens -- a\\nsymplectic version of Popov\\'s horospherical contraction -- is simply the\\nquotient of a Hamiltonian manifold $M$ by a \"stratified null foliation\" that is\\ndetermined by the group action and moment map. We also show that the quotient\\ndifferential structure on the symplectic contraction of $M$ supports a Poisson\\nbracket. We end by proving a very general description of the topology of fibers\\nof Gelfand-Zeitlin systems on multiplicity free Hamiltonian $U(n)$ and $SO(n)$\\nmanifolds.\\n'\n",
      " '  We report on two ultrastable lasers each stabilized to independent silicon\\nFabry-Pérot cavities operated at 124 K. The fractional frequency instability\\nof each laser is completely determined by the fundamental thermal Brownian\\nnoise of the mirror coatings with a flicker noise floor of $4 \\\\times 10^{-17}$\\nfor integration times between 0.8 s and a few tens of seconds. We rigorously\\ntreat the notorious divergencies encountered with the associated flicker\\nfrequency noise and derive methods to relate this noise to observable and\\npractically relevant linewidths and coherence times. The individual laser\\nlinewidth obtained from the phase noise spectrum or the direct beat note\\nbetween the two lasers can be as small as 5 mHz at 194 THz. From the measured\\nphase evolution between the two laser fields we derive usable phase coherence\\ntimes for different applications of 11 s and 60 s.\\n'\n",
      " \"  We survey some recent topics on singularities, with a focus on their\\nconnection to the minimal model program. This includes the construction and\\nproperties of dual complexes, the proof of the ACC conjecture for log canonical\\nthresholds and the recent progress on the `local stability theory' of an\\narbitrary Kawamata log terminal singularity.\\n\"\n",
      " '  Dynamic economic dispatch (DED) problem considering prohibited operating\\nzones (POZ), ramp rate constraints, transmission losses and spinning reserve\\nconstraints is a complicated non-linear problem which is difficult to solve\\nefficiently. In this paper, a mixed integer linear programming (MILP) method is\\nproposed to solve such a DED problem. Firstly, a novel MILP formulation for DED\\nproblem without considering the transmission losses, denoted by MILP-1, is\\npresented by using perspective cut reformulation technique. When the\\ntransmission losses are considered, the quadratic terms in the transmission\\nlosses are replaced by their first order Taylor expansions, and then an MILP\\nformulation for DED considering the transmission losses, denoted by MILP-2, is\\nobtained. Based on MILP-1 and MILP-2, an MILP-iteration algorithm (MILP-IA) is\\nproposed to solve the complicated DED problem. The effectiveness of the MILP-1\\nand MILP-IA are assessed by several cases and the simulation results show that\\nboth of them can solve to competitive solutions in a short time.\\n'\n",
      " '  In the first part of the thesis, we study a classical invariant of projective\\nvarieties, the secant defectivity. The second part is devoted to modern\\nalgebraic geometry, we study the birational geometry of blow-ups of\\nGrassmannians at points.\\n'\n",
      " '  We have obtained the Vlasov equation and Boltzmann kinetic equation using\\nPoisson bracket (classical Hamilton equation) and Rindler Hamiltonian. Further,\\nwe treat the whole Universe as a statistical system with galaxies as the point\\nparticle constituents in large scale structure. Since the collisions of\\ngalaxies are very rare phenomena, we assume that the gas with the constituents\\nas point galaxies satisfy Vlasov equation. Considering the astrophysical\\ncatastrophic event, e.g., the creation of gravity waves by the collisions of\\nblack holes, and further assuming that when such a wave passes through the gas\\ncauses a kind of polarization of mass distribution. This polarization of mass\\ndistribution will further gives rise to gravitational permittivity or\\ndielectric constant. We have shown that the low frequency gravity waves will be\\nabsorbed, whereas the high frequency part will pass through the gas of point\\ngalaxies. It is further noticed that the region in space with extremely high\\ngravitational field is transparent to gravity waves. In the other part of this\\nwork, using the Boltzmann equation and replacing the collision term by the\\nrelaxation time approximation and further assuming a small deviation from the\\nequilibrium configuration of the stellar / galactic plasma in Rindler space, we\\nhave obtained the kinetic coefficients. For the first time we have derived an\\nexpression for the coefficient of gravitational flow. It has further been shown\\nthat in presence of strong gravitational field all the kinetic coefficients\\nbecome vanishingly small.\\n'\n",
      " \"  This paper describes the design and implementation of a ground-related\\nodometry sensor suitable for micro aerial vehicles. The sensor is based on a\\nground-facing camera and a single-board Linux-based embedded computer with a\\nmultimedia System on a Chip (SoC). The SoC features a hardware video encoder\\nwhich is used to estimate the optical flow online. The optical flow is then\\nused in combination with a distance sensor to estimate the vehicle's velocity.\\nThe proposed sensor is compared to a similar existing solution and evaluated in\\nboth indoor and outdoor environments.\\n\"\n",
      " '  We prove polarization theorems for arbitrary classical-quantum (cq) channels.\\nThe input alphabet is endowed with an arbitrary Abelian group operation and an\\nAr{\\\\i}kan-style transformation is applied using this operation. It is shown\\nthat as the number of polarization steps becomes large, the synthetic\\ncq-channels polarize to deterministic homomorphism channels which project their\\ninput to a quotient group of the input alphabet. This result is used to\\nconstruct polar codes for arbitrary cq-channels and arbitrary classical-quantum\\nmultiple access channels (cq-MAC). The encoder can be implemented in $O(N\\\\log\\nN)$ operations, where $N$ is the blocklength of the code. A quantum successive\\ncancellation decoder for the constructed codes is proposed. It is shown that\\nthe probability of error of this decoder decays faster than $2^{-N^{\\\\beta}}$\\nfor any $\\\\beta<\\\\frac{1}{2}$.\\n'\n",
      " '  We study singular integral operators induced by $3$-dimensional\\nCalderón-Zygmund kernels in the Heisenberg group. We show that if such an\\noperator is $L^{2}$ bounded on vertical planes, with uniform constants, then it\\nis also $L^{2}$ bounded on all intrinsic graphs of compactly supported\\n$C^{1,\\\\alpha}$ functions over vertical planes.\\nIn particular, the result applies to the operator $\\\\mathcal{R}$ induced by\\nthe kernel $$\\\\mathcal{K}(z) = \\\\nabla_{\\\\mathbb{H}} \\\\| z \\\\|^{-2}, \\\\quad z \\\\in\\n\\\\mathbb{H} \\\\setminus \\\\{0\\\\},$$ the horizontal gradient of the fundamental\\nsolution of the sub-Laplacian. The $L^{2}$ boundedness of $\\\\mathcal{R}$ is\\nconnected with the question of removability for Lipschitz harmonic functions.\\nAs a corollary of our result, we infer that the intrinsic graphs mentioned\\nabove are non-removable. Apart from subsets of vertical planes, these are the\\nfirst known examples of non-removable sets with positive and locally finite\\n$3$-dimensional measure.\\n'\n",
      " \"  Upon a matrix representation of a binary bipartite network, via the\\npermutation invariance, a coupling geometry is computed to approximate the\\nminimum energy macrostate of a network's system. Such a macrostate is supposed\\nto constitute the intrinsic structures of the system, so that the coupling\\ngeometry should be taken as information contents, or even the nonparametric\\nminimum sufficient statistics of the network data. Then pertinent null and\\nalternative hypotheses, such as nestedness, are to be formulated according to\\nthe macrostate. That is, any efficient testing statistic needs to be a function\\nof this coupling geometry. These conceptual architectures and mechanisms are by\\nand large still missing in community ecology literature, and rendered\\nmisconceptions prevalent in this research area. Here the algorithmically\\ncomputed coupling geometry is shown consisting of deterministic multiscale\\nblock patterns, which are framed by two marginal ultrametric trees on row and\\ncolumn axes, and stochastic uniform randomness within each block found on the\\nfinest scale. Functionally a series of increasingly larger ensembles of matrix\\nmimicries is derived by conforming to the multiscale block configurations. Here\\nmatrix mimicking is meant to be subject to constraints of row and column sums\\nsequences. Based on such a series of ensembles, a profile of distributions\\nbecomes a natural device for checking the validity of testing statistics or\\nstructural indexes. An energy based index is used for testing whether network\\ndata indeed contains structural geometry. A new version block-based nestedness\\nindex is also proposed. Its validity is checked and compared with the existing\\nones. A computing paradigm, called Data Mechanics, and its application on one\\nreal data network are illustrated throughout the developments and discussions\\nin this paper.\\n\"\n",
      " '  Compared to rigid actuators, Series Elastic Actuators (SEAs) offer a\\npotential reduction of motor energy consumption and peak power, though these\\nbenefits are highly dependent on the design of the torque-elongation profile of\\nthe elastic element. In the case of linear springs, natural dynamics is a\\ntraditional method for this design, but it has two major limitations: arbitrary\\nload trajectories are difficult or impossible to analyze and it does not\\nconsider actuator constraints. Parametric optimization is also a popular design\\nmethod that addresses these limitations, but solutions are only optimal within\\nthe space of the parameters. To overcome these limitations, we propose a\\nnon-parametric convex optimization program for the design of the nonlinear\\nelastic element that minimizes energy consumption and peak power for an\\narbitrary periodic reference trajectory. To obtain convexity, we introduce a\\nconvex approximation to the expression of peak power; energy consumption is\\nshown to be convex without approximation. The combination of peak power and\\nenergy consumption in the cost function leads to a multiobjective convex\\noptimization framework that comprises the main contribution of this paper. As a\\ncase study, we recover the elongation-torque profile of a cubic spring, given\\nits natural oscillation as the reference load. We then design nonlinear SEAs\\nfor an ankle prosthesis that minimize energy consumption and peak power for\\ndifferent trajectories and extend the range of achievable tasks when subject to\\nactuator constraints.\\n'\n",
      " '  As AI systems become more ubiquitous, securing them becomes an emerging\\nchallenge. Over the years, with the surge in online social media use and the\\ndata available for analysis, AI systems have been built to extract, represent\\nand use this information. The credibility of this information extracted from\\nopen sources, however, can often be questionable. Malicious or incorrect\\ninformation can cause a loss of money, reputation, and resources; and in\\ncertain situations, pose a threat to human life. In this paper, we use an\\nensembled semi-supervised approach to determine the credibility of Reddit posts\\nby estimating their reputation score to ensure the validity of information\\ningested by AI systems. We demonstrate our approach in the cybersecurity\\ndomain, where security analysts utilize these systems to determine possible\\nthreats by analyzing the data scattered on social media websites, forums,\\nblogs, etc.\\n'\n",
      " '  This paper deals with the problem of detecting fallen people lying on the\\nfloor by means of a mobile robot equipped with a 3D depth sensor. In the\\nproposed algorithm, inspired by semantic segmentation techniques, the 3D scene\\nis over-segmented into small patches. Fallen people are then detected by means\\nof two SVM classifiers: the first one labels each patch, while the second one\\ncaptures the spatial relations between them. This novel approach showed to be\\nrobust and fast. Indeed, thanks to the use of small patches, fallen people in\\nreal cluttered scenes with objects side by side are correctly detected.\\nMoreover, the algorithm can be executed on a mobile robot fitted with a\\nstandard laptop making it possible to exploit the 2D environmental map built by\\nthe robot and the multiple points of view obtained during the robot navigation.\\nAdditionally, this algorithm is robust to illumination changes since it does\\nnot rely on RGB data but on depth data. All the methods have been thoroughly\\nvalidated on the IASLAB-RGBD Fallen Person Dataset, which is published online\\nas a further contribution. It consists of several static and dynamic sequences\\nwith 15 different people and 2 different environments.\\n'\n",
      " '  We present a general methodology to evaluate matrix elements of the effective\\ncore potentials (ECPs) within one-electron basis set of Slater-type orbitals\\n(STOs). The scheme is based on translation of individual STO distributions in\\nthe framework of Barnett-Coulson method. We discuss different types of\\nintegrals which naturally appear and reduce them to few basic quantities which\\ncan be calculated recursively or purely numerically. Additionally, we consider\\nevaluation of the STOs matrix elements involving the core polarisation\\npotentials (CPP) and effective spin-orbit potentials. Construction of the STOs\\nbasis sets designed specifically for use with ECPs is discussed and differences\\nin comparison with all-electron basis sets are briefly summarised. We verify\\nthe validity of the present approach by calculating excitation energies, static\\ndipole polarisabilities and valence orbital energies for the alkaline earth\\nmetals (Ca, Sr, Ba). Finally, we evaluate interaction energies, permanent\\ndipole moments and ionisation energies for barium and strontium hydrides, and\\ncompare them with the best available experimental and theoretical data.\\n'\n",
      " '  We present a study by computer simulations of a class of complex-valued\\nsolutions of the three-dimensional Navier-Stokes equations in the whole space,\\nwhich, according to Li and Sinai, present a blow-up (singularity) at a finite\\ntime. The computer results allow a detailed study of the blow-up mechanism, and\\nshow interesting features of the behavior of the solutions near the blow-up\\ntime, such as the concentration of energy and enstrophy in a small region\\naround a few points of physical space, while outside this region the \"fluid\"\\nremains \"quiet\".\\n'\n",
      " \"  Background Computer-based geometrical meshes of bones are important for\\napplications in computational biomechanics as well as clinical software. There\\nis however a lack of freely available detailed bone meshes, especially related\\nto the human female morphology.\\nMethods & Results We provide high resolution bone meshes of the lower body,\\nderived from CT images of a 59 year old female cadaver that were sourced from\\nthe Visible Human Data Set, Visible Human Project (NIH, USA). Important bone\\nlandmarks and joint rotation axes are identified from the extracted meshes. A\\nscript-based framework is developed to provide a graphical user interface that\\ncan visualize, resample and modify the meshes to fit different subject scales.\\nConclusion This open-data resource fills a gap in available data and is\\nprovided for free usage in research and other applications. The associated\\nscripts allows users to easily transform the meshes to different laboratory and\\nsoftware setups. This resource may be accessed through the following web link:\\nthis https URL\\nThis document is the author's version of this article.\\n\"\n",
      " '  Equilibrium theormodynamics is characterized by two fundamental ideas:\\nthermalisation--that systems approach a late time thermal state; and phase\\nstructure--that thermal states exhibit singular changes as various parameters\\ncharacterizing the system are changed. We summarise recent progress that has\\nestablished generalizations of these ideas to periodically driven, or Floquet,\\nclosed quantum systems. This has resulted in the discovery of entirely new\\nphases which exist only out of equilibrium, such as the $\\\\pi$-spin glass or\\nFloquet time crystal.\\n'\n",
      " '  This paper presents a deep learning method for faster magnetic resonance\\nimaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and\\nprovides a rationale for why the proposed approach works well. Uniform\\nsubsampling is used in the time-consuming phase-encoding direction to capture\\nhigh-resolution image information, while permitting the image-folding problem\\ndictated by the Poisson summation formula. To deal with the localization\\nuncertainty due to image folding, very few low-frequency k-space data are\\nadded. Training the deep learning net involves input and output images that are\\npairs of Fourier transforms of the subsampled and fully sampled k-space data.\\nNumerous experiments show the remarkable performance of the proposed method;\\nonly 29% of k-space data can generate images of high quality as effectively as\\nstandard MRI reconstruction with fully sampled data.\\n'\n",
      " '  We introduce a dynamic artificial neural network-based (ANN) adaptive\\ninference process, which learns temporal predictive models of dynamical\\nsystems. We term the process REPRISE, a REtrospective and PRospective Inference\\nSchEme. REPRISE infers the unobservable contextual state that best explains its\\nrecently encountered sensorimotor experiences as well as accompanying,\\ncontext-dependent temporal predictive models retrospectively. Meanwhile, it\\nexecutes prospective inference, optimizing upcoming motor activities in a\\ngoal-directed manner. In a first implementation, a recurrent neural network\\n(RNN) is trained to learn a temporal forward model, which predicts the\\nsensorimotor contingencies of different simulated dynamic vehicles. The RNN is\\naugmented with contextual neurons, which enable the compact encoding of\\ndistinct, but related sensorimotor dynamics. We show that REPRISE is able to\\nconcurrently learn to separate and approximate the encountered sensorimotor\\ndynamics. Moreover, we show that REPRISE can exploit the learned model to\\ninduce goal-directed, model-predictive control, that is, approximate active\\ninference: Given a goal state, the system imagines a motor command sequence\\noptimizing it with the prospective objective to minimize the distance to a\\ngiven goal. Meanwhile, the system evaluates the encountered sensorimotor\\ncontingencies retrospectively, adapting its neural hidden states for\\nmaintaining model coherence. The RNN activities thus continuously imagine the\\nupcoming future and reflect on the recent past, optimizing both, hidden state\\nand motor activities. In conclusion, the combination of temporal predictive\\nstructures with modulatory, generative encodings offers a way to develop\\ncompact event codes, which selectively activate particular types of\\nsensorimotor event-specific dynamics.\\n'\n",
      " '  The International Cosmic Day (ICD) is an astroparticle physics outreach event\\nfor high-school students and brings together students and different physics\\noutreach projects from all over the world. Groups of scientists, teachers, and\\nstudents meet for one day to learn about cosmic rays and perform an experiment\\nwith atmospheric muons. All participating groups investigate an identical\\nquestion. The students are enabled to work together like in an international\\ncollaboration, discussing their results in joint video conferences. Analyzing\\ndata, comparing and discussing with other \"young scientists\" gives the students\\na glimpse of how professional scientific research works. Scientists join the\\nvideo conferences and give lectures to provide an insight in current\\nastroparticle physics research. Several participating research experiments\\nanalyze big science data tailored to the questions addressed by the students\\nand present their results on equal terms with the students. To create a lasting\\nevent, proceedings with measurement results of all participating groups are\\npublished. Every participant receives a personal e-mail with his certificate\\nand the proceedings booklet. Organized by DESY in cooperation with Netzwerk\\nTeilchenwelt, IPPOG, QuarkNet, Fermilab, and national partners like INFN, the\\nICD is a growing event with more and more popularity. We present the\\norganization of the event and the experience from five years of ICD.\\n'\n",
      " '  The splitting number of a plane irreducible curve for a Galois cover is\\neffective to distinguish the embedded topologies of plane curves. In this\\npaper, we define a connected number of any plane curve for a Galois cover whose\\nbranch divisor has no common components with the plane curve, which is similar\\nto the splitting number. We classify the embedded topology of Artal\\narrangements of degree $b\\\\geq 4$ by the connected number, where an Artal\\narrangement of degree $b$ is a plane curve consisting of one smooth curve of\\ndgree $b$ and three total inflectional tangents.\\n'\n",
      " '  Many computer vision problems are formulated as the optimization of a cost\\nfunction. This approach faces two main challenges: (i) designing a cost\\nfunction with a local optimum at an acceptable solution, and (ii) developing an\\nefficient numerical method to search for one (or multiple) of these local\\noptima. While designing such functions is feasible in the noiseless case, the\\nstability and location of local optima are mostly unknown under noise,\\nocclusion, or missing data. In practice, this can result in undesirable local\\noptima or not having a local optimum in the expected place. On the other hand,\\nnumerical optimization algorithms in high-dimensional spaces are typically\\nlocal and often rely on expensive first or second order information to guide\\nthe search. To overcome these limitations, this paper proposes Discriminative\\nOptimization (DO), a method that learns search directions from data without the\\nneed of a cost function. Specifically, DO explicitly learns a sequence of\\nupdates in the search space that leads to stationary points that correspond to\\ndesired solutions. We provide a formal analysis of DO and illustrate its\\nbenefits in the problem of 3D point cloud registration, camera pose estimation,\\nand image denoising. We show that DO performed comparably or outperformed\\nstate-of-the-art algorithms in terms of accuracy, robustness to perturbations,\\nand computational efficiency.\\n'\n",
      " '  Over the past few years, a number of successful humanoid platforms have been\\ndeveloped, including the Nao and the DARwIn-OP, both of which are used by many\\nresearch groups for the investigation of bipedal walking, full-body motions,\\nand human-robot interaction. The NimbRo-OP is an open humanoid platform under\\ndevelopment by team NimbRo of the University of Bonn. Significantly larger than\\nthe two aforementioned humanoids, this platform has the potential to interact\\nwith a more human-scale environment. This paper describes a software framework\\nfor the NimbRo-OP that is based on the Robot Operating System (ROS) middleware.\\nThe software provides functionality for hardware abstraction, visual\\nperception, and behavior generation, and has been used to implement basic\\nsoccer skills. These were demonstrated at RoboCup 2013, as part of the winning\\nteam of the Humanoid League competition.\\n'\n",
      " '  Despite the remarkable progress in face recognition related technologies,\\nreliably recognizing faces across ages still remains a big challenge. The\\nappearance of a human face changes substantially over time, resulting in\\nsignificant intra-class variations. As opposed to current techniques for\\nage-invariant face recognition, which either directly extract age-invariant\\nfeatures for recognition, or first synthesize a face that matches target age\\nbefore feature extraction, we argue that it is more desirable to perform both\\ntasks jointly so that they can leverage each other. To this end, we propose a\\ndeep Age-Invariant Model (AIM) for face recognition in the wild with three\\ndistinct novelties. First, AIM presents a novel unified deep architecture\\njointly performing cross-age face synthesis and recognition in a mutual\\nboosting way. Second, AIM achieves continuous face rejuvenation/aging with\\nremarkable photorealistic and identity-preserving properties, avoiding the\\nrequirement of paired data and the true age of testing samples. Third, we\\ndevelop effective and novel training strategies for end-to-end learning the\\nwhole deep architecture, which generates powerful age-invariant face\\nrepresentations explicitly disentangled from the age variation. Moreover, we\\npropose a new large-scale Cross-Age Face Recognition (CAFR) benchmark dataset\\nto facilitate existing efforts and push the frontiers of age-invariant face\\nrecognition research. Extensive experiments on both our CAFR and several other\\ncross-age datasets (MORPH, CACD and FG-NET) demonstrate the superiority of the\\nproposed AIM model over the state-of-the-arts. Benchmarking our model on one of\\nthe most popular unconstrained face recognition datasets IJB-C additionally\\nverifies the promising generalizability of AIM in recognizing faces in the\\nwild.\\n'\n",
      " '  In this paper, we give a procedure of how to discretize the recursion\\noperators by considering unified bilinear forms of integrable hierarchies. As\\ntwo illustrative examples, the unified bilinear forms of the AKNS hierarchy and\\nthe KdV hierarchy are presented from their recursion operators. Via the\\ncompatibility between soliton equations and their auto-Bäcklund\\ntransformations, the bilinear integrable hierarchies are discretized and the\\ndiscrete recursion operators are obtained. The discrete recursion operators\\nconverge to the original continuous forms after a standard limit.\\n'\n",
      " '  We identify two issues with the family of algorithms based on the Adversarial\\nImitation Learning framework. The first problem is implicit bias present in the\\nreward functions used in these algorithms. While these biases might work well\\nfor some environments, they can also lead to sub-optimal behavior in others.\\nSecondly, even though these algorithms can learn from few expert\\ndemonstrations, they require a prohibitively large number of interactions with\\nthe environment in order to imitate the expert for many real-world\\napplications. In order to address these issues, we propose a new algorithm\\ncalled Discriminator-Actor-Critic that uses off-policy Reinforcement Learning\\nto reduce policy-environment interaction sample complexity by an average factor\\nof 10. Furthermore, since our reward function is designed to be unbiased, we\\ncan apply our algorithm to many problems without making any task-specific\\nadjustments.\\n'\n",
      " '  Even though end-to-end supervised learning has shown promising results for\\nsensorimotor control of self-driving cars, its performance is greatly affected\\nby the weather conditions under which it was trained, showing poor\\ngeneralization to unseen conditions. In this paper, we show how knowledge can\\nbe transferred using semantic maps to new weather conditions without the need\\nto obtain new ground truth data. To this end, we propose to divide the task of\\nvehicle control into two independent modules: a control module which is only\\ntrained on one weather condition for which labeled steering data is available,\\nand a perception module which is used as an interface between new weather\\nconditions and the fixed control module. To generate the semantic data needed\\nto train the perception module, we propose to use a generative adversarial\\nnetwork (GAN)-based model to retrieve the semantic information for the new\\nconditions in an unsupervised manner. We introduce a master-servant\\narchitecture, where the master model (semantic labels available) trains the\\nservant model (semantic labels not available). We show that our proposed method\\ntrained with ground truth data for a single weather condition is capable of\\nachieving similar results on the task of steering angle prediction as an\\nend-to-end model trained with ground truth data of 15 different weather\\nconditions.\\n'\n",
      " '  We propose a new mechanism for integration of OWL ontologies using semantic\\nimport relations. In contrast to the standard OWL importing, we do not require\\nall axioms of the imported ontologies to be taken into account for reasoning\\ntasks, but only their logical implications over a chosen signature. This\\nproperty comes natural in many ontology integration scenarios, especially when\\nthe number of ontologies is large. In this paper, we study the complexity of\\nreasoning over ontologies with semantic import relations and establish a range\\nof tight complexity bounds for various fragments of OWL.\\n'\n",
      " '  We propose modeling an angle-of-arrival (AOA) positioning measurement as a\\nvon Mises-Fisher (VMF) distributed unit vector instead of the conventional\\nnormally distributed azimuth and elevation measurements. Describing the\\n2-dimensional AOA measurement with three numbers removes discontinuities and\\nreduces nonlinearity at the poles of the azimuth-elevation coordinate system.\\nOur computer simulations show that the proposed VMF measurement noise model\\nbased filters outperform the normal distribution based algorithms in accuracy\\nin a scenario where close-to-pole measurements occur frequently.\\n'\n",
      " '  Millennials are arriving to university sometimes uncomfortable with the\\nmethods of some courses. Ideas that worked with previous generations of\\nstudents begin to fail when digital natives receive paper and pencil as tools.\\nCourses must update from old paper-based methods to hands-on and computerized\\nversions. The present work discusses about this update and comments on one\\nimplementation in the course Computer Organization of the Computer Science\\ncurriculum at Universidad de Buenos Aires. It also includes some metrics that\\nshow the effectiveness of the changes in attracting and engaging the digital\\ngeneration.\\n'\n",
      " '  Generalised contact structures are studied from the point of view of reduced\\ngeneralised complex structures, naturally incorporating non-coorientable\\nstructures as non-trivial fibering. The infinitesimal symmetries are described\\nin detail, with a geometric description given in terms of gerbes. As an\\napplication of the reduction procedure, generalised coKähler structures are\\ndefined in a way which extends the Kähler/coKähler correspondence.\\n'\n",
      " '  We introduce an axiomatic approach to group recommendations, in line of\\nprevious work on the axiomatic treatment of trust-based recommendation systems,\\nranking systems, and other foundational work on the axiomatic approach to\\ninternet mechanisms in social choice settings. In group recommendations we wish\\nto recommend to a group of agents, consisting of both opinionated and undecided\\nmembers, a joint choice that would be acceptable to them. Such a system has\\nmany applications, such as choosing a movie or a restaurant to go to with a\\ngroup of friends, recommending games for online game players, & other communal\\nactivities.\\nOur method utilizes a given social graph to extract information on the\\nundecided, relying on the agents influencing them. We first show that a set of\\nfairly natural desired requirements (a.k.a axioms) leads to an impossibility,\\nrendering mutual satisfaction of them unreachable. However, we also show a\\nmodified set of axioms that fully axiomatize a group variant of the random-walk\\nrecommendation system, expanding a previous result from the individual\\nrecommendation case.\\n'\n",
      " \"  In the context of data-mining competitions (e.g., Kaggle, KDDCup, ILSVRC\\nChallenge), we show how access to an oracle that reports a contestant's\\nlog-loss score on the test set can be exploited to deduce the ground-truth of\\nsome of the test examples. By applying this technique iteratively to batches of\\n$m$ examples (for small $m$), all of the test labels can eventually be\\ninferred. In this paper, (1) We demonstrate this attack on the first stage of a\\nrecent Kaggle competition (Intel & MobileODT Cancer Screening) and use it to\\nachieve a log-loss of $0.00000$ (and thus attain a rank of #4 out of 848\\ncontestants), without ever training a classifier to solve the actual task. (2)\\nWe prove an upper bound on the batch size $m$ as a function of the\\nfloating-point resolution of the probability estimates that the contestant\\nsubmits for the labels. (3) We derive, and demonstrate in simulation, a more\\nflexible attack that can be used even when the oracle reports the accuracy on\\nan unknown (but fixed) subset of the test set's labels. These results underline\\nthe importance of evaluating contestants based only on test data that the\\noracle does not examine.\\n\"\n",
      " '  In this paper we study the logical foundations of automated inductive theorem\\nproving. To that aim we first develop a theoretical model that is centered\\naround the difficulty of finding induction axioms which are sufficient for\\nproving a goal.\\nBased on this model, we then analyze the following aspects: the choice of a\\nproof shape, the choice of an induction rule and the language of the induction\\nformula. In particular, using model-theoretic techniques, we clarify the\\nrelationship between notions of inductiveness that have been considered in the\\nliterature on automated inductive theorem proving. This is a corrected version\\nof the paper arXiv:1704.01930v5 published originally on Nov.~16, 2017.\\n'\n",
      " '  The problem of cache enabled private information retrieval (PIR) is\\nconsidered in which a user wishes to privately retrieve one out of $K$\\nmessages, each of size $L$ bits from $N$ distributed databases. The user has a\\nlocal cache of storage $SL$ bits which can be used to store any function of the\\n$K$ messages. The main contribution of this work is the exact characterization\\nof the capacity of cache aided PIR as a function of the storage parameter $S$.\\nIn particular, for a given cache storage parameter $S$, the\\ninformation-theoretically optimal download cost $D^{*}(S)/L$ (or the inverse of\\ncapacity) is shown to be equal to $(1- \\\\frac{S}{K})\\\\left(1+ \\\\frac{1}{N}+ \\\\ldots\\n+ \\\\frac{1}{N^{K-1}}\\\\right)$. Special cases of this result correspond to the\\nsettings when $S=0$, for which the optimal download cost was shown by Sun and\\nJafar to be $\\\\left(1+ \\\\frac{1}{N}+ \\\\ldots + \\\\frac{1}{N^{K-1}}\\\\right)$, and the\\ncase when $S=K$, i.e., cache size is large enough to store all messages\\nlocally, for which the optimal download cost is $0$. The intermediate points\\n$S\\\\in (0, K)$ can be readily achieved through a simple memory-sharing based PIR\\nscheme. The key technical contribution of this work is the converse, i.e., a\\nlower bound on the download cost as a function of storage $S$ which shows that\\nmemory sharing is information-theoretically optimal.\\n'\n",
      " '  Frequency tunability of 3D microwave cavities opens up numerous possibilities\\nfor their use in hybrid quantum systems and related technologies. For many\\napplications it is desirable to tune the resonance at cryogenic temperatures\\nwithout mechanical actuation. We show that a superconducting 3D microwave\\ncavity can be tuned at the percent level by taking advantage of the dielectric\\nproperties of superfluid $^4$He at milliKelvin temperatures, without affecting\\nits intrinsic quality factor -- reaching $3\\\\times10^5$ in the present\\nexperiment.\\n'\n",
      " \"  Dynamic portfolio optimization is the process of sequentially allocating\\nwealth to a collection of assets in some consecutive trading periods, based on\\ninvestors' return-risk profile. Automating this process with machine learning\\nremains a challenging problem. Here, we design a deep reinforcement learning\\n(RL) architecture with an autonomous trading agent such that, investment\\ndecisions and actions are made periodically, based on a global objective, with\\nautonomy. In particular, without relying on a purely model-free RL agent, we\\ntrain our trading agent using a novel RL architecture consisting of an infused\\nprediction module (IPM), a generative adversarial data augmentation module\\n(DAM) and a behavior cloning module (BCM). Our model-based approach works with\\nboth on-policy or off-policy RL algorithms. We further design the back-testing\\nand execution engine which interact with the RL agent in real time. Using\\nhistorical {\\\\em real} financial market data, we simulate trading with practical\\nconstraints, and demonstrate that our proposed model is robust, profitable and\\nrisk-sensitive, as compared to baseline trading strategies and model-free RL\\nagents from prior work.\\n\"\n",
      " '  The AFiD code, an open source solver for the incompressible Navier-Stokes\\nequations ({\\\\color{blue}\\\\burl{this http URL}}), has been ported to GPU\\nclusters to tackle large-scale wall-bounded turbulent flow simulations. The GPU\\nporting has been carried out in CUDA Fortran with the extensive use of kernel\\nloop directives (CUF kernels) in order to have a source code as close as\\npossible to the original CPU version; just a few routines have been manually\\nrewritten. A new transpose scheme, which is not limited to the GPU version only\\nand can be generally applied to any CFD code that uses pencil distributed\\nparallelization, has been devised to improve the scaling of the Poisson solver,\\nthe main bottleneck of incompressible solvers. The GPU version can reduce the\\nwall clock time by an order of magnitude compared to the CPU version for large\\nmeshes. Due to the increased performance and efficient use of memory, the GPU\\nversion of AFiD can perform simulations in parameter ranges that are\\nunprecedented in thermally-driven wall-bounded turbulence. To verify the\\naccuracy of the code, turbulent Rayleigh-Bénard convection and plane Couette\\nflow are simulated and the results are in good agreement with the experimental\\nand computational data that published in previous literatures.\\n'\n",
      " '  The statistics of the deformation and breakup of neutrally buoyant\\nsub-Kolmogorov ellipsoidal drops is investigated via Lagrangian simulations of\\nhomogeneous isotropic turbulence. The mean lifetime of a drop is also studied\\nas a function of the initial drop size and the capillary number. A vector model\\nof drop previously introduced by Olbricht, Rallison and Leal [J. Non-Newtonian\\nFluid Mech. $\\\\mathbf{10}$, 291 (1982)] is used to predict the behaviour of the\\nabove quantities analytically.\\n'\n",
      " '  We implemented several multilabel classification algorithms in the machine\\nlearning package mlr. The implemented methods are binary relevance, classifier\\nchains, nested stacking, dependent binary relevance and stacking, which can be\\nused with any base learner that is accessible in mlr. Moreover, there is access\\nto the multilabel classification versions of randomForestSRC and rFerns. All\\nthese methods can be easily compared by different implemented multilabel\\nperformance measures and resampling methods in the standardized mlr framework.\\nIn a benchmark experiment with several multilabel datasets, the performance of\\nthe different methods is evaluated.\\n'\n",
      " '  The evaluation of vector wave fields can be accurately performed by means of\\ndiffraction integrals, differential equations and also series expansions. In\\nthis paper, a Bessel series expansion which basis relies on the exact solution\\nof the Helmholtz equation in cylindrical coordinates is theoretically developed\\nfor the straightforward yet accurate description of low-numerical-aperture\\nfocal waves. The validity of this approach is confirmed by explicit application\\nto Gaussian beams and apertured focused fields in the paraxial regime. Finally\\nwe discuss how our procedure can be favorably implemented in scattering\\nproblems.\\n'\n",
      " \"  We investigate the validity of two common assumptions in the modelling of\\nsuperconducting circuits: first, that the superconducting qubits are pointlike,\\nand second, that the UV behaviour of the transmission line is not relevant to\\nthe qubit dynamics. We show that in the experimentally accessible ultra-strong\\ncoupling regime and for short (but attainable) times, the use of an inaccurate\\ncutoff model (such as sharp, or none at all) could introduce very significant\\ninaccuracies in the model's predictions.\\n\"\n",
      " '  We construct an infinite family of odd-symplectic forms (also known as\\nHamiltonian structures) on the 3-sphere that do not admit a symplectic\\ncobordism to the standard contact structure on the 3-sphere. This answers in\\nthe negative a question raised by Joel Fish motivated by the search for minimal\\ncharacteristic flows.\\n'\n",
      " \"  In \\\\cite{ChCa}, Califano and Chiuderi conjectured that the energy of\\nincompressible Magnetic hydrodynamical system is dissipated at a rate that is\\nindependent of the ohmic resistivity. The goal of this paper is to\\nmathematically justify this conjecture in three space dimension provided that\\nthe initial magnetic field and velocity is a small perturbation of the\\nequilibrium state $(e_3,0).$ In particular, we prove that for such data, 3-D\\nincompressible MHD system without magnetic diffusion has a unique global\\nsolution. Furthermore, the velocity field and the difference between the\\nmagnetic field and $e_3$ decay to zero in both $L^\\\\infty$ and $L^2$ norms with\\nexplicit rates. We point out that the decay rate in the $L^2$ norm is optimal\\nin sense that this rate coincides with that of the linear system. The main idea\\nof the proof is to exploit H$\\\\ddot{o}$rmander's version of Nash-Moser iteration\\nscheme, which is very much motivated by the seminar papers \\\\cite{Kl80, Kl82,\\nKl84} by Klainerman on the long time behavior to the evolution equations.\\n\"\n",
      " \"  Designing an efficient routing strategy is of great importance to alleviate\\ntraffic congestion in multilayer networks. In this work, we design an effective\\nrouting strategy for multilayer networks by comprehensively considering the\\nroles of nodes' local structures in micro-level, as well as the macro-level\\ndifferences in transmission speeds between different layers. Both numerical and\\nanalytical results indicate that our proposed routing strategy can reasonably\\nredistribute the traffic load of the low speed layer to the high speed layer,\\nand thus the traffic capacity of multilayer networks are significantly enhanced\\ncompared with the monolayer low speed networks. There is an optimal combination\\nof macro- and micro-level control parameters at which can remarkably alleviate\\nthe congestion and thus maximize the traffic capacity for a given multilayer\\nnetwork. Moreover, we find that increasing the size and the average degree of\\nthe high speed layer can enhance the traffic capacity of multilayer networks\\nmore effectively. We finally verify that real-world network topology does not\\ninvalidate the results. The theoretical predictions agree well with the\\nnumerical simulations.\\n\"\n",
      " '  A variety of copper tellurium oxide minerals are known, and many of them\\nexhibit either unusual forms of magnetism, or potentially novel spin liquid\\nbehavior. Here, I review a number of the more interesting materials with a\\nfocus on their crystalline symmetry and, if known, the nature of their\\nmagnetism. Many of these exist (so far) in mineral form only, and most have yet\\nto have their magnetic properties studied. This means a largely unexplored\\nspace of materials awaits our exploration.\\n'\n",
      " '  The determinant method in the conformal bootstrap is applied for the critical\\nphenomena of a single polymer in arbitrary $D$ dimensions. The scale dimensions\\n(critical exponents) of the polymer ($2< D \\\\le 4$) and the branched polymer ($3\\n< D \\\\le 8$) are obtained from the small determinants. It is known that the\\ndimensional reduction of the branched polymer in $D$ dimensions to Yang-Lee\\nedge singularity in $D$-$2$ dimensions holds exactly. We examine this\\nequivalence by the small determinant method.\\n'\n",
      " '  The Generalized Burnside Theorem, due to Laudal, generalizes the classical\\nBurnside Theorem and is obtained using noncommutative deformations of the\\nfamily of simple right $A$-modules when $A$ is a finite dimensional associative\\nalgebra over an algebraically closed field. In this paper, we prove a form of\\nthe Generalized Burnside Theorem that is more general, where we do not assume\\nthat $k$ is algebraically closed. The main purpose of the paper is to clarify\\nand generalize the proof. As an application of the theorem, we introduce a\\nstandard form for finite dimensional algebras.\\n'\n",
      " '  Short- to mid-term magnetic phenomena on the stellar surface of M-type stars\\ncannot only resemble the effects of planets in radial velocity data, but also\\nmay hide them. We analyze 145 spectroscopic HARPS-N observations of GJ 3942\\ntaken over the past five years and additional photometry to disentangle stellar\\nactivity effects from genuine Doppler signals as a result of the orbital motion\\nof the star around the common barycenter with its planet. To achieve this, we\\nuse the common methods of pre-whitening, and treat the correlated red noise by\\na first-order moving average term and by Gaussian-process regression following\\nan MCMC analysis. We identify the rotational period of the star at 16.3 days\\nand discover a new super-Earth, GJ 3942 b, with an orbital period of 6.9 days\\nand a minimum mass of 7.1 Me. An additional signal in the periodogram of the\\nresiduals is present but we cannot claim it to be related to a second planet\\nwith sufficient significance at this point. If confirmed, such planet candidate\\nwould have a minimum mass of 6.3 Me and a period of 10.4 days, which might\\nindicate a 3:2 mean-motion resonance with the inner planet.\\n'\n",
      " '  We consider the polyhedral properties of two spanning tree problems with\\nadditional constraints. In the first problem, it is required to find a tree\\nwith a minimum sum of edge weights among all spanning trees with the number of\\nleaves less or equal a given value. In the second problem, an additional\\nconstraint is the assumption that the degree of all vertices of the spanning\\ntree does not exceed a given value. The decision versions of both problems are\\nNP-complete.\\nWe consider the polytopes of these problems and their 1-skeletons. We prove\\nthat in both cases it is a NP-complete problem to determine whether the\\nvertices of 1-skeleton are adjacent. Although it is possible to obtain a\\nsuperpolynomial lower bounds on the clique numbers of these graphs. These\\nvalues characterize the time complexity in a broad class of algorithms based on\\nlinear comparisons. The results indicate a fundamental difference in\\ncombinatorial and geometric properties between the considered problems and the\\nclassical minimum spanning tree problem.\\n'\n",
      " '  With the need for flexible and on-demand decision support, Dynamic Data\\nWarehouses (DDW) provide benefits over traditional data warehouses due to their\\ndynamic characteristics in structuring and access mechanism. A DDW is a data\\nframework that accommodates data source changes easily to allow seamless\\nquerying to users. Materialized Views (MV) are proven to be an effective\\nmethodology to enhance the process of retrieving data from a DDW as results are\\npre-computed and stored in it. However, due to the static nature of\\nmaterialized views, the level of dynamicity that can be provided at the MV\\naccess layer is restricted. As a result, the collection of materialized views\\nis not compatible with ever-changing reporting requirements. It is important\\nthat the MV collection is consistent with current and upcoming queries. The\\nsolution to the above problem must consider the following aspects: (a) MV must\\nbe matched against an OLAP query in order to recognize whether the MV can\\nanswer the query, (b) enable scalability in the MV collection, an intuitive\\nmechanism to prune it and retrieve closely matching MVs must be incorporated,\\n(c) MV collection must be able to evolve in correspondence to the regularly\\nchanging user query patterns. Therefore, the primary objective of this paper is\\nto explore these aspects and provide a well-rounded solution for the MV access\\nlayer to remove the mismatch between the MV collection and reporting\\nrequirements. Our contribution to solve the problem includes a Query Matching\\nTechnique, a Domain Matching Technique and Maintenance of the MV collection. We\\ndeveloped an experimental platform using real data-sets to evaluate the\\neffectiveness in terms of performance and precision of the proposed techniques.\\n'\n",
      " \"  An information owner, possessing diverse data sources, might want to offer\\ninformation services based on these sources to cooperation partners and to this\\nend interact with these partners by receiving and sending messages, which the\\nowner on his part generates by program execution. Independently from data\\nrepresentation or its physical storage, information release to a partner might\\nbe restricted by the owner's confidentiality policy on an integrated, unified\\nview of the sources. Such a policy should even be enforced if the partner as an\\nintelligent and only semi-honest attacker attempts to infer hidden information\\nfrom message data, also employing background knowledge. For this problem of\\ninference control, we present a framework for a unified, holistic control of\\ninformation flow induced by program-based processing of the data sources to\\nmessages sent to a cooperation partner. Our framework expands on and combines\\nestablished concepts for confidentiality enforcement and its verification and\\nis instantiated in a Java environment. More specifically, as a hybrid control\\nwe combine gradual release of information via declassification, enforced by\\nstatic program analysis using a security type system, with a dynamic monitoring\\napproach. The dynamic monitoring employs flow tracking for generalizing values\\nto be declassified under confidentiality policy compliance.\\n\"\n",
      " '  We study the average stack cost of Buechi pushdown automata (Buechi PDA). We\\nassociate a non-negative price with each stack symbol and define the cost of a\\nstack as the sum of costs of all its elements. We introduce and study the\\naverage stack cost problem (ASC), which asks whether there exists an accepting\\nrun of a given Buechi PDA such that the long-run average of stack costs is\\nbelow some given threshold. The ASC problem generalizes mean-payoff objective\\nand can be used to express quantitative properties of pushdown systems. In\\nparticular, we can compute the average response time using the ASC problem. We\\nshow that the ASC problem can be solved in polynomial time.\\n'\n",
      " '  Let $\\\\mathfrak{a}$ be an ideal of a commutative noetherian (not necessarily\\nlocal) ring $R$. In the case $\\\\cd(\\\\mathfrak{a},R)\\\\leq 1$, we show that the\\nsubcategory of $\\\\mathfrak{a}$-cofinite $R$-modules is abelian. Using this and\\nthe technique of way-out functors, we show that if $\\\\cd(\\\\mathfrak{a},R)\\\\leq 1$,\\nor $\\\\dim(R/\\\\mathfrak{a}) \\\\leq 1$, or $\\\\dim(R) \\\\leq 2$, then the local\\ncohomology module $H^{i}_{\\\\mathfrak{a}}(X)$ is $\\\\mathfrak{a}$-cofinite for\\nevery $R$-complex $X$ with finitely generated homology modules and every $i \\\\in\\n\\\\mathbb{Z}$. We further answer Question 1.3 in the three aforementioned cases,\\nand reveal a correlation between Questions 1.1, 1.2, and 1.3.\\n'\n",
      " '  We describe an ongoing project in learning to perform primitive actions from\\ndemonstrations using an interactive interface. In our previous work, we have\\nused demonstrations captured from humans performing actions as training samples\\nfor a neural network-based trajectory model of actions to be performed by a\\ncomputational agent in novel setups. We found that our original framework had\\nsome limitations that we hope to overcome by incorporating communication\\nbetween the human and the computational agent, using the interaction between\\nthem to fine-tune the model learned by the machine. We propose a framework that\\nuses multimodal human-computer interaction to teach action concepts to\\nmachines, making use of both live demonstration and communication through\\nnatural language, as two distinct teaching modalities, while requiring few\\ntraining samples.\\n'\n",
      " '  Symmetry is closely intertwined with the function, genetics, and chemical\\nproperties of multiprotein complexes. Here, we explore the relation between\\nstructural symmetry and the ability of membrane proteins to sense and induce\\nmembrane curvature, which is a key factor for modulating the shape and\\norganization of cell membranes. Using coarse-grained simulations and elasticity\\ntheory, we show that the potential for direction-dependent membrane curvature\\nsensing is limited to asymmetric proteins, dimers, and tetramers, and argue\\nthat one should expect this anisotropy to be strongest for dimers. Odd and\\nhigher-order symmetries strongly suppress directional curvature sensing. This\\nclassification gives a new perspective on the structure-function relation for\\nmembrane proteins, and simplifies the task of translating between molecular\\nsensing mechanisms and their large-scale cellular consequences.\\n'\n",
      " '  We would like to learn a representation of the data which decomposes an\\nobservation into factors of variation which we can independently control.\\nSpecifically, we want to use minimal supervision to learn a latent\\nrepresentation that reflects the semantics behind a specific grouping of the\\ndata, where within a group the samples share a common factor of variation. For\\nexample, consider a collection of face images grouped by identity. We wish to\\nanchor the semantics of the grouping into a relevant and disentangled\\nrepresentation that we can easily exploit. However, existing deep probabilistic\\nmodels often assume that the observations are independent and identically\\ndistributed. We present the Multi-Level Variational Autoencoder (ML-VAE), a new\\ndeep probabilistic model for learning a disentangled representation of a set of\\ngrouped observations. The ML-VAE separates the latent representation into\\nsemantically meaningful parts by working both at the group level and the\\nobservation level, while retaining efficient test-time inference. Quantitative\\nand qualitative evaluations show that the ML-VAE model (i) learns a\\nsemantically meaningful disentanglement of grouped data, (ii) enables\\nmanipulation of the latent representation, and (iii) generalises to unseen\\ngroups.\\n'\n",
      " '  We show that there are an irrational rotation $Tx=x+\\\\alpha$ on the circle\\n$\\\\mathbb{T}$ and a continuous $\\\\varphi\\\\colon\\\\mathbb{T}\\\\to\\\\mathbb{R}$ such that\\nfor each (continuous) uniquely ergodic flow\\n$\\\\mathcal{S}=(S_t)_{t\\\\in\\\\mathbb{R}}$ acting on a compact metric space $Y$, the\\nautomorphism $T_{\\\\varphi,\\\\mathcal{S}}$ acting on $(X\\\\times Y,\\\\mu\\\\otimes\\\\nu)$ by\\nthe formula $T_{\\\\varphi,\\\\mathcal{S}}(x,y)=(Tx,S_{\\\\varphi(x)}(y))$, where $\\\\mu$\\nstands for Lebesgue measure on $\\\\mathbb{T}$ and $\\\\nu$ denotes the unique\\n$\\\\mathcal{S}$-invariant measure, has the property of asymptotically orthogonal\\npowers. This gives a class of relatively weakly mixing extensions of irrational\\nrotations for which Sarnak\\'s conjecture on Möbius disjointness holds for all\\nuniquely ergodic models of $T_{\\\\varphi,\\\\mathcal{S}}$. Moreover, we obtain a\\nclass of \"random\" ergodic sequences $(c_n)\\\\subset\\\\mathbb{Z}$ such that if\\n$\\\\boldsymbol{\\\\mu}$ denotes the Möbius function, then $$\\n\\\\lim_{N\\\\to\\\\infty}\\\\frac1N\\\\sum_{n\\\\leq N}g(S_{c_n}y)\\\\boldsymbol{\\\\mu}(n)=0 $$ for\\nall (continuous) uniquely ergodic flows $\\\\mathcal{S}$, all $g\\\\in C(Y)$ and\\n$y\\\\in Y$.\\n'\n",
      " '  With the advent of the Internet, large amount of digital text is generated\\neveryday in the form of news articles, research publications, blogs, question\\nanswering forums and social media. It is important to develop techniques for\\nextracting information automatically from these documents, as lot of important\\ninformation is hidden within them. This extracted information can be used to\\nimprove access and management of knowledge hidden in large text corpora.\\nSeveral applications such as Question Answering, Information Retrieval would\\nbenefit from this information. Entities like persons and organizations, form\\nthe most basic unit of the information. Occurrences of entities in a sentence\\nare often linked through well-defined relations; e.g., occurrences of person\\nand organization in a sentence may be linked through relations such as employed\\nat. The task of Relation Extraction (RE) is to identify such relations\\nautomatically. In this paper, we survey several important supervised,\\nsemi-supervised and unsupervised RE techniques. We also cover the paradigms of\\nOpen Information Extraction (OIE) and Distant Supervision. Finally, we describe\\nsome of the recent trends in the RE techniques and possible future research\\ndirections. This survey would be useful for three kinds of readers - i)\\nNewcomers in the field who want to quickly learn about RE; ii) Researchers who\\nwant to know how the various RE techniques evolved over time and what are\\npossible future research directions and iii) Practitioners who just need to\\nknow which RE technique works best in various settings.\\n'\n",
      " '  In this paper, by using a characterization of functions having fractional\\nderivative, we propose a rigorous fractional Lyapunov function candidate method\\nto analyze stability of fractional-order nonlinear systems. First, we prove an\\ninequality concerning the fractional derivatives of convex Lyapunov functions\\nwithout the assumption on the existence of derivative of pseudo-states. Second,\\nwe establish fractional Lyapunov functions to fractional-order systems without\\nthe assumption on the global existence of solutions. Our theorems fill the gaps\\nand strengthen results in some existing papers.\\n'\n",
      " '  By using first-principles electronic structure calculations, we predict that\\nthe extreme magnetoresistance (XMR) material LaSb takes a topological phase\\ntransition without breaking any symmetry under a hydrostatic pressure applied\\nbetween 3 and 4 GPa, meanwhile the electron-hole compensation remains in its\\nelectronic band structure. Thus LaSb provides an ideal platform for studying\\nthe individual role of topological property playing in the XMR phenomenon, in\\naddition to the electron-hole compensation. This has general implication to the\\nrelationship of XMR effect and topological property in topological materials.\\n'\n",
      " '  In recent times, many of the breakthroughs in various vision-related tasks\\nhave revolved around improving learning of deep models; these methods have\\nranged from network architectural improvements such as Residual Networks, to\\nvarious forms of regularisation such as Batch Normalisation. In essence, many\\nof these techniques revolve around better conditioning, allowing for deeper and\\ndeeper models to be successfully learned. In this paper, we look towards better\\nconditioning Generative Adversarial Networks (GANs) in an unsupervised learning\\nsetting. Our method embeds the powerful discriminating capabilities of a\\ndecision forest into the discriminator of a GAN. This results in a better\\nconditioned model which learns in an extremely stable way. We demonstrate\\nempirical results which show both clear qualitative and quantitative evidence\\nof the effectiveness of our approach, gaining significant performance\\nimprovements over several popular GAN-based approaches on the Oxford Flowers\\nand Aligned Celebrity Faces datasets.\\n'\n",
      " '  We consider goodness-of-fit tests with i.i.d. samples generated from a\\ncategorical distribution $(p_1,...,p_k)$. For a given $(q_1,...,q_k)$, we test\\nthe null hypothesis whether $p_j=q_{\\\\pi(j)}$ for some label permutation $\\\\pi$.\\nThe uncertainty of label permutation implies that the null hypothesis is\\ncomposite instead of being singular. In this paper, we construct a testing\\nprocedure using statistics that are defined as indefinite integrals of some\\nsymmetric polynomials. This method is aimed directly at the invariance of the\\nproblem, and avoids the need of matching the unknown labels. The asymptotic\\ndistribution of the testing statistic is shown to be chi-squared, and its power\\nis proved to be nearly optimal under a local alternative hypothesis. Various\\ndegenerate structures of the null hypothesis are carefully analyzed in the\\npaper. A two-sample version of the test is also studied.\\n'\n",
      " '  Optimization problems pervade essentially every scientific discipline and\\nindustry. Many such problems require finding a solution that maximizes the\\nnumber of constraints satisfied. Often, these problems are particularly\\ndifficult to solve because they belong to the NP-hard class, namely algorithms\\nthat always find a solution in polynomial time are not known. Over the past\\ndecades, research has focused on developing heuristic approaches that attempt\\nto find an approximation to the solution. However, despite numerous research\\nefforts, in many cases even approximations to the optimal solution are hard to\\nfind, as the computational time for further refining a candidate solution grows\\nexponentially with input size. Here, we show a non-combinatorial approach to\\nhard optimization problems that achieves an exponential speed-up and finds\\nbetter approximations than the current state-of-the-art. First, we map the\\noptimization problem into a boolean circuit made of specially designed,\\nself-organizing logic gates, which can be built with (non-quantum) electronic\\ncomponents; the equilibrium points of the circuit represent the approximation\\nto the problem at hand. Then, we solve its associated non-linear ordinary\\ndifferential equations numerically, towards the equilibrium points. We\\ndemonstrate this exponential gain by comparing a sequential MatLab\\nimplementation of our solver with the winners of the 2016 Max-SAT competition\\non a variety of hard optimization instances. We show empirical evidence that\\nour solver scales linearly with the size of the problem, both in time and\\nmemory, and argue that this property derives from the collective behavior of\\nthe simulated physical circuit. Our approach can be applied to other types of\\noptimization problems and the results presented here have far-reaching\\nconsequences in many fields.\\n'\n",
      " '  Most of the traditional convolutional neural networks (CNNs) implements\\nbottom-up approach (feed-forward) for image classifications. However, many\\nscientific studies demonstrate that visual perception in primates rely on both\\nbottom-up and top-down connections. Therefore, in this work, we propose a CNN\\nnetwork with feedback structure for Solar power plant detection on\\nmiddle-resolution satellite images. To express the strength of the top-down\\nconnections, we introduce feedback CNN network (FB-Net) to a baseline CNN model\\nused for solar power plant classification on multi-spectral satellite data.\\nMoreover, we introduce a method to improve class activation mapping (CAM) to\\nour FB-Net, which takes advantage of multi-channel pulse coupled neural network\\n(m-PCNN) for weakly-supervised localization of the solar power plants from the\\nfeatures of proposed FB-Net. For the proposed FB-Net CAM with m-PCNN,\\nexperimental results demonstrated promising results on both solar-power plant\\nimage classification and detection task.\\n'\n",
      " '  Explicit signaling between threads is a perennial cause of bugs in concurrent\\nprograms. While there are several run-time techniques to automatically notify\\nthreads upon the availability of some shared resource, such techniques are not\\nwidely-adopted due to their run-time overhead. This paper proposes a new\\nsolution based on static analysis for automatically generating a performant\\nexplicit-signal program from its corresponding implicit-signal implementation.\\nThe key idea is to generate verification conditions that allow us to minimize\\nthe number of required signals and unnecessary context switches, while\\nguaranteeing semantic equivalence between the source and target programs. We\\nhave implemented our method in a tool called Expresso and evaluate it on\\nchallenging benchmarks from prior papers and open-source software.\\nExpresso-generated code significantly outperforms past automatic signaling\\nmechanisms (avg. 1.56x speedup) and closely matches the performance of\\nhand-optimized explicit-signal code.\\n'\n",
      " '  In this paper we express the linearized dynamics of interacting interfacial\\nwaves in stratified shear flows in the compact form of action-angle Hamilton\\nequations. The pseudo-energy serves as the Hamiltonian of the system, the\\naction coordinates are the contribution of the interfacial waves to the\\nwave-action, and the angles are their phases. The term \"generalized\\naction-angle\" aims to emphasize that the action of each wave is generally time\\ndependent and this allows instability. An attempt is made to relate this\\nformalism to the action at a distance resonance instability mechanism between\\ncounter-propagating vorticity waves via the global conservations of\\npseudo-energy and pseudo-momentum.\\n'\n",
      " '  We use polarization-resolved electronic Raman spectroscopy to study charge\\ndynamics in non-magnetic FeSe$_{1-x}$S$_x$ superconductor. We observe two\\nfeatures of the $XY$ quadrupole symmetry: a low-energy quasi-elastic peak (QEP)\\nand an electronic continuum. The QEP exhibits critical enhancement upon cooling\\ntowards the structural transition at $T_S(x)$. Below $T_S(x)$, the QEP\\ndiminishes gradually, and a gap with temperature evolution reminiscent of a\\nmean-field order parameter opens in the continuum. The intensity of the QEP\\ndevelops with increasing sulfur doping $x$ and maximizes at $x\\\\approx$ 0.15,\\nwhile the gap magnitude decreases with the suppression of $T_S(x)$. We\\ninterpret the development of the gap in the quadrupole scattering channel as\\nthe formation of a stripe quadrupole order: a wave of quadrupole moment without\\ncharge or spin modulation.\\n'\n",
      " '  We give a non-technical introduction to convergence-divergence models, a new\\nmodeling approach for phylogenetic data that allows for the usual divergence of\\nspecies post speciation but also allows for species to converge, i.e. become\\nmore similar over time. By examining the $3$-taxon case in some detail we\\nillustrate that phylogeneticists have been \"spoiled\" in the sense of not having\\nto think about the structural parameters in their models by virtue of the\\nstrong assumption that evolution is treelike. We show that there are not always\\ngood statistical reasons to prefer the usual class of treelike models over more\\ngeneral convergence-divergence models. Specifically we show many $3$-taxon\\ndatasets can be equally well explained by supposing violation of the molecular\\nclock due to change in the rate of evolution along different edges, or by\\nkeeping the assumption of a constant rate of evolution but instead assuming\\nthat evolution is not a purely divergent process. Given the abundance of\\nevidence that evolution is not strictly treelike, our discussion is an\\nillustration that as phylogeneticists we often need to think clearly about the\\nstructural form of the models we use.\\n'\n",
      " '  Asymptotics of quantum $6j$ symbols corresponding to a hyperbolic tetrahedra\\nis investigated and the first two leading terms are determined for the case\\nthat the tetrahedron has a ideal or ultra-ideal vertex. These terms are given\\nby the volume and the determinant of the Gram matrix of the tetrahedron. A\\nrelation to the volume conjecture of the Turaev-Viro invariant is also\\ndiscussed.\\n'\n",
      " '  Parameters in deep neural networks which are trained on large-scale databases\\ncan generalize across multiple domains, which is referred as \"transferability\".\\nUnfortunately, the transferability is usually defined as discrete states and it\\ndiffers with domains and network architectures. Existing works usually\\nheuristically apply parameter-sharing or fine-tuning, and there is no\\nprincipled approach to learn a parameter transfer strategy. To address the gap,\\na parameter transfer unit (PTU) is proposed in this paper. The PTU learns a\\nfine-grained nonlinear combination of activations from both the source and the\\ntarget domain networks, and subsumes hand-crafted discrete transfer states. In\\nthe PTU, the transferability is controlled by two gates which are artificial\\nneurons and can be learned from data. The PTU is a general and flexible module\\nwhich can be used in both CNNs and RNNs. Experiments are conducted with various\\nnetwork architectures and multiple transfer domain pairs. Results demonstrate\\nthe effectiveness of the PTU as it outperforms heuristic parameter-sharing and\\nfine-tuning in most settings.\\n'\n",
      " '  Network Function Virtualization (NFV) has the potential to significantly\\nreduce the capital and operating expenses, shorten product release cycle, and\\nimprove service agility. In this paper, we focus on minimizing the total number\\nof Virtual Network Function (VNF) instances to provide a specific service\\n(possibly at different locations) to all the flows in a network. Certain\\nnetwork security and analytics applications may allow fractional processing of\\na flow at different nodes (corresponding to datacenters), giving an opportunity\\nfor greater optimization of resources. Through a reduction from the set cover\\nproblem, we show that this problem is NP-hard and cannot even be approximated\\nwithin a factor of (1 - o(1)) ln(m) (where m is the number of flows) unless\\nP=NP. Then, we design two simple greedy algorithms and prove that they achieve\\nan approximation ratio of (1 - o(1)) ln(m) + 2, which is asymptotically\\noptimal. For special cases where each node hosts multiple VNF instances (which\\nis typically true in practice), we also show that our greedy algorithms have a\\nconstant approximation ratio. Further, for tree topologies we develop an\\noptimal greedy algorithm by exploiting the inherent topological structure.\\nFinally, we conduct extensive numerical experiments to evaluate the performance\\nof our proposed algorithms in various scenarios.\\n'\n",
      " '  We prove a version of the classical Mittag-Leffler Theorem for regular\\nfunctions over quaternions. Our result relies upon an appropriate notion of\\nprincipal part, that is inspired by the recent definition of spherical\\nanalyticity.\\n'\n",
      " '  A number of micro-scale biological flows are characterized by spatio-temporal\\nchaos. These include dense suspensions of swimming bacteria, microtubule\\nbundles driven by motor proteins, and dividing and migrating confluent layers\\nof cells. A characteristic common to all of these systems is that they are\\nladen with active matter, which transforms free energy in the fluid into\\nkinetic energy. Because of collective effects, the active matter induces\\nmulti-scale flow motions that bear strong visual resemblance to turbulence. In\\nthis study, multi-scale statistical tools are employed to analyze direct\\nnumerical simulations (DNS) of periodic two- (2D) and three-dimensional (3D)\\nactive flows and compare them to classic turbulent flows. Statistical\\ndescriptions of the flows and their variations with activity levels are\\nprovided in physical and spectral spaces. A scale-dependent intermittency\\nanalysis is performed using wavelets. The results demonstrate fundamental\\ndifferences between active and high-Reynolds number turbulence; for instance,\\nthe intermittency is smaller and less energetic in active flows, and the work\\nof the active stress is spectrally exerted near the integral scales and\\ndissipated mostly locally by viscosity, with convection playing a minor role in\\nmomentum transport across scales.\\n'\n",
      " '  We give a negative answer to the Newman--Shapiro problem on weighted\\napproximation for entire functions formulated in 1966 and motivated by the\\ntheory of operators on the Fock space. There exists a function in the Fock\\nspace such that its exponential multiples do not approximate some entire\\nmultiples in the space. Furthermore, we establish several positive results\\nunder different restrictions on the function in question.\\n'\n",
      " '  This work is dedicated to eliminating the overhead of guaranteeing the\\nstorage order in modern IO stack. The existing block device adopts\\nprohibitively expensive resort in ensuring the storage order among write\\nrequests: interleaving successive write requests with transfer and flush.\\nExploiting the cache barrier command for the Flash storage, we overhaul the IO\\nscheduler, the dispatch module and the filesystem so that these layers are\\norchestrated to preserve the ordering condition imposed by the application can\\nbe delivered to the storage. Key ingredients of Barrier Enabled IO stack are\\nEpoch based IO scheduling, Order Preserving Dispatch, and Dual Mode Journaling.\\nBarrier enabled IO stack successfully eliminates the root cause of excessive\\noverhead in enforcing the storage order. Dual Mode Journaling in BarrierFS\\ndedicates the separate threads to effectively decouple the control plane and\\ndata plane of the journal commit. We implement Barrier Enabled IO Stack in\\nserver as well as in mobile platform. SQLite performance increases by 270% and\\n75%, in server and in smartphone, respectively. Relaxing the durability of a\\ntransaction, SQLite performance and MySQL performance increases as much as by\\n73X and by 43X, respectively, in server storage.\\n'\n",
      " '  Malicious crowdsourcing forums are gaining traction as sources of spreading\\nmisinformation online, but are limited by the costs of hiring and managing\\nhuman workers. In this paper, we identify a new class of attacks that leverage\\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\\nthe generation of fake online reviews for products and services. Not only are\\nthese attacks cheap and therefore more scalable, but they can control rate of\\ncontent output to eliminate the signature burstiness that makes crowdsourced\\ncampaigns easy to detect.\\nUsing Yelp reviews as an example platform, we show how a two phased review\\ngeneration and customization attack can produce reviews that are\\nindistinguishable by state-of-the-art statistical detectors. We conduct a\\nsurvey-based user study to show these reviews not only evade human detection,\\nbut also score high on \"usefulness\" metrics by users. Finally, we develop novel\\nautomated defenses against these attacks, by leveraging the lossy\\ntransformation introduced by the RNN training and generation cycle. We consider\\ncountermeasures against our mechanisms, show that they produce unattractive\\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\\nsimple constraints imposed by online service providers.\\n'\n",
      " \"  This note presents several results in graph theory inspired by the author's\\nwork in the proof theory of linear logic; these results are purely\\ncombinatorial and do not involve logic.\\nWe show that trails avoiding forbidden transitions and rainbow paths for\\ncomplete multipartite color classes can be found in linear time, whereas\\nfinding rainbow paths is NP-complete for any other restriction on color\\nclasses. For the tractable cases, we also state new structural properties\\nequivalent to Kotzig's theorem on bridges in unique perfect matchings.\\nWe also exhibit a connection between blossoms and bridge deletion orders in\\nunique perfect matchings.\\n\"\n",
      " '  We introduce a novel approach for dealing with eigenvalue problems of\\nSturm-Liouville operators generated by the differential expression\\n\\\\begin{equation*} Ly=\\\\frac{1}{r}\\\\left( -(p\\\\left[ y^{\\\\prime }+sy\\\\right]\\n)^{\\\\prime }+sp\\\\left[ y^{\\\\prime }+sy\\\\right] +qy\\\\right) \\\\end{equation*} which is\\nbased on norm resolvent convergence of classical Sturm-Liouville operators.\\nThis enables us to describe the continuous dependence of the $n$-th eigenvalue\\non the space of self-adjoint boundary conditions and the coefficients of the\\ndifferential equation after giving the inequalities among the eigenvalues.\\nMoreover, oscillation properties of the eigenfunctions are also characterized.\\nIn particular, our main results can be applied to solve a class of\\nSturm-Liouville problems with transmission conditions.\\n'\n",
      " '  Koopman operator is a composition operator defined for a dynamical system\\ndescribed by nonlinear differential or difference equation. Although the\\noriginal system is nonlinear and evolves on a finite-dimensional state space,\\nthe Koopman operator itself is linear but infinite-dimensional (evolves on a\\nfunction space). This linear operator captures the full information of the\\ndynamics described by the original nonlinear system. In particular, spectral\\nproperties of the Koopman operator play a crucial role in analyzing the\\noriginal system. In the first part of this paper, we review the so-called\\nKoopman operator theory for nonlinear dynamical systems, with emphasis on modal\\ndecomposition and computation that are direct to wide applications. Then, in\\nthe second part, we present a series of applications of the Koopman operator\\ntheory to power systems technology. The applications are established as\\ndata-centric methods, namely, how to use massive quantities of data obtained\\nnumerically and experimentally, through spectral analysis of the Koopman\\noperator: coherency identification of swings in coupled synchronous generators,\\nprecursor diagnostic of instabilities in the coupled swing dynamics, and\\nstability assessment of power systems without any use of mathematical models.\\nFuture problems of this research direction are identified in the last\\nconcluding part of this paper.\\n'\n",
      " '  Scientometric techniques have been remarkably successful at mapping science\\nbut they face important difficulties when mapping research for societal\\nproblems possibly because they they are derived only from scientific documents\\nand thus do not rely on non-academic expert knowledge. Here we aim to explore\\nhow ontologies can be used in science mapping, thus enriching current\\nalgorithmic techniques with systematic domain expert knowledge. This study\\nintroduces the methodology behind the construction of an ontology and tests\\npotential uses in science mapping. We use obesity as a topic of case study.\\n'\n",
      " '  Time-varying coverage, namely sweep coverage is a recent development in the\\narea of wireless sensor networks, where a small number of mobile sensors sweep\\nor monitor comparatively large number of locations periodically. In this\\narticle we study barrier sweep coverage with mobile sensors where the barrier\\nis considered as a finite length continuous curve on a plane. The coverage at\\nevery point on the curve is time-variant. We propose an optimal solution for\\nsweep coverage of a finite length continuous curve. Usually energy source of a\\nmobile sensor is battery with limited power, so energy restricted sweep\\ncoverage is a challenging problem for long running applications. We propose an\\nenergy restricted sweep coverage problem where every mobile sensors must visit\\nan energy source frequently to recharge or replace its battery. We propose a\\n$\\\\frac{13}{3}$-approximation algorithm for this problem. The proposed algorithm\\nfor multiple curves achieves the best possible approximation factor 2 for a\\nspecial case. We propose a 5-approximation algorithm for the general problem.\\nAs an application of the barrier sweep coverage problem for a set of line\\nsegments, we formulate a data gathering problem. In this problem a set of\\nmobile sensors is arbitrarily monitoring the line segments one for each. A set\\nof data mules periodically collects the monitoring data from the set of mobile\\nsensors. We prove that finding the minimum number of data mules to collect data\\nperiodically from every mobile sensor is NP-hard and propose a 3-approximation\\nalgorithm to solve it.\\n'\n",
      " '  In the setting of a Lie group of polynomial volume growth, we derive\\ninequalities of Caffarelli-Kohn-Nirenberg type, where the weights involved are\\npowers of the Carnot-Caratheodory distance associated with a fixed system of\\nvector fields which satisfy the Hörmander condition.\\nThe use of weak $L^p$ spaces is crucial in our proofs and we formulate these\\ninequalities within the framework of $L^{p,q}$ Lorentz spaces (a scale of\\n(quasi)-Banach spaces which extend the more classical $L^p$ Lebesgue spaces)\\nthereby obtaining a refinement of, for instance, Sobolev and Hardy-Sobolev\\ninequalities.\\n'\n",
      " \"  We consider 3+1 rotationally symmetric Lorentzian Einstein spacetime\\nmanifolds with $\\\\Lambda >0$ and reduce the equations to 2+1 Einstein equations\\ncoupled to `shifted' wave maps. Subsequently, we prove various (explicit)\\npositive mass-energy theorems. No smallness is assumed.\\n\"\n",
      " '  The increased availability of the multi-view data (data on the same samples\\nfrom multiple sources) has led to strong interest in models based on low-rank\\nmatrix factorizations. These models represent each data view via shared and\\nindividual components, and have been successfully applied for exploratory\\ndimension reduction, association analysis between the views, and further\\nlearning tasks such as consensus clustering. Despite these advances, there\\nremain significant challenges in modeling partially-shared components, and\\nidentifying the number of components of each type\\n(shared/partially-shared/individual). In this work, we formulate a novel linked\\ncomponent model that directly incorporates partially-shared structures. We call\\nthis model SLIDE for Structural Learning and Integrative DEcomposition of\\nmulti-view data. We prove the existence of SLIDE decomposition and explicitly\\ncharacterize the identifiability conditions. The proposed model fitting and\\nselection techniques allow for joint identification of the number of components\\nof each type, in contrast to existing sequential approaches. In our empirical\\nstudies, SLIDE demonstrates excellent performance in both signal estimation and\\ncomponent selection. We further illustrate the methodology on the breast cancer\\ndata from The Cancer Genome Atlas repository.\\n'\n",
      " \"  We model a nonlinear price curve quoted in a market as the utility\\nindifference curve of a representative liquidity supplier. As the utility\\nfunction we adopt a g-expectation. In contrast to the standard framework of\\nfinancial engineering, a trader is no more price taker as any trade has a\\npermanent market impact via an effect to the supplier's inventory. The P&L of a\\ntrading strategy is written as a nonlinear stochastic integral. Under this\\nmarket impact model, we introduce a completeness condition under which any\\nderivative can be perfectly replicated by a dynamic trading strategy. In the\\nspecial case of a Markovian setting the corresponding pricing and hedging can\\nbe done by solving a semi-linear PDE.\\n\"\n",
      " '  When balancing, a humanoid robot can be easily subjected to unexpected\\ndisturbances like external pushes. In these circumstances, reactive movements\\nas steps become a necessary requirement in order to avoid potentially harmful\\nfalling states. In this paper we conceive a Model Predictive Controller which\\ndetermines a desired set of contact wrenches by predicting the future evolution\\nof the robot, while taking into account constraints switching in case of steps.\\nThe control inputs computed by this strategy, namely the desired contact\\nwrenches, are directly obtained on the robot through a modification of the\\nmomentum-based whole-body torque controller currently implemented on iCub. The\\nproposed approach is validated through simulations in a stepping scenario,\\nrevealing high robustness and reliability when executing a recovery strategy.\\n'\n",
      " '  Computational propaganda deploys social or political bots to try to shape,\\nsteer and manipulate online public discussions and influence decisions.\\nCollective behaviour of populations of social bots has not been yet widely\\nstudied, though understanding of collective patterns arising from interactions\\nbetween bots would aid social bot detection. Here we show that there are\\nsignificant differences in collective behaviour between population of bots and\\npopulation of humans as detected from their Twitter activity. Using a large\\ndataset of tweets we have collected during the UK EU referendum campaign, we\\nseparated users into population of bots and population of humans based on the\\nlength of sequences of their high-frequency tweeting activity. We show that\\nwhile pairwise correlations between users are weak they co-exist with\\ncollective correlated states, however the statistics of correlations and\\nco-spiking probability differ in both populations. Our results demonstrate that\\npopulations of social bots and human users in social media exhibit collective\\nproperties similar to the ones found in social and biological systems placed\\nnear a critical point.\\n'\n",
      " '  In many distributed learning problems, the heterogeneous loading of computing\\nmachines may harm the overall performance of synchronous strategies. In this\\npaper, we propose an effective asynchronous distributed framework for the\\nminimization of a sum of smooth functions, where each machine performs\\niterations in parallel on its local function and updates a shared parameter\\nasynchronously. In this way, all machines can continuously work even though\\nthey do not have the latest version of the shared parameter. We prove the\\nconvergence of the consistency of this general distributed asynchronous method\\nfor gradient iterations then show its efficiency on the matrix factorization\\nproblem for recommender systems and on binary classification.\\n'\n",
      " '  The MAP-Elites algorithm produces a set of high-performing solutions that\\nvary according to features defined by the user. This technique has the\\npotential to be a powerful tool for design space exploration, but is limited by\\nthe need for numerous evaluations. The Surrogate-Assisted Illumination\\nalgorithm (SAIL), introduced here, integrates approximative models and\\nintelligent sampling of the objective function to minimize the number of\\nevaluations required by MAP-Elites.\\nThe ability of SAIL to efficiently produce both accurate models and diverse\\nhigh performing solutions is illustrated on a 2D airfoil design problem. The\\nsearch space is divided into bins, each holding a design with a different\\ncombination of features. In each bin SAIL produces a better performing solution\\nthan MAP-Elites, and requires several orders of magnitude fewer evaluations.\\nThe CMA-ES algorithm was used to produce an optimal design in each bin: with\\nthe same number of evaluations required by CMA-ES to find a near-optimal\\nsolution in a single bin, SAIL finds solutions of similar quality in every bin.\\n'\n",
      " '  We consider the problem of determining the asymptotic order of the Gelfand\\nnumbers of mixed-(quasi-)norm embeddings $\\\\ell^b_p(\\\\ell^d_q) \\\\hookrightarrow\\n\\\\ell^b_r(\\\\ell^d_u)$ given that $p \\\\leq r$ and $q \\\\leq u$, with emphasis on\\ncases with $p\\\\leq 1$ and/or $q\\\\leq 1$. These cases turn out to be related to\\nstructured sparsity. We obtain sharp bounds in a number of interesting\\nparameter constellations. Our new matching bounds for the Gelfand numbers of\\nthe embeddings of $\\\\ell_1^b(\\\\ell_2^d)$ and $\\\\ell_2^b(\\\\ell_1^d)$ into\\n$\\\\ell_2^b(\\\\ell_2^d)$ imply optimality assertions for the recovery of\\nblock-sparse and sparse-in-levels vectors, respectively. In addition, we apply\\nthe sharp estimates for $\\\\ell^b_p(\\\\ell^d_q)$-spaces to obtain new two-sided\\nestimates for the Gelfand numbers of multivariate Besov space embeddings in\\nregimes of small mixed smoothness. It turns out that in some particular cases\\nthese estimates show the same asymptotic behaviour as in the univariate\\nsituation. In the remaining cases they differ at most by a $\\\\log\\\\log$ factor\\nfrom the univariate bound.\\n'\n",
      " '  In this paper, we present a novel nonparametric motion flow model that\\neffectively describes a motion trajectory of a human and its application to\\nhuman robot cooperation. To this end, motion flow similarity measure which\\nconsiders both spatial and temporal properties of a trajectory is proposed by\\nutilizing the mean and variance functions of a Gaussian process. We also\\npresent a human robot cooperation method using the proposed motion flow model.\\nGiven a set of interacting trajectories of two workers, the underlying reward\\nfunction of cooperating behaviors is optimized by using the learned motion\\ndescription as an input to the reward function where a stochastic trajectory\\noptimization method is used to control a robot. The presented human robot\\ncooperation method is compared with the state-of-the-art algorithm, which\\nutilizes a mixture of interaction primitives (MIP), in terms of the RMS error\\nbetween generated and target trajectories. While the proposed method shows\\ncomparable performance with the MIP when the full observation of human\\ndemonstrations is given, it shows superior performance with respect to given\\npartial trajectory information.\\n'\n",
      " \"  Deep Learning is a consolidated, state-of-the-art Machine Learning tool to\\nfit a function when provided with large data sets of examples. However, in\\nregression tasks, the straightforward application of Deep Learning models\\nprovides a point estimate of the target. In addition, the model does not take\\ninto account the uncertainty of a prediction. This represents a great\\nlimitation for tasks where communicating an erroneous prediction carries a\\nrisk. In this paper we tackle a real-world problem of forecasting impending\\nfinancial expenses and incomings of customers, while displaying predictable\\nmonetary amounts on a mobile app. In this context, we investigate if we would\\nobtain an advantage by applying Deep Learning models with a Heteroscedastic\\nmodel of the variance of a network's output. Experimentally, we achieve a\\nhigher accuracy than non-trivial baselines. More importantly, we introduce a\\nmechanism to discard low-confidence predictions, which means that they will not\\nbe visible to users. This should help enhance the user experience of our\\nproduct.\\n\"\n",
      " '  Cable-in-Conduit Conductors (CICCs) are used in the fabrication of\\nsuperconducting fusion grade magnets. It acts as a narrow cryostat to provide\\ncryo-stability with direct contact of coolant fluid to conductor. The\\nsuperconducting magnets are cooled using forced flow (FF), supercritical helium\\nor two phase (TP) cooling through void space in the CICC. Thermo-hydraulics\\nusing supercritical helium single phase flow is well-known and established.\\nResearch topic of behavior of forced flow, two phase (TP) helium cooling in\\nCICC involves perceived risks of the CICC running into flow chocking and\\npossible thermo-acoustic oscillations leading to flow instabilities. This\\nresearch work involves study of forced flow two phase helium cooling in CICC\\nwound superconducting magnets. The TP flow provides cryo-stability by the\\nlatent heat of helium not by enthalpy as in case of CICC being cooled with\\nsupercritical helium. Study reveals some attractive regimes in the case of TP\\ncooling, at a given mass flow rate of single phase helium at the inlet and a\\nheat flux acting on the CICC. Analysis carried out predicts significant gains\\nwith TP cooling on a prototype CICC, which is circular in cross section and\\nappropriate for fusion devices for high magnetic field applications. These\\ngeneral formalisms may be extended to specific magnets wound with CICC. This\\npaper describes analysis of TP cooling of a CICC.\\n'\n",
      " '  Scenarios of execution are commonly used to specify partial behaviour and\\ninteractions between different objects and components in a system. To avoid\\noverall inconsistency in specifications, various automated methods have emerged\\nin the literature to compose (behavioural) models. In recent work, we have\\nshown how the theorem prover Isabelle can be combined with the constraint\\nsolver Z3 to efficiently detect inconsistencies in two or more behavioural\\nmodels and, in their absence, generate the composition. Here, we extend our\\napproach further and show how to generate the correct composition (as a set of\\nvalid traces) of dephased models. This work has been inspired by a problem from\\na medical domain where different care pathways (for chronic conditions) may be\\napplied to the same patient with different starting points.\\n'\n",
      " '  In this paper, we describe how the hypergeometric test can be used to\\ndetermine whether a given theme of interest occurs in a storyset at a frequency\\nmore than would be expected by chance. By a storyset we mean simply a list of\\nstories defined according to a common attribute (e.g., author, movement,\\nperiod). The test works roughly as follows: Given a background storyset and a\\nsub-storyset of interest, the test determines whether a given theme is\\nover-represented in the sub-storyset, based on comparing the proportions of\\nstories in the sub-storyset and background storyset featuring the theme. A\\nstoryset is said to be \"enriched\" for a theme with respect to a particular\\nbackground storyset, when the theme is identified as being significantly\\nover-represented by the test. Furthermore, we introduce here a toy dataset\\nconsisting of 280 manually themed Star Trek television franchise episodes. As a\\nproof of concept, we use the hypergeometric test to analyze the Star Trek\\nstories for enriched themes. The hypergeometric testing approach to theme\\nenrichment analysis is implemented for the Star Trek thematic dataset in the R\\npackage stoRy. A related R Shiny web application can be found at\\nthis https URL.\\n'\n",
      " '  We develop a simple routine unifying the analysis of several important\\nrecently-developed stochastic optimization methods including SAGA, Finito, and\\nstochastic dual coordinate ascent (SDCA). First, we show an intrinsic\\nconnection between stochastic optimization methods and dynamic jump systems,\\nand propose a general jump system model for stochastic optimization methods.\\nOur proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then\\nwe combine jump system theory with several simple quadratic inequalities to\\nderive sufficient conditions for convergence rate certifications of the\\nproposed jump system model under various assumptions (with or without\\nindividual convexity, etc). The derived conditions are linear matrix\\ninequalities (LMIs) whose sizes roughly scale with the size of the training\\nset. We make use of the symmetry in the stochastic optimization methods and\\nreduce these LMIs to some equivalent small LMIs whose sizes are at most 3 by 3.\\nWe solve these small LMIs to provide analytical proofs of new convergence rates\\nfor SAGA, Finito and SDCA (with or without individual convexity). We also\\nexplain why our proposed LMI fails in analyzing SAG. We reveal a key difference\\nbetween SAG and other methods, and briefly discuss how to extend our LMI\\nanalysis for SAG. An advantage of our approach is that the proposed analysis\\ncan be automated for a large class of stochastic methods under various\\nassumptions (with or without individual convexity, etc).\\n'\n",
      " '  Network structure can have significant effects on the propagation of\\ndiseases, memes, and information on social networks. Such effects depend on the\\nspecific type of dynamical process that affects the nodes and edges of a\\nnetwork, and it is important to develop tractable models of spreading processes\\non networks to explore how network structure affects dynamics. In this paper,\\nwe incorporate the idea of \\\\emph{synergy} into a two-state (\"active\" or\\n\"passive\") threshold model of social influence on networks. Our model\\'s update\\nrule is deterministic, and the influence of each meme-carrying (i.e., active)\\nneighbor can --- depending on a parameter --- either be enhanced or inhibited\\nby an amount that depends on the number of active neighbors of a node. Such a\\nsynergistic system models social behavior in which the willingness to adopt\\neither accelerates or saturates depending on the number of neighbors who have\\nadopted that behavior. We illustrate that the synergy parameter in our model\\nhas a crucial effect on system dynamics, as it determines whether degree-$k$\\nnodes are possible or impossible to activate. We simulate synergistic meme\\nspreading on both random-graph models and networks constructed from empirical\\ndata. Using a local-tree approximation, we examine the spreading of synergistic\\nmemes and find good agreement on all but one of the networks on which we\\nsimulate spreading. We find for any network and for a broad family of\\nsynergistic models that one can predict which synergy-parameter values allow\\ndegree-$k$ nodes to be activated.\\n'\n",
      " '  Detection of atrial fibrillation (AF), a type of cardiac arrhythmia, is\\ndifficult since many cases of AF are usually clinically silent and undiagnosed.\\nIn particular paroxysmal AF is a form of AF that occurs occasionally, and has a\\nhigher probability of being undetected. In this work, we present an attention\\nbased deep learning framework for detection of paroxysmal AF episodes from a\\nsequence of windows. Time-frequency representation of 30 seconds recording\\nwindows, over a 10 minute data segment, are fed sequentially into a deep\\nconvolutional neural network for image-based feature extraction, which are then\\npresented to a bidirectional recurrent neural network with an attention layer\\nfor AF detection. To demonstrate the effectiveness of the proposed framework\\nfor transient AF detection, we use a database of 24 hour Holter\\nElectrocardiogram (ECG) recordings acquired from 2850 patients at the\\nUniversity of Virginia heart station. The algorithm achieves an AUC of 0.94 on\\nthe testing set, which exceeds the performance of baseline models. We also\\ndemonstrate the cross-domain generalizablity of the approach by adapting the\\nlearned model parameters from one recording modality (ECG) to another\\n(photoplethysmogram) with improved AF detection performance. The proposed high\\naccuracy, low false alarm algorithm for detecting paroxysmal AF has potential\\napplications in long-term monitoring using wearable sensors.\\n'\n",
      " '  Confinement at the helical edge of a topological insulator is possible in the\\npresence of proximity-induced magnetic (F) or superconducting (S) order. The\\ninterplay of both phenomena leads to the formation of localized Majorana bound\\nstates (MBS) or likewise (under certain resonance conditions) the formation of\\nordinary Andreev bound states (ABS). We investigate the properties of bound\\nstates in junctions composed of alternating regions of F or S barriers.\\nInterestingly, the direction of magnetization in F regions and the relative\\nsuperconducting phase between S regions can be exploited to hybridize MBS or\\nABS at will. We show that the local properties of MBS translate into a\\nparticular nonlocal superconducting pairing amplitude. Remarkably, the symmetry\\nof the pairing amplitude contains information about the nature of the bound\\nstate that it stems from. Hence, this symmetry can in principle be used to\\ndistinguish MBS from ABS, owing to the strong connection between local density\\nof states and nonlocal pairing in our setup.\\n'\n",
      " '  Statistical agencies utilize models to synthesize respondent-level data for\\nrelease to the general public as an alternative to the actual data records. A\\nBayesian model synthesizer encodes privacy protection by employing a\\nhierarchical prior construction that induces smoothing of the real data\\ndistribution. Synthetic respondent-level data records are often preferred to\\nsummary data tables due to the many possible uses by researchers and data\\nanalysts. Agencies balance a trade-off between utility of the synthetic data\\nversus disclosure risks and hold a specific target threshold for disclosure\\nrisk before releasing synthetic datasets. We introduce a pseudo posterior\\nlikelihood that exponentiates each contribution by an observation\\nrecord-indexed weight in (0, 1), defined to be inversely proportional to the\\ndisclosure risk for that record in the synthetic data. Our use of a vector of\\nweights allows more precise downweighting of high risk records in a fashion\\nthat better preserves utility as compared with using a scalar weight. We\\nillustrate our method with a simulation study and an application to the\\nConsumer Expenditure Survey of the U.S. Bureau of Labor Statistics. We\\ndemonstrate how the frequentist consistency and uncertainty quantification are\\naffected by the inverse risk-weighting.\\n'\n",
      " '  We perform the calculation of the dc resistivity as a function of temperature\\nof the \"strange-metal\" state that emerges in the vicinity of a\\nspin-density-wave phase transition in the presence of weak disorder. This\\nscenario is relevant to the phenomenology of many important correlated\\nmaterials, such as, e.g., the pnictides, the heavy-fermion compounds and the\\ncuprates. To accomplish this task, we implement the memory-matrix approach that\\nallows the calculation of the transport coefficients of the model beyond the\\nquasiparticle paradigm. Our computation is also inspired by the $\\\\epsilon=3-d$\\nexpansion in a hot-spot model embedded in $d$-space dimensions recently put\\nforth by Sur and Lee [Phys. Rev. B 91, 125136 (2015)], in which they find a new\\nlow-energy non-Fermi liquid fixed point that is perturbatively accessible near\\nthree dimensions. As a consequence, we are able to establish here the\\ntemperature and doping dependence of the electrical resistivity at intermediate\\ntemperatures of a two-dimensional disordered antiferromagnetic metallic model\\nwith a composite operator that couples the order-parameter fluctuations to the\\nentire Fermi surface. We argue that our present theory provides a good basis in\\norder to unify the experimental transport data, e.g., in the cuprates and the\\npnictide superconductors, within a wide range of doping regimes.\\n'\n",
      " '  We introduce a method to evaluate the relative populations of different\\nconformers of molecular species in solution, aiming at quantum mechanical\\naccuracy, while keeping the computational cost at a nearly molecular-mechanics\\nlevel. This goal is achieved by combining long classical molecular-dynamics\\nsimulations to sample the free-energy landscape of the system, advanced\\nclustering techniques to identify the most relevant conformers, and\\nthermodynamic perturbation theory to correct the resulting populations, using\\nquantum-mechanical energies from density-functional theory. A quantitative\\ncriterion for assessing the accuracy thus achieved is proposed. The resulting\\nmethodology is demonstrated in the specific case of cyanin\\n(cyanidin-3-glucoside) in water solution.\\n'\n",
      " '  RNNs and their variants have been widely adopted for image captioning. In\\nRNNs, the production of a caption is driven by a sequence of latent states.\\nExisting captioning models usually represent latent states as vectors, taking\\nthis practice for granted. We rethink this choice and study an alternative\\nformulation, namely using two-dimensional maps to encode latent states. This is\\nmotivated by the curiosity about a question: how the spatial structures in the\\nlatent states affect the resultant captions? Our study on MSCOCO and Flickr30k\\nleads to two significant observations. First, the formulation with 2D states is\\ngenerally more effective in captioning, consistently achieving higher\\nperformance with comparable parameter sizes. Second, 2D states preserve spatial\\nlocality. Taking advantage of this, we visually reveal the internal dynamics in\\nthe process of caption generation, as well as the connections between input\\nvisual domain and output linguistic domain.\\n'\n",
      " '  While several approaches to face emotion recognition task are proposed in\\nliterature, none of them reports on power consumption nor inference time\\nrequired to run the system in an embedded environment. Without adequate\\nknowledge about these factors it is not clear whether we are actually able to\\nprovide accurate face emotion recognition in the embedded environment or not,\\nand if not, how far we are from making it feasible and what are the biggest\\nbottlenecks we face.\\nThe main goal of this paper is to answer these questions and to convey the\\nmessage that instead of reporting only detection accuracy also power\\nconsumption and inference time should be reported as real usability of the\\nproposed systems and their adoption in human computer interaction strongly\\ndepends on it. In this paper, we identify the state-of-the art face emotion\\nrecognition methods that are potentially suitable for embedded environment and\\nthe most frequently used datasets for this task. Our study shows that most of\\nthe performed experiments use datasets with posed expressions or in a\\nparticular experimental setup with special conditions for image collection.\\nSince our goal is to evaluate the performance of the identified promising\\nmethods in the realistic scenario, we collect a new dataset with\\nnon-exaggerated emotions and we use it, in addition to the publicly available\\ndatasets, for the evaluation of detection accuracy, power consumption and\\ninference time on three frequently used embedded devices with different\\ncomputational capabilities. Our results show that gray images are still more\\nsuitable for embedded environment than color ones and that for most of the\\nanalyzed systems either inference time or energy consumption or both are\\nlimiting factor for their adoption in real-life embedded applications.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9b9079e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data= article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ff51f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4dc5c",
   "metadata": {},
   "source": [
    "Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba20f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = []\n",
    "for i in article:\n",
    "    if(len(str(i))>0):\n",
    "        art.append(str(i))\n",
    "article = art\n",
    "len(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b92e3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7a7f8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [\"FW\", \"NN\", \"NNS\", \"NNP\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7f56612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8687044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(s):\n",
    "    unique_list = []\n",
    "    for x in s:\n",
    "        if x not in unique_list:\n",
    "            check = x.isnumeric()\n",
    "            if(check):\n",
    "                unique_list.append(\"num\")\n",
    "            else:\n",
    "                unique_list.append(x)\n",
    "            \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "216fa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(art):\n",
    "    articles = []\n",
    "    for l in art:\n",
    "        l = str(l)\n",
    "        if(len(l)>300):\n",
    "            txt = l\n",
    "            tokenized = sent_tokenize(txt)\n",
    "            t = []\n",
    "            for i in tokenized:\n",
    "                wordsList = nltk.word_tokenize(i)\n",
    "                wordsList = [w for w in wordsList if not w in stop_words]\n",
    "                tagged = nltk.pos_tag(wordsList)\n",
    "                for i in tagged:\n",
    "                    t.append(i)\n",
    "            s = \"\"\n",
    "            for i in t:\n",
    "                if(i[1] in pos):\n",
    "                    s=s+\" \"+i[0]\n",
    "            article = s\n",
    "            article = article.lower()\n",
    "            article = re.sub(r'[^\\w\\s]','',article)\n",
    "            article = remove_stopwords(article)\n",
    "            words_article = word_tokenize(article)\n",
    "            wa = []\n",
    "            for i in words_article:\n",
    "                a = wn.lemmatize(i)\n",
    "                wa.append(a)\n",
    "            \n",
    "            s = unique(wa)\n",
    "            articles.append(s)\n",
    "            \n",
    "            \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "08ad39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sen = preprocess(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8b6ce288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  We study tensor powers of rank 1 sign-normalized Drinfeld A-modules, where A\\nis the coordinate ring of an elliptic curve over a finite field. Using the\\ntheory of vector valued Anderson generating functions, we give formulas for the\\ncoefficients of the logarithm and exponential functions associated to these\\nA-modules. We then show that there exists a vector whose bottom coordinate\\ncontains a Goss zeta value, whose evaluation under the exponential function is\\ndefined over the Hilbert class field. This allows us to prove the transcendence\\nof Goss zeta values and periods of Drinfeld modules as well as the\\ntranscendence of certain ratios of those quantities.\\n',\n",
       " '  We performed $^{59}$Co nuclear magnetic resonance (NMR) measurements of\\nsingle-crystalline U$_6$Co. There is a small decrease in the Knight shift in\\nthe superconducting (SC) state, but this change mainly arises from the SC\\ndiamagnetic effect. The negligible change of the spin part of the Knight shift,\\ntogether with the absence of the Pauli-paramagnetic effect in the SC U$_6$Co,\\nis understood as a consequence of the small spin susceptibility. The nuclear\\nspin-lattice relaxation rate $1/T_1$ is also measured in the SC state under the\\nmagnetic field, and exhibits a tiny Hebel-Slichter peak just below the SC\\ntransition temperature and exponential behavior at lower temperatures. These\\nbehaviors are in agreement with the full-gap s-wave pairing in U$_6$Co.\\n',\n",
       " \"  Background and objective: Stacking is an ensemble machine learning method\\nthat averages predictions from multiple other algorithms, such as generalized\\nlinear models and regression trees. A recent iteration of stacking, called\\nsuper learning, has been developed as a general approach to black box\\nsupervised learning and has seen frequent usage, in part due to the\\navailability of an R package. I develop super learning in the SAS software\\nsystem using a new macro, and demonstrate its performance relative to the R\\npackage.\\nMethods: I follow closely previous work using the R SuperLearner package and\\nassess the performance of super learning in a number of domains. I compare the\\nR package with the new SAS macro in a small set of simulations assessing curve\\nfitting in a prediction model, a set of 14 publicly available datasets to\\nassess cross-validated, expected loss, and data from a randomized trial of job\\nseekers' training to assess the utility of super learning in causal inference\\nusing inverse probability weighting.\\nResults: Across the simulated data and the publicly available data, the macro\\nperformed similarly to the R package, even with a different set of potential\\nalgorithms available natively in R and SAS. The example with inverse\\nprobability weighting demonstrated the ability of the SAS macro to include\\nalgorithms developed in R.\\nConclusions: The super learner macro performs as well as the R package at a\\nnumber of tasks. Further, by extending the macro to include the use of R\\npackages, the macro can leverage both the robust, enterprise oriented\\nprocedures in SAS and the nimble, cutting edge packages in R. In the spirit of\\nensemble learning, this macro extends the potential library of algorithms\\nbeyond a single software system and provides a simple avenue into machine\\nlearning in SAS.\\n\",\n",
       " '  Rogue waves in the nonlocal PT-symmetric nonlinear Schrodinger (NLS) equation\\nare studied by Darboux transformation. Three types of rogue waves are derived,\\nand their explicit expressions in terms of Schur polynomials are presented.\\nThese rogue waves show a much wider variety than those in the local NLS\\nequation. For instance, the polynomial degrees of their denominators can be not\\nonly $n(n+1)$, but also $n(n-1)+1$ and $n^2$, where $n$ is an arbitrary\\npositive integer. Dynamics of these rogue waves is also examined. It is shown\\nthat these rogue waves can be bounded for all space and time, or develop\\ncollapsing singularities, depending on their types as well as values of their\\nfree parameters. In addition, the solution dynamics exhibits rich patterns,\\nmost of which have no counterparts in the local NLS equation.\\n',\n",
       " \"  Developing students' ability to troubleshoot is an important learning outcome\\nfor many undergraduate physics lab courses, especially electronics courses. In\\nother work, metacognition has been identified as an important feature of\\ntroubleshooting. However, that work has focused primarily on individual\\nstudents' metacognitive processes or troubleshooting abilities. In contrast,\\nelectronics courses often require students to work in pairs, and hence\\nstudents' in-class experiences likely have significant social dimensions that\\nare not well understood. In this work, we use an existing framework for\\nsocially mediated metacognition to analyze audiovisual data from think-aloud\\nactivities in which eight pairs of students from two institutions attempted to\\ndiagnose and repair a malfunctioning electric circuit. In doing so, we provide\\ninsight into some of the social metacognitive dynamics that arise during\\ncollaborative troubleshooting. We find that students engaged in socially\\nmediated metacognition at multiple key transitions during the troubleshooting\\nprocess. Reciprocated metacognitive dialogue arose when students were\\ncollectively strategizing about which measurements to perform, or reaching a\\nshared understanding of the circuit's behavior. In addition to elaborating upon\\nthese findings, we discuss implications for instruction, and we identify areas\\nfor potential future investigation.\\n\",\n",
       " '  We prove a new and general concentration inequality for the excess risk in\\nleast-squares regression with random design and heteroscedastic noise. No\\nspecific structure is required on the model, except the existence of a suitable\\nfunction that controls the local suprema of the empirical process. So far, only\\nthe case of linear contrast estimation was tackled in the literature with this\\nlevel of generality on the model. We solve here the case of a quadratic\\ncontrast, by separating the behavior of a linearized empirical process and the\\nempirical process driven by the squares of functions of models.\\n',\n",
       " '  In recent years, dynamic languages, such as JavaScript or Python, have faced\\nan important increment of usage in a wide range of fields and applications.\\nTheir tricky and misunderstood behaviors pose a hard challenge for static\\nanalysis of these programming languages. A key aspect of any dynamic language\\nprogram is the multiple usage of strings, since they can be implicitly\\nconverted to another type value, transformed by string-to-code primitives or\\nused to access an object-property. Unfortunately, string analyses for dynamic\\nlanguages still lack of precision and do not take into account some important\\nstring features. Moreover, string obfuscation is very popular in the context of\\ndynamic language malicious code, for example, to hide code information inside\\nstrings and then to dynamically transform strings into executable code. In this\\nscenario, more precise string analyses become a necessity. This paper proposes\\na new semantics for string analysis placing a first step for handling dynamic\\nlanguages string features.\\n',\n",
       " \"  From our experiences in the past, we have seen that the growth of cities is\\nvery much dependent on the transportation networks. In mega cities,\\ntransportation networks determine to a significant extent as to where the\\npeople will move and houses will be built. Hence, transportation network data\\nis crucial to an urban growth prediction system. Existing works have used\\nmanually derived distance based features based on the road networks to build\\nmodels on urban growth. But due to the non-generic and laborious nature of the\\nmanual feature engineering process, we can shift to End-to-End systems which do\\nnot rely on manual feature engineering. In this paper, we propose a method to\\nintegrate road network data to an existing Rule based End-to-End framework\\nwithout manual feature engineering. Our method employs recurrent neural\\nnetworks to represent road networks in a structured way such that it can be\\nplugged into the previously proposed End-to-End framework. The proposed\\napproach enhances the performance in terms of Figure of Merit, Producer's\\naccuracy, User's accuracy and Overall accuracy of the existing Rule based\\nEnd-to-End framework.\\n\",\n",
       " '  We introduce a new discrete coherence monotone named the \\\\emph{coherence\\nnumber}, which is a generalization of the coherence rank to mixed states. After\\ndefining the coherence number in a similar manner to the Schmidt number in\\nentanglement theory, we present a necessary and sufficient condition of the\\ncoherence number for a coherent state to be converted to an entangled state of\\nnonzero $k$-concurrence (a member of the generalized concurrence family with\\n$2\\\\le k \\\\le d$). It also turns out that the coherence number is a useful\\nmeasure to understand the process of Grover search algorithm of $N$ items. We\\nshow that the coherence number remains $N$ and falls abruptly when the success\\nprobability of the searching process becomes maximal. This phenomenon motivates\\nus to analyze the depletion pattern of $C_c^{(N)}$ (the last member of the\\ngeneralized coherence concurrence, nonzero when the coherence number is $N$),\\nwhich turns out to be an optimal resource for the process since it is\\ncompletely consumed to finish the searching task.\\n',\n",
       " '  We study dynamics of Dirac solitons in prototypical networks modeling them by\\nthe nonlinear Dirac equation on metric graphs. Soliton solutions of the\\nnonlinear Dirac equation on simple metric graphs are obtained. It is shown that\\nthese solutions provide reflectionless vertex transmission of the Dirac\\nsolitons under suitable conditions. The constraints for bond nonlinearity\\ncoefficients, allowing reflectionless transmission over a Y-junction are\\nderived. The analytical results are confirmed by direct numerical simulations.\\n',\n",
       " '  Threat intelligence sharing has become a growing concept, whereby entities\\ncan exchange patterns of threats with each other, in the form of indicators, to\\na community of trust for threat analysis and incident response. However,\\nsharing threat-related information have posed various risks to an organization\\nthat pertains to its security, privacy, and competitiveness. Given the\\ncoinciding benefits and risks of threat information sharing, some entities have\\nadopted an elusive behavior of \"free-riding\" so that they can acquire the\\nbenefits of sharing without contributing much to the community. So far,\\nunderstanding the effectiveness of sharing has been viewed from the perspective\\nof the amount of information exchanged as opposed to its quality. In this\\npaper, we introduce the notion of quality of indicators (\\\\qoi) for the\\nassessment of the level of contribution by participants in information sharing\\nfor threat intelligence. We exemplify this notion through various metrics,\\nincluding correctness, relevance, utility, and uniqueness of indicators. In\\norder to realize the notion of \\\\qoi, we conducted an empirical study and taken\\na benchmark approach to define quality metrics, then we obtained a reference\\ndataset and utilized tools from the machine learning literature for quality\\nassessment. We compared these results against a model that only considers the\\nvolume of information as a metric for contribution, and unveiled various\\ninteresting observations, including the ability to spot low quality\\ncontributions that are synonym to free riding in threat information sharing.\\n',\n",
       " \"  Estimating the angular separation between two incoherently radiating\\nmonochromatic point sources is a canonical toy problem to quantify spatial\\nresolution in imaging. In recent work, Tsang {\\\\em et al.} showed, using a\\nFisher Information analysis, that Rayleigh's resolution limit is just an\\nartifact of the conventional wisdom of intensity measurement in the image\\nplane. They showed that the optimal sensitivity of estimating the angle is only\\na function of the total photons collected during the camera's integration time\\nbut entirely independent of the angular separation itself no matter how small\\nit is, and found the information-optimal mode basis, intensity detection in\\nwhich achieves the aforesaid performance. We extend the above analysis, which\\nwas done for a Gaussian point spread function (PSF) to a hard-aperture pupil\\nproving the information optimality of image-plane sinc-Bessel modes, and\\ngeneralize the result further to an arbitrary PSF. We obtain new\\ncounterintuitive insights on energy vs. information content in spatial modes,\\nand extend the Fisher Information analysis to exact calculations of minimum\\nmean squared error, both for Gaussian and hard aperture pupils.\\n\",\n",
       " '  A particle swarm optimizer (PSO) loosely based on the phenomena of\\ncrystallization and a chaos factor which follows the complimentary error\\nfunction is described. The method features three phases: diffusion, directed\\nmotion, and nucleation. During the diffusion phase random walk is the only\\ncontributor to particle motion. As the algorithm progresses the contribution\\nfrom chaos decreases and movement toward global best locations is pursued until\\nconvergence has occurred. The algorithm was found to be more robust to local\\nminima in multimodal test functions than a standard PSO algorithm and is\\ndesigned for problems which feature experimental precision.\\n',\n",
       " '  We prove that any classical affine W-algebra W(g,f), where g is a classical\\nLie algebra and f is an arbitrary nilpotent element of g, carries an integrable\\nHamiltonian hierarchy of Lax type equations. This is based on the theories of\\ngeneralized Adler type operators and of generalized quasideterminants, which we\\ndevelop in the paper. Moreover, we show that under certain conditions, the\\nproduct of two generalized Adler type operators is a Lax type operator. We use\\nthis fact to construct a large number of integrable Hamiltonian systems,\\nrecovering, as a special case, all KdV type hierarchies constructed by Drinfeld\\nand Sokolov.\\n',\n",
       " '  Non-free data types are data types whose data have no canonical forms. For\\nexample, multisets are non-free data types because the multiset $\\\\{a,b,b\\\\}$ has\\ntwo other equivalent but literally different forms $\\\\{b,a,b\\\\}$ and $\\\\{b,b,a\\\\}$.\\nPattern matching is known to provide a handy tool set to treat such data types.\\nAlthough many studies on pattern matching and implementations for practical\\nprogramming languages have been proposed so far, we observe that none of these\\nstudies satisfy all the criteria of practical pattern matching, which are as\\nfollows: i) efficiency of the backtracking algorithm for non-linear patterns,\\nii) extensibility of matching process, and iii) polymorphism in patterns.\\nThis paper aims to design a new pattern-matching-oriented programming\\nlanguage that satisfies all the above three criteria. The proposed language\\nfeatures clean Scheme-like syntax and efficient and extensible pattern matching\\nsemantics. This programming language is especially useful for the processing of\\ncomplex non-free data types that not only include multisets and sets but also\\ngraphs and symbolic mathematical expressions. We discuss the importance of our\\ncriteria of practical pattern matching and how our language design naturally\\narises from the criteria. The proposed language has been already implemented\\nand open-sourced as the Egison programming language.\\n',\n",
       " '  This paper enlarges classical syllogistic logic with assertions having to do\\nwith comparisons between the sizes of sets. So it concerns a logical system\\nwhose sentences are of the following forms: {\\\\sf All $x$ are $y$} and {\\\\sf Some\\n$x$ are $y$}, {\\\\sf There are at least as many $x$ as $y$}, and {\\\\sf There are\\nmore $x$ than $y$}. Here $x$ and $y$ range over subsets (not elements) of a\\ngiven \\\\emph{infinite} set. Moreover, $x$ and $y$ may appear complemented (i.e.,\\nas $\\\\overset{-}{x}$ and $\\\\overset{-}{y}$), with the natural meaning. We\\nformulate a logic for our language that is based on the classical syllogistic.\\nThe main result is a soundness/completeness theorem. There are efficient\\nalgorithms for proof search and model construction.\\n',\n",
       " '  In this paper, we prove that for any fixed $205/243<\\\\gamma\\\\leqslant1$, every\\nsufficiently large $N$ satisfying $N\\\\equiv 5 \\\\pmod {24}$ can be represented as\\nfive squares of primes with one prime in $\\\\mathcal{P}_\\\\gamma$, which improves\\nthe previous result of Zhang and Zhai.\\n',\n",
       " '  The widely known linear time algorithm for computing the maximum area\\ntriangle in a convex polygon was found incorrect recently by Keikha et.\\nal.(arXiv:1705.11035). We present an alternative algorithm in this paper.\\nComparing to the only previously known correct solution, ours is much simpler\\nand more efficient. More importantly, our new approach is powerful in solving\\nrelated problems.\\n',\n",
       " \"  What does it take for a system, biological or not, to have goals? Here, this\\nquestion is approached in the context of in silico artificial evolution. By\\nexamining the informational and causal properties of artificial organisms\\n('animats') controlled by small, adaptive neural networks (Markov Brains), this\\nessay discusses necessary requirements for intrinsic information, autonomy, and\\nmeaning. The focus lies on comparing two types of Markov Brains that evolved in\\nthe same simple environment: one with purely feedforward connections between\\nits elements, the other with an integrated set of elements that causally\\nconstrain each other. While both types of brains 'process' information about\\ntheir environment and are equally fit, only the integrated one forms a causally\\nautonomous entity above a background of external influences. This suggests that\\nto assess whether goals are meaningful for a system itself, it is important to\\nunderstand what the system is, rather than what it does.\\n\",\n",
       " '  Neural language models are a critical component of state-of-the-art systems\\nfor machine translation, summarization, audio transcription, and other tasks.\\nThese language models are almost universally autoregressive in nature,\\ngenerating sentences one token at a time from left to right. This paper studies\\nthe influence of token generation order on model quality via a novel two-pass\\nlanguage model that produces partially-filled sentence \"templates\" and then\\nfills in missing tokens. We compare various strategies for structuring these\\ntwo passes and observe a surprisingly large variation in model quality. We find\\nthe most effective strategy generates function words in the first pass followed\\nby content words in the second. We believe these experimental results justify a\\nmore extensive investigation of generation order for neural language models.\\n',\n",
       " '  Internet greatly assist people in improving their quality of life. Almost all\\nareas of human life can be accessed using the internet. Human aided by the\\ninternet that provides all sorts of information that they need. Along with the\\ndevelopment of the Internet network infrastructure remotely control began to\\nchange using the internet. In this study using notebooks and servers Raspberry\\nPi to find out the quality control of each device server used. In this study we\\ninvestigate the possibility of improving the quality of web-based remote\\ncontrol to implement Raspberry Pi as a web server and how much improvement the\\nquality of web-based remote control obtained in this research.\\n',\n",
       " '  Dropout is used to avoid overfitting by randomly dropping units from the\\nneural networks during training. Inspired by dropout, this paper presents\\nGI-Dropout, a novel dropout method integrating with global information to\\nimprove neural networks for text classification. Unlike the traditional dropout\\nmethod in which the units are dropped randomly according to the same\\nprobability, we aim to use explicit instructions based on global information of\\nthe dataset to guide the training process. With GI-Dropout, the model is\\nsupposed to pay more attention to inapparent features or patterns. Experiments\\ndemonstrate the effectiveness of the dropout with global information on seven\\ntext classification tasks, including sentiment analysis and topic\\nclassification.\\n',\n",
       " '  Spectral methods provide an elegant and efficient way of numerically solving\\ndifferential equations of all kinds. For smooth problems, truncation error for\\nspectral methods vanishes exponentially in the infinity norm and $L_2$-norm.\\nHowever, for non-smooth problems, convergence is significantly worse---the\\n$L_2$-norm of the error for a discontinuous problem will converge at a\\nsub-linear rate and the infinity norm will not converge at all. We explore and\\nimprove upon a post-processing technique---optimally convergent mollifiers---to\\nrecover exponential convergence from a poorly-converging spectral\\nreconstruction of non-smooth data. This is an important first step towards\\nusing these techniques for simulations of realistic systems.\\n',\n",
       " '  Despite large incentives, ecorrectness in software remains an elusive goal.\\nDeclarative programming techniques, where algorithms are derived from a\\nspecification of the desired behavior, offer hope to address this problem,\\nsince there is a combinatorial reduction in complexity in programming in terms\\nof specifications instead of algorithms, and arbitrary desired properties can\\nbe expressed and enforced in specifications directly. However, limitations on\\nperformance have prevented programming with declarative specifications from\\nbecoming a mainstream technique for general-purpose programming. To address the\\nperformance bottleneck in deriving an algorithm from a specification, I propose\\ninformation-gain computation, a framework where an adaptive evaluation strategy\\nis used to efficiently perform a search which derives algorithms that provide\\ninformation about a query most directly. Within this framework, opportunities\\nto compress the search space present themselves, which suggest that\\ninformation-theoretic bounds on the performance of such a system might be\\narticulated and a system designed to achieve them. In a preliminary empirical\\nstudy of adaptive evaluation for a simple test program, the evaluation strategy\\nadapts successfully to evaluate a query efficiently.\\n',\n",
       " '  The sequence $3, 5, 9, 11, 15, 19, 21, 25, 29, 35,\\\\dots$ consists of odd legs\\nin right triangles with integer side lengths and prime hypotenuse. We show that\\nthe upper density of this sequence is zero, with logarithmic decay. The same\\nestimate holds for the sequence of even legs in such triangles. We expect our\\nupper bound, which involves the Erdős--Ford--Tenenbaum constant, to be\\nsharp up to a double-logarithmic factor. We also provide a nontrivial lower\\nbound. Our techniques involve sieve methods, the distribution of Gaussian\\nprimes in narrow sectors, and the Hardy--Ramanujan inequality.\\n',\n",
       " '  An improved algorithm is proposed for the reconstruction of singular\\nconnectivity from the available pairwise connections during preprocessing\\nphase. To evaluate the performance of the algorithm, an in-house computational\\nfluid dynamics (CFD) code is used in which high-order finite-difference method\\nfor spatial discretization running on the Tianhe-1A supercomputer is employed.\\nTest cases with a varied amount of mesh points are chosen, and the test results\\nindicate that the improved singular connection reconstruction algorithm can\\nachieve a speedup factor of 1000X or more when compared with the naive search\\nmethod adopted in the former version of our code. Moreover, the parallel\\nefficiency can benefit from the strategy of local communication based on the\\nalgorithm.\\n',\n",
       " '  Citations are the cornerstone of knowledge propagation and the primary means\\nof assessing the quality of research, as well as directing investments in\\nscience. Science is increasingly becoming \"data-intensive\", where large volumes\\nof data are collected and analyzed to discover complex patterns through\\nsimulations and experiments, and most scientific reference works have been\\nreplaced by online curated datasets. Yet, given a dataset, there is no\\nquantitative, consistent and established way of knowing how it has been used\\nover time, who contributed to its curation, what results have been yielded or\\nwhat value it has.\\nThe development of a theory and practice of data citation is fundamental for\\nconsidering data as first-class research objects with the same relevance and\\ncentrality of traditional scientific products. Many works in recent years have\\ndiscussed data citation from different viewpoints: illustrating why data\\ncitation is needed, defining the principles and outlining recommendations for\\ndata citation systems, and providing computational methods for addressing\\nspecific issues of data citation.\\nThe current panorama is many-faceted and an overall view that brings together\\ndiverse aspects of this topic is still missing. Therefore, this paper aims to\\ndescribe the lay of the land for data citation, both from the theoretical (the\\nwhy and what) and the practical (the how) angle.\\n',\n",
       " '  We address the issue of inter-particle dipolar interactions in the context of\\nmagnetic hyperthermia. More precisely, the main question dealt with here is\\nconcerned with the conditions under which the specific absorption rate is\\nenhanced or reduced by dipolar interactions. For this purpose, we propose a\\ntheory for the calculation of the AC susceptibility, and thereby the specific\\nabsorption rate, for a monodisperse two-dimensional assembly of nanoparticles\\nwith oriented anisotropy, in the presence of a DC magnetic field, in addition\\nto the AC magnetic field. We also study the competition between the dipolar\\ninteractions and the DC field, both in the transverse and longitudinal\\nconfigurations. In both cases, we find that the specific absorption rate has a\\nmaximum at some critical DC field that depends on the inter-particle\\nseparation. In the longitudinal setup, this critical field falls well within\\nthe range of experiments.\\n',\n",
       " '  Predicting long-term outcomes of interventions is necessary for educational\\nand social policy-making processes that might widely influence our society for\\nthe long-term. However, performing such predictions based on data from\\nlarge-scale experiments might be challenging due to the lack of time and\\nresources. In order to address this issue, computer simulations based on\\nEvolutionary Causal Matrices and Markov Chain can be used to predict long-term\\noutcomes with relatively small-scale lab data. In this paper, we introduce\\nPython classes implementing a computer simulation model and presented some\\npilots implementations demonstrating how the model can be utilized for\\npredicting outcomes of diverse interventions. We also introduce the\\nclass-structured simulation module both with real experimental data and with\\nhypothetical data formulated based on social psychological theories. Classes\\ndeveloped and tested in the present study provide researchers and practitioners\\nwith a feasible and practical method to simulate intervention outcomes\\nprospectively.\\n',\n",
       " '  Many physical processes involve spatio-temporal observations, which can be\\nstudied at different spatial and temporal scales. For example, rainfall data\\nmeasured daily by rain gauges can be considered at daily, monthly or annual\\ntemporal scales, and local, grid-wise, region-wise or country-wise spatial\\nscales. In this work, we focus on detection of anomalies in such multi-scale\\nspatio-temporal data. We consider an anomaly as an event where the measured\\nvalues over a spatio-temporally extended region are significantly different\\nfrom their long-term means. However we aim to avoid setting any thresholds on\\nthe measured values and spatio-temporal sizes, because not only are thresholds\\nsubjective but also the long-term mean values often vary spatially and\\ntemporally. For this purpose we use spatio-Temporal Markov Random Field, where\\nlatent states indicate anomaly type (positive anomaly, negative anomaly, no\\nanomaly/normal). Spatio-temporal coherence is maintained through suitable edge\\npotentials. The model is extended to multiple spatio-temporal scales to achieve\\nour second goal: anomalies at any scale should be defined both on the data at\\nthat scale, and also on anomalies at other scales. This allows us to trace an\\nanomaly at a coarse scale to finer scales. For example, whether rainfall in a\\nparticular year is anomalous over a region should depend not only on the total\\nvolume of rainfall over the entire region, but also on whether there were such\\nanomalies at the grid-scale, and the monthly scale. We use this approach to\\nstudy rainfall anomalies over India -extremely diverse with respect to\\nrainfall- for the period 1901-2011, and show its benefits over existing\\napproaches.\\n',\n",
       " \"  This paper has three main contributions to our understanding of fixed-depth\\nminimax search: (A) A new formulation for Stockman's SSS* algorithm, based on\\nAlpha-Beta, is presented. It solves all the perceived drawbacks of SSS*,\\nfinally transforming it into a practical algorithm. In effect, we show that\\nSSS* = alpha-beta + ransposition tables. The crucial step is the realization\\nthat transposition tables contain so-called solution trees, structures that are\\nused in best-first search algorithms like SSS*. Having created a practical\\nversion, we present performance measurements with tournament game-playing\\nprograms for three different minimax games, yielding results that contradict a\\nnumber of publications. (B) Based on the insights gained in our attempts at\\nunderstanding SSS*, we present a framework that facilitates the construction of\\nseveral best-first fixed- depth game-tree search algorithms, known and new. The\\nframework is based on depth-first null-window Alpha-Beta search, enhanced with\\nstorage to allow for the refining of previous search results. It focuses\\nattention on the essential differences between algorithms. (C) We present a new\\ninstance of the framework, MTD(f). It is well-suited for use with iterative\\ndeepening, and performs better than algorithms that are currently used in most\\nstate-of-the-art game-playing programs. We provide experimental evidence to\\nexplain why MTD(f) performs better than the other fixed-depth minimax\\nalgorithms.\\n\",\n",
       " \"  Humans are able to explain their reasoning. On the contrary, deep neural\\nnetworks are not. This paper attempts to bridge this gap by introducing a new\\nway to design interpretable neural networks for classification, inspired by\\nphysiological evidence of the human visual system's inner-workings. This paper\\nproposes a neural network design paradigm, termed InterpNET, which can be\\ncombined with any existing classification architecture to generate natural\\nlanguage explanations of the classifications. The success of the module relies\\non the assumption that the network's computation and reasoning is represented\\nin its internal layer activations. While in principle InterpNET could be\\napplied to any existing classification architecture, it is evaluated via an\\nimage classification and explanation task. Experiments on a CUB bird\\nclassification and explanation dataset show qualitatively and quantitatively\\nthat the model is able to generate high-quality explanations. While the current\\nstate-of-the-art METEOR score on this dataset is 29.2, InterpNET achieves a\\nmuch higher METEOR score of 37.9.\\n\",\n",
       " '  Global constraints and reranking have not been used in cognates detection\\nresearch to date. We propose methods for using global constraints by performing\\nrescoring of the score matrices produced by state of the art cognates detection\\nsystems. Using global constraints to perform rescoring is complementary to\\nstate of the art methods for performing cognates detection and results in\\nsignificant performance improvements beyond current state of the art\\nperformance on publicly available datasets with different language pairs and\\nvarious conditions such as different levels of baseline state of the art\\nperformance and different data size conditions, including with more realistic\\nlarge data size conditions than have been evaluated with in the past.\\n',\n",
       " '  We propose a method to optimise the parameters of a policy which will be used\\nto safely perform a given task in a data-efficient manner. We train a Gaussian\\nprocess model to capture the system dynamics, based on the PILCO framework. Our\\nmodel has useful analytic properties, which allow closed form computation of\\nerror gradients and estimating the probability of violating given state space\\nconstraints. During training, as well as operation, only policies that are\\ndeemed safe are implemented on the real system, minimising the risk of failure.\\n',\n",
       " '  Among the family of TMDs, ReS2 takes a special position, which crystalizes in\\na unique distorted low-symmetry structure at ambient conditions. The interlayer\\ninteraction in ReS2 is rather weak, thus its bulk properties are similar to\\nthat of monolayer. However, how does compression change its structure and\\nelectronic properties is unknown so far. Here using ab initio crystal structure\\nsearching techniques, we explore the high-pressure phase transitions of ReS2\\nextensively and predict two new high-pressure phases. The ambient pressure\\nphase transforms to a \"distorted-1T\" structure at very low pressure and then to\\na tetragonal I41/amd structure at around 90 GPa. The \"distorted-1T\" structure\\nundergoes a semiconductor-metal transition (SMT) at around 70 GPa with a band\\noverlap mechanism. Electron-phonon calculations suggest that the I41/amd\\nstructure is superconducting and has a critical superconducting temperature of\\nabout 2 K at 100 GPa. We further perform high-pressure electrical resistance\\nmeasurements up to 102 GPa. Our experiments confirm the SMT and the\\nsuperconducting phase transition of ReS2 under high pressure. These\\nexperimental results are in good agreement with our theoretical predictions.\\n',\n",
       " '  We propose a strategy to measure weak static magnetic fields with\\nnitrogen-vacancy color center in diamond. Inspired by avian magnetoreception\\nmodels, we consider the feasibility of utilizing quantum coherence phenomena to\\nmeasure weak static magnetic fields. Nitrogen-vacancy (NV) color centers are\\nregarded as the ideal platform to study quantum sciences as a result of its\\nlong coherence time up to a millisecond timescale. In high-purity diamond,\\nhyperfine interaction with 13C nuclear spins dominates the decoherence process.\\nIn this paper, we numerically simulate the decoherence process between 0 and +1\\nof the individual NV color center spin in 13C nuclear baths with various of\\nmagnitudes of external magnetic fields. By applying Hahn echo into the system,\\nwe obtain the coherence of NV color center spin as a function of total\\nevolution time and magnetic field. Furthermore we obtain the high-accuracy\\nrelationship between the three decoherence-characteristic timescales, i.e. T_W,\\nT_R, T_2, and magnetic field B. And we draw a conclusion that T_R has the\\nhighest sensitivity about magnetic field among the three time-scales. Thus, for\\na certain NV color center, T_R can be the scale for the magnitude of magnetic\\nfield, or rather, the component along the NV electronic spin axis. When\\nmeasuring an unknown magnetic field, we adjust the NV axis to three mutually\\northogonal directions respectively. By this means, we obtain the three\\ncomponents of the magnetic field and thus the magnitude and direction of the\\nactual magnetic field. The accuracy could reach 60 nT/Hz^{1/2},and could be\\ngreatly improved by using an ensemble of NV color centers or diamond crystals\\npurified with 12C atoms.\\n',\n",
       " '  We demonstrate that a broad class of excited state variational principles is\\nnot size consistent. In light of this difficulty, we develop and test an\\napproach to excited state optimization that transforms between variational\\nprinciples in order to achieve state selectivity, size consistency, and\\ncompatibility with quantum Monte Carlo. To complement our formal analysis, we\\nprovide numerical examples that confirm these properties and demonstrate how\\nthey contribute to a more black box approach to excited states in quantum Monte\\nCarlo.\\n',\n",
       " '  In German, relative clauses can be positioned in-situ or extraposed. A\\npotential factor for the variation might be information density. In this study,\\nthis hypothesis is tested with a corpus of 17th century German funeral sermons.\\nFor each referent in the relative clauses and their matrix clauses, the\\nattention state was determined (first calculation). In a second calculation,\\nfor each word the surprisal values were determined, using a bi-gram language\\nmodel. In a third calculation, the surprisal values were accommodated as to\\nwhether it is the first occurrence of the word in question or not. All three\\ncalculations pointed in the same direction: With in-situ relative clauses, the\\nrate of new referents was lower and the average surprisal values were lower,\\nespecially the accommodated surprisal values, than with extraposed relative\\nclauses. This indicated that in-formation density is a factor governing the\\nchoice between in-situ and extraposed relative clauses. The study also sheds\\nlight on the intrinsic relation-ship between the information theoretic concept\\nof information density and in-formation structural concepts such as givenness\\nwhich are used under a more linguistic perspective.\\n',\n",
       " '  Population protocols are a model of distributed computing, in which $n$\\nagents with limited local state interact randomly, and cooperate to\\ncollectively compute global predicates. An extensive series of papers, across\\ndifferent communities, has examined the computability and complexity\\ncharacteristics of this model. Majority, or consensus, is a central task, in\\nwhich agents need to collectively reach a decision as to which one of two\\nstates $A$ or $B$ had a higher initial count. Two complexity metrics are\\nimportant: the time that a protocol requires to stabilize to an output\\ndecision, and the state space size that each agent requires.\\nIt is known that majority requires $\\\\Omega(\\\\log \\\\log n)$ states per agent to\\nallow for poly-logarithmic time stabilization, and that $O(\\\\log^2 n)$ states\\nare sufficient. Thus, there is an exponential gap between the upper and lower\\nbounds.\\nWe address this question. We provide a new lower bound of $\\\\Omega(\\\\log n)$\\nstates for any protocol which stabilizes in $O( n^{1-c} )$ time, for any $c >\\n0$ constant. This result is conditional on basic monotonicity and output\\nassumptions, satisfied by all known protocols. Technically, it represents a\\nsignificant departure from previous lower bounds. Instead of relying on dense\\nconfigurations, we introduce a new surgery technique to construct executions\\nwhich contradict the correctness of algorithms that stabilize too fast.\\nSubsequently, our lower bound applies to general initial configurations.\\nWe give an algorithm for majority which uses $O(\\\\log n)$ states, and\\nstabilizes in $O(\\\\log^2 n)$ time. Central to the algorithm is a new leaderless\\nphase clock, which allows nodes to synchronize in phases of $\\\\Theta(n \\\\log{n})$\\nconsecutive interactions using $O(\\\\log n)$ states per node. We also employ our\\nphase clock to build a leader election algorithm with $O(\\\\log n )$ states,\\nwhich stabilizes in $O(\\\\log^2 n)$ time.\\n',\n",
       " '  The intrinsically hole-doped RbEuFe$_4$As$_4$ exhibits bulk superconductivity\\nat $T_{\\\\mathrm{sc}}=36.5$ K and ferromagnetic ordering in the Eu sublattice at\\n$T_\\\\mathrm{m}=15$ K. Here we present a hole-compensation study by introducing\\nextra itinerant electrons via a Ni substitution in the ferromagnetic\\nsuperconductor RbEuFe$_4$As$_4$ with $T_{\\\\mathrm{sc}}>T_{\\\\mathrm{m}}$. With the\\nNi doping, $T_{\\\\mathrm{sc}}$ decreases rapidly, and the Eu-spin ferromagnetism\\nand its $T_{\\\\mathrm{m}}$ remain unchanged. Consequently, the system\\nRbEu(Fe$_{1-x}$Ni$_x$)$_4$As$_4$ transforms into a superconducting ferromagnet\\nwith $T_{\\\\mathrm{m}}>T_{\\\\mathrm{sc}}$ for $0.07\\\\leq x\\\\leq0.08$. The occurrence\\nof superconducting ferromagnets is attributed to the decoupling between\\nEu$^{2+}$ spins and superconducting Cooper pairs. The superconducting and\\nmagnetic phase diagram is established, which additionally includes a recovered\\nyet suppressed spin-density-wave state.\\n',\n",
       " '  This paper addresses maximum likelihood (ML) estimation based model fitting\\nin the context of extrasolar planet detection. This problem is featured by the\\nfollowing properties: 1) the candidate models under consideration are highly\\nnonlinear; 2) the likelihood surface has a huge number of peaks; 3) the\\nparameter space ranges in size from a few to dozens of dimensions. These\\nproperties make the ML search a very challenging problem, as it lacks any\\nanalytical or gradient based searching solution to explore the parameter space.\\nA population based searching method, called estimation of distribution\\nalgorithm (EDA), is adopted to explore the model parameter space starting from\\na batch of random locations. EDA is featured by its ability to reveal and\\nutilize problem structures. This property is desirable for characterizing the\\ndetections. However, it is well recognized that EDAs can not scale well to\\nlarge scale problems, as it consists of iterative random sampling and model\\nfitting procedures, which results in the well-known dilemma curse of\\ndimensionality. A novel mechanism to perform EDAs in interactive random\\nsubspaces spanned by correlated variables is proposed and the hope is to\\nalleviate the curse of dimensionality for EDAs by performing the operations of\\nsampling and model fitting in lower dimensional subspaces. The effectiveness of\\nthe proposed algorithm is verified via both benchmark numerical studies and\\nreal data analysis.\\n',\n",
       " '  The recent proposed Tensor Nuclear Norm (TNN) [Lu et al., 2016; 2018a] is an\\ninteresting convex penalty induced by the tensor SVD [Kilmer and Martin, 2011].\\nIt plays a similar role as the matrix nuclear norm which is the convex\\nsurrogate of the matrix rank. Considering that the TNN based Tensor Robust PCA\\n[Lu et al., 2018a] is an elegant extension of Robust PCA with a similar tight\\nrecovery bound, it is natural to solve other low rank tensor recovery problems\\nextended from the matrix cases. However, the extensions and proofs are\\ngenerally tedious. The general atomic norm provides a unified view of\\nlow-complexity structures induced norms, e.g., the $\\\\ell_1$-norm and nuclear\\nnorm. The sharp estimates of the required number of generic measurements for\\nexact recovery based on the atomic norm are known in the literature. In this\\nwork, with a careful choice of the atomic set, we prove that TNN is a special\\natomic norm. Then by computing the Gaussian width of certain cone which is\\nnecessary for the sharp estimate, we achieve a simple bound for guaranteed low\\ntubal rank tensor recovery from Gaussian measurements. Specifically, we show\\nthat by solving a TNN minimization problem, the underlying tensor of size\\n$n_1\\\\times n_2\\\\times n_3$ with tubal rank $r$ can be exactly recovered when the\\ngiven number of Gaussian measurements is $O(r(n_1+n_2-r)n_3)$. It is order\\noptimal when comparing with the degrees of freedom $r(n_1+n_2-r)n_3$. Beyond\\nthe Gaussian mapping, we also give the recovery guarantee of tensor completion\\nbased on the uniform random mapping by TNN minimization. Numerical experiments\\nverify our theoretical results.\\n',\n",
       " '  Here, we explore some peculiar orbital features of the recently discovered\\nasteroid A/2017 U1, which is a clear outlier when considering the average value\\nof the eccentricity of known hyperbolic comets. As for the orientation of its\\norbit in space, the orbital plane of A/2017 U1 seems to be away from any\\nobvious clusters present for this population. The orbital nodes of A/2017 U1\\nare well away from the paths of the planets of the Solar System and the Sun.\\nAll these orbital properties appear to confirm A/2017 U1 as the first known\\ninterstellar asteroid.\\n',\n",
       " \"  Sensor data has been playing an important role in machine learning tasks,\\ncomplementary to the human-annotated data that is usually rather costly.\\nHowever, due to systematic or accidental mis-operations, sensor data comes very\\noften with a variety of missing values, resulting in considerable difficulties\\nin the follow-up analysis and visualization. Previous work imputes the missing\\nvalues by interpolating in the observational feature space, without consulting\\nany latent (hidden) dynamics. In contrast, our model captures the latent\\ncomplex temporal dynamics by summarizing each observation's context with a\\nnovel Iterative Imputing Network, thus significantly outperforms previous work\\non the benchmark Beijing air quality and meteorological dataset. Our model also\\nyields consistent superiority over other methods in cases of different missing\\nrates.\\n\",\n",
       " '  A linear connection is associated to a nonlinear connection on a vector\\nbundle by a linearization procedure. Our definition is intrinsic in terms of\\nvector fields on the bundle. For a connection on an affine bundle our procedure\\ncan be applied after homogenization and restriction. Several applications in\\nClassical Mechanics are provided.\\n',\n",
       " \"  We present a new stabilised and efficient high-order nodal spectral element\\nmethod based on the Mixed Eulerian Lagrangian (MEL) method for general-purpose\\nsimulation of fully nonlinear water waves and wave-body interactions. In this\\nMEL formulation a standard Laplace formulation is used to handle arbitrary body\\nshapes using unstructured - possibly hybrid - meshes consisting of high-order\\ncurvilinear iso-parametric quadrilateral/triangular elements to represent the\\nbody surfaces and for the evolving free surface. Importantly, our numerical\\nanalysis highlights that a single top layer of quadrilaterals elements resolves\\ntemporal instabilities in the numerical MEL scheme that are known to be\\nassociated with mesh topology containing asymmetric element orderings. The\\n'surface variable only' free surface formulation based on introducing a\\nparticle-following (Lagrangian) reference frame contains quartic nonlinear\\nterms that require proper treatment by numerical discretisation due to the\\npossibility of strong aliasing effects. We demonstrate how to stabilise this\\nnonlinear MEL scheme using an efficient combination of (i) global L2 projection\\nwithout quadrature errors, (ii) mild nonlinear spectral filtering and (iii)\\nre-meshing techniques. Numerical experiments revisiting known benchmarks are\\npresented, and highlights that modelling using a high-order spectral element\\nmethod provides excellent accuracy in prediction of nonlinear and dispersive\\nwave propagation, and of nonlinear wave-induced loads on fixed submerged and\\nsurface-piercing bodies.\\n\",\n",
       " '  The problem of sparse rewards is one of the hardest challenges in\\ncontemporary reinforcement learning. Hierarchical reinforcement learning (HRL)\\ntackles this problem by using a set of temporally-extended actions, or options,\\neach of which has its own subgoal. These subgoals are normally handcrafted for\\nspecific tasks. Here, though, we introduce a generic class of subgoals with\\nbroad applicability in the visual domain. Underlying our approach (in common\\nwith work using \"auxiliary tasks\") is the hypothesis that the ability to\\ncontrol aspects of the environment is an inherently useful skill to have. We\\nincorporate such subgoals in an end-to-end hierarchical reinforcement learning\\nsystem and test two variants of our algorithm on a number of games from the\\nAtari suite. We highlight the advantage of our approach in one of the hardest\\ngames -- Montezuma\\'s revenge -- for which the ability to handle sparse rewards\\nis key. Our agent learns several times faster than the current state-of-the-art\\nHRL agent in this game, reaching a similar level of performance. UPDATE\\n22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e.\\nextrinsic reward + feature control intrinsic reward, has comparable performance\\nto our agent in Montezuma Revenge. In light of the new experiments performed,\\nthe advantage of our HRL approach can be attributed more to its ability to\\nlearn useful features from intrinsic rewards rather than its ability to explore\\nand reuse abstracted skills with hierarchical components. This has led us to a\\nnew conclusion about the result.\\n',\n",
       " '  Various hypotheses exist about the paths used for communication between the\\nnodes of complex networks. Most studies simply suppose that communication goes\\nvia shortest paths, while others have more explicit assumptions about how\\nrouting (alternatively navigation or search) works or should work in real\\nnetworks. However, these assumptions are rarely checked against real data. Here\\nwe directly analyze the structure of operational paths using real measurements.\\nFor this purpose we use existing and newly created datasets having both the\\ntopology of the network and a sufficient number of empirically-determined paths\\nover it. Such datasets are processed for air transportation networks, the human\\nbrain, the Internet and the fit-fat-cat word ladder game. Our results suggest\\nthat from the great number of possible paths, nature seems to pick according to\\nsome simple rules, which we will refer to as routing policies. First we\\nconfirm, that the preference of short paths is an inevitable policy element,\\nhowever the observed stretch of the paths suggests that there are other\\npolicies at work simultaneously. We identify two additional policies common in\\nour networks: the \"conform hierarchy\", meaning that the paths should obey the\\nstructural hierarchy of the network, and the \"prefer downstream\" policy which\\npromotes avoiding the network core if possible. Building upon these simple\\npolicies, we propose a synthetic routing policy which can recover the basic\\nstatistical properties of the operational paths in networks. Our results can be\\nhelpful in estimating the reaction of complex systems for stress coming from\\nthe outside more accurately than the shortest path assumption permits.\\n',\n",
       " '  An evaluation of distributed word representation is generally conducted using\\na word similarity task and/or a word analogy task. There are many datasets\\nreadily available for these tasks in English. However, evaluating distributed\\nrepresentation in languages that do not have such resources (e.g., Japanese) is\\ndifficult. Therefore, as a first step toward evaluating distributed\\nrepresentations in Japanese, we constructed a Japanese word similarity dataset.\\nTo the best of our knowledge, our dataset is the first resource that can be\\nused to evaluate distributed representations in Japanese. Moreover, our dataset\\ncontains various parts of speech and includes rare words in addition to common\\nwords.\\n',\n",
       " \"  One single error can result in a total compromise of all security in today's\\nlarge, monolithic software. Partitioning of software can help simplify\\ncode-review and verification, whereas isolated execution of software-components\\nlimits the impact of incorrect implementations. However, existing application\\npartitioning techniques are too expensive, too imprecise, or involve unsafe\\nmanual steps. An automatic, yet safe, approach to dissect security protocols\\ninto component-based systems is not available. We present a method and toolset\\nto automatically segregate security related software into an indefinite number\\nof partitions, based on the security guarantees required by the deployed\\ncryptographic building blocks. As partitioning imposes communication overhead,\\nwe offer a range of sound performance optimizations. Furthermore, by applying\\nour approach to the secure messaging protocol OTR, we demonstrate its\\napplicability and achieve a significant reduction of the trusted computing\\nbase. Compared to a monolithic implementation, only 29% of the partitioned\\nprotocol requires confidentiality guarantees with a process overhead comparable\\nto common sandboxing techniques.\\n\",\n",
       " '  The incorporation of prior knowledge into learning is essential in achieving\\ngood performance based on small noisy samples. Such knowledge is often\\nincorporated through the availability of related data arising from domains and\\ntasks similar to the one of current interest. Ideally one would like to allow\\nboth the data for the current task and for previous related tasks to\\nself-organize the learning system in such a way that commonalities and\\ndifferences between the tasks are learned in a data-driven fashion. We develop\\na framework for learning multiple tasks simultaneously, based on sharing\\nfeatures that are common to all tasks, achieved through the use of a modular\\ndeep feedforward neural network consisting of shared branches, dealing with the\\ncommon features of all tasks, and private branches, learning the specific\\nunique aspects of each task. Once an appropriate weight sharing architecture\\nhas been established, learning takes place through standard algorithms for\\nfeedforward networks, e.g., stochastic gradient descent and its variations. The\\nmethod deals with domain adaptation and multi-task learning in a unified\\nfashion, and can easily deal with data arising from different types of sources.\\nNumerical experiments demonstrate the effectiveness of learning in domain\\nadaptation and transfer learning setups, and provide evidence for the flexible\\nand task-oriented representations arising in the network.\\n',\n",
       " '  We investigate the effect of disorder on the propagation of surface plasmon\\npolaritons in arrays of evanescently coupled dielectric loaded surface plasmon\\npolariton waveguides. Diagonal disorder is implemented by randomly varying the\\nheights of the waveguides. Real-space as well as Fourier-space images of the\\nsurface plasmon polariton intensity distribution in the waveguide arrays are\\nrecorded by leakage radiation microscopy. With these techniques we\\nexperimentally demonstrate the transverse localization of surface plasmon\\npolaritons with increasing disorder.\\n',\n",
       " '  Inspired by the combination of feedforward and iterative computations in the\\nvirtual cortex, and taking advantage of the ability of denoising autoencoders\\nto estimate the score of a joint distribution, we propose a novel approach to\\niterative inference for capturing and exploiting the complex joint distribution\\nof output variables conditioned on some input variables. This approach is\\napplied to image pixel-wise segmentation, with the estimated conditional score\\nused to perform gradient ascent towards a mode of the estimated conditional\\ndistribution. This extends previous work on score estimation by denoising\\nautoencoders to the case of a conditional distribution, with a novel use of a\\ncorrupted feedforward predictor replacing Gaussian corruption. An advantage of\\nthis approach over more classical ways to perform iterative inference for\\nstructured outputs, like conditional random fields (CRFs), is that it is not\\nany more necessary to define an explicit energy function linking the output\\nvariables. To keep computations tractable, such energy function\\nparametrizations are typically fairly constrained, involving only a few\\nneighbors of each of the output variables in each clique. We experimentally\\nfind that the proposed iterative inference from conditional score estimation by\\nconditional denoising autoencoders performs better than comparable models based\\non CRFs or those not using any explicit modeling of the conditional joint\\ndistribution of outputs.\\n',\n",
       " \"  Let $X_1,\\\\ldots,X_n$ be a standard normal sample in $\\\\mathbb R^d$. We compute\\nexactly the expected volume of the Gaussian polytope\\n$\\\\mathrm{conv}[X_1,\\\\ldots,X_n]$, the symmetric Gaussian polytope\\n$\\\\mathrm{conv}[\\\\pm X_1,\\\\ldots,\\\\pm X_n]$, and the Gaussian zonotope\\n$[0,X_1]+\\\\ldots+[0,X_n]$ by exploiting their connection to the regular simplex,\\nthe regular crosspolytope, and the cube with the aid of Tsirelson's formula.\\nThe expected volumes of these random polytopes are given by essentially the\\nsame expressions as the intrinsic volumes and external angles of the regular\\npolytopes. For all these quantities, we obtain asymptotic formulae which are\\nmore precise than the results which were known before. More generally, we\\ndetermine the expected volumes of some heteroscedastic random polytopes\\nincluding $ \\\\mathrm{conv}[l_1X_1,\\\\ldots,l_nX_n] $ and $ \\\\mathrm{conv}[\\\\pm l_1\\nX_1,\\\\ldots, \\\\pm l_n X_n], $ where $l_1,\\\\ldots,l_n\\\\geq 0$ are parameters, and\\nthe intrinsic volumes of the corresponding deterministic polytopes. Finally, we\\nrelate the $k$-th intrinsic volume of the regular simplex $S^{n-1}$ to the\\nexpected maximum of independent standard Gaussian random variables\\n$\\\\xi_1,\\\\ldots,\\\\xi_n$ given that the maximum has multiplicity $k$. Namely, we\\nshow that $$ V_k(S^{n-1}) = \\\\frac {(2\\\\pi)^{\\\\frac k2}} {k!} \\\\cdot\\n\\\\lim_{\\\\varepsilon\\\\downarrow 0} \\\\varepsilon^{1-k} \\\\mathbb E\\n[\\\\max\\\\{\\\\xi_1,\\\\ldots,\\\\xi_n\\\\} 1_{\\\\{\\\\xi_{(n)} - \\\\xi_{(n-k+1)}\\\\leq \\\\varepsilon\\\\}}],\\n$$ where $\\\\xi_{(1)} \\\\leq \\\\ldots \\\\leq \\\\xi_{(n)}$ denote the order statistics. A\\nsimilar result holds for the crosspolytope if we replace $\\\\xi_1,\\\\ldots,\\\\xi_n$\\nby their absolute values.\\n\",\n",
       " '  We investigate $n$-component systems of conservation laws that possess\\nthird-order Hamiltonian structures of differential-geometric type. The\\nclassification of such systems is reduced to the projective classification of\\nlinear congruences of lines in $\\\\mathbb{P}^{n+2}$ satisfying additional\\ngeometric constraints. Algebraically, the problem can be reformulated as\\nfollows: for a vector space $W$ of dimension $n+2$, classify $n$-tuples of\\nskew-symmetric 2-forms $A^{\\\\alpha} \\\\in \\\\Lambda^2(W)$ such that \\\\[ \\\\phi_{\\\\beta\\n\\\\gamma}A^{\\\\beta}\\\\wedge A^{\\\\gamma}=0, \\\\] for some non-degenerate symmetric\\n$\\\\phi$.\\n',\n",
       " '  We analyze holomorphic Jacobi forms of weight one with level. One such form\\nplays an important role in umbral moonshine, leading to simplifications of the\\nstatements of the umbral moonshine conjectures. We prove that non-zero\\nholomorphic Jacobi forms of weight one do not exist for many combinations of\\nindex and level, and use this to establish a characterization of the\\nMcKay--Thompson series of umbral moonshine in terms of Rademacher sums.\\n',\n",
       " '  The Weyl semimetal is a new quantum state of topological semimetal, of which\\ntopological surface states -- the Fermi arcs exist. In this paper, the Fermi\\narcs in Weyl semimetals are classified into two classes -- class-1 and class-2.\\nBased on a tight-binding model, the evolution and transport properties of\\nclass-1/2 Fermi arcs are studied via the tilting strength of the bulk Weyl\\ncones. The (residual) anomalous Hall conductivity of topological surface states\\nis a physical consequence of class-1 Fermi arc and thus class-1 Fermi arc\\nbecomes a nontrivial topological property for hybrid or type-II Weyl semimetal.\\nTherefore, this work provides an intuitive method to learn topological\\nproperties of Weyl semimetal.\\n',\n",
       " '  Consider the graph induced by $\\\\mathbb{Z}^d$, equipped with uniformly\\nelliptic random conductances. At time $0$, place a Poisson point process of\\nparticles on $\\\\mathbb{Z}^d$ and let them perform independent simple random\\nwalks. Tessellate the graph into cubes indexed by $i\\\\in\\\\mathbb{Z}^d$ and\\ntessellate time into intervals indexed by $\\\\tau$. Given a local event\\n$E(i,\\\\tau)$ that depends only on the particles inside the space time region\\ngiven by the cube $i$ and the time interval $\\\\tau$, we prove the existence of a\\nLipschitz connected surface of cells $(i,\\\\tau)$ that separates the origin from\\ninfinity on which $E(i,\\\\tau)$ holds. This gives a directly applicable and\\nrobust framework for proving results in this setting that need a multi-scale\\nargument. For example, this allows us to prove that an infection spreads with\\npositive speed among the particles.\\n',\n",
       " \"  The Wide-Field InfraRed Space Telescope (WFIRST) will be capable of\\ndelivering precise astrometry for faint sources over the enormous field of view\\nof its main camera, the Wide-Field Imager (WFI). This unprecedented combination\\nwill be transformative for the many scientific questions that require precise\\npositions, distances, and velocities of stars. We describe the expectations for\\nthe astrometric precision of the WFIRST WFI in different scenarios, illustrate\\nhow a broad range of science cases will see significant advances with such\\ndata, and identify aspects of WFIRST's design where small adjustments could\\ngreatly improve its power as an astrometric instrument.\\n\",\n",
       " '  A grand challenge of the 21st century cosmology is to accurately estimate the\\ncosmological parameters of our Universe. A major approach to estimating the\\ncosmological parameters is to use the large-scale matter distribution of the\\nUniverse. Galaxy surveys provide the means to map out cosmic large-scale\\nstructure in three dimensions. Information about galaxy locations is typically\\nsummarized in a \"single\" function of scale, such as the galaxy correlation\\nfunction or power-spectrum. We show that it is possible to estimate these\\ncosmological parameters directly from the distribution of matter. This paper\\npresents the application of deep 3D convolutional networks to volumetric\\nrepresentation of dark-matter simulations as well as the results obtained using\\na recently proposed distribution regression framework, showing that machine\\nlearning techniques are comparable to, and can sometimes outperform,\\nmaximum-likelihood point estimates using \"cosmological models\". This opens the\\nway to estimating the parameters of our Universe with higher accuracy.\\n',\n",
       " '  In contrast with goal-oriented dialogue, social dialogue has no clear measure\\nof task success. Consequently, evaluation of these systems is notoriously hard.\\nIn this paper, we review current evaluation methods, focusing on automatic\\nmetrics. We conclude that turn-based metrics often ignore the context and do\\nnot account for the fact that several replies are valid, while end-of-dialogue\\nrewards are mainly hand-crafted. Both lack grounding in human perceptions.\\n',\n",
       " \"  We propose a novel adaptive test of goodness-of-fit, with computational cost\\nlinear in the number of samples. We learn the test features that best indicate\\nthe differences between observed samples and a reference model, by minimizing\\nthe false negative rate. These features are constructed via Stein's method,\\nmeaning that it is not necessary to compute the normalising constant of the\\nmodel. We analyse the asymptotic Bahadur efficiency of the new test, and prove\\nthat under a mean-shift alternative, our test always has greater relative\\nefficiency than a previous linear-time kernel test, regardless of the choice of\\nparameters for that test. In experiments, the performance of our method exceeds\\nthat of the earlier linear-time test, and matches or exceeds the power of a\\nquadratic-time kernel test. In high dimensions and where model structure may be\\nexploited, our goodness of fit test performs far better than a quadratic-time\\ntwo-sample test based on the Maximum Mean Discrepancy, with samples drawn from\\nthe model.\\n\",\n",
       " '  Transient responses in disordered systems typically show a heavy-tail\\nrelaxation behavior: the decay time constant increases as time increases,\\nrevealing a spectral distribution of time constants. The asymptotic value of\\nsuch transients is notoriously difficult to experimentally measure due to the\\nincreasing decay time-scale. However, if the heavy-tail transient is plotted\\nversus log-time, a reduced set of data around the inflection point of such a\\nplot is sufficient for an accurate fit. From a derivative plot in log-time, the\\npeak height, position, line width, and, most importantly, skewness are all that\\nis needed to accurately predict the asymptotic value of various heavy-tail\\ndecay models to within less than a percent. This curve fitting strategy reduces\\nby orders of magnitude the amount of experimental data required, and clearly\\nidentifies a threshold below which the amount of data is insufficient to\\ndistinguish various models. The skew normal spectral fit and dispersive\\ndiffusion transient fit are proposed as four-parameter fits, with the latter\\nincluding the stretched exponential as a limiting case. The line fit and\\nasymptotic prediction are demonstrated using experimental transient responses\\nin previously published amorphous silicon and amorphous InGaZnO data.\\n',\n",
       " '  We numerically investigate dynamical property in the one-dimensional\\ntight-binding model with long-range correlated disorder having power spectrum\\n$1/f^\\\\alpha$ ($\\\\alpha:$spectrum exponent) generated by Fourier filtering\\nmethod. For relatively small $\\\\alpha<\\\\alpha_c(=2)$ time-dependence of mean\\nsquare displacement (MSD) of the initially localized wavepacket shows ballistic\\nspread and localizes as time elapses. It is shown that $\\\\alpha-$dependence of\\nthe dynamical localization length (DLL) determined by the MSD exhibits a simple\\nscaling law in the localization regime for the relatively weak disorder\\nstrength $W$. Furthermore, scaled MSD by the DLL almost obeys an universal\\nfunction from the ballistic to the localization regime in the various\\ncombinations of the parameters $\\\\alpha$ and $W$.\\n',\n",
       " '  The higher-order topological insulator (HOTI) protected by spacial symmetry\\nhas been studied in-depth on models with square lattice. Our work, based on an\\nalternative model on the breathing Kagome lattice, revealed that the different\\ntypes of corners in the lattice could actually be conditionally gapless, or\\nalways gapped. Using the Wilson loop formalism, we argue that these corner\\nstates occur when the eigenvalues of the Wannier Hamiltonian cross through a\\ncertain reference point during the conceptual \"pumping\" procedure. The results\\ndemonstrate the corner of the Kagome lattice based HOTI is a zero-dimensional\\nanalogue of the 1D chiral edge states on the boundary of a Chern insulator, but\\nwith a sensitive dependence on the shape of the corner. Our method of the\\npumping cylinder, which reveals the symmetry/gapless-ability correspondence,\\ncan be generalized into a general scheme in determining the classification of\\ncorner(hinge) states in HOTI.\\n',\n",
       " '  We give a complete characterization of invariant subspaces for $(M_{z_1},\\n\\\\ldots, M_{z_n})$ on the Hardy space $H^2(\\\\mathbb{D}^n)$ over the unit polydisc\\n$\\\\mathbb{D}^n$ in $\\\\mathbb{C}^n$, $n >1$. In particular, this yields a complete\\nset of unitary invariants for invariant subspaces for $(M_{z_1}, \\\\ldots,\\nM_{z_n})$ on $H^2(\\\\mathbb{D}^n)$, $n > 1$. As a consequence, we classify a\\nlarge class of $n$-tuples, $n > 1$, of commuting isometries. All of our results\\nhold for vector-valued Hardy spaces over $\\\\mathbb{D}^n$, $n > 1$. Our invariant\\nsubspace theorem solves the well-known open problem on characterizations of\\ninvariant subspaces of the Hardy space over the unit polydisc.\\n',\n",
       " '  In this note we present an explicit realization of the affine vertex algebra\\n$V^{cri}(\\\\frak{gl}(1 \\\\vert 1)) $ inside of the tensor product $F\\\\otimes M$\\nwhere $F$ is a fermionic verex algebra and $M$ is a commutative vertex algebra.\\nThis immediately gives an alternative description of the center of\\n$V^{cri}(\\\\frak{gl}(1 \\\\vert 1) ) )$ as a subalgebra $M _ 0$ of $M$. We\\nreconstruct the Molev-Mukhin formula for the Hilbert-Poincare series of the\\ncenter of $V^ {cri}(\\\\frak{gl}(1 \\\\vert 1) )$. Moreover, we construct a family of\\nirreducible $V^{cri}(\\\\frak{gl}(1 \\\\vert 1))$ -modules realized on $F$ and\\nparameterized by $\\\\chi^+, \\\\chi ^- \\\\in {\\\\Bbb C}((z)). $ We propose a\\ngeneralization of $V^ {cri}(\\\\frak{gl}(1 \\\\vert 1))$ as a critical level version\\nof the super $\\\\mathcal W_{1+\\\\infty}$ vertex algebra.\\n',\n",
       " '  Lifelong learning aims to develop machine learning systems that can learn new\\ntasks while preserving the performance on previous learned tasks. In this paper\\nwe present a method to overcome catastrophic forgetting on convolutional neural\\nnetworks, that learns new tasks and preserves the performance on old tasks\\nwithout accessing the data of the original model, by selective network\\naugmentation. The experiment results showed that SeNA-CNN, in some scenarios,\\noutperforms the state-of-art Learning without Forgetting algorithm. Results\\nalso showed that in some situations it is better to use SeNA-CNN instead of\\ntraining a neural network using isolated learning.\\n',\n",
       " '  In this paper, we investigate the sample size requirement for exact recovery\\nof a high order tensor of low rank from a subset of its entries. We show that a\\ngradient descent algorithm with initial value obtained from a spectral method\\ncan, in particular, reconstruct a ${d\\\\times d\\\\times d}$ tensor of multilinear\\nranks $(r,r,r)$ with high probability from as few as\\n$O(r^{7/2}d^{3/2}\\\\log^{7/2}d+r^7d\\\\log^6d)$ entries. In the case when the ranks\\n$r=O(1)$, our sample size requirement matches those for nuclear norm\\nminimization (Yuan and Zhang, 2016a), or alternating least squares assuming\\northogonal decomposability (Jain and Oh, 2014). Unlike these earlier\\napproaches, however, our method is efficient to compute, easy to implement, and\\ndoes not impose extra structures on the tensor. Numerical results are presented\\nto further demonstrate the merits of the proposed approach.\\n',\n",
       " '  The two-dimensional character and reduced screening in monolayer\\ntransition-metal dichalcogenides (TMDs) lead to the ubiquitous formation of\\nrobust excitons with binding energies orders of magnitude larger than in bulk\\nsemiconductors. Focusing on neutral excitons, bound electron-hole pairs, that\\ndominate the optical response in TMDs, it is shown that they can provide\\nfingerprints for magnetic proximity effects in magnetic heterostructures. These\\nproximity effects cannot be described by the widely used single-particle\\ndescription, but instead reveal the possibility of a conversion between\\noptically inactive and active excitons by rotating the magnetization of the\\nmagnetic substrate. With recent breakthroughs in fabricating Mo- and W-based\\nmagnetic TMD-heterostructures, this emergent optical response can be directly\\ntested experimentally.\\n',\n",
       " '  Rubenstein et al. present an interesting system of programmable\\nself-assembled structure formation using 1000 Kilobot robots. The paper claims\\nto advance work in artificial swarms similar to capabilities of natural systems\\nbesides being highly robust. However, the system lacks in terms of matching\\nmotility and complex shapes with holes, thereby limiting practical similarity\\nto self-assembly in living systems.\\n',\n",
       " '  In this note, given a regular Courant algebroid, we compute its group of\\nautomorphisms relative to a dissection. We also propose an infinitesimal\\nversion and recover examples of the literature.\\n',\n",
       " '  Categorical random variables are a common staple in machine learning methods\\nand other applications across disciplines. Many times, correlation within\\ncategorical predictors exists, and has been noted to have an effect on various\\nalgorithm effectiveness, such as feature ranking and random forests. We present\\na mathematical construction of a sequence of identically distributed but\\ndependent categorical random variables, and give a generalized multinomial\\ndistribution to model the probability of counts of such variables.\\n',\n",
       " '  The Subarcsecond Telescope And BaLloon Experiment, STABLE, is the fine stage\\nof a guidance system for a high-altitude ballooning platform designed to\\ndemonstrate subarcsecond pointing stability, over one minute using relatively\\ndim guide stars in the visible spectrum. The STABLE system uses an attitude\\nrate sensor and the motion of the guide star on a detector to control a Fast\\nSteering Mirror in order to stabilize the image. The characteristics of the\\nthermal-optical-mechanical elements in the system directly affect the quality\\nof the point spread function of the guide star on the detector, and so, a\\nseries of thermal, structural, and optical models were built to simulate system\\nperformance and ultimately inform the final pointing stability predictions.\\nThis paper describes the modeling techniques employed in each of these\\nsubsystems. The results from those models are discussed in detail, highlighting\\nthe development of the worst-case cold and hot cases, the optical metrics\\ngenerated from the finite element model, and the expected STABLE residual\\nwavefront error and decenter. Finally, the paper concludes with the predicted\\nsensitivities in the STABLE system, which show that thermal deadbanding,\\nstructural preloading and self-deflection under different loading conditions,\\nand the speed of individual optical elements were particularly important to the\\nresulting STABLE optical performance.\\n',\n",
       " '  A closure endomorphism of a Hilbert algebra A is a mapping that is\\nsimultaneously an endomorphism of and a closure operator on A. It is known that\\nthe set CE of all closure endomorphisms of A is a distributive lattice where\\nthe meet of two elements is defined pointwise and their join is given by their\\ncomposition. This lattice is shown in the paper to be isomorphic to the lattice\\nof certain filters of A, anti-isomorphic to the lattice of certain closure\\nretracts of A, and compactly generated. The set of compact elements of CE\\ncoincides with the adjoint semilattice of A, conditions under which two Hilbert\\nalgebras have isomorphic adjoint semilattices (equivalently, minimal Brouwerian\\nextensions) are discussed. Several consequences are drawn also for implication\\nalgebras.\\n',\n",
       " '  We present an attention based visual analysis framework to compute\\ngrasp-relevant information in order to guide grasp planning using a\\nmulti-fingered robotic hand. Our approach uses a computational visual attention\\nmodel to locate regions of interest in a scene, and uses a deep convolutional\\nneural network to detect grasp type and point for a sub-region of the object\\npresented in a region of interest. We demonstrate the proposed framework in\\nobject grasping tasks, in which the information generated from the proposed\\nframework is used as prior information to guide the grasp planning. Results\\nshow that the proposed framework can not only speed up grasp planning with more\\nstable configurations, but also is able to handle unknown objects. Furthermore,\\nour framework can handle cluttered scenarios. A new Grasp Type Dataset (GTD)\\nthat considers 6 commonly used grasp types and covers 12 household objects is\\nalso presented.\\n',\n",
       " '  As machine learning algorithms are increasingly applied to high impact yet\\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\\ncritical that researchers can explain how such algorithms arrived at their\\npredictions. In recent years, a number of image saliency methods have been\\ndeveloped to summarize where highly complex neural networks \"look\" in an image\\nfor evidence for their predictions. However, these techniques are limited by\\ntheir heuristic nature and architectural constraints. In this paper, we make\\ntwo main contributions: First, we propose a general framework for learning\\ndifferent kinds of explanations for any black box algorithm. Second, we\\nspecialise the framework to find the part of an image most responsible for a\\nclassifier decision. Unlike previous works, our method is model-agnostic and\\ntestable because it is grounded in explicit and interpretable image\\nperturbations.\\n',\n",
       " '  The ability to compare two degenerate probability distributions (i.e. two\\nprobability distributions supported on two distinct low-dimensional manifolds\\nliving in a much higher-dimensional space) is a crucial problem arising in the\\nestimation of generative models for high-dimensional observations such as those\\narising in computer vision or natural language. It is known that optimal\\ntransport metrics can represent a cure for this problem, since they were\\nspecifically designed as an alternative to information divergences to handle\\nsuch problematic scenarios. Unfortunately, training generative machines using\\nOT raises formidable computational and statistical challenges, because of (i)\\nthe computational burden of evaluating OT losses, (ii) the instability and lack\\nof smoothness of these losses, (iii) the difficulty to estimate robustly these\\nlosses and their gradients in high dimension. This paper presents the first\\ntractable computational method to train large scale generative models using an\\noptimal transport loss, and tackles these three issues by relying on two key\\nideas: (a) entropic smoothing, which turns the original OT loss into one that\\ncan be computed using Sinkhorn fixed point iterations; (b) algorithmic\\n(automatic) differentiation of these iterations. These two approximations\\nresult in a robust and differentiable approximation of the OT loss with\\nstreamlined GPU execution. Entropic smoothing generates a family of losses\\ninterpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus\\nallowing to find a sweet spot leveraging the geometry of OT and the favorable\\nhigh-dimensional sample complexity of MMD which comes with unbiased gradient\\nestimates. The resulting computational architecture complements nicely standard\\ndeep network generative models by a stack of extra layers implementing the loss\\nfunction.\\n',\n",
       " '  The GAPS experiment is designed to carry out a sensitive dark matter search\\nby measuring low-energy cosmic ray antideuterons and antiprotons. GAPS will\\nprovide a new avenue to access a wide range of dark matter models and masses\\nthat is complementary to direct detection techniques, collider experiments and\\nother indirect detection techniques. Well-motivated theories beyond the\\nStandard Model contain viable dark matter candidates which could lead to a\\ndetectable signal of antideuterons resulting from the annihilation or decay of\\ndark matter particles. The dark matter contribution to the antideuteron flux is\\nbelieved to be especially large at low energies (E < 1 GeV), where the\\npredicted flux from conventional astrophysical sources (i.e. from secondary\\ninteractions of cosmic rays) is very low. The GAPS low-energy antiproton search\\nwill provide stringent constraints on less than 10 GeV dark matter, will\\nprovide the best limits on primordial black hole evaporation on Galactic length\\nscales, and will explore new discovery space in cosmic ray physics.\\nUnlike other antimatter search experiments such as BESS and AMS that use\\nmagnetic spectrometers, GAPS detects antideuterons and antiprotons using an\\nexotic atom technique. This technique, and its unique event topology, will give\\nGAPS a nearly background-free detection capability that is critical in a\\nrare-event search. GAPS is designed to carry out its science program using\\nlong-duration balloon flights in Antarctica. A prototype instrument was\\nsuccessfully flown from Taiki, Japan in 2012. GAPS has now been approved by\\nNASA to proceed towards the full science instrument, with the possibility of a\\nfirst long-duration balloon flight in late 2020. Here we motivate low-energy\\ncosmic ray antimatter searches and discuss the current status of the GAPS\\nexperiment and the design of the payload.\\n',\n",
       " \"  The support vector machine (SVM) is a widely used machine learning tool for\\nclassification based on statistical learning theory. Given a set of training\\ndata, the SVM finds a hyperplane that separates two different classes of data\\npoints by the largest distance. While the standard form of SVM uses L2-norm\\nregularization, other regularization approaches are particularly attractive for\\nbiomedical datasets where, for example, sparsity and interpretability of the\\nclassifier's coefficient values are highly desired features. Therefore, in this\\npaper we consider different types of regularization approaches for SVMs, and\\nexplore them in both synthetic and real biomedical datasets.\\n\",\n",
       " '  Potassium (K) intercalated manganese phthalocyanine (MnPc) reveals vast\\nchanges of its electronic states close to the Fermi level. However, theoretical\\nstudies are controversial regarding the electronic configuration. Here, MnPc\\ndoped with K was studied by ultraviolet, X-ray, and inverse photoemission, as\\nwell as near edge X-ray absorption fine structure spectroscopy. Upon K\\nintercalation the Fermi level shifts toward the lowest unoccupied molecular\\norbital filling it up with donated electrons with the appearance of an\\nadditional feature in the energy region of the occupied states. The electronic\\nbands are pinned 0.5 eV above and 0.4 eV below the Fermi level. The branching\\nratio of the Mn L3 and L2 edges indicate an increase of the spin state.\\nMoreover, the evolution of the Mn L and N K edges reveals strong hybridization\\nbetween Mn 3d and N 2p states of MnPc and sheds light on the electron\\noccupation in the ground and n-doped configurations.\\n',\n",
       " '  The Intelligent vehicle (IV) is experiencing revolutionary growth in research\\nand industry, but it still suffers from many security vulnerabilities.\\nTraditional security methods are incapable to provide secure IV communication.\\nThe major issues in IV communication, are trust, data accuracy and reliability\\nof communication data in the communication channel. Blockchain technology works\\nfor the crypto currency, Bit-coin, which is recently used to build trust and\\nreliability in peer-to-peer networks having similar topologies as IV\\nCommunication. In this paper, we are proposing, Intelligent Vehicle-Trust Point\\n(IV-TP) mechanism for IV communication among IVs using Blockchain technology.\\nThe IVs communicated data provides security and reliability using our proposed\\nIV-TP. Our IV-TP mechanism provides trustworthiness for vehicles behavior, and\\nvehicles legal and illegal action. Our proposal presents a reward based system,\\nan exchange of some IV-TP among IVs, during successful communication. For the\\ndata management of the IV-TP, we are using blockchain technology in the\\nintelligent transportation system (ITS), which stores all IV-TP details of\\nevery vehicle and is accessed ubiquitously by IVs. In this paper, we evaluate\\nour proposal with the help of intersection use case scenario for intelligent\\nvehicles communication.\\n',\n",
       " '  Significant research contributions and Directives approach the issue of the\\ninsertion of renewable-based energy systems on urban territory in order to face\\nwith the growing energy needs of citizens. The introduction of such systems\\ngives raise to installers to both satisfy their energy demands and distribute\\neventual energy excesses to close neighbours. This paper presents a multi-layer\\nagent-based computational model that simulates multiple event of the network of\\nthe energy distribution occurring within urban areas. The model runs on the\\nNetLogo platform and aims at elaborating the most suitable strategy when\\ndealing with the design of a network of energy distribution. Experimental data\\nare discussed on the basis of two main scenarios within an operating period of\\n24 hours. Scenarios consider both the variation of the percentages of\\ninstallers of renewable-based energy systems and the distance along which\\nenergy exchanges occur.\\n',\n",
       " '  We obtain matching direct and inverse theorems for the degree of weighted\\n$L_p$-approximation by polynomials with the Jacobi weights $(1-x)^\\\\alpha\\n(1+x)^\\\\beta$. Combined, the estimates yield a constructive characterization of\\nvarious smoothness classes of functions via the degree of their approximation\\nby algebraic polynomials.\\n',\n",
       " '  Matrix decomposition is a popular and fundamental approach in machine\\nlearning and data mining. It has been successfully applied into various fields.\\nMost matrix decomposition methods focus on decomposing a data matrix from one\\nsingle source. However, it is common that data are from different sources with\\nheterogeneous noise. A few of matrix decomposition methods have been extended\\nfor such multi-view data integration and pattern discovery. While only few\\nmethods were designed to consider the heterogeneity of noise in such multi-view\\ndata for data integration explicitly. To this end, we propose a joint matrix\\ndecomposition framework (BJMD), which models the heterogeneity of noise by\\nGaussian distribution in a Bayesian framework. We develop two algorithms to\\nsolve this model: one is a variational Bayesian inference algorithm, which\\nmakes full use of the posterior distribution; and another is a maximum a\\nposterior algorithm, which is more scalable and can be easily paralleled.\\nExtensive experiments on synthetic and real-world datasets demonstrate that\\nBJMD considering the heterogeneity of noise is superior or competitive to the\\nstate-of-the-art methods.\\n',\n",
       " '  There are no two identical leaves in the world, so how to find effective\\nmarkers or features to distinguish them is an important issue. Function\\ntransformation, such as f(x,y) and f(x,y,z), can transform two, three, or\\nmultiple input/observation variables (in biology, it generally refers to the\\nobserved/measured value of biomarkers, biological characteristics, or other\\nindicators) into a new output variable (new characteristics or indicators).\\nThis provided us a chance to re-cognize objective things or relationships\\nbeyond the original measurements. For example, Body Mass Index, which transform\\nweight and high into a new indicator BMI=x/y^2 (where x is weight and y is\\nhigh), is commonly used in to gauge obesity. Here, we proposed a new system,\\nFunomics (Function Transformation Omics), for understanding the world in a\\ndifferent perspective. Funome can be understood as a set of math functions\\nconsist of basic elementary functions (such as power functions and exponential\\nfunctions) and basic mathematical operations (such as addition, subtraction).\\nBy scanning the whole Funome, researchers can identify some special functions\\n(called handsome functions) which can generate the novel important output\\nvariable (characteristics or indicators). We also start \"the Funome project\" to\\ndevelop novel methods, function library and analysis software for Funome\\nstudies. The Funome project will accelerate the discovery of new useful\\nindicators or characteristics, will improve the utilization efficiency of\\ndirectly measured data, and will enhance our ability to understand the world.\\nThe analysis tools and data resources about the Funome project can be found\\ngradually at this http URL.\\n',\n",
       " '  Videos for outdoor scene often show unpleasant blur effects due to the large\\nrelative motion between the camera and the dynamic objects and large depth\\nvariations. Existing works typically focus monocular video deblurring. In this\\npaper, we propose a novel approach to deblurring from stereo videos. In\\nparticular, we exploit the piece-wise planar assumption about the scene and\\nleverage the scene flow information to deblur the image. Unlike the existing\\napproach [31] which used a pre-computed scene flow, we propose a single\\nframework to jointly estimate the scene flow and deblur the image, where the\\nmotion cues from scene flow estimation and blur information could reinforce\\neach other, and produce superior results than the conventional scene flow\\nestimation or stereo deblurring methods. We evaluate our method extensively on\\ntwo available datasets and achieve significant improvement in flow estimation\\nand removing the blur effect over the state-of-the-art methods.\\n',\n",
       " '  The polycrystalline Sm2MgMnO6 (SMMO) was synthesized at 1173K by means of\\nsol-gel technique. Rietveld refine-ment of X-ray diffraction (XRD) pattern\\nconfirmed the formation of a single phase monoclinic structure with space group\\nP21/n. The band gap achieved from UV-vis spectra shows the semiconducting\\nnature of the material. To observe the effect of grains and grain-boundaries in\\nthe conduction process and dielectric relaxation measurements are carried out\\non SMMO sample at different frequencies between 313 K and 673 K. An electrical\\nequivalent circuit consisting of the resistance and constant phase element is\\nused to clarify the impedance data.\\n',\n",
       " \"  The multiplicity of a weight $\\\\mu$ in an irreducible representation of a\\nsimple Lie algebra $\\\\mathfrak{g}$ with highest weight $\\\\lambda$ can be computed\\nvia the use of Kostant's weight multiplicity formula. This formula is an\\nalternating sum over the Weyl group and involves the computation of a partition\\nfunction. In this paper we consider a $q$-analog of Kostant's weight\\nmultiplicity and present a SageMath program to compute $q$-multiplicities for\\nthe simple Lie algebras.\\n\",\n",
       " '  We investigate the dynamics of the localized nonlinear matter wave in spin-1\\nBose-Einstein condensates with trapping potentials and nonlinearities dependent\\non time and space. We solve the three coupled Gross-Pitaevskii equation by\\nsimilarity transformation and obtain two families of exact matter wave\\nsolutions in terms of Jacobi elliptic functions and Mathieu equation. The\\nlocalized states of the spinor matter wave describe the dynamics of vector\\nbreathing solitons, moving breathing solitons, quasibreathing solitons and\\nresonant solitons. The results of stability show that one order vector\\nbreathing solitons, quasibreathing solitons, resonant solitons, and the moving\\nbreathing solitons \\\\psi_{\\\\pm1} are all stable but the moving breathing solitons\\n\\\\psi_0 is unstable. We also present the experimental parameters to realize\\nthese phenomena in the future experiments.\\n',\n",
       " '  The tremendous growth of positioning technologies and GPS enabled devices has\\nproduced huge volumes of tracking data during the recent years. This source of\\ninformation constitutes a rich input for data analytics processes, either\\noffline (e.g. cluster analysis, hot motion discovery) or online (e.g.\\nshort-term forecasting of forthcoming positions). This paper focuses on\\npredictive analytics for moving objects (could be pedestrians, cars, vessels,\\nplanes, animals, etc.) and surveys the state-of-the-art in the context of\\nfuture location and trajectory prediction. We provide an extensive review of\\nover 50 works, also proposing a novel taxonomy of predictive algorithms over\\nmoving objects. We also list the properties of several real datasets used in\\nthe past for validation purposes of those works and, motivated by this, we\\ndiscuss challenges that arise in the transition from conventional to Big Data\\napplications.\\nCCS Concepts: Information systems > Spatial-temporal systems; Information\\nsystems > Data analytics; Information systems > Data mining; Computing\\nmethodologies > Machine learning Additional Key Words and Phrases: mobility\\ndata, moving object trajectories, trajectory prediction, future location\\nprediction.\\n',\n",
       " '  Many neuroimaging studies focus on the cortex, in order to benefit from\\nbetter signal to noise ratios and reduced computational burden. Cortical data\\nare usually projected onto a reference mesh, where subsequent analyses are\\ncarried out. Several multiscale approaches have been proposed for analyzing\\nthese surface data, such as spherical harmonics and graph wavelets. As far as\\nwe know, however, the hierarchical structure of the template icosahedral meshes\\nused by most neuroimaging software has never been exploited for cortical data\\nfactorization. In this paper, we demonstrate how the structure of the\\nubiquitous icosahedral meshes can be exploited by data factorization methods\\nsuch as sparse dictionary learning, and we assess the optimization speed-up\\noffered by extrapolation methods in this context. By testing different\\nsparsity-inducing norms, extrapolation methods, and factorization schemes, we\\ncompare the performances of eleven methods for analyzing four datasets: two\\nstructural and two functional MRI datasets obtained by processing the data\\npublicly available for the hundred unrelated subjects of the Human Connectome\\nProject. Our results demonstrate that, depending on the level of details\\nrequested, a speedup of several orders of magnitudes can be obtained.\\n',\n",
       " '  Voice conversion (VC) using sequence-to-sequence learning of context\\nposterior probabilities is proposed. Conventional VC using shared context\\nposterior probabilities predicts target speech parameters from the context\\nposterior probabilities estimated from the source speech parameters. Although\\nconventional VC can be built from non-parallel data, it is difficult to convert\\nspeaker individuality such as phonetic property and speaking rate contained in\\nthe posterior probabilities because the source posterior probabilities are\\ndirectly used for predicting target speech parameters. In this work, we assume\\nthat the training data partly include parallel speech data and propose\\nsequence-to-sequence learning between the source and target posterior\\nprobabilities. The conversion models perform non-linear and variable-length\\ntransformation from the source probability sequence to the target one. Further,\\nwe propose a joint training algorithm for the modules. In contrast to\\nconventional VC, which separately trains the speech recognition that estimates\\nposterior probabilities and the speech synthesis that predicts target speech\\nparameters, our proposed method jointly trains these modules along with the\\nproposed probability conversion modules. Experimental results demonstrate that\\nour approach outperforms the conventional VC.\\n',\n",
       " \"  We prove a downward separation for $\\\\mathsf{\\\\Sigma}_2$-time classes.\\nSpecifically, we prove that if $\\\\Sigma_2$E does not have polynomial size\\nnon-deterministic circuits, then $\\\\Sigma_2$SubEXP does not have \\\\textit{fixed}\\npolynomial size non-deterministic circuits. To achieve this result, we use\\nSanthanam's technique on augmented Arthur-Merlin protocols defined by\\nAydinlioğlu and van Melkebeek. We show that augmented Arthur-Merlin\\nprotocols with one bit of advice do not have fixed polynomial size\\nnon-deterministic circuits. We also prove a weak unconditional derandomization\\nof a certain type of promise Arthur-Merlin protocols. Using Williams' easy\\nhitting set technique, we show that $\\\\Sigma_2$-promise AM problems can be\\ndecided in $\\\\Sigma_2$SubEXP with $n^c$ advice, for some fixed constant $c$.\\n\",\n",
       " '  We introduce a new type of categorical object called a \\\\emph{hom-tensor\\ncategory} and show that it provides the appropriate setting for modules over an\\narbitrary hom-bialgebra. Next we introduce the notion of \\\\emph{hom-braided\\ncategory} and show that this is the right setting for modules over\\nquasitriangular hom-bialgebras. We also show how the hom-Yang-Baxter equation\\nfits into this framework and how the category of Yetter-Drinfeld modules over a\\nhom-bialgebra with bijective structure map can be organized as a hom-braided\\ncategory. Finally we prove that, under certain conditions, one can obtain a\\ntensor category (respectively a braided tensor category) from a hom-tensor\\ncategory (respectively a hom-braided category).\\n',\n",
       " '  Our goal is to design architectures that retain the groundbreaking\\nperformance of CNNs for landmark localization and at the same time are\\nlightweight, compact and suitable for applications with limited computational\\nresources. To this end, we make the following contributions: (a) we are the\\nfirst to study the effect of neural network binarization on localization tasks,\\nnamely human pose estimation and face alignment. We exhaustively evaluate\\nvarious design choices, identify performance bottlenecks, and more importantly\\npropose multiple orthogonal ways to boost performance. (b) Based on our\\nanalysis, we propose a novel hierarchical, parallel and multi-scale residual\\narchitecture that yields large performance improvement over the standard\\nbottleneck block while having the same number of parameters, thus bridging the\\ngap between the original network and its binarized counterpart. (c) We perform\\na large number of ablation studies that shed light on the properties and the\\nperformance of the proposed block. (d) We present results for experiments on\\nthe most challenging datasets for human pose estimation and face alignment,\\nreporting in many cases state-of-the-art performance. Code can be downloaded\\nfrom this https URL\\n',\n",
       " '  Trained recurrent networks are powerful tools for modeling dynamic neural\\ncomputations. We present a target-based method for modifying the full\\nconnectivity matrix of a recurrent network to train it to perform tasks\\ninvolving temporally complex input/output transformations. The method\\nintroduces a second network during training to provide suitable \"target\"\\ndynamics useful for performing the task. Because it exploits the full recurrent\\nconnectivity, the method produces networks that perform tasks with fewer\\nneurons and greater noise robustness than traditional least-squares (FORCE)\\napproaches. In addition, we show how introducing additional input signals into\\nthe target-generating network, which act as task hints, greatly extends the\\nrange of tasks that can be learned and provides control over the complexity and\\nnature of the dynamics of the trained, task-performing network.\\n',\n",
       " '  Learning sparse combinations is a frequent theme in machine learning. In this\\npaper, we study its associated optimization problem in the distributed setting\\nwhere the elements to be combined are not centrally located but spread over a\\nnetwork. We address the key challenges of balancing communication costs and\\noptimization errors. To this end, we propose a distributed Frank-Wolfe (dFW)\\nalgorithm. We obtain theoretical guarantees on the optimization error\\n$\\\\epsilon$ and communication cost that do not depend on the total number of\\ncombining elements. We further show that the communication cost of dFW is\\noptimal by deriving a lower-bound on the communication cost required to\\nconstruct an $\\\\epsilon$-approximate solution. We validate our theoretical\\nanalysis with empirical studies on synthetic and real-world data, which\\ndemonstrate that dFW outperforms both baselines and competing methods. We also\\nstudy the performance of dFW when the conditions of our analysis are relaxed,\\nand show that dFW is fairly robust.\\n',\n",
       " '  Explainable recommendation is an important task. Many methods have been\\nproposed which generate explanations from the content and reviews written for\\nitems. When review text is unavailable, generating explanations is still a hard\\nproblem. In this paper, we illustrate how explanations can be generated in such\\na scenario by leveraging external knowledge in the form of knowledge graphs.\\nOur method jointly ranks items and knowledge graph entities using a\\nPersonalized PageRank procedure to produce recommendations together with their\\nexplanations.\\n',\n",
       " '  Fractal scale-free networks are empirically known to exhibit disassortative\\ndegree mixing. It is, however, not obvious whether a negative degree\\ncorrelation between nearest neighbor nodes makes a scale-free network fractal.\\nHere we examine the possibility that disassortativity in complex networks is\\nthe origin of fractality. To this end, maximally disassortative (MD) networks\\nare prepared by rewiring edges while keeping the degree sequence of an initial\\nuncorrelated scale-free network that is guaranteed to become fractal by\\nrewiring edges. Our results show that most of MD networks with different\\ntopologies are not fractal, which demonstrates that disassortativity does not\\ncause the fractal property of networks. In addition, we suggest that fractality\\nof scale-free networks requires a long-range repulsive correlation in similar\\ndegrees.\\n',\n",
       " '  We incorporate the non-linear clustering of dark matter halos, as modelled by\\nJose et al. (2016) into the halo model to better understand the clustering of\\nLyman break galaxies (LBGs) in the redshift range $z=3-5$. We find that, with\\nthis change, the predicted LBG clustering increases significantly on\\nquasi-linear scales ($0.1 \\\\leq r\\\\,/\\\\,h^{-1} \\\\,{\\\\rm Mpc} \\\\leq 10$) compared to\\nthat in the linear halo bias model. This in turn results in an increase in the\\nclustering of LBGs by an order of magnitude on angular scales $5\" \\\\leq \\\\theta\\n\\\\leq 100\"$. Remarkably, the predictions of our new model on the whole remove\\nthe systematic discrepancy between the linear halo bias predictions and the\\nobservations. The correlation length and large scale galaxy bias of LBGs are\\nfound to be significantly higher in the non-linear halo bias model than in the\\nlinear halo bias model. The resulting two-point correlation function retains an\\napproximate power-law form in contrast with that computed using the linear halo\\nbias theory. We also find that the non-linear clustering of LBGs increases with\\nincreasing luminosity and redshift. Our work emphasizes the importance of using\\nnon-linear halo bias in order to model the clustering of high-z galaxies to\\nprobe the physics of galaxy formation and extract cosmological parameters\\nreliably.\\n',\n",
       " '  In 2010, Joyce et. al defined the leverage centrality of vertices in a graph\\nas a means to analyze functional connections within the human brain. In this\\nmetric a degree of a vertex is compared to the degrees of all it neighbors. We\\ninvestigate this property from a mathematical perspective. We first outline\\nsome of the basic properties and then compute leverage centralities of vertices\\nin different families of graphs. In particular, we show there is a surprising\\nconnection between the number of distinct leverage centralities in the\\nCartesian product of paths and the triangle numbers.\\n',\n",
       " \"  We address the problem of defining a network graph on a large collection of\\nclasses. Each class is comprised of a collection of data points, sampled in a\\nnon i.i.d. way, from some unknown underlying distribution. The application we\\nconsider in this paper is a large scale high dimensional survey of people\\nliving in the US, and the question of how similar or different are the various\\ncounties in which these people live. We use a co-clustering diffusion metric to\\nlearn the underlying distribution of people, and build an approximate earth\\nmover's distance algorithm using this data adaptive transportation cost.\\n\",\n",
       " '  We investigate the merits of replication, and provide methods for optimal\\ndesign (including replicates), with the goal of obtaining globally accurate\\nemulation of noisy computer simulation experiments. We first show that\\nreplication can be beneficial from both design and computational perspectives,\\nin the context of Gaussian process surrogate modeling. We then develop a\\nlookahead based sequential design scheme that can determine if a new run should\\nbe at an existing input location (i.e., replicate) or at a new one (explore).\\nWhen paired with a newly developed heteroskedastic Gaussian process model, our\\ndynamic design scheme facilitates learning of signal and noise relationships\\nwhich can vary throughout the input space. We show that it does so efficiently,\\non both computational and statistical grounds. In addition to illustrative\\nsynthetic examples, we demonstrate performance on two challenging real-data\\nsimulation experiments, from inventory management and epidemiology.\\n',\n",
       " '  We tackle the problem of object detection and pose estimation in a shared\\nspace downtown environment. For perception multiple laser scanners with\\n360° coverage were fused in a dynamic occupancy grid map (DOGMa). A\\nsingle-stage deep convolutional neural network is trained to provide object\\nhypotheses comprising of shape, position, orientation and an existence score\\nfrom a single input DOGMa. Furthermore, an algorithm for offline object\\nextraction was developed to automatically label several hours of training data.\\nThe algorithm is based on a two-pass trajectory extraction, forward and\\nbackward in time. Typical for engineered algorithms, the automatic label\\ngeneration suffers from misdetections, which makes hard negative mining\\nimpractical. Therefore, we propose a loss function counteracting the high\\nimbalance between mostly static background and extremely rare dynamic grid\\ncells. Experiments indicate, that the trained network has good generalization\\ncapabilities since it detects objects occasionally lost by the label algorithm.\\nEvaluation reaches an average precision (AP) of 75.9%\\n',\n",
       " '  This paper concerns statistical inference for the components of a\\nhigh-dimensional regression parameter despite possible endogeneity of each\\nregressor. Given a first-stage linear model for the endogenous regressors and a\\nsecond-stage linear model for the response variable, we develop a novel\\nadaptation of the parametric one-step update to a generic second-stage\\nestimator. We provide high-level conditions under which the scaled update is\\nasymptotically normal. We introduce a two-stage Lasso procedure and show that,\\nunder a sub-Gaussian noise regime, the second-stage Lasso estimator satisfies\\nthe aforementioned conditions. Using these results, we construct asymptotically\\nvalid confidence intervals for the components of the second-stage regression\\nvector. We complement our asymptotic theory with empirical studies, which\\ndemonstrate the relevance of our method in finite samples.\\n',\n",
       " '  Let $f$ be a holomorphic cusp form for $SL_2(\\\\mathbb{Z})$ of weight $k>1$. In\\nthese notes, we follow Munshi to prove the Burgess bound $$\\nL(1/2+it,f)\\\\ll_{f,\\\\varepsilon} (1+|t|)^{1/2-1/8+\\\\varepsilon}. $$\\n',\n",
       " '  We compute the (primary) equivariant Euler characteristics of the building\\nfor the general linear group over a finite field.\\n',\n",
       " '  With the nonuniform media taken into account, the nonisospectral and\\nvariable-coefficient Korteweg-de Vries equation, which describes various\\nphysical situations such as fluid dynamics and plasma, is under investigation\\nin this paper. With appropriate selection of wave functions, the Darboux\\ntransformation is constructed, by which the multi-soliton solutions are derived\\nand graphs are presented. The spectral parameters, coefficients and initial\\nphase are discussed analytically and numerically to demonstrate their\\nrespective effect on the soliton dynamics, which plays a role in achieving the\\nfeasible soliton management with explicit conditions taken into account.\\n',\n",
       " '  Prior change is discussed in observational constraints studies of nonlocally\\nmodified gravity. In the latter, a model characterized by a modification of the\\nform $\\\\sim m^2 R\\\\Box^{-2}R$ to the Einstein-Hilbert action was compared against\\nthe base $\\\\Lambda$CDM one in a Bayesian way. It was found that the competing\\nmodified gravity model is significantly disfavored (at $22 \\\\,$:$\\\\, 1$ in terms\\nof betting-odds) against $\\\\Lambda$CDM given CMB+SNIa+BAO data, because of a\\ndominant tension appearing in the $H_0 \\\\,$-$\\\\, \\\\Omega_M$ plan. We identify the\\nunderlying mechanism generating such a tension and show that it is mostly\\ncaused by the late-time, quite smooth, phantom nature of the effective dark\\nenergy described by the nonlocal model. We find possible solutions for it to be\\nresolved and explore a given one that consists in extending the initial\\nbaseline from one massive neutrino eigenstate to three degenerate ones, whose\\nabsolute mass $\\\\sum m_\\\\nu \\\\, / \\\\, 3$ is allowed to take values within a\\nreasonable prior interval. As a net effect, the absolute neutrino mass is\\ninferred to be non-vanishing at $2 \\\\sigma$ level, best-fitting at $\\\\sum m_\\\\nu\\n\\\\approx 0.21 {\\\\, \\\\rm eV}$, and the Bayesian tension disappears rendering the\\nnonlocal gravity model statistically equivalent to $\\\\Lambda$CDM, given recent\\nCMB+SNIa+BAO data. We also discuss constraints from growth rate measurements $f\\n\\\\sigma_8$ whose fit is found to be improved by a larger massive neutrino\\nfraction as well. The $\\\\nu$-extended nonlocal model also prefers a higher value\\nof $H_0$ than $\\\\Lambda$CDM, therefore in better agreement with local\\nmeasurements.\\n',\n",
       " '  We identify the Taylor coefficients of the transfer matrices corresponding to\\nquantum toroidal algebras with the elliptic local and non-local integrals of\\nmotion introduced by Kojima, Shiraishi, Watanabe, and one of the authors.\\nThat allows us to prove the Litvinov conjectures on the Intermediate Long\\nWave model.\\nWe also discuss the (gl(m),gl(n)) duality of XXZ models in quantum toroidal\\nsetting and the implications for the quantum KdV model. In particular, we\\nconjecture that the spectrum of non-local integrals of motion of Bazhanov,\\nLukyanov, and Zamolodchikov is described by Gaudin Bethe ansatz equations\\nassociated to affine sl(2).\\n',\n",
       " \"  In Geomagnetism it is of interest to separate the Earth's core magnetic field\\nfrom the crustal magnetic field. However, measurements by satellites can only\\nsense the sum of the two contributions. In practice, the measured magnetic\\nfield is expanded in spherical harmonics and separation into crust and core\\ncontribution is achieved empirically, by a sharp cutoff in the spectral domain.\\nIn this paper, we derive a mathematical setup in which the two contributions\\nare modeled by harmonic potentials $\\\\Phi_0$ and $\\\\Phi_1$ generated on two\\ndifferent spheres $\\\\mathbb{S}_{R_0}$ (crust) and $\\\\mathbb{S}_{R_1}$ (core) with\\nradii $R_1<R_0$. Although it is not possible in general to recover $\\\\Phi_0$ and\\n$\\\\Phi_1$ knowing their superposition $\\\\Phi_0+\\\\Phi_1$ on a sphere\\n$\\\\mathbb{S}_{R_2}$ with radius $R_2>R_0$, we show that it becomes possible if\\nthe magnetization $\\\\mathbf{m}$ generating $\\\\Phi_0$ is localized in a strict\\nsubregion of $\\\\mathbb{S}_{R_0}$. Beyond unique recoverability, we show in this\\ncase how to numerically reconstruct characteristic features of $\\\\Phi_0$ (e.g.,\\nspherical harmonic Fourier coefficients). An alternative way of phrasing the\\nresults is that knowledge of $\\\\mathbf{m}$ on a nonempty open subset of\\n$\\\\mathbb{S}_{R_0}$ allows one to perform separation.\\n\",\n",
       " \"  We generate coherent ultraviolet radiation at 313 nm as the third harmonic of\\nan external-cavity diode laser. We use this radiation for laser cooling of\\ntrapped beryllium atomic ions and sympathetic cooling of co-trapped\\nberyllium-hydride molecular ions. An LBO crystal in an enhancement cavity\\ngenerates the second harmonic, and a BBO crystal in a doubly resonant\\nenhancement cavity mixes this second harmonic with the fundamental to produce\\nthe third harmonic. Each enhancement cavity is preceded by a tapered amplifier\\nto increase the fundamental light. The 36-mW output power of this\\nall-semiconductor-gain system will enable quantum control of the beryllium\\nions' motion.\\n\",\n",
       " '  We discuss the generalized Kurepa hypothesis $KH_{\\\\lambda}$ at singular\\ncardinals $\\\\lambda$. In particular, we answer questions of Erdös-Hajnal [1]\\nand Todorcevic [6], [7] by showing that $GCH$ does not imply\\n$KH_{\\\\aleph_\\\\omega}$ nor the existence of a family $ \\\\mathcal{F} \\\\subseteq\\n[\\\\aleph_\\\\omega]^{\\\\aleph_0}$ of size $\\\\aleph_{\\\\omega+1}$ such that $\\\\mathcal{F}\\n\\\\restriction X$ has size $\\\\aleph_0$ for every $X \\\\subseteq S, |X|=\\\\aleph_0$.\\n',\n",
       " '  Consider estimating the G-formula for the counterfactual mean outcome under a\\ngiven treatment regime in a longitudinal study. Bang and Robins provided an\\nestimator for this quantity that relies on a sequential regression formulation\\nof this parameter. This approach is doubly robust in that it is consistent if\\neither the outcome regressions or the treatment mechanisms are consistently\\nestimated. We define a stronger notion of double robustness, termed sequential\\ndouble robustness, for estimators of the longitudinal G-formula. The definition\\nemerges naturally from a more general definition of sequential double\\nrobustness for the outcome regression estimators. An outcome regression\\nestimator is sequentially doubly robust (SDR) if, at each subsequent time\\npoint, either the outcome regression or the treatment mechanism is consistently\\nestimated. This form of robustness is exactly what one would anticipate is\\nattainable by studying the remainder term of a first-order expansion of the\\nG-formula parameter. We show that a particular implementation of an existing\\nprocedure is SDR. We also introduce a novel SDR estimator, whose development\\ninvolves a novel translation of ideas used in targeted minimum loss-based\\nestimation to the infinite-dimensional setting.\\n',\n",
       " '  Given a set of n points in a d-dimensional space, we seek to compute the\\nskyline, i.e., those points that are not strictly dominated by any other point,\\nusing few comparisons between elements. We study the crowdsourcing-inspired\\nsetting ([FRPU94]) where comparisons fail with constant probability. In this\\nmodel, Groz & Milo [GM15] show three bounds on the query complexity for the\\nskyline problem. We provide two output-sensitive algorithms computing the\\nskyline with query complexity O(nd log(dk)) and O(ndk log(k)), where k is the\\nsize of the skyline. These results improve significantly on the\\nstate-of-the-art and are tight for low dimensions.\\n',\n",
       " \"  Comparison of Lasserre's measure--based bounds for polynomial optimization to\\nbounds obtained by simulated annealing. We consider the problem of minimizing a\\ncontinuous function $f$ over a compact set $\\\\mathbf{K}$. We compare the\\nhierarchy of upper bounds proposed by Lasserre in [{\\\\em SIAM J. Optim.} $21(3)$\\n$(2011)$, pp. $864-885$] to bounds that may be obtained from simulated\\nannealing.\\nWe show that, when $f$ is a polynomial and $\\\\mathbf{K}$ a convex body, this\\ncomparison yields a faster rate of convergence of the Lasserre hierarchy than\\nwhat was previously known in the literature.\\n\",\n",
       " '  We study a classification problem where each feature can be acquired for a\\ncost and the goal is to optimize a trade-off between the expected\\nclassification error and the feature cost. We revisit a former approach that\\nhas framed the problem as a sequential decision-making problem and solved it by\\nQ-learning with a linear approximation, where individual actions are either\\nrequests for feature values or terminate the episode by providing a\\nclassification decision. On a set of eight problems, we demonstrate that by\\nreplacing the linear approximation with neural networks the approach becomes\\ncomparable to the state-of-the-art algorithms developed specifically for this\\nproblem. The approach is flexible, as it can be improved with any new\\nreinforcement learning enhancement, it allows inclusion of pre-trained\\nhigh-performance classifier, and unlike prior art, its performance is robust\\nacross all evaluated datasets.\\n',\n",
       " '  Internet-native audio-visual services are witnessing rapid development. Among\\nthese services, object-based audio-visual services are gaining importance. In\\n2014, we established the Software Defined Media (SDM) consortium to target new\\nresearch areas and markets involving object-based digital media and\\nInternet-by-design audio-visual environments. In this paper, we introduce the\\nSDM architecture that virtualizes networked audio-visual services along with\\nthe development of smart buildings and smart cities using Internet of Things\\n(IoT) devices and smart building facilities. Moreover, we design the SDM\\narchitecture as a layered architecture to promote the development of innovative\\napplications on the basis of rapid advancements in software-defined networking\\n(SDN). Then, we implement a prototype system based on the architecture, present\\nthe system at an exhibition, and provide it as an SDM API to application\\ndevelopers at hackathons. Various types of applications are developed using the\\nAPI at these events. An evaluation of SDM API access shows that the prototype\\nSDM platform effectively provides 3D audio reproducibility and interactiveness\\nfor SDM applications.\\n',\n",
       " '  The task of estimating the maximum number of concurrent speakers from single\\nchannel mixtures is important for various audio-based applications, such as\\nblind source separation, speaker diarisation, audio surveillance or auditory\\nscene classification. Building upon powerful machine learning methodology, we\\ndevelop a Deep Neural Network (DNN) that estimates a speaker count. While DNNs\\nefficiently map input representations to output targets, it remains unclear how\\nto best handle the network output to infer integer source count estimates, as a\\ndiscrete count estimate can either be tackled as a regression or a\\nclassification problem. In this paper, we investigate this important design\\ndecision and also address complementary parameter choices such as the input\\nrepresentation. We evaluate a state-of-the-art DNN audio model based on a\\nBi-directional Long Short-Term Memory network architecture for speaker count\\nestimations. Through experimental evaluations aimed at identifying the best\\noverall strategy for the task and show results for five seconds speech segments\\nin mixtures of up to ten speakers.\\n',\n",
       " '  We investigate the role of the pairing field dynamics in low-energy heavy ion\\nreactions within the nuclear time-dependent density functional theory extended\\nto superfluid systems. Recently, we have reported on unexpectedly large effects\\nassociated with the relative phase of the pairing field of colliding nuclei on\\nthe reaction outcomes, such as the total kinetic energy and the fusion cross\\nsection [P. Magierski, K. Sekizawa, and G. Wlaz{\\\\l}owski, arXiv:1611.10261\\n[nucl-th]]. We have elucidated that the effects are due to creation of a\\n\"domain wall\" or a \"solitonic structure\" of the pairing field in the neck\\nregion, which hinders energy dissipation as well as the neck formation, leading\\nto significant changes of the reaction dynamics. The situation nicely mimics\\nthe one extensively studied experimentally with ultracold atomic gases, where\\ntwo clouds of superfluid atoms possessing different phases of the pairing field\\nare forced to merge, creating various topological excitations, quantum vortices\\nand solitons, as well as Josephson currents. In this paper, we present\\nunpublished results for a lighter system, namely, $^{44}$Ca+$^{44}$Ca. It is\\nshown that the pairing effects on the fusion hindrance are rather small in\\nlighter systems, due to a strong tendency towards fusion, which is consistent\\nwith an earlier study.\\n',\n",
       " '  The present paper is devoted to provide conditions for the Levi--Malcev\\ntheorem to hold or not to hold (i.e. for two Levi subalgebras to be or not\\nconjugate by an inner automorphism) in the context of finite-dimensional\\nLeibniz algebras over a field of characteristic zero. Particularly, in the case\\nof the field $\\\\mathbb{C}$ of complex numbers, we consider all possible cases in\\nwhich Levi subalgebras are conjugate and not conjugate.\\n',\n",
       " '  Understanding high-field amplitude electromagnetic heat loss phenomena is of\\ngreat importance, in particular in the biomedical field, since the\\nheat-delivery treatment plans might rely on analytical models that are only\\nvalid at low field amplitudes. Here, we develop a nonlinear response model\\nvalid for single- domain nanoparticles of larger particle sizes and higher\\nfield amplitudes in comparison to linear response theory. A nonlinear\\nmagnetization expression and a generalized heat loss power equation are\\nobtained and compared with the exact solution of the stochastic\\nLandau-Lifshitz-Gilbert equation assuming the giant-spin hypothesis. The model\\nis valid within the hyperthermia therapeutic window and predicts a shift of\\noptimum particle size and distinct heat loss field amplitude exponents.\\nExperimental hyperthermia data with distinct ferrite-based nanoparticles, as\\nwell as third harmonic magnetization data supports the nonlinear model, which\\nalso has implications for magnetic particle imaging and magnetic thermometry.\\n',\n",
       " '  The order parameter of a critical system defined in a layered parallel plate\\ngeometry subject to Neumann boundary conditions at the limiting surfaces is\\nstudied. We utilize a one-particle irreducible vertex parts framework in order\\nto study the critical behavior of such a system. The renormalized vertex parts\\nare defined at zero external quasi-momenta, which makes the analysis\\nparticularly simple. The distance between the boundary plates $L$\\ncharacterizing the finite size system direction perpendicular to the\\nhyperplanes plays a similar role here in comparison with our recent unified\\ntreatment for Neumann and Dirichlet boundary conditions. Critical exponents are\\ncomputed using diagrammatic expansion at least up to two-loop order and are\\nshown to be identical to those from the bulk theory (limit $L \\\\rightarrow\\n\\\\infty$).\\n',\n",
       " '  The purpose of this paper is to study Rota-Baxter structures for\\nBiHom-associative algebras. Moreover, we introduce and discuss the properties\\nof the notions of BiHom-(tri)dendriform algebras and BiHom-quadri-algebras. We\\nconstruct the free Rota-Baxter BiHom-associative algebra and present some\\nobservations about categories and functors related to Rota-Baxter structures.\\n',\n",
       " '  In this paper we introduce new, easily implementable designs for drawing\\ncausal inference from randomized experiments on networks with interference.\\nInspired by the idea of matching in observational studies, we introduce the\\nnotion of considering a treatment assignment as a quasi-coloring\" on a graph.\\nOur idea of a perfect quasi-coloring strives to match every treated unit on a\\ngiven network with a distinct control unit that has identical number of treated\\nand control neighbors. For a wide range of interference functions encountered\\nin applications, we show both by theory and simulations that the classical\\nNeymanian estimator for the direct effect has desirable properties for our\\ndesigns. This further extends to settings where homophily is present in\\naddition to interference.\\n',\n",
       " '  Implicit semantic role labeling (iSRL) is the task of predicting the semantic\\nroles of a predicate that do not appear as explicit arguments, but rather\\nregard common sense knowledge or are mentioned earlier in the discourse. We\\nintroduce an approach to iSRL based on a predictive recurrent neural semantic\\nframe model (PRNSFM) that uses a large unannotated corpus to learn the\\nprobability of a sequence of semantic arguments given a predicate. We leverage\\nthe sequence probabilities predicted by the PRNSFM to estimate selectional\\npreferences for predicates and their arguments. On the NomBank iSRL test set,\\nour approach improves state-of-the-art performance on implicit semantic role\\nlabeling with less reliance than prior work on manually constructed language\\nresources.\\n',\n",
       " '  Let $N$ be a lattice of rank $n$ and let $M = N^{\\\\vee}$ be its dual lattice.\\nIn this note we show that given two compact, bounded, full-dimensional convex\\nsets $K_1 \\\\subseteq K_2 \\\\subseteq M_{\\\\R} \\\\coloneqq M \\\\otimes_{\\\\Z} \\\\R$, there is\\na canonical convex decomposition of the difference $K_2 \\\\setminus K_1$ and we\\ninterpret the volume of the pieces geometrically in terms of intersection\\nnumbers of toric $b$-divisors.\\n',\n",
       " '  We present a novel distributed Gauss-Newton method for the non-linear state\\nestimation (SE) model based on a probabilistic inference method called belief\\npropagation (BP). The main novelty of our work comes from applying BP\\nsequentially over a sequence of linear approximations of the SE model, akin to\\nwhat is done by the Gauss-Newton method. The resulting iterative Gauss-Newton\\nbelief propagation (GN-BP) algorithm can be interpreted as a distributed\\nGauss-Newton method with the same accuracy as the centralized SE, however,\\nintroducing a number of advantages of the BP framework. The paper provides\\nextensive numerical study of the GN-BP algorithm, provides details on its\\nconvergence behavior, and gives a number of useful insights for its\\nimplementation.\\n',\n",
       " '  Considering Riemannian submersions, we find necessary and sufficient\\nconditions for when sub-Riemannian normal geodesics project to curves of\\nconstant first geodesic curvature or constant first and vanishing second\\ngeodesic curvatures. We describe a canonical extension of the sub-Riemannian\\nmetric and study geometric properties of the obtained Riemannian manifold. This\\nwork contains several examples illustrating the results.\\n',\n",
       " \"  We formulate the AJ-conjecture for the Teichmüller TQFT and we prove it in\\nthe case of the figure-eight knot complement and the $5_2$-knot complement.\\nThis states that the level-$N$ Andersen-Kashaev invariant,\\n$J^{(\\\\mathrm{b},N)}_{M,K}$, is annihilated by the non-homogeneous\\n$\\\\widehat{A}$-polynomial, evaluated at appropriate $q$-commutative operators.\\nThese are obtained via geometric quantisation on the moduli space of flat\\n$\\\\operatorname{SL}(2,\\\\mathbb{C})$-connections on a genus-$1$ surface. The\\nconstruction depends on a parameter $\\\\sigma$ in the Teichmüller space in a\\nway measured by the Hitchin-Witten connection, and results in Hitchin-Witten\\ncovariantly constant quantum operators for the holonomy functions $m$ and\\n$\\\\ell$ along the meridian and longitude. Their action on\\n$J^{(\\\\mathrm{b},N)}_{M,K}$ is then defined via a trivialisation of the\\nHitchin-Witten connection and the Weil-Gel'Fand-Zak transform.\\n\",\n",
       " '  We clarify relationships between conditional (CAR) and simultaneous (SAR)\\nautoregressive models. We review the literature on this topic and find that it\\nis mostly incomplete. Our main result is that a SAR model can be written as a\\nunique CAR model, and while a CAR model can be written as a SAR model, it is\\nnot unique. In fact, we show how any multivariate Gaussian distribution on a\\nfinite set of points with a positive-definite covariance matrix can be written\\nas either a CAR or a SAR model. We illustrate how to obtain any number of SAR\\ncovariance matrices from a single CAR covariance matrix by using Givens\\nrotation matrices on a simulated example. We also discuss sparseness in the\\noriginal CAR construction, and for the resulting SAR weights matrix. For a real\\nexample, we use crime data in 49 neighborhoods from Columbus, Ohio, and show\\nthat a geostatistical model optimizes the likelihood much better than typical\\nfirst-order CAR models. We then use the implied weights from the geostatistical\\nmodel to estimate CAR model parameters that provides the best overall\\noptimization.\\n',\n",
       " '  Graph embedding provides an efficient solution for graph analysis by\\nconverting the graph into a low-dimensional space which preserves the structure\\ninformation. In contrast to the graph structure data, the i.i.d. node embedding\\ncan be processed efficiently in terms of both time and space. Current\\nsemi-supervised graph embedding algorithms assume the labelled nodes are given,\\nwhich may not be always true in the real world. While manually label all\\ntraining data is inapplicable, how to select the subset of training data to\\nlabel so as to maximize the graph analysis task performance is of great\\nimportance. This motivates our proposed active graph embedding (AGE) framework,\\nin which we design a general active learning query strategy for any\\nsemi-supervised graph embedding algorithm. AGE selects the most informative\\nnodes as the training labelled nodes based on the graphical information (i.e.,\\nnode centrality) as well as the learnt node embedding (i.e., node\\nclassification uncertainty and node embedding representativeness). Different\\nquery criteria are combined with the time-sensitive parameters which shift the\\nfocus from graph based query criteria to embedding based criteria as the\\nlearning progresses. Experiments have been conducted on three public data sets\\nand the results verified the effectiveness of each component of our query\\nstrategy and the power of combining them using time-sensitive parameters. Our\\ncode is available online at: this https URL.\\n',\n",
       " '  Fashion landmarks are functional key points defined on clothes, such as\\ncorners of neckline, hemline, and cuff. They have been recently introduced as\\nan effective visual representation for fashion image understanding. However,\\ndetecting fashion landmarks are challenging due to background clutters, human\\nposes, and scales. To remove the above variations, previous works usually\\nassumed bounding boxes of clothes are provided in training and test as\\nadditional annotations, which are expensive to obtain and inapplicable in\\npractice. This work addresses unconstrained fashion landmark detection, where\\nclothing bounding boxes are not provided in both training and test. To this\\nend, we present a novel Deep LAndmark Network (DLAN), where bounding boxes and\\nlandmarks are jointly estimated and trained iteratively in an end-to-end\\nmanner. DLAN contains two dedicated modules, including a Selective Dilated\\nConvolution for handling scale discrepancies, and a Hierarchical Recurrent\\nSpatial Transformer for handling background clutters. To evaluate DLAN, we\\npresent a large-scale fashion landmark dataset, namely Unconstrained Landmark\\nDatabase (ULD), consisting of 30K images. Statistics show that ULD is more\\nchallenging than existing datasets in terms of image scales, background\\nclutters, and human poses. Extensive experiments demonstrate the effectiveness\\nof DLAN over the state-of-the-art methods. DLAN also exhibits excellent\\ngeneralization across different clothing categories and modalities, making it\\nextremely suitable for real-world fashion analysis.\\n',\n",
       " '  Online health communities are a valuable source of information for patients\\nand physicians. However, such user-generated resources are often plagued by\\ninaccuracies and misinformation. In this work we propose a method for\\nautomatically establishing the credibility of user-generated medical statements\\nand the trustworthiness of their authors by exploiting linguistic cues and\\ndistant supervision from expert sources. To this end we introduce a\\nprobabilistic graphical model that jointly learns user trustworthiness,\\nstatement credibility, and language objectivity. We apply this methodology to\\nthe task of extracting rare or unknown side-effects of medical drugs --- this\\nbeing one of the problems where large scale non-expert data has the potential\\nto complement expert medical knowledge. We show that our method can reliably\\nextract side-effects and filter out false statements, while identifying\\ntrustworthy users that are likely to contribute valuable medical information.\\n',\n",
       " '  This work addresses the task of generating English sentences from Abstract\\nMeaning Representation (AMR) graphs. To cope with this task, we transform each\\ninput AMR graph into a structure similar to a dependency tree and annotate it\\nwith syntactic information by applying various predefined actions to it.\\nSubsequently, a sentence is obtained from this tree structure by visiting its\\nnodes in a specific order. We train maximum entropy models to estimate the\\nprobability of each individual action and devise an algorithm that efficiently\\napproximates the best sequence of actions to be applied. Using a substandard\\nlanguage model, our generator achieves a Bleu score of 27.4 on the LDC2014T12\\ntest set, the best result reported so far without using silver standard\\nannotations from another corpus as additional training data.\\n',\n",
       " '  Topology changes in multi-phase fluid flows are difficult to model within a\\ntraditional sharp interface theory. Diffuse interface models turn out to be an\\nattractive alternative to model two-phase flows. Based on a\\nCahn-Hilliard-Navier-Stokes model introduced by Abels, Garcke and Grün\\n(Math. Models Methods Appl. Sci. 2012), which uses a volume averaged velocity,\\nwe derive a diffuse interface model in a Hele-Shaw geometry, which in the case\\nof non-matched densities, simplifies an earlier model of Lee, Lowengrub and\\nGoodman (Phys. Fluids 2002). We recover the classical Hele-Shaw model as a\\nsharp interface limit of the diffuse interface model. Furthermore, we show the\\nexistence of weak solutions and present several numerical computations\\nincluding situations with rising bubbles and fingering instabilities.\\n',\n",
       " \"  Kennedy and O'Hagan (2001) propose a model for calibrating some unknown\\nparameters in a computer model and estimating the discrepancy between the\\ncomputer output and physical response. This model is known to have certain\\nidentifiability issues. Tuo and Wu (2016) show that there are examples for\\nwhich the Kennedy-O'Hagan method renders unreasonable results in calibration.\\nIn spite of its unstable performance in calibration, the Kennedy-O'Hagan\\napproach has a more robust behavior in predicting the physical response. In\\nthis work, we present some theoretical analysis to show the consistency of\\npredictor based on their calibration model in the context of radial basis\\nfunctions.\\n\",\n",
       " '  In frustrated magnetism, making a stringent connection between microscopic\\nspin models and macroscopic properties of spin liquids remains an important\\nchallenge. A recent step towards this goal has been the development of the\\npseudofermion functional renormalization group approach (pf-FRG) which,\\nbuilding on a fermionic parton construction, enables the numerical detection of\\nthe onset of spin liquid states as temperature is lowered. In this work,\\nfocusing on the SU(N) Heisenberg model at large N, we extend this approach in a\\nway that allows us to directly enter the low-temperature spin liquid phase, and\\nto probe its character. Our approach proceeds in momentum space, making it\\npossible to keep the truncation minimalistic, while also avoiding the bias\\nintroduced by an explicit decoupling of the fermionic parton interactions into\\na given channel. We benchmark our findings against exact mean-field results in\\nthe large-N limit, and show that even without prior knowledge the pf-FRG\\napproach identifies the correct mean-field decoupling channel. On a technical\\nlevel, we introduce an alternative finite temperature regularization scheme\\nthat is necessitated to access the spin liquid ordered phase. In a companion\\npaper arXiv:1711.02182 we present a different set of modifications of the\\npf-FRG scheme that allow us to study SU(N) Heisenberg models (using a\\nreal-space RG approach) for arbitrary values of N, albeit only up to the phase\\ntransition towards spin liquid physics.\\n',\n",
       " '  Quantum dissipation arises when a large system can be split in a quantum\\nsystem and an environment where the energy of the former flows to.\\nUnderstanding the effect of dissipation on quantum many-body systems is of\\nparticular importance due to its potential relations with quantum information\\nprocessing. We propose a conceptually simple approach to introduce the\\ndissipation into interacting quantum systems in a thermodynamical context, in\\nwhich every site of a 1d lattice is coupled off-diagonally to its own bath. The\\ninterplay between quantum dissipation and interactions gives rise to\\ncounterintuitive interpretations such as a compressible zero-temperature state\\nwith spontaneous discrete symmetry breaking and a thermal phase transition in a\\none-dimensional dissipative quantum many-body system as revealed by Quantum\\nMonte Carlo path integral simulations.\\n',\n",
       " '  We propose a novel adaptive approximation approach for test-time\\nresource-constrained prediction. Given an input instance at test-time, a gating\\nfunction identifies a prediction model for the input among a collection of\\nmodels. Our objective is to minimize overall average cost without sacrificing\\naccuracy. We learn gating and prediction models on fully labeled training data\\nby means of a bottom-up strategy. Our novel bottom-up method first trains a\\nhigh-accuracy complex model. Then a low-complexity gating and prediction model\\nare subsequently learned to adaptively approximate the high-accuracy model in\\nregions where low-cost models are capable of making highly accurate\\npredictions. We pose an empirical loss minimization problem with cost\\nconstraints to jointly train gating and prediction models. On a number of\\nbenchmark datasets our method outperforms state-of-the-art achieving higher\\naccuracy for the same cost.\\n',\n",
       " '  In this paper we study the problem of learning Rectified Linear Units (ReLUs)\\nwhich are functions of the form $max(0,<w,x>)$ with $w$ denoting the weight\\nvector. We study this problem in the high-dimensional regime where the number\\nof observations are fewer than the dimension of the weight vector. We assume\\nthat the weight vector belongs to some closed set (convex or nonconvex) which\\ncaptures known side-information about its structure. We focus on the realizable\\nmodel where the inputs are chosen i.i.d.~from a Gaussian distribution and the\\nlabels are generated according to a planted weight vector. We show that\\nprojected gradient descent, when initialization at 0, converges at a linear\\nrate to the planted model with a number of samples that is optimal up to\\nnumerical constants. Our results on the dynamics of convergence of these very\\nshallow neural nets may provide some insights towards understanding the\\ndynamics of deeper architectures.\\n',\n",
       " \"  Graph coloring is one of the central problems in distributed graph\\nalgorithms. Much of the research on this topic has focused on coloring with\\n$\\\\Delta+1$ colors, where $\\\\Delta$ denotes the maximum degree. Using $\\\\Delta+1$\\ncolors may be unsatisfactory in sparse graphs, where not all nodes have such a\\nhigh degree; it would be more desirable to use a number of colors that improves\\nwith sparsity. A standard measure that captures sparsity is arboricity, which\\nis the smallest number of forests into which the edges of the graph can be\\npartitioned.\\nWe present simple randomized distributed algorithms that, with high\\nprobability, color any $n$-node $\\\\alpha$-arboricity graph:\\n- using $(2+\\\\varepsilon)\\\\cdot \\\\alpha$ colors, for constant $\\\\varepsilon>0$,\\nin $O(\\\\log n)$ rounds, if $\\\\alpha=\\\\tilde{\\\\Omega}(\\\\log n)$, or\\n- using $O(\\\\alpha \\\\log \\\\alpha )$ colors, in $O(\\\\log n)$ rounds, or\\n- using $O(\\\\alpha)$ colors, in $O(\\\\log n \\\\cdot \\\\min\\\\{\\\\log\\\\log n,\\\\; \\\\log\\n\\\\alpha\\\\})$ rounds.\\nThese algorithms are nearly-optimal, as it is known by results of Linial\\n[FOCS'87] and Barenboim and Elkin [PODC'08] that coloring with $\\\\Theta(\\\\alpha)$\\ncolors, or even poly$(\\\\alpha)$ colors, requires $\\\\Omega(\\\\log_{\\\\alpha} n)$\\nrounds. The previously best-known $O(\\\\log n)$-time result was a deterministic\\nalgorithm due to Barenboim and Elkin [PODC'08], which uses $\\\\Theta(\\\\alpha ^2)$\\ncolors. Barenboim and Elkin stated improving this number of colors as an open\\nproblem in their Distributed Graph Coloring Book.\\n\",\n",
       " '  We consider the sampling of the coupled cluster expansion within stochastic\\ncoupled cluster theory. Observing the limitations of previous approaches due to\\nthe inherently non-linear behaviour of a coupled cluster wavefunction\\nrepresentation we propose new approaches based upon an intuitive, well-defined\\ncondition for sampling weights and on sampling the expansion in cluster\\noperators of different excitation levels. We term these modifications even and\\ntruncated selection respectively. Utilising both approaches demonstrates\\ndramatically improved calculation stability as well as reduced computational\\nand memory costs. These modifications are particularly effective at higher\\ntruncation levels owing to the large number of terms within the cluster\\nexpansion that can be neglected, as demonstrated by the reduction of the number\\nof terms to be sampled at the level of CCSDT by 77% and at CCSDTQ56 by 98%.\\n',\n",
       " '  Exposure assessment models are deterministic models derived from\\nphysical-chemical laws. In real workplace settings, chemical concentration\\nmeasurements can be noisy and indirectly measured. In addition, inference on\\nimportant parameters such as generation and ventilation rates are usually of\\ninterest since they are difficult to obtain. In this paper we outline a\\nflexible Bayesian framework for parameter inference and exposure prediction. In\\nparticular, we propose using Bayesian state space models by discretizing the\\ndifferential equation models and incorporating information from observed\\nmeasurements and expert prior knowledge. At each time point, a new measurement\\nis available that contains some noise, so using the physical model and the\\navailable measurements, we try to obtain a more accurate state estimate, which\\ncan be called filtering. We consider Monte Carlo sampling methods for parameter\\nestimation and inference under nonlinear and non-Gaussian assumptions. The\\nperformance of the different methods is studied on computer-simulated and\\ncontrolled laboratory-generated data. We consider some commonly used exposure\\nmodels representing different physical hypotheses.\\n',\n",
       " '  We prove that a relatively hyperbolic pair $(G,P)$ has Bowditch boundary a\\n2-sphere if and only if it is a 3-dimensional Poincare duality pair. We prove\\nthis by studying the relationship between the Bowditch and Dahmani boundaries\\nof relatively hyperbolic groups.\\n',\n",
       " '  We consider the task of analyzing message-passing programs by observing their\\nrun-time behavior.\\nWe introduce a purely library-based instrumentation method to trace\\ncommunication events during execution. A model of the dependencies among events\\ncan be constructed to identify potential bugs. Compared to the vector clock\\nmethod, our approach is much simpler and has in general a significant lower\\nrun-time overhead.\\nA further advantage is that we also trace events that could not commit. Thus,\\nwe can infer alternative communications. This provides the user with additional\\ninformation to identify potential bugs.\\nWe have fully implemented our approach in the Go programming language and\\nprovide a number of examples to substantiate our claims.\\n',\n",
       " '  This research uses Twitter, as a social media device, to track communications\\nrelated to the 2015 U.S. foodborne illness outbreak linked to Salmonella in\\nimported cucumbers from Mexico. The relevant Twitter data are analyzed in light\\nof the timeline of the official announcements made by the Centers for Disease\\nControl and Prevention (CDC). The largest number of registered tweets is\\nassociated with the period immediately following the CDC initial announcement\\nand the official release of the first recall of cucumbers.\\n',\n",
       " '  In this work we define log-linear models to compare several square\\ncontingency tables under the quasi-independence or the quasi-symmetry model,\\nand the relevant Markov bases are theoretically characterized. Through Markov\\nbases, an exact test to evaluate if two or more tables fit a common model is\\nintroduced. Two real-data examples illustrate the use of these models in\\ndifferent fields of applications.\\n',\n",
       " \"  We present two efficient algorithms that compute the optimal strategy for cop\\nin the game of Cop v.s. Gambler where the gambler's strategy is not optimal but\\nknown to the cop. The first algorithm is analogous to Bellman-Ford algorithm\\nfor single source shortest path problem and runs in $O(|V(G)||E(G)|)$ time. The\\nsecond is analogous to Dijkstra's algorithm and runs in $O(|E(G)|+|V(G)|\\\\log\\n|V(G)|)$ time. Compared with each other, they are more suitable for sparse and\\ndense graphs, respectively.\\n\",\n",
       " '  The aim of the paper is to investigate the solutions of special inhomogeneous\\nlinear functional equations by using spectral analysis in a translation\\ninvariant closed linear subspace of additive/multiadditive functions containing\\nthe restrictions of the solutions to finitely generated fields. The application\\nof spectral analysis in some related varieties is a new and important trend in\\nthe theory of functional equations; especially they have successful\\napplications in case of homogeneous linear functional equations. The foundation\\nof the theory can be found in M. Laczkovich and G. Kiss \\\\cite{KL}, see also G.\\nKiss and A. Varga \\\\cite{KV}. We are going to adopt the main theoretical tools\\nto solve some inhomogeneous problems due to T. Szostok \\\\cite{KKSZ08}, see also\\n\\\\cite{KKSZ} and \\\\cite{KKSZW}. They are motivated by quadrature rules of\\napproximate integration.\\n',\n",
       " '  We capitalize on large amounts of readily-available, synchronous data to\\nlearn a deep discriminative representations shared across three major natural\\nmodalities: vision, sound and language. By leveraging over a year of sound from\\nvideo and millions of sentences paired with images, we jointly train a deep\\nconvolutional network for aligned representation learning. Our experiments\\nsuggest that this representation is useful for several tasks, such as\\ncross-modal retrieval or transferring classifiers between modalities. Moreover,\\nalthough our network is only trained with image+text and image+sound pairs, it\\ncan transfer between text and sound as well, a transfer the network never\\nobserved during training. Visualizations of our representation reveal many\\nhidden units which automatically emerge to detect concepts, independent of the\\nmodality.\\n',\n",
       " '  We introduce the notion of \"seminar users\", who are social media users\\nengaged in propaganda in support of a political entity. We develop a framework\\nthat can identify such users with 84.4% precision and 76.1% recall. While our\\ndataset is from the Arab region, omitting language-specific features has only a\\nminor impact on classification performance, and thus, our approach could work\\nfor detecting seminar users in other parts of the world and in other languages.\\nWe further explored a controversial political topic to observe the prevalence\\nand potential potency of such users. In our case study, we found that 25% of\\nthe users engaged in the topic are in fact seminar users and their tweets make\\nnearly a third of the on-topic tweets. Moreover, they are often successful in\\naffecting mainstream discourse with coordinated hashtag campaigns.\\n',\n",
       " '  A system of Lorentz oscillators is considered to interpret of spectral lines\\nof hydrogen atoms. The dielectric permittivity of this system, which takes into\\naccount its electric polarization, is considered. The substance is examined in\\nthe gas state or in the form of small dust of matter. It is shown that the\\nconsidering of the electric polarization results in a redshift of spectral\\nlines of the substance and the appearance of dip of curve of spectrum. This dip\\ntakes place in the blue side with respect to the spectral position of the\\nalready shifted line. The magnitude of the red shift of spectral line and the\\nwidth of this dip in the spectrum depend strongly on the concentration of\\nhydrogen atoms that create this spectrum and on the spectral position of line\\nthat not shifted.\\n',\n",
       " '  This study aims to inspect and evaluate the integration of database queries\\nand their use in e-commerce product searches. It has been observed that\\ne-commerce is one of the most prominent trends, which have been emerged in the\\nbusiness world, for the past decade. E-commerce has gained tremendous\\npopularity, as it offers higher flexibility, cost efficiency, effectiveness,\\nand convenience, to both, consumers and businesses. Large number of retailing\\ncompanies has adopted this technology, in order to expand their operations,\\nacross of the globe; hence they needs to have highly responsive and integrated\\ndatabases. In this regard, the approach of database queries is found to be the\\nmost appropriate and adequate techniques, as it simplifies the searches of\\ne-commerce products.\\n',\n",
       " '  Informally, a chemical reaction network is \"atomic\" if each reaction may be\\ninterpreted as the rearrangement of indivisible units of matter. There are\\nseveral reasonable definitions formalizing this idea. We investigate the\\ncomputational complexity of deciding whether a given network is atomic\\naccording to each of these definitions.\\nOur first definition, primitive atomic, which requires each reaction to\\npreserve the total number of atoms, is to shown to be equivalent to mass\\nconservation. Since it is known that it can be decided in polynomial time\\nwhether a given chemical reaction network is mass-conserving, the equivalence\\ngives an efficient algorithm to decide primitive atomicity.\\nAnother definition, subset atomic, further requires that all atoms are\\nspecies. We show that deciding whether a given network is subset atomic is in\\n$\\\\textsf{NP}$, and the problem \"is a network subset atomic with respect to a\\ngiven atom set\" is strongly $\\\\textsf{NP}$-$\\\\textsf{Complete}$.\\nA third definition, reachably atomic, studied by Adleman, Gopalkrishnan et\\nal., further requires that each species has a sequence of reactions splitting\\nit into its constituent atoms. We show that there is a $\\\\textbf{polynomial-time\\nalgorithm}$ to decide whether a given network is reachably atomic, improving\\nupon the result of Adleman et al. that the problem is $\\\\textbf{decidable}$. We\\nshow that the reachability problem for reachably atomic networks is\\n$\\\\textsf{Pspace}$-$\\\\textsf{Complete}$.\\nFinally, we demonstrate equivalence relationships between our definitions and\\nsome special cases of another existing definition of atomicity due to Gnacadja.\\n',\n",
       " '  We investigate from first principles the field-like spin-orbit torques (SOTs)\\nin a Ag$_{2}$Bi-terminated Ag(111) film grown on ferromagnetic Fe(110). We find\\nthat a large part of the SOT arises from the spin-orbit interaction (SOI) in\\nthe Ag$_{2}$Bi layer far away from the Fe layers. These results clearly hint at\\na long range spin transfer in the direction perpendicular to the film that does\\nnot originate in the spin Hall effect. In order to bring evidence of the\\nnon-local character of the computed SOT, we show that the torque acting on the\\nFe layers can be engineered by the introduction of Bi vacancies in the\\nAg$_{2}$Bi layer. Overall, we find a drastic dependence of the SOT on the\\ndisorder type, which we explain by a complex interplay of different\\ncontributions to the SOT in the Brillouin zone.\\n',\n",
       " '  Inspired by Nature, molecular communications (MC), i.e., use of molecules to\\nencode, transmit and receive information, stands as the most promising\\ncommunication paradigm to realize nanonetworks. Even though there has been\\nextensive theoretical research towards nanoscale MC, there are no examples of\\nimplemented nanoscale MC networks. The main reason for this lies in the\\npeculiarities of nanoscale physics, challenges in nanoscale fabrication and\\nhighly stochastic nature of biochemical domain of envisioned nanonetwork\\napplications. This mandates developing novel device architectures and\\ncommunication methods compatible with MC constraints. To that end, various\\ntransmitter and receiver designs for MC have been proposed in literature\\ntogether with numerable modulation, coding and detection techniques. However,\\nthese works fall into domains of a very wide spectrum of disciplines, including\\nbut not limited to information and communication theory, quantum physics,\\nmaterials science, nanofabrication, physiology and synthetic biology.\\nTherefore, we believe it is imperative for the progress of the field that, an\\norganized exposition of cumulative knowledge on subject matter be compiled.\\nThus, to fill this gap, in this comprehensive survey we review the existing\\nliterature on transmitter and receiver architectures towards realizing MC\\namongst nanomaterial-based nanomachines and/or biological entities, and provide\\na complete overview of modulation, coding and detection techniques employed for\\nMC. Moreover, we identify the most significant shortcomings and challenges in\\nall these research areas, and propose potential solutions to overcome some of\\nthem.\\n',\n",
       " '  We introduce a new method to estimate the Markov equivalence class of a\\ndirected acyclic graph (DAG) in the presence of hidden variables, in settings\\nwhere the underlying DAG among the observed variables is sparse, and there are\\na few hidden variables that have a direct effect on many of the observed ones.\\nBuilding on the so-called low rank plus sparse framework, we suggest a\\ntwo-stage approach which first removes the effect of the hidden variables, and\\nthen estimates the Markov equivalence class of the underlying DAG under the\\nassumption that there are no remaining hidden variables. This approach is\\nconsistent in certain high-dimensional regimes and performs favourably when\\ncompared to the state of the art, both in terms of graphical structure recovery\\nand total causal effect estimation.\\n',\n",
       " '  We study the problem of determining whether a given temporal specification\\ncan be implemented by a symmetric system, i.e., a system composed from\\nidentical components. Symmetry is an important goal in the design of\\ndistributed systems, because systems that are composed from identical\\ncomponents are easier to build and maintain. We show that for the class of\\nrotation-symmetric architectures, i.e., multi-process architectures where all\\nprocesses have access to all system inputs, but see different rotations of the\\ninputs, the symmetric synthesis problem is EXPTIME-complete in the number of\\nprocesses. In architectures where the processes do not have access to all input\\nvariables, the symmetric synthesis problem becomes undecidable, even in cases\\nwhere the standard distributed synthesis problem is decidable.\\n',\n",
       " \"  The Mott insulator $\\\\beta'$-EtMe$_3$Sb[Pd(dmit)$_2$]$_2$ belongs to a class\\nof charge transfer solids with highly-frustrated triangular lattice of $S=1/2$\\nmolecular dimers and a quantum-spin-liquid ground state. Our experimental and\\nab initio theoretical studies show the fingerprints of strong correlations and\\ndisorder, important role of cation-dimer bonding in charge redistribution, no\\nsign of intra- and inter-dimer dipoles, and the decisive van der Waals\\ncontribution to inter-dimer interactions and the ground state structure. The\\nlatter consists of quasi-degenerate electronic states related to the different\\nconfigurations of cation moieties which permit two different equally probable\\norientations. Upon reducing the temperature, the low-energy excitations slow\\ndown, indicating glassy signatures as the cation motion freezes out.\\n\",\n",
       " \"  A representation is supposed universal if it encodes any element of the\\nvisual world (e.g., objects, scenes) in any configuration (e.g., scale,\\ncontext). While not expecting pure universal representations, the goal in the\\nliterature is to improve the universality level, starting from a representation\\nwith a certain level. To do so, the state-of-the-art consists in learning\\nCNN-based representations on a diversified training problem (e.g., ImageNet\\nmodified by adding annotated data). While it effectively increases\\nuniversality, such approach still requires a large amount of efforts to satisfy\\nthe needs in annotated data. In this work, we propose two methods to improve\\nuniversality, but pay special attention to limit the need of annotated data. We\\nalso propose a unified framework of the methods based on the diversifying of\\nthe training problem. Finally, to better match Atkinson's cognitive study about\\nuniversal human representations, we proposed to rely on the transfer-learning\\nscheme as well as a new metric to evaluate universality. This latter, aims us\\nto demonstrates the interest of our methods on 10 target-problems, relating to\\nthe classification task and a variety of visual domains.\\n\",\n",
       " \"  Modularity plays an important role in brain networks' architecture and\\ninfluences its dynamics and the ability to integrate and segregate different\\nmodules of cerebral regions. Alterations in community structure are associated\\nwith several clinical disorders, specially schizophrenia, although its time\\nevolution is not clear yet. In the present work, we analyze fMRI functional\\nnetworks of $65$ healthy subjects (HC) and $44$ patients of schizophrenia (SZ),\\n$28$ of them in a chronic state (CR) of illness, and $16$ at early stage (ES).\\nWe find clear differences in edges' weights distribution, networks density,\\ncommunity structure consistency and robustness against edge removal. In\\ncomparison to healthy subjects, we found that networks from SZ patients\\nexhibits wider weight distribution, larger overall connectivity, and are more\\nconsistent in the community structure across subjects. We also showed that the\\nnetworks of SZ patients tend to be more robust to edge removal than healthy\\nsubjects, while having lower network density. In the case of early stages\\npatients, we found that their networks exhibit topological features\\nconsistently in between the ones obtained from the other two groups, resulting\\nin a tendency towards the chronic group state.\\n\",\n",
       " '  Recurrent neural networks can be difficult to train on long sequence data due\\nto the well-known vanishing gradient problem. Some architectures incorporate\\nmethods to reduce RNN state updates, therefore allowing the network to preserve\\nmemory over long temporal intervals. To address these problems of convergence,\\nthis paper proposes a timing-gated LSTM RNN model, called the Gaussian-gated\\nLSTM (g-LSTM). The time gate controls when a neuron can be updated during\\ntraining, enabling longer memory persistence and better error-gradient flow.\\nThis model captures long-temporal dependencies better than an LSTM and the time\\ngate parameters can be learned even from non-optimal initialization values.\\nBecause the time gate limits the updates of the neuron state, the number of\\ncomputes needed for the network update is also reduced. By adding a\\ncomputational budget term to the training loss, we can obtain a network which\\nfurther reduces the number of computes by at least 10x. Finally, by employing a\\ntemporal curriculum learning schedule for the g-LSTM, we can reduce the\\nconvergence time of the equivalent LSTM network on long sequences.\\n',\n",
       " '  This paper is concerned with a set of novel coupling conditions for the\\n$3\\\\times 3$ one-dimensional Euler system with source terms at a junction of\\npipes with possibly different cross-sectional areas. Beside conservation of\\nmass, we require the equality of the total enthalpy at the junction and that\\nthe specific entropy for pipes with outgoing flow equals the convex combination\\nof all entropies that belong to pipes with incoming flow. Previously used\\ncoupling conditions include equality of pressure or dynamic pressure. They are\\nrestricted to the special case of a junction having only one pipe with outgoing\\nflow direction. Recently, Reigstad [SIAM J. Appl. Math., 75:679--702, 2015]\\nshowed that such pressure-based coupling conditions can produce non-physical\\nsolutions for isothermal flows through the production of mechanical energy. Our\\nnew coupling conditions ensure energy as well as entropy conservation and also\\napply to junctions connecting an arbitrary number of pipes with flexible flow\\ndirections. We prove the existence and uniqueness of solutions to the\\ngeneralised Riemann problem at a junction in the neighbourhood of constant\\nstationary states which belong to the subsonic region. This provides the basis\\nfor the well-posedness of the homogeneous and inhomogeneous Cauchy problems for\\ninitial data with sufficiently small total variation.\\n',\n",
       " '  We call a positive real number $\\\\lambda$ admissible if it belongs to the\\nLagrange spectrum and there exists an irrational number $\\\\alpha$ such that\\n$\\\\mu(\\\\alpha)=\\\\lambda$. Here $\\\\mu(\\\\alpha)$ denotes the Lagrange constant of\\n$\\\\alpha$ - maximal real number $c$ such that $\\\\forall \\\\varepsilon>0$ the\\ninequality $|\\\\alpha-\\\\frac{p}{q}|\\\\le\\\\frac{1}{(c-\\\\varepsilon)q^2}$ has infinitely\\nmany solutions for relatively prime $p$ and $q$. In this paper we establish a\\nnecessary and sufficient condition of admissibility of the Lagrange spectrum\\nelement and construct an infinite series of not admissible numbers.\\n',\n",
       " '  Knowledge of the topology of the electronic ground state of materials has led\\nto deep insights to novel phenomena such as the integer quantum Hall effect and\\nfermion-number fractionalization, as well as other properties of matter.\\nJoining two insulators of different topological classes produces fascinating\\nboundary states in the band gap. Another exciting recent development is the\\nbottom-up synthesis (from molecular precursors) of graphene nanoribbons (GNRs)\\nwith atomic precision control of their edge and width. Here we connect these\\ntwo fields, and show for the first time that semiconducting GNRs of different\\nwidth, edge, and end termination belong to different topological classes. The\\ntopology of GNRs is protected by spatial symmetries and dictated by the\\nterminating unit cell. We have derived explicit formula for their topological\\ninvariants, and show that localized junction states developed between two GNRs\\nof distinct topology may be tuned by lateral junction geometry. The topology of\\na GNR can be further modified by dopants, such as a periodic array of boron\\natoms. In a superlattice consisted of segments of doped and pristine GNRs, the\\njunction states are stable spin centers, forming a Heisenberg antiferromagnetic\\nspin 1/2 chain with tunable exchange interaction. The discoveries here are not\\nonly of scientific interest for studies of quasi one-dimensional systems, but\\nalso open a new path for design principles of future GNR-based devices through\\ntheir topological characters.\\n',\n",
       " '  We study reinforcement learning under model misspecification, where we do not\\nhave access to the true environment but only to a reasonably close\\napproximation to it. We address this problem by extending the framework of\\nrobust MDPs to the model-free Reinforcement Learning setting, where we do not\\nhave access to the model parameters, but can only sample states from it. We\\ndefine robust versions of Q-learning, SARSA, and TD-learning and prove\\nconvergence to an approximately optimal robust policy and approximate value\\nfunction respectively. We scale up the robust algorithms to large MDPs via\\nfunction approximation and prove convergence under two different settings. We\\nprove convergence of robust approximate policy iteration and robust approximate\\nvalue iteration for linear architectures (under mild assumptions). We also\\ndefine a robust loss function, the mean squared robust projected Bellman error\\nand give stochastic gradient descent algorithms that are guaranteed to converge\\nto a local minimum.\\n',\n",
       " '  Algorithms are increasingly common components of high-impact decision-making,\\nand a growing body of literature on adversarial examples in laboratory settings\\nindicates that standard machine learning models are not robust. This suggests\\nthat real-world systems are also susceptible to manipulation or\\nmisclassification, which especially poses a challenge to machine learning\\nmodels used in financial services. We use the loan grade classification problem\\nto explore how machine learning models are sensitive to small changes in\\nuser-reported data, using adversarial attacks documented in the literature and\\nan original, domain-specific attack. Our work shows that a robust optimization\\nalgorithm can build models for financial services that are resistant to\\nmisclassification on perturbations. To the best of our knowledge, this is the\\nfirst study of adversarial attacks and defenses for deep learning in financial\\nservices.\\n',\n",
       " '  Metal-organic frameworks (MOFs) are an attractive substrate for catalytic\\nreactions due to the high area density of reaction sites and the ability to\\ntailor an array of material attributes. This study focuses on a thermally\\nstable crystalline UiO-66(Zr) MOF structure and the modulation of the\\nelectronic structure using two strategies to improve the catalytic conversion\\nand selectivity of benzene alcohol to benzedehyate. Those two strategies\\ninclude the functionalization of the organic struts with branched ligands and\\nmanually creating structural defects with unsaturated organic linkers. A\\ncombination of computational and experimental results provide evidence of\\nimproved catalytic activity of MOFs via these two approaches. Functional groups\\nattached to the main organic strut modify the electronic environment of the\\nphotoactive aromatic carbon and thereby decrease the optical band gap by 1eV.\\nWhereas the introduction of structural defects due to the organic linker\\ndesaturation provided a shift in the HUMO as a result of the decrease in strut\\ncoordination with the inorganic knots.\\n',\n",
       " \"  Solving a large-scale system of linear equations is a key step at the heart\\nof many algorithms in machine learning, scientific computing, and beyond. When\\nthe problem dimension is large, computational and/or memory constraints make it\\ndesirable, or even necessary, to perform the task in a distributed fashion. In\\nthis paper, we consider a common scenario in which a taskmaster intends to\\nsolve a large-scale system of linear equations by distributing subsets of the\\nequations among a number of computing machines/cores. We propose an accelerated\\ndistributed consensus algorithm, in which at each iteration every machine\\nupdates its solution by adding a scaled version of the projection of an error\\nsignal onto the nullspace of its system of equations, and where the taskmaster\\nconducts an averaging over the solutions with momentum. The convergence\\nbehavior of the proposed algorithm is analyzed in detail and analytically shown\\nto compare favorably with the convergence rate of alternative distributed\\nmethods, namely distributed gradient descent, distributed versions of\\nNesterov's accelerated gradient descent and heavy-ball method, the block\\nCimmino method, and ADMM. On randomly chosen linear systems, as well as on\\nreal-world data sets, the proposed method offers significant speed-up relative\\nto all the aforementioned methods. Finally, our analysis suggests a novel\\nvariation of the distributed heavy-ball method, which employs a particular\\ndistributed preconditioning, and which achieves the same theoretical\\nconvergence rate as the proposed consensus-based method.\\n\",\n",
       " '  Cloud computing is steadily growing and, as IaaS vendors have started to\\noffer pay-as-you-go billing policies, it is fundamental to achieve as much\\nelasticity as possible, avoiding over-provisioning that would imply higher\\ncosts. In this paper, we briefly analyse the orchestration characteristics of\\nPaaSSOA, a proposed architecture already implemented for Jolie microservices,\\nand Kubernetes, one of the various orchestration plugins for Docker; then, we\\noutline similarities and differences of the two approaches, with respect to\\ntheir own domain of application. Furthermore, we investigate some ideas to\\nachieve a federation of the two technologies, proposing an architectural\\ncomposition of Jolie microservices on Docker Container-as-a-Service layer.\\n',\n",
       " '  In recent years, endomicroscopy has become increasingly used for diagnostic\\npurposes and interventional guidance. It can provide intraoperative aids for\\nreal-time tissue characterization and can help to perform visual investigations\\naimed for example to discover epithelial cancers. Due to physical constraints\\non the acquisition process, endomicroscopy images, still today have a low\\nnumber of informative pixels which hampers their quality. Post-processing\\ntechniques, such as Super-Resolution (SR), are a potential solution to increase\\nthe quality of these images. SR techniques are often supervised, requiring\\naligned pairs of low-resolution (LR) and high-resolution (HR) images patches to\\ntrain a model. However, in our domain, the lack of HR images hinders the\\ncollection of such pairs and makes supervised training unsuitable. For this\\nreason, we propose an unsupervised SR framework based on an adversarial deep\\nneural network with a physically-inspired cycle consistency, designed to impose\\nsome acquisition properties on the super-resolved images. Our framework can\\nexploit HR images, regardless of the domain where they are coming from, to\\ntransfer the quality of the HR images to the initial LR images. This property\\ncan be particularly useful in all situations where pairs of LR/HR are not\\navailable during the training. Our quantitative analysis, validated using a\\ndatabase of 238 endomicroscopy video sequences from 143 patients, shows the\\nability of the pipeline to produce convincing super-resolved images. A Mean\\nOpinion Score (MOS) study also confirms this quantitative image quality\\nassessment.\\n',\n",
       " '  This article proposes a universal simulation platform for simulating systems\\nundergoing duress. In other words, this paper introduces a total simulation\\npackage which includes a number of methods of simulating the flexibility of a\\ngiven system. This platform includes detailed procedures for simulating a\\nflexible link by a numerical method called finite difference method. In order\\nto verify the effectiveness of the proposed process, two examples are covered\\nin different situations to discuss the importance of boundary control and mesh\\nselection in the way of ensuring the stability of the system. In addition, a\\ngraphical user interface (GUI) application called the SimuFlex is designed\\nhaving a selection of methods that the user can choose along with the\\nparameters of the controllers that can be easily manipulated from the GUI.\\n',\n",
       " '  Let $G$ be a simple algebraic group over an algebraically closed field $K$ of\\ncharacteristic $p > 0$. We consider connected reductive subgroups $X$ of $G$\\nthat contain a given distinguished unipotent element $u$ of $G$. A result of\\nTesterman and Zalesski (Proc. Amer. Math. Soc., 2013) shows that if $u$ is a\\nregular unipotent element, then $X$ cannot be contained in a proper parabolic\\nsubgroup of $G$. We generalize their result and show that if $u$ has order $p$,\\nthen except for two known examples which occur in the case $(G, p) = (C_2, 2)$,\\nthe subgroup $X$ cannot be contained in a proper parabolic subgroup of $G$. In\\nthe case where $u$ has order $> p$, we also present further examples arising\\nfrom indecomposable tilting modules with quasi-minuscule highest weight.\\n',\n",
       " '  We consider the problem of reconstructing a rank-$k$ $n \\\\times n$ matrix $M$\\nfrom a sampling of its entries. Under a certain incoherence assumption on $M$\\nand for the case when both the rank and the condition number of $M$ are\\nbounded, it was shown in \\\\cite{CandesRecht2009, CandesTao2010, keshavan2010,\\nRecht2011, Jain2012, Hardt2014} that $M$ can be recovered exactly or\\napproximately (depending on some trade-off between accuracy and computational\\ncomplexity) using $O(n \\\\, \\\\text{poly}(\\\\log n))$ samples in super-linear time\\n$O(n^{a} \\\\, \\\\text{poly}(\\\\log n))$ for some constant $a \\\\geq 1$.\\nIn this paper, we propose a new matrix completion algorithm using a novel\\nsampling scheme based on a union of independent sparse random regular bipartite\\ngraphs. We show that under the same conditions w.h.p. our algorithm recovers an\\n$\\\\epsilon$-approximation of $M$ in terms of the Frobenius norm using $O(n\\n\\\\log^2(1/\\\\epsilon))$ samples and in linear time $O(n \\\\log^2(1/\\\\epsilon))$. This\\nprovides the best known bounds both on the sample complexity and computational\\ncomplexity for reconstructing (approximately) an unknown low-rank matrix.\\nThe novelty of our algorithm is two new steps of thresholding singular values\\nand rescaling singular vectors in the application of the \"vanilla\" alternating\\nminimization algorithm. The structure of sparse random regular graphs is used\\nheavily for controlling the impact of these regularization steps.\\n',\n",
       " '  This paper provides an existence-and-uniqueness theorem characterizing the\\nstochastic integral with respect to a Wiener process. The integral is\\nrepresented as a mapping from the space of measurable and adapted pathwise\\nlocally integrable processes to the space of continuous adapted processes. It\\nis characterized in terms of two properties: (1) how the stochastic integrals\\nof simple processes are calculated and (2) how these integrals converge in\\nprobability when the time integrals of the squared integrands converge in\\nprobability.\\n',\n",
       " '  We propose a probabilistic model for interpreting gene expression levels that\\nare observed through single-cell RNA sequencing. In the model, each cell has a\\nlow-dimensional latent representation. Additional latent variables account for\\ntechnical effects that may erroneously set some observations of gene expression\\nlevels to zero. Conditional distributions are specified by neural networks,\\ngiving the proposed model enough flexibility to fit the data well. We use\\nvariational inference and stochastic optimization to approximate the posterior\\ndistribution. The inference procedure scales to over one million cells, whereas\\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\\nproposed procedure outperforms state-of-the-art methods like ZIFA and\\nZINB-WaVE. We also extend our framework to account for batch effects and other\\nconfounding factors, and propose a Bayesian hypothesis test for differential\\nexpression that outperforms DESeq2.\\n',\n",
       " '  We prove a well-posedness result for stochastic Allen-Cahn type equations in\\na bounded domain coupled with generic boundary conditions. The (nonlinear) flux\\nat the boundary aims at describing the interactions with the hard walls and is\\nmotivated by some recent literature in physics. The singular character of the\\ndrift part allows for a large class of maximal monotone operators, generalizing\\nthe usual double-well potentials. One of the main novelties of the paper is the\\nabsence of any growth condition on the drift term of the evolution, neither on\\nthe domain nor on the boundary. A well-posedness result for variational\\nsolutions of the system is presented using a priori estimates as well as\\nmonotonicity and compactness techniques. A vanishing viscosity argument for the\\ndynamic on the boundary is also presented.\\n',\n",
       " '  To estimate the value functions of policies from exploratory data, most\\nmodel-free off-policy algorithms rely on importance sampling, where the use of\\nimportance sampling ratios often leads to estimates with severe variance. It is\\nthus desirable to learn off-policy without using the ratios. However, such an\\nalgorithm does not exist for multi-step learning with function approximation.\\nIn this paper, we introduce the first such algorithm based on\\ntemporal-difference (TD) learning updates. We show that an explicit use of\\nimportance sampling ratios can be eliminated by varying the amount of\\nbootstrapping in TD updates in an action-dependent manner. Our new algorithm\\nachieves stability using a two-timescale gradient-based TD update. A prior\\nalgorithm based on lookup table representation called Tree Backup can also be\\nretrieved using action-dependent bootstrapping, becoming a special case of our\\nalgorithm. In two challenging off-policy tasks, we demonstrate that our\\nalgorithm is stable, effectively avoids the large variance issue, and can\\nperform substantially better than its state-of-the-art counterpart.\\n',\n",
       " '  Matrix factorization was used to generate investment recommendations for\\ninvestors. An iterative conjugate gradient method was used to optimize the\\nregularized squared-error loss function. The number of latent factors, number\\nof iterations, and regularization values were explored. Overfitting can be\\naddressed by either early stopping or regularization parameter tuning. The\\nmodel achieved the highest average prediction accuracy of 13.3%. With a similar\\nmodel, the same dataset was used to generate investor recommendations for\\ncompanies undergoing fundraising, which achieved highest prediction accuracy of\\n11.1%.\\n',\n",
       " '  Ambient backscatter communication technology has been introduced recently,\\nand is then quickly becoming a promising choice for self-sustainable\\ncommunication systems as an external power supply or a dedicated carrier\\nemitter is not required. By leveraging existing RF signal resources, ambient\\nbackscatter technology can support sustainable and independent communications\\nand consequently open up a whole new set of applications that facilitate\\nInternet-of-Things (IoT). In this article, we study an integration of ambient\\nbackscatter with wireless powered communication networks (WPCNs). We first\\npresent an overview of backscatter communication systems with an emphasis on\\nthe emerging ambient backscatter technology. Then we propose a novel hybrid\\ntransmitter design by combining the advantages of both ambient backscatter and\\nwireless powered communications. Furthermore, in the cognitive radio\\nenvironment, we introduce a multiple access scheme to coordinate the hybrid\\ndata transmissions. The performance evaluation shows that the hybrid\\ntransmitter outperforms traditional designs. In addition, we discuss some open\\nissues related to the ambient backscatter networking.\\n',\n",
       " '  Content-centric mobile hybrid Internet-of-Things (IoT) networks consisting of\\nmobile devices and static femto access points (FAPs) are studied, where each\\ndevice moves according to the random walk mobility model and requests a content\\nobject from the library independently at random according to a Zipf popularity\\ndistribution. Instead of allowing access to content objects at macro base\\nstations via costly backhaul providing connection to the core network, we\\nconsider a more practical scenario where mobile devices and static FAPs, each\\nhaving a finite-size cache space, are able to cache a subset of content objects\\nso that each request is served by other mobile devices or static FAPs. Under a\\ngeneral multihop-based content delivery protocol, we analyze the order-optimal\\nthroughput--delay trade-off by presenting a new cache allocation strategy. In\\nparticular, under a given caching strategy, we first characterize a\\nthroughput--delay trade-off in terms of scaling laws along with the general\\ncontent delivery multihop routing protocol. Then, the order-optimal\\nthroughput--delay trade-off is characterized by presenting the order-optimal\\ncache allocation strategy, which jointly finds the replication sets at mobile\\ndevices and static FAPs via a novel variable decoupling approach. In our mobile\\nIoT network, an interesting observation is that highly popular content objects\\nare mainly served by mobile devices while the rest of content objects are\\nserved by static FAPs. We perform numerical evaluation to validate our\\nanalytical results. We also show that the order-optimal strategy strictly\\noutperforms a baseline approach, where the replication sets at mobile devices\\nand static FAPs are optimized separately.\\n',\n",
       " '  We consider the class of control systems where the differential equation,\\nstate and control system are described by polynomials. Given a set of\\ntrajectories and a class of Lagrangians, we are interested to find a Lagrangian\\nin this class for which these trajectories are optimal. To model this inverse\\nproblem we use a relaxed version of Hamilton-Jacobi-Bellman optimality\\nconditions, in the continuity of previous work in this vein. Then we provide a\\ngeneral numerical scheme based on polynomial optimization and positivity\\ncertificates, and illustrate the concepts on a few academic examples.\\n',\n",
       " \"  We use Beltrami's theorem as an excuse to present some arguments from\\nparabolic differential geometry without any of the parabolic machinery.\\n\",\n",
       " '  The theory of multidimensional Poisson vertex algebras (mPVAs) provides a\\ncompletely algebraic formalism to study the Hamiltonian structure of PDEs, for\\nany number of dependent and independent variables. In this paper, we compute\\nthe cohomology of the PVAs associated with two-dimensional, two-components\\nPoisson brackets of hydrodynamic type at the third differential degree. This\\nallows us to obtain their corresponding Poisson-Lichnerowicz cohomology, which\\nis the main building block of the theory of their deformations. Such a\\ncohomology is trivial neither in the second group, corresponding to the\\nexistence of a class of not equivalent infinitesimal deformation, nor in the\\nthird, corresponding to the obstruction to extend such deformations\\n',\n",
       " '  An innovative model is presented for merging of bubbles inside a liquid\\nmetal. The proposed model is based on forming a thin film (narrow channel)\\nbetween merging bubbles during growth. Rupturing of the film occurs when an\\noscillation in velocity and pressure arises inside the channel followed by\\nmerging of the bubbles. The proposed model based on lattice Boltzmann Method is\\ncapable of simulating merging bubbles in micro, meso, and macro-scales with no\\nlimitation on the number of bubbles. Experimental studies reveal a good\\nconsistency between modeling results and real conditions.\\n',\n",
       " '  Concept maps can be used to concisely represent important information and\\nbring structure into large document collections. Therefore, we study a variant\\nof multi-document summarization that produces summaries in the form of concept\\nmaps. However, suitable evaluation datasets for this task are currently\\nmissing. To close this gap, we present a newly created corpus of concept maps\\nthat summarize heterogeneous collections of web documents on educational\\ntopics. It was created using a novel crowdsourcing approach that allows us to\\nefficiently determine important elements in large document collections. We\\nrelease the corpus along with a baseline system and proposed evaluation\\nprotocol to enable further research on this variant of summarization.\\n',\n",
       " '  We provide a mathematical definition of a low energy scaling limit of a\\nsequence of general non-relativistic quantum theories in any dimension, and\\napply our formalism to anyonic chains. We formulate Conjecture 4.3 on\\nconditions when a chiral unitary rational (1+1)-conformal field theory would\\narise as such a limit and verify the conjecture for the Ising minimal model\\n$M(4,3)$ using Ising anyonic chains. Part of the conjecture is a precise\\nrelation between Temperley-Lieb generators $\\\\{e_i\\\\}$ and some finite stage\\noperators of the Virasoro generators $\\\\{L_m+L_{-m}\\\\}$ and $\\\\{i(L_m-L_{-m})\\\\}$\\nfor unitary minimal models $M(k+2,k+1)$ in Conjecture 5.5. A similar earlier\\nrelation is known as the Koo-Saleur formula in the physics literature [39].\\nAssuming Conjecture 4.3, most of our main results for the Ising minimal model\\n$M(4,3)$ hold for unitary minimal models $M(k+2,k+1), k\\\\geq 3$ as well. Our\\napproach is inspired by an eventual application to an efficient simulation of\\nconformal field theories by quantum computers, and supported by extensive\\nnumerical simulation and physical proofs in the physics literature.\\n',\n",
       " '  Image segmentation is a fundamental problem in biomedical image analysis.\\nRecent advances in deep learning have achieved promising results on many\\nbiomedical image segmentation benchmarks. However, due to large variations in\\nbiomedical images (different modalities, image settings, objects, noise, etc),\\nto utilize deep learning on a new application, it usually needs a new set of\\ntraining data. This can incur a great deal of annotation effort and cost,\\nbecause only biomedical experts can annotate effectively, and often there are\\ntoo many instances in images (e.g., cells) to annotate. In this paper, we aim\\nto address the following question: With limited effort (e.g., time) for\\nannotation, what instances should be annotated in order to attain the best\\nperformance? We present a deep active learning framework that combines fully\\nconvolutional network (FCN) and active learning to significantly reduce\\nannotation effort by making judicious suggestions on the most effective\\nannotation areas. We utilize uncertainty and similarity information provided by\\nFCN and formulate a generalized version of the maximum set cover problem to\\ndetermine the most representative and uncertain areas for annotation. Extensive\\nexperiments using the 2015 MICCAI Gland Challenge dataset and a lymph node\\nultrasound image segmentation dataset show that, using annotation suggestions\\nby our method, state-of-the-art segmentation performance can be achieved by\\nusing only 50% of training data.\\n',\n",
       " '  This paper introduce a software system including widely-used Swarm\\nIntelligence algorithms or approaches to be used for the related scientific\\nresearch studies associated with the subject area. The programmatic\\ninfrastructure of the system allows working on a fast, easy-to-use, interactive\\nplatform to perform Swarm Intelligence based studies in a more effective,\\nefficient and accurate way. In this sense, the system employs all of the\\nnecessary controls for the algorithms and it ensures an interactive platform on\\nwhich computer users can perform studies on a wide spectrum of solution\\napproaches associated with simple and also more advanced problems.\\n',\n",
       " '  This paper provides a full characterization of the value function and\\nsolution(s) of an optimal stopping problem for a one-dimensional diffusion with\\nan integral criterion. The results hold under very weak assumptions, namely,\\nthe diffusion is assumed to be a weak solution of stochastic differential\\nequation satisfying the Engelbert-Schmidt conditions, while the (stochastic)\\ndiscount rate and the integrand are required to satisfy only general\\nintegrability conditions.\\n',\n",
       " '  Recent detections of merging black holes allow observational tests of the\\nnature of these objects. In some proposed models, non-trivial structure at or\\nnear the black hole horizon could lead to echo signals in gravitational wave\\ndata. Recently, Abedi et al. claimed tentative evidence for repeating damped\\necho signals following the gravitational-wave signals of the binary black hole\\nmerger events recorded in the first observational period of the Advanced LIGO\\ninterferometers. We reanalyse the same data, addressing some of the\\nshortcomings of their method using more background data and a modified\\nprocedure. We find a reduced statistical significance for the claims of\\nevidence for echoes, calculating increased p-values for the null hypothesis of\\necho-free noise. The reduced significance is entirely consistent with noise,\\nand so we conclude that the analysis of Abedi et al. does not provide any\\nobservational evidence for the existence of Planck-scale structure at black\\nhole horizons.\\n',\n",
       " '  The universe is permeated by magnetic fields, with strengths ranging from a\\nfemtogauss in the voids between the filaments of galaxy clusters to several\\nteragauss in black holes and neutron stars. The standard model behind\\ncosmological magnetic fields is the nonlinear amplification of seed fields via\\nturbulent dynamo to the values observed. We have conceived experiments that aim\\nto demonstrate and study the turbulent dynamo mechanism in the laboratory. Here\\nwe describe the design of these experiments through simulation campaigns using\\nFLASH, a highly capable radiation magnetohydrodynamics code that we have\\ndeveloped, and large-scale three-dimensional simulations on the Mira\\nsupercomputer at Argonne National Laboratory. The simulation results indicate\\nthat the experimental platform may be capable of reaching a turbulent plasma\\nstate and study dynamo amplification. We validate and compare our numerical\\nresults with a small subset of experimental data using synthetic diagnostics.\\n',\n",
       " '  The chemotaxis system \\\\[ \\\\left\\\\{ \\\\begin{array}{l} u_t = \\\\Delta u - \\\\chi\\\\nabla\\n\\\\cdot (\\\\frac{u}{v}\\\\nabla v), v_t=\\\\Delta v - v+u, \\\\end{array} \\\\right. \\\\] is\\nconsidered in a bounded domain $\\\\Omega\\\\subset \\\\mathbb{R}^n$ with smooth\\nboundary, where $\\\\chi>0$. An apparently novel type of generalized solution\\nframework is introduced within which an extension of previously known ranges\\nfor the key parameter $\\\\chi$ with regard to global solvability is achieved. In\\nparticular, it is shown that under the hypothesis that\\\\[ \\\\chi < \\\\left\\\\{\\n\\\\begin{array}{ll} \\\\infty \\\\qquad & \\\\mbox{if } n=2, \\\\sqrt{8} \\\\qquad & \\\\mbox{if }\\nn=3, \\\\frac{n}{n-2} \\\\qquad & \\\\mbox{if } n\\\\ge 4, \\\\end{array} \\\\right. \\\\] for all\\ninitial data satisfying suitable assumptions on regularity and positivity, an\\nassociated no-flux initial-boundary value problem admits a globally defined\\ngeneralized solution. This solution inter alia has the property that \\\\[ u\\\\in\\nL^1_{loc}(\\\\bar\\\\Omega\\\\times [0,\\\\infty)). \\\\]\\n',\n",
       " '  Exploration of an unknown environment by a mobile robot is a complex task\\ninvolving solution of many fundamental problems from data processing,\\nlocalization to high-level planning and decision making. The exploration\\nframework we developed is based on processing of RGBD data provided by a MS\\nKinect2 sensor, which allows to take advantage of state-of-the-art SLAM\\n(Simultaneous Localization and Mapping) algorithms and to autonomously build a\\nrealistic 3D map of the environment with projected visual information about the\\nscene. In this paper, we describe practical issues that appeared during\\ndeployment of the framework in real indoor and outdoor environments and discuss\\nespecially properties of SLAM algorithms processing MS Kinect2 data on an\\nembedded computer.\\n',\n",
       " '  Humans have rich understanding of liquid containers and their contents; for\\nexample, we can effortlessly pour water from a pitcher to a cup. Doing so\\nrequires estimating the volume of the cup, approximating the amount of water in\\nthe pitcher, and predicting the behavior of water when we tilt the pitcher.\\nVery little attention in computer vision has been made to liquids and their\\ncontainers. In this paper, we study liquid containers and their contents, and\\npropose methods to estimate the volume of containers, approximate the amount of\\nliquid in them, and perform comparative volume estimations all from a single\\nRGB image. Furthermore, we show the results of the proposed model for\\npredicting the behavior of liquids inside containers when one tilts the\\ncontainers. We also introduce a new dataset of Containers Of liQuid contEnt\\n(COQE) that contains more than 5,000 images of 10,000 liquid containers in\\ncontext labelled with volume, amount of content, bounding box annotation, and\\ncorresponding similar 3D CAD models.\\n',\n",
       " \"  A theoretical study of ionization of the hydrogen atom due to an XUV pulse in\\nthe presence of an IR laser is presented. Well-established theories are usually\\nused to describe the problem of laser assisted photoelectron effect. However,\\nthe well-known soft-photon approximation firstly posed by Maquet et al in\\nJournal of Modern Optics 54, 1847 (2007) and Kazansky's theory in Phys. Rev. A\\n82, 033420 (2010) completely fails to predict the electron emission\\nprependicularly to the polarization direction. Making use of a simple\\nsemiclassical model, we study the angle-resolved energy distribution of\\nphotoelectrons for the case that both fields are linearly polarized in the same\\ndirection. We thoroughly analize and characterize two different emission\\nregions in the angle-energy domain: (i) the parallel-like region with\\ncontribution of two classical trajectories per optical cycle and (ii) the\\nperpendicular-like region with contribution of four classical trajectories per\\noptical cycle. We show that our semiclassical model is able to asses the\\ninterference patterns of the angle-resolved photoelectron spectrum in the two\\ndifferent mentioned regions. Electron trajectories stemming from different\\noptical laser cycles give rise to angle-independent intercycle interference\\nknown as sidebands. These sidebands are modulated by an angle-dependent\\ncoarse-grained structure coming from the intracycle interference of the\\nelectron trajectories born during the same optical cycle. We show the accuracy\\nof our semiclassical model as a function of the time delay between the IR and\\nthe XUV pulses and also as a function of the laser intensity by comparing the\\nsemiclassical predictions of the angle-resolved photoelectron spectrum with the\\ncontinuum-distorted wave strong field approximation and the ab initio solution\\nof the time dependent Schrödinger equation.\\n\",\n",
       " '  We present an image-based method for comparing the structural properties of\\ngalaxies produced in hydrodynamical simulations to real galaxies in the Sloan\\nDigital Sky Survey. The key feature of our work is the introduction of\\nextensive observational realism, such as object crowding, noise and viewing\\nangle, to the synthetic images of simulated galaxies, so that they can be\\nfairly compared to real galaxy catalogs. We apply our methodology to the\\ndust-free synthetic image catalog of galaxies from the Illustris simulation at\\n$z=0$, which are then fit with bulge+disc models to obtain morphological\\nparameters. In this first paper in a series, we detail our methods, quantify\\nobservational biases, and present publicly available bulge+disc decomposition\\ncatalogs. We find that our bulge+disc decompositions are largely robust to the\\nobservational biases that affect decompositions of real galaxies. However, we\\nidentify a significant population of galaxies (roughly 30\\\\% of the full sample)\\nin Illustris that are prone to internal segmentation, leading to systematically\\nreduced flux estimates by up to a factor of 6, smaller half-light radii by up\\nto a factor of $\\\\sim$ 2, and generally erroneous bulge-to-total fractions of\\n(B/T)=0.\\n',\n",
       " '  We determine the irreducible components of the space of 3x3 matrices of\\nlinear forms with vanishing determinant. We show that there are four\\nirreducible components and we identify them concretely. In particular, under\\nelementary row and column operations with constant coefficients, a 3x3 matrix\\nwith vanishing determinant is equivalent to one of the following four: a matrix\\nwith a zero row, a zero column, a zero 2x2 square or an antisymmetric matrix.\\n',\n",
       " '  Deep reinforcement learning (DRL) has gained a lot of attention in recent\\nyears, and has been proven to be able to play Atari games and Go at or above\\nhuman levels. However, those games are assumed to have a small fixed number of\\nactions and could be trained with a simple CNN network. In this paper, we study\\na special class of Asian popular card games called Dou Di Zhu, in which two\\nadversarial groups of agents must consider numerous card combinations at each\\ntime step, leading to huge number of actions. We propose a novel method to\\nhandle combinatorial actions, which we call combinational Q-learning (CQL). We\\nemploy a two-stage network to reduce action space and also leverage\\norder-invariant max-pooling operations to extract relationships between\\nprimitive actions. Results show that our method prevails over state-of-the art\\nmethods like naive Q-learning and A3C. We develop an easy-to-use card game\\nenvironments and train all agents adversarially from sractch, with only\\nknowledge of game rules and verify that our agents are comparative to humans.\\nOur code to reproduce all reported results will be available online.\\n',\n",
       " \"  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\\nin deep learning. Specifically, cuDNN implements several equivalent convolution\\nalgorithms, whose performance and memory footprint may vary considerably,\\ndepending on the layer dimensions. When an algorithm is automatically selected\\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\\nresorts to slower algorithms that fit the workspace size constraints. We\\npresent {\\\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\\nProgramming and Integer Linear Programming, {\\\\mu}-cuDNN enables faster\\nalgorithms by decreasing the workspace requirements. At the same time,\\n{\\\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\\neffectiveness of {\\\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\\nGPU. These results indicate that using micro-batches can seamlessly increase\\nthe performance of deep learning, while maintaining the same memory footprint.\\n\",\n",
       " '  In this paper, we endeavour to show that from the noncommutative nature of\\nspacetime one can deduce the concept of relativity in the sense that the\\nvelocity cannot be infinite as in the case of Galilean relativity.\\n',\n",
       " '  We demonstrate a simple projective measurement based on the quantum eraser\\nconcept that can be used to characterize the disturbances of any communication\\nchannel. Quantum erasers are commonly implemented as spatially separated path\\ninterferometric schemes. Here we exploit the advantages of redefining the\\nwhich-path information in terms of spatial modes, replacing physical paths with\\nabstract paths of orbital angular momentum (OAM). Remarkably, vector modes\\n(natural modes of free-space and fiber) have a non-separable feature of\\nspin-orbit coupled states, equivalent to the description of two independently\\nmarked paths. We explore the effects of fiber perturbations by probing a\\nstep-index optical fiber channel with a vector mode, relevant to high-order\\nspatial mode encoding of information for ultra-fast fiber communications.\\n',\n",
       " '  In this paper we consider Anderson model with a large number of sites with\\nzero interaction. For such models we study the spectral statistics in the\\nregion of complete localization. We show that Poisson statistics holds for such\\nenergies, by proving the Minami estimate.\\n',\n",
       " '  We study the slowing down of particle beams passing through the dusty plasma\\nwith power-law kappa-distributions. Three plasma components, electrons, ions\\nand dust particles, can have different kappa-parameter. We derive the\\ndeceleration factor (the velocity moment equation) and the slowing down time of\\na test particle, and numerically study the slowing down properties of an\\nelectron beam, a proton beam and a dust particle beam, respectively, in the\\nkappa-distributed dusty plasma. We show that the slowing down properties of\\nparticle beams depend strongly on the kappa-parameters of the plasma\\ncomponents, and the dust component plays a dominant role in the slowing down.\\nAnd the slowing down also depends on mass and charge of the dust particles in\\nthe dusty plasma. More detailed results are shown in 17 numerical graphs.\\n',\n",
       " '  We explore a natural analogy between Bayesian statistics and thermal physics\\nin which sample size corresponds to inverse temperature. This analogy motivates\\nthe definition of two novel statistical quantities: a learning capacity and a\\nGibbs entropy. The analysis of the learning capacity, corresponding to the heat\\ncapacity in thermal physics, leads to a critical insight into why some models\\nhave anomalously good learning performance. The mechanism is a statistical\\nanalogue of the failure of the equipartition theorem formula for the heat\\ncapacity. We explore the properties of the learning capacity in a number of\\nexamples, including a sloppy model. We also propose that the Gibbs entropy\\nprovides a natural device for counting distinguishable distributions in the\\ncontext of Bayesian inference. This insight results in a new solution to a\\nlong-standing problem in Bayesian inference: the definition of an objective or\\nuninformative prior. We use the Gibbs entropy to define a generalized principle\\nof indifference (GPI) in which every distinguishable model is assigned equal a\\npriori probability. This approach both resolves a number of long standing\\ninconsistencies in objective Bayesian inference and unifies several seemingly\\nunrelated Bayesian methods with the information-based paradigm of inference.\\n',\n",
       " '  The majority of medical documents and electronic health records (EHRs) are in\\ntext format that poses a challenge for data processing and finding relevant\\ndocuments. Looking for ways to automatically retrieve the enormous amount of\\nhealth and medical knowledge has always been an intriguing topic. Powerful\\nmethods have been developed in recent years to make the text processing\\nautomatic. One of the popular approaches to retrieve information based on\\ndiscovering the themes in health & medical corpora is topic modeling, however,\\nthis approach still needs new perspectives. In this research we describe fuzzy\\nlatent semantic analysis (FLSA), a novel approach in topic modeling using fuzzy\\nperspective. FLSA can handle health & medical corpora redundancy issue and\\nprovides a new method to estimate the number of topics. The quantitative\\nevaluations show that FLSA produces superior performance and features to latent\\nDirichlet allocation (LDA), the most popular topic model.\\n',\n",
       " \"  Stakeholders in the science system need to decide where to place their bets.\\nExample questions include: Which areas of research should get more funding? Who\\nshould we hire? Which projects should we abandon and which new projects should\\nwe start? Making informed choices requires knowledge about these research\\noptions. Unfortunately, to date research portfolio options have not been\\ndefined in a consistent, transparent and relevant manner. Furthermore, we don't\\nknow how to define demand for these options. In this article, we address the\\nissues of consistency, transparency, relevance and demand by using a model of\\nscience consisting of 91,726 topics (or research options) that contain over 58\\nmillion documents. We present a new indicator of topic prominence - a measure\\nof visibility, momentum and, ultimately, demand. We assign over $203 billion of\\nproject-level funding data from STAR METRICS to individual topics in science,\\nand show that the indicator of topic prominence, explains over one-third of the\\nvariance in current (or future) funding by topic. We also show that highly\\nprominent topics receive far more funding per researcher than topics that are\\nnot prominent. Implications of these results for research planning and\\nportfolio analysis by institutions and researchers are emphasized.\\n\",\n",
       " '  Sufficient and necessary conditions for the stability of positive feedback\\ninterconnections of negative imaginary systems are derived via an integral\\nquadratic constraint (IQC) approach. The IQC framework accommodates\\ndistributed-parameter systems with irrational transfer function\\nrepresentations, while generalising existing results in the literature and\\nallowing exploitation of flexibility at zero and infinite frequencies to reduce\\nconservatism in the analysis. The main results manifest the important property\\nthat the negative imaginariness of systems gives rise to a certain form of IQCs\\non positive frequencies that are bounded away from zero and infinity. Two\\nadditional sets of IQCs on the DC and instantaneous gains of the systems are\\nshown to be sufficient and necessary for closed-loop stability along a homotopy\\nof systems.\\n',\n",
       " '  In the modern era where highly-commodified cultural products compete heavily\\nfor mass consumption, finding the principles behind the complex process of how\\nsuccessful, \"hit\" products emerge remains a vital scientific goal that requires\\nan interdisciplinary approach. Here we present a framework for tracing the\\ncycle of prosperity-and-decline of a product to find insights into influential\\nand potent factors that determine its success. As a rapid, high-throughput\\nindicator of the preference of the public, popularity charts have emerged as a\\nuseful information source for finding the market performance patterns of\\nproducts over time, which we call the on-chart life trajectories that show how\\nthe products enter the chart, fare inside it, and eventually exit from it. We\\npropose quantitative parameters to characterise a life trajectory, and analyse\\na large-scale data set of nearly $7\\\\,000$ songs from Gaon Chart, a major weekly\\nKorean Pop (K-Pop) chart that cover a span of six years. We find that a\\nsignificant role is played by non-musical extrinsic factors such as the\\nestablished fan base of the artist and the might of production companies in the\\non-chart success of songs, strongly indicative of the commodified nature of\\nmodern cultural products. We also review a possible mathematical model of this\\nphenomenon, and discuss several nontrivial yet intriguing trajectories that we\\ncall the \"Late Bloomers\" and the \"Re-entrants\" that appears to be strongly\\ndriven by serendipitous exposure on mass media and the changes of seasons.\\n',\n",
       " '  The existence of several 2D materials with heavy atoms in their composition\\nhas been recently demonstrated. The electronic and optical properties of these\\nmaterials can be accurately computed with numerically intensive density\\nfunctional theory methods. However, it is desirable to have simple effective\\nmodels that can accurately describe these properties at low energies. Here we\\npresent an effective model for stanene that is reliable for electronic and\\noptical properties for photon energies up to 1.1 eV. For this material, we find\\nthat a quadratic model with respect to the lattice momentum is the best suited\\nfor calculations based on the bandstructure, even with respect to band warping.\\nWe also find that splitting the two spin-z subsectors is a good approximation,\\nwhich indicates that the lattice buckling can be neglected in calculations\\nbased on the bandstructure. We illustrate the applicability of the model by\\ncomputing the linear optical injection rates of carrier and spin densities in\\nstanene. Our calculations indicate that an incident circularly polarized\\noptical field only excites electrons with spin that matches its helicity.\\n',\n",
       " '  We prove that it is decidable whether or not a finitely generated submonoid\\nof a virtually free group is graded, introduce a new geometric characterization\\nas quasi-geodesic monoids, and show that their word problem is rational (as a\\nrelation). We also solve the isomorphism problem for this class of monoids,\\ngeneralizing earlier results for submonoids of free monoids. We also prove that\\nthe classes of graded monoids, regular monoids and Kleene monoids coincide for\\nsubmonoids of free groups.\\n',\n",
       " '  In this paper, we prove the existence of certain lifts of Hilbert cusp forms\\nto general odd spin groups. We then use those lifts to provide evidence for a\\nconjecture of Gross on the modularity of abelian varieties not of ${\\\\rm\\nGL}_2$-type.\\n',\n",
       " '  Recurrent Neural Networks (RNN) are widely used to solve a variety of\\nproblems and as the quantity of data and the amount of available compute have\\nincreased, so have model sizes. The number of parameters in recent\\nstate-of-the-art networks makes them hard to deploy, especially on mobile\\nphones and embedded devices. The challenge is due to both the size of the model\\nand the time it takes to evaluate it. In order to deploy these RNNs\\nefficiently, we propose a technique to reduce the parameters of a network by\\npruning weights during the initial training of the network. At the end of\\ntraining, the parameters of the network are sparse while accuracy is still\\nclose to the original dense neural network. The network size is reduced by 8x\\nand the time required to train the model remains constant. Additionally, we can\\nprune a larger dense network to achieve better than baseline performance while\\nstill reducing the total number of parameters significantly. Pruning RNNs\\nreduces the size of the model and can also help achieve significant inference\\ntime speed-up using sparse matrix multiply. Benchmarks show that using our\\ntechnique model size can be reduced by 90% and speed-up is around 2x to 7x.\\n',\n",
       " '  We introduce a novel method of quantum emulation of a classical reversible\\ncellular automaton. By applying this method to a chaotic cellular automaton,\\nthe obtained quantum many-body system thermalizes while all the energy\\neigenstates and eigenvalues are solvable. These explicit solutions allow us to\\nverify the validity of some scenarios of thermalization to this system. We find\\nthat two leading scenarios, the eigenstate thermalization hypothesis scenario\\nand the large effective dimension scenario, do not explain thermalization in\\nthis model.\\n',\n",
       " '  Recently, Dil and Boyadzhiev \\\\cite{AD2015} proved an explicit formula for the\\nsum of multiple harmonic numbers whose indices are the sequence $\\\\left(\\n{{\\\\left\\\\{ 0 \\\\right\\\\}_r},1} \\\\right)$. In this paper we show that the sums of\\nmultiple harmonic numbers whose indices are the sequence $\\\\left( {{\\\\left\\\\{ 0\\n\\\\right\\\\}_r,1};{\\\\left\\\\{ 1 \\\\right\\\\}_{k-1}}} \\\\right)$ can be expressed in terms\\nof (multiple) zeta values, multiple harmonic numbers and Stirling numbers of\\nthe first kind, and give an explicit formula.\\n',\n",
       " '  We ascertain the modularity-like objective function whose optimization is\\nequivalent to the maximum likelihood in annotated networks. We demonstrate that\\nthe modularity-like objective function is a linear combination of modularity\\nand conditional entropy. In contrast with statistical inference methods, in our\\nmethod, the influence of the metadata is adjustable; when its influence is\\nstrong enough, the metadata can be recovered. Conversely, when it is weak, the\\ndetection may correspond to another partition. Between the two, there is a\\ntransition. This paper provides a concept for expanding the scope of modularity\\nmethods.\\n',\n",
       " '  We give an efficient algorithm to enumerate all sets of $r\\\\ge 1$ quadratic\\npolynomials over a finite field, which remain irreducible under iterations and\\ncompositions.\\n',\n",
       " '  Mn doping of group-IV semiconductors (Si/Ge) is achieved by embedding a thin\\nMn-film as a {\\\\delta}-doped layer in group-IV matrix. The Mn-layer consists of\\na dense layer of monoatomic Mn-wires, which are oriented perpendicular to the\\nSi(001)-(2x1) dimer rows, or Mn-clusters. The nanostructures are covered with\\nan amorphous Si or Ge capping layer, which conserves the identity of the\\n{\\\\delta}-doped layer. The analysis of the bonding environment with STM is\\ncombined with the element-specific detection of the magnetic signature with\\nX-ray magnetic circular dichroism. The largest moment (2.5 {\\\\mu}B/Mn) is\\nmeasured for Mn-wires, which have ionic bonding character, with an a-Ge\\noverlayer cap, a-Si capping leads to a slightly reduced moment which has its\\norigin in subtle variation of bonding geometry. Our results directly confirm\\ntheoretical predictions on magnetism for Mn-adatoms on Si(001). The moment is\\nquenched to 0.5{\\\\mu}B/Mn for {\\\\delta}-doped layers, which are dominated by\\nclusters, and thus develop an antiferromagnetic component from Mn-Mn bonding.\\n',\n",
       " '  Pain remains a major concern in patients suffering from metastatic cancer to\\nthe bone and more knowledge of the condition, as well as novel treatment\\navenues, are called for. Neuropeptide Y (NPY) is a highly conserved peptide\\nthat appears to play a central role in nociceptive signaling in inflammatory\\nand neuropathic pain. However, little is known about the peptide in\\ncancer-induced bone pain. Here, we evaluate the role of spinal NPY in the\\nMRMT-1 rat model of cancer-induced bone pain. Our studies revealed an\\nup-regulation of NPY-immunoreactivity in the dorsal horn of cancer-bearing rats\\n17 days after inoculation, which could be a compensatory antinociceptive\\nresponse. Consistent with this interpretation, intrathecal administration of\\nNPY to rats with cancer-induced bone pain caused a reduction in nociceptive\\nbehaviors that lasted up to 150 min. This effect was diminished by both Y1\\n(BIBO3304) and Y2 (BIIE0246) receptor antagonists, indicating that both\\nreceptors participate in mediating the antinociceptive effect of NPY. Y1 and Y2\\nreceptor binding in the spinal cord was unchanged in the cancer state as\\ncompared to sham-operated rats, consistent with the notion that increased NPY\\nresults in a net antinociceptive effect in the MRMT-1 model. In conclusion, the\\ndata indicate that NPY is involved in the spinal nociceptive signaling of\\ncancer-induced bone pain and could be a new therapeutic target for patients\\nwith this condition.\\n',\n",
       " '  The mineral linarite, PbCuSO$_4$(OH)$_2$, is a spin 1/2 chain with\\nfrustrating nearest neighbor ferromagnetic and next-nearest neighbor\\nantiferromagnetic exchange interactions. Our inelastic neutron scattering\\nexperiments performed above the saturation field establish that the ratio\\nbetween these exchanges is such that linarite is extremely close to the quantum\\ncritical point between spin-multipolar phases and the ferromagnetic state.\\nHowever, the measured complex magnetic phase diagram depends strongly on the\\nmagnetic field direction. The field-dependent phase sequence is explained by\\nour classical simulations of a nearly critical model with tiny orthorhombic\\nexchange anisotropy. The simulations also capture qualitatively the measured\\nvariations of the wave vector as well as the staggered and the uniform\\nmagnetizations in an applied field.\\n',\n",
       " '  We extend the idea of tempering stable Levy processes to tempering more\\ngeneral classes of Levy processes. We show that the original process can be\\ndecomposed into the sum of the tempered process and an independent point\\nprocess of large jumps. We then use this to set up a rejection sampling\\nalgorithm for sampling from the tempered process. A small scale simulation\\nstudy is given to help understand the performance of this algorithm.\\n',\n",
       " '  A collection of articles on the statistical modelling and inference of social\\nnetworks is analysed in a network fashion. The references of these articles are\\nused to construct a citation network data set, which is almost a directed\\nacyclic graph because only existing articles can be cited. A mixed membership\\nstochastic block model is then applied to this data set to soft cluster the\\narticles. The results obtained from a Gibbs sampler give us insights into the\\ninfluence and the categorisation of these articles.\\n',\n",
       " '  We employ the very large cosmological hydrodynamical simulation BLUETIDES to\\ninvestigate the predicted properties of the galaxy population during the epoch\\nof reionisation ($z>8$). BLUETIDES has a resolution and volume ($(400/h\\\\approx\\n577)^{3}\\\\,{\\\\rm cMpc^3}$) providing a population of galaxies which is well\\nmatched to depth and area of current observational surveys targeting the\\nhigh-redshift Universe. At $z=8$ BLUETIDES includes almost 160,000 galaxies\\nwith stellar masses $>10^{8}\\\\,{\\\\rm M_{\\\\odot}}$. The population of galaxies\\npredicted by BLUETIDES closely matches observational constraints on both the\\ngalaxy stellar mass function and far-UV ($150\\\\,{\\\\rm nm}$) luminosity function.\\nGalaxies in BLUETIDES are characterised by rapidly increasing star formation\\nhistories. Specific star formation rates decrease with redshift though remain\\nlargely insensitive to stellar mass. As a result of the enhanced surface\\ndensity of metals more massive galaxies are predicted to have higher dust\\nattenuation resulting in a significant steepening of the observed far-UV\\nluminosity function at high luminosities. The contribution of active SMBHs to\\nthe UV luminosities of galaxies with stellar masses $10^{9-10}\\\\,{\\\\rm\\nM_{\\\\odot}}$ is around $3\\\\%$ on average. Approximately $25\\\\%$ of galaxies with\\n$M_{*}\\\\approx 10^{10}\\\\,{\\\\rm M_{\\\\odot}}$ are predicted to have active SMBH which\\ncontribute $>10\\\\%$ of the total UV luminosity.\\n',\n",
       " '  Empirical copula functions can be used to model the dependence structure of\\nmultivariate data. The Greenwald and Khanna algorithm is adapted in order to\\nprovide a space-memory efficient approximation to the empirical copula function\\nof a bivariate stream of data. A succinct space-memory efficient summary of\\nvalues seen in the stream up to a certain time is maintained and can be queried\\nat any point to return an approximation to the empirical bivariate copula\\nfunction with guaranteed error bounds. An example then illustrates how these\\nsummaries can be used as a tool to compute approximations to higher dimensional\\ncopula decompositions containing bivariate copulas. The computational benefits\\nand approximation error of the algorithm is theoretically and numerically\\nassessed.\\n',\n",
       " '  We give a simple, fast algorithm for hyperparameter optimization inspired by\\ntechniques from the analysis of Boolean functions. We focus on the\\nhigh-dimensional regime where the canonical example is training a neural\\nnetwork with a large number of hyperparameters. The algorithm --- an iterative\\napplication of compressed sensing techniques for orthogonal polynomials ---\\nrequires only uniform sampling of the hyperparameters and is thus easily\\nparallelizable.\\nExperiments for training deep neural networks on Cifar-10 show that compared\\nto state-of-the-art tools (e.g., Hyperband and Spearmint), our algorithm finds\\nsignificantly improved solutions, in some cases better than what is attainable\\nby hand-tuning. In terms of overall running time (i.e., time required to sample\\nvarious settings of hyperparameters plus additional computation time), we are\\nat least an order of magnitude faster than Hyperband and Bayesian Optimization.\\nWe also outperform Random Search 8x.\\nAdditionally, our method comes with provable guarantees and yields the first\\nimprovements on the sample complexity of learning decision trees in over two\\ndecades. In particular, we obtain the first quasi-polynomial time algorithm for\\nlearning noisy decision trees with polynomial sample complexity.\\n',\n",
       " '  This paper introduces a novel neural network-based reinforcement learning\\napproach for robot gaze control. Our approach enables a robot to learn and to\\nadapt its gaze control strategy for human-robot interaction neither with the\\nuse of external sensors nor with human supervision. The robot learns to focus\\nits attention onto groups of people from its own audio-visual experiences,\\nindependently of the number of people, of their positions and of their physical\\nappearances. In particular, we use a recurrent neural network architecture in\\ncombination with Q-learning to find an optimal action-selection policy; we\\npre-train the network using a simulated environment that mimics realistic\\nscenarios that involve speaking/silent participants, thus avoiding the need of\\ntedious sessions of a robot interacting with people. Our experimental\\nevaluation suggests that the proposed method is robust against parameter\\nestimation, i.e. the parameter values yielded by the method do not have a\\ndecisive impact on the performance. The best results are obtained when both\\naudio and visual information is jointly used. Experiments with the Nao robot\\nindicate that our framework is a step forward towards the autonomous learning\\nof socially acceptable gaze behavior.\\n',\n",
       " '  With the aim to reveal universal features of hadronic matter and correlated\\nDirac insulators in strong AC-electric fields, we study the $\\\\mathcal{N}=2$\\nsupersymmetric QCD with a finite quark mass driven by a rotating electric field\\n$\\\\mathcal{E}_x+i\\\\mathcal{E}_y= E e^{i\\\\Omega t}$. The analysis is done in the\\nholographically dual D3/D7 system in the co-rotating frame, effectively. The\\nnonequilibrium phase diagram is determined from the threshold electric field at\\nwhich the insulator phase breaks down to a conductive phase due to the AC\\nversion of the Schwinger mechanism. The external field induces a rotating\\ncurrent $\\\\mathcal{J}_x + i \\\\mathcal{J}_y = J e^{i\\\\Omega t}$ originating from\\nvacuum polarization and dissipative current in the insulating and conductive\\nphases respectively. Intriguing features are observed as the frequency $\\\\Omega$\\napproaches resonance with the meson excitation energy $\\\\Omega_{\\\\rm meson}$.\\nThere, the threshold minimizes and a condensate of vector mesons with\\noscillating current exists even in the zero driving field limit. This state,\\nwhich we call Floquet condensate of vector mesons, is expected to be\\ndynamically stable realizing a non-thermal fixed point that breaks time\\ntranslational and reversal symmetries. Our finding has many similarities with\\nexciton BEC discussed in solid state systems, where the semiconductor is to be\\nreplaced by materials hosting gapped Dirac electrons, e.g. 3D topological\\ninsulators or bismuth. Vector meson Floquet condensate may also have\\nimplications in the pre-thermalized dynamics in heavy ion collision\\nexperiments.\\n',\n",
       " '  We investigate how three different possibilities of neutrino mass\\nhierarchies, namely normal, inverted, and degenerate, can affect the\\nobservational constraints on three well known dynamical dark energy models,\\nnamely the Chevallier-Polarski-Linder, logarithmic, and the\\nJassal-Bagla-Padmanabhan parametrizations. In order to impose the observational\\nconstraints on the models, we performed a robust analysis using Planck 2015\\ntemperature and polarization data, Supernovae type Ia from Joint Light curve\\nanalysis, baryon acoustic oscillations distance measurements, redshift space\\ndistortion characterized by $f(z)\\\\sigma_8(z)$ data, weak gravitational lensing\\ndata from Canada-France-Hawaii Telescope Lensing Survey, and cosmic\\nchronometers data plus the local value of the Hubble parameter. We find that\\ndifferent neutrino mass hierarchies return similar fit on almost all model\\nparameters and mildly change the dynamical dark energy properties.\\n',\n",
       " '  Despite the rapid progress of the techniques for image classification, video\\nannotation has remained a challenging task. Automated video annotation would be\\na breakthrough technology, enabling users to search within the videos.\\nRecently, Google introduced the Cloud Video Intelligence API for video\\nanalysis. As per the website, the system can be used to \"separate signal from\\nnoise, by retrieving relevant information at the video, shot or per frame\"\\nlevel. A demonstration website has been also launched, which allows anyone to\\nselect a video for annotation. The API then detects the video labels (objects\\nwithin the video) as well as shot labels (description of the video events over\\ntime). In this paper, we examine the usability of the Google\\'s Cloud Video\\nIntelligence API in adversarial environments. In particular, we investigate\\nwhether an adversary can subtly manipulate a video in such a way that the API\\nwill return only the adversary-desired labels. For this, we select an image,\\nwhich is different from the video content, and insert it, periodically and at a\\nvery low rate, into the video. We found that if we insert one image every two\\nseconds, the API is deceived into annotating the video as if it only contained\\nthe inserted image. Note that the modification to the video is hardly\\nnoticeable as, for instance, for a typical frame rate of 25, we insert only one\\nimage per 50 video frames. We also found that, by inserting one image per\\nsecond, all the shot labels returned by the API are related to the inserted\\nimage. We perform the experiments on the sample videos provided by the API\\ndemonstration website and show that our attack is successful with different\\nvideos and images.\\n',\n",
       " '  A new slow growth formulation for DNS of wall-bounded turbulent flow is\\ndeveloped and demonstrated to enable extension of slow growth modeling concepts\\nto complex boundary layer flows. As in previous slow growth approaches, the\\nformulation assumes scale separation between the fast scales of turbulence and\\nthe slow evolution of statistics such as the mean flow. This separation enables\\nthe development of approaches where the fast scales of turbulence are directly\\nsimulated while the forcing provided by the slow evolution is modeled. The\\nresulting model admits periodic boundary conditions in the streamwise\\ndirection, which avoids the need for extremely long domains and complex inflow\\nconditions that typically accompany spatially developing simulations. Further,\\nit enables the use of efficient Fourier numerics. Unlike previous approaches,\\nthe present approach is based on a temporally evolving boundary layer and is\\nspecifically tailored to give results for calibration and validation of RANS\\nturbulence models. The use of a temporal homogenization simplifies the\\nmodeling, enabling straightforward extension to flows with complicating\\nfeatures, including cold and blowing walls. To generate data useful for\\ncalibration and validation of RANS models, special care is taken to ensure that\\nthe mean slow growth forcing is closed in terms of the mean and other\\nquantities that appear in standard RANS models, ensuring that there is no\\nconfounding between typical RANS closures and additional closures required for\\nthe slow growth problem. The performance of the method is demonstrated on two\\nproblems: an essentially incompressible, zero-pressure-gradient boundary layer\\nand a transonic boundary layer over a cooled wall with wall transpiration.\\n',\n",
       " \"  The primary aim of market segmentation is to identify relevant groups of\\nconsumers that can be addressed efficiently by marketing or advertising\\ncampaigns. This paper addresses the issue whether consumer groups can be\\nidentified from background variables that are not brand-related and how much\\npersonality vs. socio-demographic variables contribute to the identification of\\nconsumer clusters. This is done by clustering aggregated preferences for 25\\nbrands across 5 different product categories, and by relating socio-demographic\\nand personality variables to the clusters using logistic regression and random\\nforests over a range of different numbers of clusters. Results indicate that\\nsome personality variables contribute significantly to the identification of\\nconsumer groups in one sample. However, these results were not replicated on a\\nsecond sample that was more heterogeneous in terms of socio-demographic\\ncharacteristics and not representative of the brands' target audience.\\n\",\n",
       " '  Reliable propagation of information through large networks, e.g.,\\ncommunication networks, social networks or sensor networks is very important in\\nmany applications concerning marketing, social networks, and wireless sensor\\nnetworks. However, social ties of friendship may be obsolete, and communication\\nlinks may fail, inducing the notion of uncertainty in such networks. In this\\npaper, we address the problem of optimizing information propagation in\\nuncertain networks given a constrained budget of edges. We show that this\\nproblem requires to solve two NP-hard subproblems: the computation of expected\\ninformation flow, and the optimal choice of edges. To compute the expected\\ninformation flow to a source vertex, we propose the F-tree as a specialized\\ndata structure, that identifies independent components of the graph for which\\nthe information flow can either be computed analytically and efficiently, or\\nfor which traditional Monte-Carlo sampling can be applied independently of the\\nremaining network. For the problem of finding the optimal edges, we propose a\\nseries of heuristics that exploit properties of this data structure. Our\\nevaluation shows that these heuristics lead to high quality solutions, thus\\nyielding high information flow, while maintaining low running time.\\n',\n",
       " '  We address the role of Sn-substitution and Pb-vacancy (Pb-$\\\\Box$) in\\nregulating stability and carrier concentration of\\nCH$_3$NH$_3$Pb$_{1-X-Y}$Sn$_X$$\\\\Box_Y$I$_3$ perovskite using density functional\\ntheory, where the performance of the exchange-correlation functional is\\ncarefully analyzed, and validated w.r.t. available experimental results. We\\nfind the most stable configuration does not prefer any Pb at 50\\\\% concentration\\nof Sn. However, the Pb-$\\\\Box$s become unfavourable above 250K due to the\\nreduced linearity of Sn-I bonds. For n-type host the Sn substitution is more\\npreferable than Pb-$\\\\Box$ formation, while for p-type host the trend is exactly\\nopposite. The charge states of both Sn and Pb-$\\\\Box$ are found to be dependent\\non the Sn concentration, which in turn alters the perovskite from n-type to\\np-type with increasing $X$ ($>$0.5).\\n',\n",
       " '  The goal of point set registration is to find point-by-point correspondences\\nbetween point sets, each of which characterizes the shape of an object. Because\\nlocal preservation of object geometry is assumed, prevalent algorithms in the\\narea can often elegantly solve the problems without using geometric information\\nspecific to the objects. This means that registration performance can be\\nfurther improved by using prior knowledge of object geometry. In this paper, we\\npropose a novel point set registration method using the Gaussian mixture model\\nwith prior shape information encoded as a statistical shape model. Our\\ntransformation model is defined as a combination of the similar transformation,\\nmotion coherence, and the statistical shape model. Therefore, the proposed\\nmethod works effectively if the target point set includes outliers and missing\\nregions, or if it is rotated. The computational cost can be reduced to linear,\\nand therefore the method is scalable to large point sets. The effectiveness of\\nthe method will be verified through comparisons with existing algorithms using\\ndatasets concerning human body shapes, hands, and faces.\\n',\n",
       " '  We study the phase transition between conducting and insulating states taking\\nplace in disordered multi-channel Luttinger liquids with inter-channel\\ninteractions. We derive renormalisation group equations which are perturbative\\nin disorder but nonperturbative in interaction. In the vicinity of the\\nsimultaneous phase transition in all channels, these equations become a set of\\ncoupled Berezinskii--Kosterlitz--Thouless equations, which we analyze within\\ntwo models: an array of identical wires and a two-channel model with distinct\\nchannels. We show that a competition between disorder and interaction results\\nin a variety of phases, expected to be observable at intermediate temperatures\\nwhere the interaction and disorder are relevant but weak hybridization and the\\ncharge-density wave interaction may be ignored.\\n',\n",
       " '  In this paper, we study isolated singular positive solutions for the\\nfollowing Kirchhoff--type Laplacian problem: \\\\begin{equation*}\\n-\\\\left(\\\\theta+\\\\int_{\\\\Omega} |\\\\nabla u| dx\\\\right)\\\\Delta u =u^p \\\\quad{\\\\rm\\nin}\\\\quad \\\\Omega\\\\setminus \\\\{0\\\\},\\\\qquad u=0\\\\quad {\\\\rm on}\\\\quad \\\\partial \\\\Omega,\\n\\\\end{equation*} where $p>1$, $\\\\theta\\\\in \\\\R$, $\\\\Omega$ is a bounded smooth\\ndomain containing the origin in $\\\\R^N$ with $N\\\\ge 2$. In the subcritical case:\\n$1<p<N/(N-2)$ if $N\\\\ge3$, $1<p<+\\\\infty$ if $N=2$, we employ the Schauder\\nfixed-point theorem to derive a sequence of positive isolated singular\\nsolutions for the above problem such that $M_\\\\theta(u)>0$. To estimate\\n$M_\\\\theta(u)$, we make use of the rearrangement argument. Furthermore, we\\nobtain a sequence of isolated singular solutions such that $M_\\\\theta(u)<0$, by\\nanalyzing relationship between the parameter $\\\\lambda$ and the unique solution\\n$u_\\\\lambda$ of $$-\\\\Delta u+\\\\lambda u^p=k\\\\delta_0\\\\quad{\\\\rm in}\\\\quad\\nB_1(0),\\\\qquad u=0\\\\quad {\\\\rm on}\\\\quad \\\\partial B_1(0).$$ In the supercritical\\ncase: $N/(N-2)\\\\le p<(N+2)/(N-2)$ with $N\\\\ge3$, we obtain two isolated singular\\nsolutions $u_i$ with $i=1,2$ such that $M_\\\\theta(u_i)>0$ under some appropriate\\nassumptions.\\n',\n",
       " '  General human action recognition requires understanding of various visual\\ncues. In this paper, we propose a network architecture that computes and\\nintegrates the most important visual cues for action recognition: pose, motion,\\nand the raw images. For the integration, we introduce a Markov chain model\\nwhich adds cues successively. The resulting approach is efficient and\\napplicable to action classification as well as to spatial and temporal action\\nlocalization. The two contributions clearly improve the performance over\\nrespective baselines. The overall approach achieves state-of-the-art action\\nclassification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover,\\nit yields state-of-the-art spatio-temporal action localization results on\\nUCF101 and J-HMDB.\\n',\n",
       " \"  The reinforcement learning community has made great strides in designing\\nalgorithms capable of exceeding human performance on specific tasks. These\\nalgorithms are mostly trained one task at the time, each new task requiring to\\ntrain a brand new agent instance. This means the learning algorithm is general,\\nbut each solution is not; each agent can only solve the one task it was trained\\non. In this work, we study the problem of learning to master not one but\\nmultiple sequential-decision tasks at once. A general issue in multi-task\\nlearning is that a balance must be found between the needs of multiple tasks\\ncompeting for the limited resources of a single learning system. Many learning\\nalgorithms can get distracted by certain tasks in the set of tasks to solve.\\nSuch tasks appear more salient to the learning process, for instance because of\\nthe density or magnitude of the in-task rewards. This causes the algorithm to\\nfocus on those salient tasks at the expense of generality. We propose to\\nautomatically adapt the contribution of each task to the agent's updates, so\\nthat all tasks have a similar impact on the learning dynamics. This resulted in\\nstate of the art performance on learning to play all games in a set of 57\\ndiverse Atari games. Excitingly, our method learned a single trained policy -\\nwith a single set of weights - that exceeds median human performance. To our\\nknowledge, this was the first time a single agent surpassed human-level\\nperformance on this multi-task domain. The same approach also demonstrated\\nstate of the art performance on a set of 30 tasks in the 3D reinforcement\\nlearning platform DeepMind Lab.\\n\",\n",
       " '  We present the first results of a search for transient hard X-ray (HXR)\\nemission in the quiet solar corona with the \\\\textit{Nuclear Spectroscopic\\nTelescope Array} (\\\\textit{NuSTAR}) satellite. While \\\\textit{NuSTAR} was\\ndesigned as an astrophysics mission, it can observe the Sun above 2~keV with\\nunprecedented sensitivity due to its pioneering use of focusing optics.\\n\\\\textit{NuSTAR} first observed quiet Sun regions on 2014 November 1, although\\nout-of-view active regions contributed a notable amount of background in the\\nform of single-bounce (unfocused) X-rays. We conducted a search for quiet Sun\\ntransient brightenings on time scales of 100 s and set upper limits on emission\\nin two energy bands. We set 2.5--4~keV limits on brightenings with time scales\\nof 100 s, expressed as the temperature T and emission measure EM of a thermal\\nplasma. We also set 10--20~keV limits on brightenings with time scales of 30,\\n60, and 100 s, expressed as model-independent photon fluxes. The limits in both\\nbands are well below previous HXR microflare detections, though not low enough\\nto detect events of equivalent T and EM as quiet Sun brightenings seen in soft\\nX-ray observations. We expect future observations during solar minimum to\\nincrease the \\\\textit{NuSTAR} sensitivity by over two orders of magnitude due to\\nhigher instrument livetime and reduced solar background.\\n',\n",
       " '  Let n points be placed on a closed convex domain on the plane, no three\\npoints on a straight line.\\n',\n",
       " '  Networked applications traditionally derive their identity from the identity\\nof the host on which they run. The default application identity acquired from\\nthe host results in subtle and substantial problems related to application\\ndeployment, discovery and access, especially for modern distributed\\napplications. A number of mechanisms and workarounds, often quite elaborate,\\nare used to address those problems but they only address them indirectly and\\nincompletely.\\nThis paper presents AppSwitch, a novel transport layer network element that\\ndecouples applications from underlying network at the system call layer and\\nenables them to be identified independently of the network. Without requiring\\nchanges to existing applications or infrastructure, it removes the cost and\\ncomplexity associated with operating distributed applications while offering a\\nnumber of benefits including an efficient implementation of common network\\nfunctions such as application firewall and load balancer. Experiments with our\\nimplementation show that AppSwitch model also effectively removes the\\nperformance penalty associated with unnecessary data path processing that is\\ntypical in those application environments.\\n',\n",
       " '  Code loops are certain Moufang $2$-loops constructed from doubly even binary\\ncodes that play an important role in the construction of local subgroups of\\nsporadic groups. More precisely, code loops are central extensions of the group\\nof order $2$ by an elementary abelian $2$-group $V$ in the variety of loops\\nsuch that their squaring map, commutator map and associator map are related by\\ncombinatorial polarization and the associator map is a trilinear alternating\\nform.\\nUsing existing classifications of trilinear alternating forms over the field\\nof $2$ elements, we enumerate code loops of dimension $d=\\\\mathrm{dim}(V)\\\\le 8$\\n(equivalently, of order $2^{d+1}\\\\le 512$) up to isomorphism. There are $767$\\ncode loops of order $128$, and $80826$ of order $256$, and $937791557$ of order\\n$512$.\\n',\n",
       " '  It is proved that the derived subgroup of a finite group is nilpotent if and\\nonly if $|ab|\\\\ge |a||b|$ for all primary commutators $a$ and $b$ of coprime\\norders.\\n',\n",
       " '  We examine many-body localization properties for the eigenstates that lie in\\nthe droplet sector of the random-field spin-$\\\\frac 1 2$ XXZ chain. These states\\nsatisfy a basic single cluster localization property (SCLP), derived in\\n\\\\cite{EKS}. This leads to many consequences, including dynamical exponential\\nclustering, non-spreading of information under the time evolution, and a zero\\nvelocity Lieb Robinson bound. Since SCLP is only applicable to the droplet\\nsector, our definitions and proofs do not rely on knowledge of the spectral and\\ndynamical characteristics of the model outside this regime. Rather, to allow\\nfor a possible mobility transition, we adapt the notion of restricting the\\nHamiltonian to an energy window from the single particle setting to the many\\nbody context.\\n',\n",
       " \"  We perform mathematical anaysis of the biofilm development process. A model\\ndescribing biomass growth is proposed: It arises from coupling three parabolic\\nnonlinear equations: a biomass equation with degenerate and singular diffusion,\\na nutrient tranport equation with a biomass-density dependent diffusion, and an\\nequation of the Navier-Stokes type, describing the fluid flow in which the\\nbiofilm develops. This flow is subject to a biomass--density dependent\\nobstacle. The model is treated as a system of three inclusions, or variational\\ninequalities; the third one causes major difficulties for the system's\\nsolvability. Our approach is based on the recent development of the theory on\\nNavier-Stokes variational inequalities.\\n\",\n",
       " \"  In this paper, we propose a hybrid analog-digital beamforming architecture\\nwith resolution-adaptive ADCs for millimeter wave (mmWave) receivers with large\\nantenna arrays. We adopt array response vectors for the analog combiners and\\nderive ADC bit-allocation (BA) solutions in closed form. The BA solutions\\nreveal that the optimal number of ADC bits is logarithmically proportional to\\nthe RF chain's signal-to-noise ratio raised to the 1/3 power. Using the\\nsolutions, two proposed BA algorithms minimize the mean square quantization\\nerror of received analog signals under a total ADC power constraint.\\nContributions of this paper include 1) ADC bit-allocation algorithms to improve\\ncommunication performance of a hybrid MIMO receiver, 2) approximation of the\\ncapacity with the BA algorithm as a function of channels, and 3) a worst-case\\nanalysis of the ergodic rate of the proposed MIMO receiver that quantifies\\nsystem tradeoffs and serves as the lower bound. Simulation results demonstrate\\nthat the BA algorithms outperform a fixed-ADC approach in both spectral and\\nenergy efficiency, and validate the capacity and ergodic rate formula. For a\\npower constraint equivalent to that of fixed 4-bit ADCs, the revised BA\\nalgorithm makes the quantization error negligible while achieving 22% better\\nenergy efficiency. Having negligible quantization error allows existing\\nstate-of-the-art digital beamformers to be readily applied to the proposed\\nsystem.\\n\",\n",
       " '  Recently, Factorization Machines (FM) has become more and more popular for\\nrecommendation systems, due to its effectiveness in finding informative\\ninteractions between features. Usually, the weights for the interactions is\\nlearnt as a low rank weight matrix, which is formulated as an inner product of\\ntwo low rank matrices. This low rank can help improve the generalization\\nability of Factorization Machines. However, to choose the rank properly, it\\nusually needs to run the algorithm for many times using different ranks, which\\nclearly is inefficient for some large-scale datasets. To alleviate this issue,\\nwe propose an Adaptive Boosting framework of Factorization Machines (AdaFM),\\nwhich can adaptively search for proper ranks for different datasets without\\nre-training. Instead of using a fixed rank for FM, the proposed algorithm will\\nadaptively gradually increases its rank according to its performance until the\\nperformance does not grow, using boosting strategy. To verify the performance\\nof our proposed framework, we conduct an extensive set of experiments on many\\nreal-world datasets. Encouraging empirical results shows that the proposed\\nalgorithms are generally more effective than state-of-the-art other\\nFactorization Machines.\\n',\n",
       " '  For a given region, we have a dataset composed of car theft locations along\\nwith a linked dataset of recovery locations which, due to partial recovery, is\\na relatively small subset of the set of theft locations. For an investigator\\nseeking to understand the behavior of car thefts and recoveries in the region,\\nseveral questions are addressed. Viewing the set of theft locations as a point\\npattern, can we propose useful models to explain the pattern? What types of\\npredictive models can be built to learn about recovery location given theft\\nlocation? Can the dependence between theft locations and recovery locations be\\nformalized? Can the flow between theft sites and recovery sites be captured?\\nOrigin-destination modeling offers a natural framework for such problems.\\nHowever, here the data is not for areal units but rather is a pair of point\\npatterns, with the recovery point pattern only partially observed. We offer\\nmodeling approaches for investigating the questions above and apply the\\napproaches to two datasets. One is small from the state of Neza in Mexico with\\nareal covariate information regarding population features and crime type. A\\nsecond, much larger one, is from Belo Horizonte in Brazil but lacks covariates.\\n',\n",
       " '  We consider a parameter estimation problem for one dimensional stochastic\\nheat equations, when data is sampled discretely in time or spatial component.\\nWe establish some general results on derivation of consistent and\\nasymptotically normal estimators based on computation of the $p$-variations of\\nstochastic processes and their smooth perturbations. We apply these results to\\nthe considered SPDEs, by using some convenient representations of the\\nsolutions. For some equations such results were ready available, while for\\nother classes of SPDEs we derived the needed representations along with their\\nstatistical asymptotical properties. We prove that the real valued parameter\\nnext to the Laplacian, and the constant parameter in front of the noise (the\\nvolatility) can be consistently estimated by observing the solution at a fixed\\ntime and on a discrete spatial grid, or at a fixed space point and at discrete\\ntime instances of a finite interval, assuming that the mesh-size goes to zero.\\n',\n",
       " '  We report the first experimental measurement of the near-threshold\\nphoto-ionization spectra of polycyclic aromatic hydrocarbon clusters made of\\npyrene C16H10 and coronene C24H12, obtained using imaging photoelectron\\nphotoion coincidence spectrometry with a VUV synchrotron beamline. The\\nexperimental results of the ionization energy are confronted to calculated ones\\nobtained from simulations using dedicated electronic structure treatment for\\nlarge ionized molecular clusters. Experiment and theory consistently find a\\ndecrease of the ionization energy with cluster size. The inclusion of\\ntemperature effects in the simulations leads to a lowering of this energy and\\nto a quantitative agreement with the experiment. In the case of pyrene, both\\ntheory and experiment show a discontinuity in the IE trend for the hexamer.\\n',\n",
       " '  We consider the problem of training generative models with deep neural\\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\\ndominant paradigm combines simple priors over codes with complex deterministic\\nmodels, we argue that it might be advantageous to use more flexible code\\ndistributions. We demonstrate how these distributions can be induced directly\\nfrom the data. The benefits include: more powerful generative models, better\\nmodeling of latent structure and explicit control of the degree of\\ngeneralization.\\n',\n",
       " \"  Let $K$ be a field. We simplify and extend work of Althaler \\\\& Dür on\\nfinite sequences over $K$ by regarding $K[x^{-1},z^{-1}]$ as a $K[x,z]$ module,\\nand studying forms in $K[x^{-1},z^{-1}]$ from first principles. Then we apply\\nour results to finite sequences.\\nFirst we define the annihilator ideal $I_F$ of a non-zero form $F\\\\in\\nK[x^{-1},z^{-1}]$, a homogeneous ideal. We inductively construct an ordered\\npair ($f_1$\\\\,,\\\\,$f_2$) of forms which generate $I_F$\\\\,; our generators are\\nspecial in that $z$ does not divide the leading grlex monomial of $f_1$ but $z$\\ndivides $f_2$\\\\,, and the sum of their total degrees is always $2-|F|$, where\\n$|F|$ is the total degree of $F$. We show that $f_1,f_2$ is a maximal regular\\nsequence for $I_F$, so that the height of $I_F$ is 2. The corresponding\\nalgorithm is $\\\\sim |F|^2/2$.\\nThe row vector obtained by accumulating intermediate forms of the\\nconstruction gives a minimal grlex Gröbner basis for $I_F$ for no extra\\ncomputational cost other than storage and apply this to determining $\\\\dim_K\\n(K[x,z] /I_F)$\\\\,. We show that either the form vector is reduced or a monomial\\nof $f_1$ can be reduced by $f_2$\\\\,. This enables us to efficiently construct\\nthe unique reduced Gröbner basis for $I_F$ from the vector extension of our\\nalgorithm.\\nThen we specialise to the inverse form of a finite sequence, obtaining\\ngenerator forms for its annihilator ideal and a corresponding algorithm which\\ndoes not use the last 'length change' of Massey. We compute the intersection of\\ntwo annihilator ideals using syzygies in $K[x,z]^5$. This improves a result of\\nAlthaler \\\\& Dür. Finally, dehomogenisation induces a one-to-one\\ncorrespondence ($f_1$\\\\,,$f_2$) $\\\\mapsto$ (minimal polynomial, auxiliary\\npolynomial), the output of the author's variant of the Berlekamp-Massey\\nalgorithm. So we can also solve the LFSR synthesis problem via the\\ncorresponding algorithm for sequences.\\n\",\n",
       " \"  Named Entity Recognition (NER) is one of the most common tasks of the natural\\nlanguage processing. The purpose of NER is to find and classify tokens in text\\ndocuments into predefined categories called tags, such as person names,\\nquantity expressions, percentage expressions, names of locations,\\norganizations, as well as expression of time, currency and others. Although\\nthere is a number of approaches have been proposed for this task in Russian\\nlanguage, it still has a substantial potential for the better solutions. In\\nthis work, we studied several deep neural network models starting from vanilla\\nBi-directional Long Short-Term Memory (Bi-LSTM) then supplementing it with\\nConditional Random Fields (CRF) as well as highway networks and finally adding\\nexternal word embeddings. All models were evaluated across three datasets:\\nGareev's dataset, Person-1000, FactRuEval-2016. We found that extension of\\nBi-LSTM model with CRF significantly increased the quality of predictions.\\nEncoding input tokens with external word embeddings reduced training time and\\nallowed to achieve state of the art for the Russian NER task.\\n\",\n",
       " '  Most visual odometry algorithm for a monocular camera focuses on points,\\neither by feature matching, or direct alignment of pixel intensity, while\\nignoring a common but important geometry entity: edges. In this paper, we\\npropose an odometry algorithm that combines points and edges to benefit from\\nthe advantages of both direct and feature based methods. It works better in\\ntexture-less environments and is also more robust to lighting changes and fast\\nmotion by increasing the convergence basin. We maintain a depth map for the\\nkeyframe then in the tracking part, the camera pose is recovered by minimizing\\nboth the photometric error and geometric error to the matched edge in a\\nprobabilistic framework. In the mapping part, edge is used to speed up and\\nincrease stereo matching accuracy. On various public datasets, our algorithm\\nachieves better or comparable performance than state-of-the-art monocular\\nodometry methods. In some challenging texture-less environments, our algorithm\\nreduces the state estimation error over 50%.\\n',\n",
       " '  Data for good implies unfettered access to data. But data owners must be\\nconservative about how, when, and why they share data or risk violating the\\ntrust of the people they aim to help, losing their funding, or breaking the\\nlaw. Data sharing agreements can help prevent privacy violations, but require a\\nlevel of specificity that is premature during preliminary discussions, and can\\ntake over a year to establish.\\nWe consider the generation and use of synthetic data to facilitate ad hoc\\ncollaborations involving sensitive data. A good synthetic dataset has two\\nproperties: it is representative of the original data, and it provides strong\\nguarantees about privacy.\\nIn this paper, we discuss important use cases for synthetic data that\\nchallenge the state of the art in privacy-preserving data generation, and\\ndescribe DataSynthesizer, a dataset generation tool that takes a sensitive\\ndataset as input and generates a structurally and statistically similar\\nsynthetic dataset, with strong privacy guarantees, as output. The data owners\\nneed not release their data, while potential collaborators can begin developing\\nmodels and methods with some confidence that their results will work similarly\\non the real dataset. The distinguishing feature of DataSynthesizer is its\\nusability - in most cases, the data owner need not specify any parameters to\\nstart generating and sharing data safely and effectively.\\nThe code implementing DataSynthesizer is publicly available on GitHub at\\nthis https URL. The work on DataSynthesizer is part of the\\nData, Responsibly project, where the goal is to operationalize responsibility\\nin data sharing, integration, analysis and use.\\n',\n",
       " '  We prove that when suitably normalized, small enough powers of the absolute\\nvalue of the characteristic polynomial of random Hermitian matrices, drawn from\\none-cut regular unitary invariant ensembles, converge in law to Gaussian\\nmultiplicative chaos measures. We prove this in the so-called $L^2$-phase of\\nmultiplicative chaos. Our main tools are asymptotics of Hankel determinants\\nwith Fisher-Hartwig singularities. Using Riemann-Hilbert methods, we prove a\\nrather general Fisher-Hartwig formula for one-cut regular unitary invariant\\nensembles.\\n',\n",
       " '  In horizontal collaborations, carriers form coalitions in order to perform\\nparts of their logistics operations jointly. By exchanging transportation\\nrequests among each other, they can operate more efficiently and in a more\\nsustainable way. Collaborative vehicle routing has been extensively discussed\\nin the literature. We identify three major streams of research: (i) centralized\\ncollaborative planning, (ii) decentralized planning without auctions, and (ii)\\nauction-based decentralized planning. For each of them we give a structured\\noverview on the state of knowledge and discuss future research directions.\\n',\n",
       " '  We use an atomistic spin model derived from density functional theory\\ncalculations for the ultra-thin film Pd/Fe/Ir(111) to show that temperature\\ninduces coexisting non-zero skyrmion and antiskyrmion densities. We apply the\\nparallel tempering Monte Carlo method in order to reliably compute\\nthermodynamical quantities and the B-T phase diagram in the presence of\\nfrustrated exchange interactions. We evaluate the critical temperatures using\\nthe topological susceptibility. We show that the critical temperatures depend\\non the magnetic field in contrast to previous work. In total, we identify five\\nphases: spin spiral, skyrmion lattice, ferromagnetic phase, intermediate region\\nwith finite topological charge and paramagnetic phase. To explore the effect of\\nfrustrated exchange interactions, we calculate the B-T phase diagram, when only\\neffective exchange parameters are taken into account.\\n',\n",
       " '  We present a framework to systematically analyze convolutional neural\\nnetworks (CNNs) used in classification of cars in autonomous vehicles. Our\\nanalysis procedure comprises an image generator that produces synthetic\\npictures by sampling in a lower dimension image modification subspace and a\\nsuite of visualization tools. The image generator produces images which can be\\nused to test the CNN and hence expose its vulnerabilities. The presented\\nframework can be used to extract insights of the CNN classifier, compare across\\nclassification models, or generate training and validation datasets.\\n',\n",
       " '  A geometrical pattern is a set of points with all pairwise distances (or,\\nmore generally, relative distances) specified. Finding matches to such patterns\\nhas applications to spatial data in seismic, astronomical, and transportation\\ncontexts. For example, a particularly interesting geometric pattern in\\nastronomy is the Einstein cross, which is an astronomical phenomenon in which a\\nsingle quasar is observed as four distinct sky objects (due to gravitational\\nlensing) when captured by earth telescopes. Finding such crosses, as well as\\nother geometric patterns, is a challenging problem as the potential number of\\nsets of elements that compose shapes is exponentially large in the size of the\\ndataset and the pattern. In this paper, we denote geometric patterns as\\nconstellation queries and propose algorithms to find them in large data\\napplications. Our methods combine quadtrees, matrix multiplication, and\\nunindexed join processing to discover sets of points that match a geometric\\npattern within some additive factor on the pairwise distances. Our distributed\\nexperiments show that the choice of composition algorithm (matrix\\nmultiplication or nested loops) depends on the freedom introduced in the query\\ngeometry through the distance additive factor. Three clearly identified blocks\\nof threshold values guide the choice of the best composition algorithm.\\nFinally, solving the problem for relative distances requires a novel\\ncontinuous-to-discrete transformation. To the best of our knowledge this paper\\nis the first to investigate constellation queries at scale.\\n',\n",
       " '  We present an Environmental Control System (ECS) designed to achieve\\nmilliKelvin (mK) level temperature stability for small-scale astronomical\\ninstruments. This ECS is inexpensive and is primarily built from commercially\\navailable components. The primary application for our ECS is the high-precision\\nDoppler spectrometer MINERVA-Red, where the thermal variations of the optical\\ncomponents within the instrument represent a major source of systematic error.\\nWe demonstrate $\\\\pm 2$ mK temperature stability within a 0.5 m$^{3}$ Thermal\\nEnclosure using resistive heaters in conjunction with a commercially available\\nPID controller and off-the-shelf thermal sensors. The enclosure is maintained\\nabove ambient temperature, enabling rapid cooling through heat dissipation into\\nthe surrounding environment. We demonstrate peak-to-valley (PV) temperature\\nstability of better than 5 mK within the MINERVA-Red vacuum chamber, which is\\nlocated inside the Thermal Enclosure, despite large temperature swings in the\\nambient laboratory environment. During periods of stable laboratory conditions,\\nthe PV variations within the vacuum chamber are less than 3 mK. This\\ntemperature stability is comparable to the best stability demonstrated for\\nDoppler spectrometers currently achieving 1 m s$^{-1}$ radial velocity\\nprecision. We discuss the challenges of using commercially available\\nthermoelectrically cooled CCD cameras in a temperature-stabilized environment,\\nand demonstrate that the effects of variable heat output from the CCD camera\\nbody can be mitigated using PID-controlled chilled water systems. The ECS\\npresented here could potentially provide the stable operating environment\\nrequired for future compact, \"astro-photonic\" precise radial velocity (PRV)\\nspectrometers to achieve high Doppler measurement precision with a modest\\nbudget.\\n',\n",
       " '  We consider a multi-server queueing system under the power-of-two policy with\\nPoisson job arrivals, heterogeneous servers and a general job requirement\\ndistribution; each server operates under the first-come first-serve policy and\\nthere are no buffer constraints. We analyze the performance of this system in\\nlight traffic by evaluating the first two light traffic derivatives of the\\naverage job response time. These expressions point to several interesting\\nstructural features associated with server heterogeneity in light traffic: For\\nunequal capacities, the average job response time is seen to decrease for small\\nvalues of the arrival rate, and the more diverse the server speeds, the greater\\nthe gain in performance. These theoretical findings are assessed through\\nlimited simulations.\\n',\n",
       " '  Can Crowds serve as useful allies in policy design? How do non-expert Crowds\\nperform relative to experts in the assessment of policy measures? Does the\\ngeographic location of non-expert Crowds, with relevance to the policy context,\\nalter the performance of non-experts Crowds in the assessment of policy\\nmeasures? In this work, we investigate these questions by undertaking\\nexperiments designed to replicate expert policy assessments with non-expert\\nCrowds recruited from Virtual Labor Markets. We use a set of ninety-six climate\\nchange adaptation policy measures previously evaluated by experts in the\\nNetherlands as our control condition to conduct experiments using two discrete\\nsets of non-expert Crowds recruited from Virtual Labor Markets. We vary the\\ncomposition of our non-expert Crowds along two conditions: participants\\nrecruited from a geographical location directly relevant to the policy context\\nand participants recruited at-large. We discuss our research methods in detail\\nand provide the findings of our experiments.\\n',\n",
       " '  Co-occurrences between two words provide useful insights into the semantics\\nof those words. Consequently, numerous prior work on word embedding learning\\nhave used co-occurrences between two words as the training signal for learning\\nword embeddings. However, in natural language texts it is common for multiple\\nwords to be related and co-occurring in the same context. We extend the notion\\nof co-occurrences to cover $k(\\\\geq\\\\!\\\\!2)$-way co-occurrences among a set of\\n$k$-words. Specifically, we prove a theoretical relationship between the joint\\nprobability of $k(\\\\geq\\\\!\\\\!2)$ words, and the sum of $\\\\ell_2$ norms of their\\nembeddings. Next, we propose a learning objective motivated by our theoretical\\nresult that utilises $k$-way co-occurrences for learning word embeddings. Our\\nexperimental results show that the derived theoretical relationship does indeed\\nhold empirically, and despite data sparsity, for some smaller $k$ values,\\n$k$-way embeddings perform comparably or better than $2$-way embeddings in a\\nrange of tasks.\\n',\n",
       " '  Recent advances in the understanding and control of quantum technologies,\\nsuch as those based on cold atoms, have resulted in devices with extraordinary\\nmetrological sensitivities. To realise this potential outside of a lab\\nenvironment the size, weight and power consumption need to be reduced. Here we\\ndemonstrate the use of laser powder bed fusion, an additive manufacturing\\ntechnique, as a production technique for the components that make up quantum\\nsensors. As a demonstration we have constructed two key components using\\nadditive manufacturing, namely magnetic shielding and vacuum chambers. The\\ninitial prototypes for magnetic shields show shielding factors within a factor\\nof 3 of conventional approaches. The vacuum demonstrator device shows that\\n3D-printed titanium structures are suitable for use as vacuum chambers, with\\nthe test system reaching base pressures of $5 \\\\pm 0.5 \\\\times 10^{-10}$ mbar.\\nThese demonstrations show considerable promise for the use of additive\\nmanufacturing for cold atom based quantum technologies, in future enabling\\nimproved integrated structures, allowing for the reduction in size, weight and\\nassembly complexity.\\n',\n",
       " \"  Graph layout is the process of creating a visual representation of a graph\\nthrough a node-link diagram. Node-attribute graphs have additional data stored\\non the nodes which describe certain properties of the nodes called attributes.\\nTypical force-directed representations often produce hairball-like structures\\nthat neither aid in understanding the graph's topology nor the relationship to\\nits attributes. The aim of this research was to investigate the use of\\nnode-attributes for graph layout in order to improve the analysis process and\\nto give further insight into the graph over purely topological layouts. In this\\narticle we present graphTPP, a graph based extension to targeted projection\\npursuit (TPP) --- an interactive, linear, dimension reduction technique --- as\\na method for graph layout and subsequent further analysis. TPP allows users to\\ncontrol the projection and is optimised for clustering. Three case studies were\\nconducted in the areas of influence graphs, network security, and citation\\nnetworks. In each case graphTPP was shown to outperform standard force-directed\\ntechniques and even other dimension reduction methods in terms of clarity of\\nclustered structure in the layout, the association between the structure and\\nthe attributes and the insights elicited in each domain area.\\n\",\n",
       " '  We study light propagation through a slab of cold gas using both the standard\\nelectrodynamics of polarizable media, and massive atom-by-atom simulations of\\nthe electrodynamics. The main finding is that the predictions from the two\\nmethods may differ qualitatively when the density of the atomic sample $\\\\rho$\\nand the wavenumber of resonant light $k$ satisfy $\\\\rho k^{-3}\\\\gtrsim 1$. The\\nreason is that the standard electrodynamics is a mean-field theory, whereas for\\nsufficiently strong light-mediated dipole-dipole interactions the atomic sample\\nbecomes correlated. The deviations from mean-field theory appear to scale with\\nthe parameter $\\\\rho k^{-3}$, and we demonstrate noticeable effects already at\\n$\\\\rho k^{-3} \\\\simeq 10^{-2}$. In dilute gases and in gases with an added\\ninhomogeneous broadening the simulations show shifts of the resonance lines in\\nqualitative agreement with the predicted Lorentz-Lorenz shift and \"cooperative\\nLamb shift\", but the quantitative agreement is unsatisfactory. Our\\ninterpretation is that the microscopic basis for the local-field corrections in\\nelectrodynamics is not fully understood.\\n',\n",
       " '  Big data has shown its uniquely powerful ability to reveal, model, and\\nunderstand driver behaviors. The amount of data affects the experiment cost and\\nconclusions in the analysis. Insufficient data may lead to inaccurate models\\nwhile excessive data waste resources. For projects that cost millions of\\ndollars, it is critical to determine the right amount of data needed. However,\\nhow to decide the appropriate amount has not been fully studied in the realm of\\ndriver behaviors. This paper systematically investigates this issue to estimate\\nhow much naturalistic driving data (NDD) is needed for understanding driver\\nbehaviors from a statistical point of view. A general assessment method is\\nproposed using a Gaussian kernel density estimation to catch the underlying\\ncharacteristics of driver behaviors. We then apply the Kullback-Liebler\\ndivergence method to measure the similarity between density functions with\\ndiffering amounts of NDD. A max-minimum approach is used to compute the\\nappropriate amount of NDD. To validate our proposed method, we investigated the\\ncar-following case using NDD collected from the University of Michigan Safety\\nPilot Model Deployment (SPMD) program. We demonstrate that from a statistical\\nperspective, the proposed approach can provide an appropriate amount of NDD\\ncapable of capturing most features of the normal car-following behavior, which\\nis consistent with the experiment settings in many literatures.\\n',\n",
       " '  We theoretically discuss why deep neural networks (DNNs) performs better than\\nother models in some cases by investigating statistical properties of DNNs for\\nnon-smooth functions. While DNNs have empirically shown higher performance than\\nother standard methods, understanding its mechanism is still a challenging\\nproblem. From an aspect of the statistical theory, it is known many standard\\nmethods attain the optimal rate of generalization errors for smooth functions\\nin large sample asymptotics, and thus it has not been straightforward to find\\ntheoretical advantages of DNNs. This paper fills this gap by considering\\nlearning of a certain class of non-smooth functions, which was not covered by\\nthe previous theory. We derive the generalization error of estimators by DNNs\\nwith a ReLU activation, and show that convergence rates of the generalization\\nby DNNs are almost optimal to estimate the non-smooth functions, while some of\\nthe popular models do not attain the optimal rate. In addition, our theoretical\\nresult provides guidelines for selecting an appropriate number of layers and\\nedges of DNNs. We provide numerical experiments to support the theoretical\\nresults.\\n',\n",
       " '  Large-scale collaborative analysis of brain imaging data, in psychiatry and\\nneu-rology, offers a new source of statistical power to discover features that\\nboost ac-curacy in disease classification, differential diagnosis, and outcome\\nprediction. However, due to data privacy regulations or limited accessibility\\nto large datasets across the world, it is challenging to efficiently integrate\\ndistributed information. Here we propose a novel classification framework\\nthrough multi-site weighted LASSO: each site performs an iterative weighted\\nLASSO for feature selection separately. Within each iteration, the\\nclassification result and the selected features are collected to update the\\nweighting parameters for each feature. This new weight is used to guide the\\nLASSO process at the next iteration. Only the fea-tures that help to improve\\nthe classification accuracy are preserved. In tests on da-ta from five sites\\n(299 patients with major depressive disorder (MDD) and 258 normal controls),\\nour method boosted classification accuracy for MDD by 4.9% on average. This\\nresult shows the potential of the proposed new strategy as an ef-fective and\\npractical collaborative platform for machine learning on large scale\\ndistributed imaging and biobank data.\\n',\n",
       " '  It is already known that the Cesàro matrices of orders one and two are\\ncoposinormal, hyponormal operators on $\\\\ell^2$. Here it is shown that the\\nCesàro matrices of order three and four are also coposinormal, hyponormal;\\nthe proofs employ posinormality, achieved by means of a diagonal interrupter,\\nand elementary computational techniques from calculus. A conjecture is then\\npropounded for the Cesàro matrix of positive integer order greater than\\nfour.\\n',\n",
       " '  We consider an energy harvesting communication system where the temperature\\ndynamics is governed by the transmission power policy. Different from the\\nprevious work, we consider a discrete time system where transmission power is\\nkept constant in each slot. We consider two models that capture different\\neffects of temperature. In the first model, the temperature is constrained to\\nbe below a critical temperature at all time instants; we coin this model as\\nexplicit temperature constrained model. We investigate throughput optimal power\\nallocation for multiple energy arrivals under general, as well as temperature\\nand energy limited regimes. We show that the optimal power allocation for the\\ntemperature limited case is monotone decreasing. In the second model, we\\nconsider the effect of the temperature on the channel quality via its influence\\non additive noise power; we coin this model as implicit temperature constrained\\nmodel. In this model, the change in the variance of the additive noise due to\\nprevious transmissions is non-negligible. In particular, transmitted signals\\ncontribute as interference for all subsequent slots and thus affect the signal\\nto interference plus noise ratio (SINR). In this case, we investigate\\nthroughput optimal power allocation under general, as well as low and high SINR\\nregimes. We show in the low SINR regime that the optimal allocation dictates\\nthe transmitter to save its harvested energy till the last slot. In the high\\nSINR regime, we show that the optimal power sequence is monotone increasing.\\nFinally, we consider the case in which implicit and explicit temperature\\nconstraints are simultaneously active and we show under certain conditions that\\nthe optimal power sequence is monotone decreasing.\\n',\n",
       " '  Consider an experiment involving a potentially small number of subjects. Some\\nrandom variables are observed on each subject: a high-dimensional one called\\nthe \"observed\" random variable, and a one-dimensional one called the \"outcome\"\\nrandom variable. We are interested in the dependencies between the observed\\nrandom variable and the outcome random variable. We propose a method to\\nquantify and validate the dependencies of the outcome random variable on the\\nvarious patterns contained in the observed random variable. Different degrees\\nof relationship are explored (linear, quadratic, cubic, ...). This work is\\nmotivated by the need to analyze educational data, which often involves\\nhigh-dimensional data representing a small number of students. Thus our\\nimplementation is designed for a small number of subjects; however, it can be\\neasily modified to handle a very large dataset. As an illustration, the\\nproposed method is used to study the influence of certain skills on the course\\ngrade of students in a signal processing class. A valid dependency of the grade\\non the different skill patterns is observed in the data.\\n',\n",
       " '  Sentence simplification aims to make sentences easier to read and understand.\\nMost recent approaches draw on insights from machine translation to learn\\nsimplification rewrites from monolingual corpora of complex and simple\\nsentences. We address the simplification problem with an encoder-decoder model\\ncoupled with a deep reinforcement learning framework. Our model, which we call\\n{\\\\sc Dress} (as shorthand for {\\\\bf D}eep {\\\\bf RE}inforcement {\\\\bf S}entence\\n{\\\\bf S}implification), explores the space of possible simplifications while\\nlearning to optimize a reward function that encourages outputs which are\\nsimple, fluent, and preserve the meaning of the input. Experiments on three\\ndatasets demonstrate that our model outperforms competitive simplification\\nsystems.\\n',\n",
       " '  In this manuscript, we demonstrate the ability of nonlinear light-atom\\ninteractions to produce tunably non-Gaussian, partially self-healing optical\\nmodes. Gaussian spatial-mode light tuned near to the atomic resonances in hot\\nrubidium vapor is shown to result in non-Gaussian output mode structures that\\nmay be controlled by varying either the input beam power or the temperature of\\nthe atomic vapor. We show that the output modes exhibit a degree of\\nself-reconstruction after encountering an obstruction in the beam path. The\\nresultant modes are similar to truncated Bessel-Gauss modes that exhibit the\\nability to self-reconstruct earlier upon propagation than Gaussian modes. The\\nability to generate tunable, self-reconstructing beams has potential\\napplications to a variety of imaging and communication scenarios.\\n',\n",
       " '  In this work we establish the first linear convergence result for the\\nstochastic heavy ball method. The method performs SGD steps with a fixed\\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\\nminimizing the expected loss and not on finite-sum minimization, which is\\ntypically a much harder problem. While in the analysis we constrain ourselves\\nto quadratic loss, the overall objective is not necessarily strongly convex.\\n',\n",
       " '  Many problems in computational science and engineering are simultaneously\\ncharacterized by the following challenging issues: uncertainty, nonlinearity,\\nnonstationarity and high dimensionality. Existing numerical techniques for such\\nmodels would typically require considerable computational and storage\\nresources. This is the case, for instance, for an optimization problem governed\\nby time-dependent Navier-Stokes equations with uncertain inputs. In particular,\\nthe stochastic Galerkin finite element method often leads to a prohibitively\\nhigh dimensional saddle-point system with tensor product structure. In this\\npaper, we approximate the solution by the low-rank Tensor Train decomposition,\\nand present a numerically efficient algorithm to solve the optimality equations\\ndirectly in the low-rank representation. We show that the solution of the\\nvorticity minimization problem with a distributed control admits a\\nrepresentation with ranks that depend modestly on model and discretization\\nparameters even for high Reynolds numbers. For lower Reynolds numbers this is\\nalso the case for a boundary control. This opens the way for a reduced-order\\nmodeling of the stochastic optimal flow control with a moderate cost at all\\nstages.\\n',\n",
       " '  We propose a method to generate multiple diverse and valid human pose\\nhypotheses in 3D all consistent with the 2D detection of joints in a monocular\\nRGB image. We use a novel generative model uniform (unbiased) in the space of\\nanatomically plausible 3D poses. Our model is compositional (produces a pose by\\ncombining parts) and since it is restricted only by anatomical constraints it\\ncan generalize to every plausible human 3D pose. Removing the model bias\\nintrinsically helps to generate more diverse 3D pose hypotheses. We argue that\\ngenerating multiple pose hypotheses is more reasonable than generating only a\\nsingle 3D pose based on the 2D joint detection given the depth ambiguity and\\nthe uncertainty due to occlusion and imperfect 2D joint detection. We hope that\\nthe idea of generating multiple consistent pose hypotheses can give rise to a\\nnew line of future work that has not received much attention in the literature.\\nWe used the Human3.6M dataset for empirical evaluation.\\n',\n",
       " '  Mechanical or electromechanical amplifiers can exploit the high-Q and low\\nnoise features of mechanical resonance, in particular when parametric\\nexcitation is employed. Multi-frequency parametric excitation introduces\\ntunability and is able to project weak input signals on a selected resonance.\\nThe present paper addresses multi degree of freedom mechanical amplifiers or\\nresonators whose analysis and features require treatment of the spatial as well\\nas temporal behavior. In some cases, virtual electronic coupling can alter the\\ngiven topology of the resonator to better amplify specific inputs. An\\nanalytical development is followed by a numerical and experimental sensitivity\\nand performance verifications, illustrating the advantages and disadvantages of\\nsuch topologies.\\n',\n",
       " '  In this paper, we analyze and compare three of the many algebraic structures\\nthat have been used for modeling dependent type theories: categories with\\nfamilies, split type-categories, and representable maps of presheaves. We study\\nthese in univalent type theory, where the comparisons between them can be given\\nmore elementarily than in set-theoretic foundations. Specifically, we construct\\nmaps between the various types of structures, and show that assuming the\\nUnivalence axiom, some of the comparisons are equivalences.\\nWe then analyze how these structures transfer along (weak and strong)\\nequivalences of categories, and, in particular, show how they descend from a\\ncategory (not assumed univalent/saturated) to its Rezk completion. To this end,\\nwe introduce relative universes, generalizing the preceding notions, and study\\nthe transfer of such relative universes along suitable structure.\\nWe work throughout in (intensional) dependent type theory; some results, but\\nnot all, assume the univalence axiom. All the material of this paper has been\\nformalized in Coq, over the UniMath library.\\n',\n",
       " \"  The spin-phonon interaction is the dominant process for spin relaxation in\\nSi, and as thermal transport in Si is dominated by phonons, one would expect\\nspin polarization to influence Si's thermal conductivity. Here we report the\\nexperimental evidence of just such a coupling. We have performed concurrent\\nmeasurements of spin, charge, and phonon transport in p-doped Si across a wide\\nrange of temperatures. In an experimental system of a freestanding two um p-Si\\nbeam coated on one side with a thin (25 nm) ferromagnetic spin injection layer,\\nwe use the self-heating 3 omega method to measure changes in electrical and\\nthermal conductivity under the influence of a magnetic field. These\\nmagneto-thermal transport measurements reveal signatures in the variation of\\nelectrical and thermal transport that are consistent with spin-phonon\\ninteraction. Raman spectroscopy measurements and first principle's calculations\\nsupport that these variations are due to spin-phonon interaction. Spin\\npolarization leads to softening of phonon modes, a reduction in the group\\nvelocity of acoustic modes, and a subsequent decrease in thermal conductivity\\nat room temperature. Moreover, magneto-thermal transport measurements as a\\nfunction of temperature indicate a change in the spin-phonon relaxation\\nbehavior at low temperature.\\n\",\n",
       " '  We prove the existence and the linear stability of Cantor families of small\\namplitude time quasi-periodic standing water wave solutions - namely periodic\\nand even in the space variable x - of a bi-dimensional ocean with finite depth\\nunder the action of pure gravity. Such a result holds for all the values of the\\ndepth parameter in a Borel set of asymptotically full measure. This is a small\\ndivisor problem. The main difficulties are the quasi-linear nature of the\\ngravity water waves equations and the fact that the linear frequencies grow\\njust in a sublinear way at infinity. We overcome these problems by first\\nreducing the linearized operators obtained at each approximate quasi-periodic\\nsolution along the Nash-Moser iteration to constant coefficients up to\\nsmoothing operators, using pseudo-differential changes of variables that are\\nquasi-periodic in time. Then we apply a KAM reducibility scheme which requires\\nvery weak Melnikov non-resonance conditions (losing derivatives both in time\\nand space), which we are able to verify for most values of the depth parameter\\nusing degenerate KAM theory arguments.\\n',\n",
       " '  Let $\\\\Omega\\\\subset{\\\\mathbb R}^n$ be a relatively compact domain. A finite\\ncollection of real-valued functions on $\\\\Omega$ is called a \\\\emph{Noetherian\\nchain} if the partial derivatives of each function are expressible as\\npolynomials in the functions. A \\\\emph{Noetherian function} is a polynomial\\ncombination of elements of a Noetherian chain. We introduce \\\\emph{Noetherian\\nparameters} (degrees, size of the coefficients) which measure the complexity of\\na Noetherian chain. Our main result is an explicit form of the Pila-Wilkie\\ntheorem for sets defined using Noetherian equalities and inequalities: for any\\n$\\\\epsilon>0$, the number of points of height $H$ in the transcendental part of\\nthe set is at most $C\\\\cdot H^{\\\\epsilon}$ where $C$ can be \\\\emph{explicitly}\\nestimated from the Noetherian parameters and $\\\\epsilon$.\\nWe show that many functions of interest in arithmetic geometry fall within\\nthe Noetherian class, including elliptic and abelian functions, modular\\nfunctions and universal covers of compact Riemann surfaces, Jacobi theta\\nfunctions, periods of algebraic integrals, and the uniformizing map of the\\nSiegel modular variety $\\\\mathcal{A}_g$. We thus effectivize the (geometric side\\nof) Pila-Zannier strategy for unlikely intersections in those instances that\\ninvolve only compact domains.\\n',\n",
       " '  We present a detailed analysis of the white dwarf luminosity functions\\nderived from the local 40 pc sample and the deep proper motion catalog of Munn\\net al (2014, 2017). Many of the previous studies ignored the contribution of\\nthick disk white dwarfs to the Galactic disk luminosity function, which results\\nin an erronous age measurement. We demonstrate that the ratio of thick/thin\\ndisk white dwarfs is roughly 20\\\\% in the local sample. Simultaneously fitting\\nfor both disk components, we derive ages of 6.8-7.0 Gyr for the thin disk and\\n8.7 $\\\\pm$ 0.1 Gyr for the thick disk from the local 40 pc sample. Similarly, we\\nderive ages of 7.4-8.2 Gyr for the thin disk and 9.5-9.9 Gyr for the thick disk\\nfrom the deep proper motion catalog, which shows no evidence of a deviation\\nfrom a constant star formation rate in the past 2.5 Gyr. We constrain the time\\ndifference between the onset of star formation in the thin disk and the thick\\ndisk to be $1.6^{+0.3}_{-0.4}$ Gyr. The faint end of the luminosity function\\nfor the halo white dwarfs is less constrained, resulting in an age estimate of\\n$12.5^{+1.4}_{-3.4}$ Gyr for the Galactic inner halo. This is the first time\\nages for all three major components of the Galaxy are obtained from a sample of\\nfield white dwarfs that is large enough to contain significant numbers of disk\\nand halo objects. The resultant ages agree reasonably well with the age\\nestimates for the oldest open and globular clusters.\\n',\n",
       " '  A novel deep learning architecture (XmasNet) based on convolutional neural\\nnetworks was developed for the classification of prostate cancer lesions, using\\nthe 3D multiparametric MRI data provided by the PROSTATEx challenge. End-to-end\\ntraining was performed for XmasNet, with data augmentation done through 3D\\nrotation and slicing, in order to incorporate the 3D information of the lesion.\\nXmasNet outperformed traditional machine learning models based on engineered\\nfeatures, for both train and test data. For the test data, XmasNet outperformed\\n69 methods from 33 participating groups and achieved the second highest AUC\\n(0.84) in the PROSTATEx challenge. This study shows the great potential of deep\\nlearning for cancer imaging.\\n',\n",
       " '  Payments architectures are on the verge of a great bifurcation that must be\\ndocumented in order to be debated. Google is moving towards a quasi bank while\\nApple and Google disseminate payment systems over smartphones. At the same\\ntime, block chain might become a distributed ledger introducing a radical new\\nmodel of trusted third-party. The detailed history of credit card systems helps\\nunderstand why the game of security has always been trigged by a delegation\\nprocess of the risk to third parties and by the cat-and-mouse game of security\\nand fraud. Technologies were designed to solve these issues but have always\\nbeen closely related to innovations in institutional assemblages. These\\npayments systems shape our social life and the stakes of trust that we put in\\nthese architectures require a truly political examination.\\n',\n",
       " \"  Social ties are the invisible glue that keeps together human ecosystems.\\nDespite the massive amount of research studying the role of social ties in\\ncommunities (groups, teams, etc.) and society at large, little attention has\\nbeen devoted to study their interplay with other human behavioral dynamics. Of\\nparticular interest is the influence that social ties have on human performance\\nin collaborative team-based settings. Our research aims to elucidate the\\ninfluence of social ties on individual and team performance dynamics. We will\\nfocus on a popular Multiplayer Online Battle Arena (MOBA) collaborative\\nteam-based game, Defense of the Ancients 2 (Dota 2), a rich dataset with\\nmillions of players and matches. Our research reveals that, when playing with\\ntheir friends, individuals are systematically more active in the game as\\nopposed to taking part in a team of strangers. However, we find that increased\\nactivity does not homogeneously lead to an improvement in players' performance.\\nDespite being beneficial to low skill players, playing with friends negatively\\naffects performance of high skill players. Our findings shed light on the mixed\\ninfluence of social ties on performance, and can inform new perspectives on\\nvirtual team management and on behavioral incentives.\\n\",\n",
       " \"  This paper is devoted to study multiplicity and regularity as well as to\\npresent some classifications of complex analytic sets. We present an\\nequivalence for complex analytical sets, namely blow-spherical equivalence and\\nwe receive several applications with this new approach. For example, we reduce\\nto homogeneous complex algebraic sets a version of Zariski's multiplicity\\nconjecture in the case of blow-spherical homeomorphism, we give some partial\\nanswers to the Zariski's multiplicity conjecture, we show that a blow-spherical\\nregular complex analytic set is smooth and we give a complete classification of\\ncomplex analytic curves.\\n\",\n",
       " '  Laboratory spectral measurements of relevant analogue materials were\\nperformed in the framework of the Rosetta mission in order to explain the\\nsurface spectral properties of comet 67P. Fine powders of coal, iron sulphides,\\nsilicates and their mixtures were prepared and their spectra measured in the\\nVis-IR range. These spectra are compared to a reference spectrum of 67P nucleus\\nobtained with the VIRTIS/Rosetta instrument up to 2.7 {\\\\mu}m, excluding the\\norganics band centred at 3.2 {\\\\mu}m. The species used are known to be chemical\\nanalogues for cometary materials which could be present at the surface of 67P.\\nGrain sizes of the powders range from tens of nanometres to hundreds of\\nmicrometres. Some of the mixtures studied here actually reach the very low\\nreflectance level observed by VIRTIS on 67P. The best match is provided by a\\nmixture of sub-micron coal, pyrrhotite, and silicates. Grain sizes are in\\nagreement with the sizes of the dust particles detected by the GIADA, MIDAS and\\nCOSIMA instruments on board Rosetta. The coal used in the experiment is\\nresponsible for the spectral slope in the visible and infrared ranges.\\nPyrrhotite, which is strongly absorbing, is responsible for the low albedo\\nobserved in the NIR. The darkest components dominate the spectra, especially\\nwithin intimate mixtures. Depending on sample preparation, pyrrhotite can coat\\nthe coal and silicate aggregates. Such coating effects can affect the spectra\\nas much as particle size. In contrast, silicates seem to play a minor role.\\n',\n",
       " '  Real world programming languages crucially depend on the availability of\\ncomputational effects to achieve programming convenience and expressive power\\nas well as program efficiency. Logical frameworks rely on predicates, or\\ndependent types, to express detailed logical properties about entities.\\nAccording to the Curry-Howard correspondence, programming languages and logical\\nframeworks should be very closely related. However, a language that has both\\ngood support for real programming and serious proving is still missing from the\\nprogramming languages zoo. We believe this is due to a fundamental lack of\\nunderstanding of how dependent types should interact with computational\\neffects. In this thesis, we make a contribution towards such an understanding,\\nwith a focus on semantic methods.\\n',\n",
       " '  The security of several post-quantum cryptosystems is based on the assumption\\nthat solving a system of multivariate (quadratic) polynomial equations\\n$p_1=\\\\dots=p_r=0$ over a finite field is hard. Such a system can be solved by\\ncomputing a lexicographic Gröbner basis of the ideal $(p_1,\\\\dots,p_r)$. The\\nmost efficient algorithms for computing Gröbner bases transform the problem\\ninto several instances of Gaussian elimination. The computational complexity of\\nthese algorithms is not completely understood, especially when the polynomials\\n$p_1,\\\\dots,p_r$ are not homogeneous. In this paper, we prove that this\\ncomplexity is controlled by the Castelnuovo-Mumford regularity of the ideal\\n$(p_1^h,\\\\dots,p_r^h)$ obtained by homogenizing the input polynomials. This\\nallows us to bound the complexity of solving a system of polynomial equations\\nwhen the associated ideal is zero-dimensional, a common situation in\\ncryptography. In combination with some theorems in commutative algebra, our\\nresults also allow us to bound the complexity of the ABC and cubic simple\\nmatrix schemes, as well as some instances of the MinRank Problem.\\n',\n",
       " '  Scientists are increasingly turning to datacenter-scale computers to produce\\nand analyze massive arrays. Despite decades of database research that extols\\nthe virtues of declarative query processing, scientists still write, debug and\\nparallelize imperative HPC kernels even for the most mundane queries. This\\nimpedance mismatch has been partly attributed to the cumbersome data loading\\nprocess; in response, the database community has proposed in situ mechanisms to\\naccess data in scientific file formats. Scientists, however, desire more than a\\npassive access method that reads arrays from files.\\nThis paper describes ArrayBridge, a bi-directional array view mechanism for\\nscientific file formats, that aims to make declarative array manipulations\\ninteroperable with imperative file-centric analyses. Our prototype\\nimplementation of ArrayBridge uses HDF5 as the underlying array storage library\\nand seamlessly integrates into the SciDB open-source array database system. In\\naddition to fast querying over external array objects, ArrayBridge produces\\narrays in the HDF5 file format just as easily as it can read from it.\\nArrayBridge also supports time travel queries from imperative kernels through\\nthe unmodified HDF5 API, and automatically deduplicates between array versions\\nfor space efficiency. Our extensive performance evaluation in NERSC, a\\nlarge-scale scientific computing facility, shows that ArrayBridge exhibits\\nstatistically indistinguishable performance and I/O scalability to the native\\nSciDB storage engine.\\n',\n",
       " '  Trans-dimensional random field language models (TRF LMs) where sentences are\\nmodeled as a collection of random fields, have shown close performance with\\nLSTM LMs in speech recognition and are computationally more efficient in\\ninference. However, the training efficiency of neural TRF LMs is not\\nsatisfactory, which limits the scalability of TRF LMs on large training corpus.\\nIn this paper, several techniques on both model formulation and parameter\\nestimation are proposed to improve the training efficiency and the performance\\nof neural TRF LMs. First, TRFs are reformulated in the form of exponential\\ntilting of a reference distribution. Second, noise-contrastive estimation (NCE)\\nis introduced to jointly estimate the model parameters and normalization\\nconstants. Third, we extend the neural TRF LMs by marrying the deep\\nconvolutional neural network (CNN) and the bidirectional LSTM into the\\npotential function to extract the deep hierarchical features and\\nbidirectionally sequential features. Utilizing all the above techniques enables\\nthe successful and efficient training of neural TRF LMs on a 40x larger\\ntraining set with only 1/3 training time and further reduces the WER with\\nrelative reduction of 4.7% on top of a strong LSTM LM baseline.\\n',\n",
       " '  In this paper we first identify a basic limitation in gradient descent-based\\noptimization methods when used in conjunctions with smooth kernels. An analysis\\nbased on the spectral properties of the kernel demonstrates that only a\\nvanishingly small portion of the function space is reachable after a polynomial\\nnumber of gradient descent iterations. This lack of approximating power\\ndrastically limits gradient descent for a fixed computational budget leading to\\nserious over-regularization/underfitting. The issue is purely algorithmic,\\npersisting even in the limit of infinite data.\\nTo address this shortcoming in practice, we introduce EigenPro iteration,\\nbased on a preconditioning scheme using a small number of approximately\\ncomputed eigenvectors. It can also be viewed as learning a new kernel optimized\\nfor gradient descent. It turns out that injecting this small (computationally\\ninexpensive and SGD-compatible) amount of approximate second-order information\\nleads to major improvements in convergence. For large data, this translates\\ninto significant performance boost over the standard kernel methods. In\\nparticular, we are able to consistently match or improve the state-of-the-art\\nresults recently reported in the literature with a small fraction of their\\ncomputational budget.\\nFinally, we feel that these results show a need for a broader computational\\nperspective on modern large-scale learning to complement more traditional\\nstatistical and convergence analyses. In particular, many phenomena of\\nlarge-scale high-dimensional inference are best understood in terms of\\noptimization on infinite dimensional Hilbert spaces, where standard algorithms\\ncan sometimes have properties at odds with finite-dimensional intuition. A\\nsystematic analysis concentrating on the approximation power of such algorithms\\nwithin a budget of computation may lead to progress both in theory and\\npractice.\\n',\n",
       " '  We present the first paper of a series focused on the Blazhko effect in RR\\nLyrae type stars pulsating in the fundamental mode, that are located in the\\nGalactic bulge. A~comprehensive overview about the incidence rate and\\nlight-curve characteristics of the Blazhko stars is given. We analysed 8\\\\,282\\nstars having the best quality data in the OGLE-IV survey, and found that at\\nleast $40.3$\\\\,\\\\% of stars show modulation of their light curves. The number of\\nBlazhko stars we identified is 3\\\\,341, which is the largest sample ever studied\\nimplying the most relevant statistical results currently available. Using\\ncombined data sets with OGLE-III observations, we found that 50\\\\,\\\\% of stars\\nthat show unresolved close peaks to the main component in OGLE-IV are actually\\nBlazhko stars with extremely long periods. Blazhko stars with modulation occur\\npreferentially among RR Lyrae stars with shorter pulsation periods in the\\nGalactic bulge. Fourier amplitude and phase coefficients based on the mean\\nlight curves appear to be substantially lower for Blazhko stars than for stars\\nwith unmodulated light curve in average. We derived new relations for the\\ncompatibility parameter $D_{m}$ in $I$ passband and relations that allow for\\ndifferentiating modulated and non-modulated stars easily on the basis of\\n$R_{31}$, $\\\\phi_{21}$ and $\\\\phi_{31}$. Photometric metallicities, intrinsic\\ncolours and absolute magnitudes computed using empirical relations are the same\\nfor Blazhko and non-modulated stars in the Galactic bulge suggesting no\\ncorrelation between the occurrence of the Blazhko effect and these parameters.\\n',\n",
       " \"  An autonomous and resilient controller is proposed for leader-follower\\nmulti-agent systems under uncertainties and cyber-physical attacks. The leader\\nis assumed non-autonomous with a nonzero control input, which allows changing\\nthe team behavior or mission in response to environmental changes. A resilient\\nlearning-based control protocol is presented to find optimal solutions to the\\nsynchronization problem in the presence of attacks and system dynamic\\nuncertainties. An observer-based distributed H_infinity controller is first\\ndesigned to prevent propagating the effects of attacks on sensors and actuators\\nthroughout the network, as well as to attenuate the effect of these attacks on\\nthe compromised agent itself. Non-homogeneous game algebraic Riccati equations\\nare derived to solve the H_infinity optimal synchronization problem and\\noff-policy reinforcement learning is utilized to learn their solution without\\nrequiring any knowledge of the agent's dynamics. A trust-confidence based\\ndistributed control protocol is then proposed to mitigate attacks that hijack\\nthe entire node and attacks on communication links. A confidence value is\\ndefined for each agent based solely on its local evidence. The proposed\\nresilient reinforcement learning algorithm employs the confidence value of each\\nagent to indicate the trustworthiness of its own information and broadcast it\\nto its neighbors to put weights on the data they receive from it during and\\nafter learning. If the confidence value of an agent is low, it employs a trust\\nmechanism to identify compromised agents and remove the data it receives from\\nthem from the learning process. Simulation results are provided to show the\\neffectiveness of the proposed approach.\\n\",\n",
       " '  It is demonstrated that non-coalescent droplets of acetone can be formed on\\nliquid substrates. The fluid flows around and in an acetone droplet hovering on\\nwater are recorded to shed light on the mechanisms which might lead to\\nnon-coalescence. For sufficiently low impact velocities, droplets undergo a\\ndamped oscillation on the surface of the liquid substrate but at higher\\nvelocities clean bounce-off occurs. Comparisons of experimentally observed\\nstatic configurations of floating droplets to predictions from a theoretical\\nmodel for a small non-wetting rigid sphere resting on a liquid substrate are\\nmade and a tentative strategy for determining the thickness of the vapor layer\\nunder a small droplet on a liquid is proposed. This strategy is based on the\\nnotion of effective surface tension. The droplets show self-propulsion in\\nstraight line trajectories in a manner which can be ascribed to a Marangoni\\neffect. Surprisingly, self-propelled droplets can become immersed beneath the\\nundisturbed water surface. This phenomenon is reasoned to be drag-inducing and\\nmight provide a basis for refining observations in previous work.\\n',\n",
       " '  In this note we show that the union of $r$ general lines and one fat line in\\n${\\\\mathbb P}^3$ imposes independent conditions on forms of sufficiently high\\ndegree $d$, where the bound on $d$ is independent of the number of lines. This\\nextends former results of Hartshorne and Hirschowitz on unions of general\\nlines, and of Aladpoosh on unions of general lines and one double line.\\n',\n",
       " '  With the advent of automated machine learning, automated hyperparameter\\noptimization methods are by now routinely used in data mining. However, this\\nprogress is not yet matched by equal progress on automatic analyses that yield\\ninformation beyond performance-optimizing hyperparameter settings. In this\\nwork, we aim to answer the following two questions: Given an algorithm, what\\nare generally its most important hyperparameters, and what are typically good\\nvalues for these? We present methodology and a framework to answer these\\nquestions based on meta-learning across many datasets. We apply this\\nmethodology using the experimental meta-data available on OpenML to determine\\nthe most important hyperparameters of support vector machines, random forests\\nand Adaboost, and to infer priors for all their hyperparameters. The results,\\nobtained fully automatically, provide a quantitative basis to focus efforts in\\nboth manual algorithm design and in automated hyperparameter optimization. The\\nconducted experiments confirm that the hyperparameters selected by the proposed\\nmethod are indeed the most important ones and that the obtained priors also\\nlead to statistically significant improvements in hyperparameter optimization.\\n',\n",
       " '  \"Hot super-Earths\" (or \"Mini-Neptunes\") between 1 and 4 times Earth\\'s size\\nwith period shorter than 100 days orbit 30-50\\\\% of Sun-like type stars. Their\\norbital configuration -- measured as the period ratio distribution of adjacent\\nplanets in multi-planet systems -- is a strong constraint for formation models.\\nHere we use N-body simulations with synthetic forces from an underlying\\nevolving gaseous disk to model the formation and long-term dynamical evolution\\nof super-Earth systems. While the gas disk is present, planetary embryos grow\\nand migrate inward to form a resonant chain anchored at the inner edge of the\\ndisk. These resonant chains are far more compact than the observed super-Earth\\nsystems. Once the gas dissipates resonant chains may become dynamically\\nunstable. They undergo a phase of giant impacts that spreads the systems out.\\nDisk turbulence has no measurable effect on the outcome. Our simulations match\\nobservations if a small fraction of resonant chains remain stable, while most\\nsuper-Earths undergo a late dynamical instability. Our statistical analysis\\nrestricts the contribution of stable systems to less than $25\\\\%$. Our results\\nalso suggest that the large fraction of observed single planet systems does not\\nnecessarily imply any dichotomy in the architecture of planetary systems.\\nFinally, we use the low abundance of resonances in Kepler data to argue that,\\nin reality, the survival of resonant chains happens likely only in $\\\\sim 5\\\\%$\\nof the cases. This leads to a mystery: in our simulations only 50-60\\\\% of\\nresonant chains became unstable whereas at least 75\\\\% (and probably 90-95\\\\%)\\nmust be unstable to match observations.\\n',\n",
       " '  We present a new technique for demonstrating the reachability of states in\\ndeterministic finite automata representing the concatenation of two languages.\\nSuch demonstrations are a necessary step in establishing the state complexity\\nof the concatenation of two languages, and thus in establishing the state\\ncomplexity of concatenation as an operation. Typically, ad-hoc induction\\narguments are used to show particular states are reachable in concatenation\\nautomata. We prove some results that seem to capture the essence of many of\\nthese induction arguments. Using these results, reachability proofs in\\nconcatenation automata can often be done more simply and without using\\ninduction directly.\\n',\n",
       " '  Smartphones are a popular device class for mobile Augmented Reality but\\nsuffer from a limited input space. Around-device interaction techniques aim at\\nextending this input space using various sensing modalities. In this paper we\\npresent our work towards extending the input area of mobile devices using\\nfront-facing device-centered cameras that capture reflections in the cornea. As\\ncurrent generation mobile devices lack high resolution front-facing cameras, we\\nstudy the feasibility of around-device interaction using corneal reflective\\nimaging based on a high resolution camera. We present a workflow, a technical\\nprototype and a feasibility evaluation.\\n',\n",
       " '  We present {\\\\it block analysis}, an efficient method to perform finite-size\\nscaling for obtaining the length scale of dynamic heterogeneity and the\\npoint-to-set length scale for generic glass-forming liquids. This method\\ninvolves considering blocks of varying sizes embedded in a system of a fixed\\n(large) size. The length scale associated with dynamic heterogeneity is\\nobtained from a finite-size scaling analysis of the dependence of the\\nfour-point dynamic susceptibility on the block size. The block size dependence\\nof the variance of the $\\\\alpha$-relaxation time yields the static point-to-set\\nlength scale. The values of the obtained length scales agree quantitatively\\nwith those obtained from other conventional methods. This method provides an\\nefficient experimental tool for studying the growth of length scales in systems\\nsuch as colloidal glasses for which performing finite-size scaling by carrying\\nout experiments for varying system sizes may not be feasible.\\n',\n",
       " '  Autonomous robotic grasp plays an important role in intelligent robotics.\\nHowever, it is challenging due to: (1) robotic grasp is a comprehensive task\\ninvolving perception, planning and control; (2) autonomous robotic grasp in\\ncomplex scenarios requires reasoning ability. In this paper, we propose a\\nmulti-task convolutional neural network for Robotic Perception, Reasoning and\\nGrasping (RPRG), which can help robot find the target, make the plan for\\ngrasping and finally grasp the target step by step in object stacking scenes.\\nWe integrate vision-based robotic grasp detection and visual manipulation\\nrelationship reasoning in one single deep network and build the autonomous\\nrobotic grasp system. The proposed network has state-of-the-art performance in\\nboth tasks. Experiments demonstrate that with our model, Baxter robot can\\nautonomously grasp the target with a success rate of 94.2%, 77.1% and 62.5% in\\nobject cluttered scenes, familiar stacking scenes and complex stacking scenes\\nrespectively at a speed of 6.5 FPS for each detection.\\n',\n",
       " '  We revisit the classical problem of optimal experimental design (OED) under a\\nnew mathematical model grounded in a geometric motivation. Specifically, we\\nintroduce models based on elementary symmetric polynomials; these polynomials\\ncapture \"partial volumes\" and offer a graded interpolation between the widely\\nused A-optimal design and D-optimal design models, obtaining each of them as\\nspecial cases. We analyze properties of our models, and derive both greedy and\\nconvex-relaxation algorithms for computing the associated designs. Our analysis\\nestablishes approximation guarantees on these algorithms, while our empirical\\nresults substantiate our claims and demonstrate a curious phenomenon concerning\\nour greedy method. Finally, as a byproduct, we obtain new results on the theory\\nof elementary symmetric polynomials that may be of independent interest.\\n',\n",
       " '  Deep learning is finding its way into the embedded world with applications\\nsuch as autonomous driving, smart sensors and aug- mented reality. However, the\\ncomputation of deep neural networks is demanding in energy, compute power and\\nmemory. Various approaches have been investigated to reduce the necessary\\nresources, one of which is to leverage the sparsity occurring in deep neural\\nnetworks due to the high levels of redundancy in the network parameters. It has\\nbeen shown that sparsity can be promoted specifically and the achieved sparsity\\ncan be very high. But in many cases the methods are evaluated on rather small\\ntopologies. It is not clear if the results transfer onto deeper topologies. In\\nthis paper, the TensorQuant toolbox has been extended to offer a platform to\\ninvestigate sparsity, especially in deeper models. Several practical relevant\\ntopologies for varying classification problem sizes are investigated to show\\nthe differences in sparsity for activations, weights and gradients.\\n',\n",
       " '  We study the behavior of a fundamental tool in sparse statistical modeling\\n--the best-subset selection procedure (aka \"best-subsets\"). Assuming that the\\nunderlying linear model is sparse, it is well known, both in theory and in\\npractice, that the best-subsets procedure works extremely well in terms of\\nseveral statistical metrics (prediction, estimation and variable selection)\\nwhen the signal to noise ratio (SNR) is high. However, its performance degrades\\nsubstantially when the SNR is low -- it is outperformed in predictive accuracy\\nby continuous shrinkage methods, such as ridge regression and the Lasso. We\\nexplain why this behavior should not come as a surprise, and contend that the\\noriginal version of the classical best-subsets procedure was, perhaps, not\\ndesigned to be used in the low SNR regimes. We propose a close cousin of\\nbest-subsets, namely, its $\\\\ell_{q}$-regularized version, for $q \\\\in\\\\{1, 2\\\\}$,\\nwhich (a) mitigates, to a large extent, the poor predictive performance of\\nbest-subsets in the low SNR regimes; (b) performs favorably and generally\\ndelivers a substantially sparser model when compared to the best predictive\\nmodels available via ridge regression and the Lasso. Our estimator can be\\nexpressed as a solution to a mixed integer second order conic optimization\\nproblem and, hence, is amenable to modern computational tools from mathematical\\noptimization. We explore the theoretical properties of the predictive\\ncapabilities of the proposed estimator and complement our findings via several\\nnumerical experiments.\\n',\n",
       " '  This work presents a novel ensemble of Bayesian Neural Networks (BNNs) for\\ncontrol of safety-critical systems. Decision making for safety-critical systems\\nis challenging due to performance requirements with significant consequences in\\nthe event of failure. In practice, failure of such systems can be avoided by\\nintroducing redundancies of control. Neural Networks (NNs) are generally not\\nused for safety-critical systems as they can behave in unexpected ways in\\nresponse to novel inputs. In addition, there may not be any indication as to\\nwhen they will fail. BNNs have been recognized for their ability to produce not\\nonly viable outputs but also provide a measure of uncertainty in these outputs.\\nThis work combines the knowledge of prediction uncertainty obtained from BNNs\\nand ensemble control for a redundant control methodology. Our technique is\\napplied to an agile autonomous driving task. Multiple BNNs are trained to\\ncontrol a vehicle in an end-to-end fashion on different sensor inputs provided\\nby the system. We show that an individual network is successful in maneuvering\\naround the track but crashes in the presence of unforeseen input noise. Our\\nproposed ensemble of BNNs shows successful task performance even in the event\\nof multiple sensor failures.\\n',\n",
       " '  In this paper, we propose a robust profile estimation method for the\\nparametric and nonparametric components of a single index model when the errors\\nhave a strongly unimodal density with unknown nuisance parameter. Under\\nregularity conditions, we derive consistency results for the link function\\nestimators as well as consistency and asymptotic distribution results for the\\nsingle index parameter estimators. Under a log--Gamma model, the sensitivity to\\nanomalous observations is studied by means of the empirical influence curve. We\\nalso discuss a robust $K-$fold procedure to select the smoothing parameters\\ninvolved. A numerical study is conducted to evaluate the small sample\\nperformance of the robust proposal with that of their classical relatives, both\\nfor errors following a log--Gamma model and for contaminated schemes. The\\nnumerical experiment shows the good robustness properties of the proposed\\nestimators and the advantages of considering a robust approach instead of the\\nclassical one.\\n',\n",
       " '  Hippocampal dentate granule cells are among the few neuronal cell types\\ngenerated throughout adult life in mammals. In the normal brain, new granule\\ncells are generated from progenitors in the subgranular zone and integrate in a\\ntypical fashion. During the development of epilepsy, granule cell integration\\nis profoundly altered. The new cells migrate to ectopic locations and develop\\nmisoriented basal dendrites. Although it has been established that these\\nabnormal cells are newly generated, it is not known whether they arise\\nubiquitously throughout the progenitor cell pool or are derived from a smaller\\nnumber of bad actor progenitors. To explore this question, we conducted a\\nclonal analysis study in mice expressing the Brainbow fluorescent protein\\nreporter construct in dentate granule cell progenitors. Mice were examined 2\\nmonths after pilocarpine-induced status epilepticus, a treatment that leads to\\nthe development of epilepsy. Brain sections were rendered translucent so that\\nentire hippocampi could be reconstructed and all fluorescently labeled cells\\nidentified. Our findings reveal that a small number of progenitors produce the\\nmajority of ectopic cells following status epilepticus, indicating that either\\nthe affected progenitors or their local microenvironments have become\\npathological. By contrast, granule cells with basal dendrites were equally\\ndistributed among clonal groups. This indicates that these progenitors can\\nproduce normal cells and suggests that global factors sporadically disrupt the\\ndendritic development of some new cells. Together, these findings strongly\\npredict that distinct mechanisms regulate different aspects\\n',\n",
       " '  We show that time-resolved x-ray scattering from molecules prepared in a\\nsuperposition of electronic states moving through an avoided crossing has new\\nfeatures not found in diffraction from the corresponding classical mixed state.\\nPhotoabsorption in molecular iodine at 520 nm produces a superposition of two\\ndipole-allowed nearly degenerate electronic states, which interact due to\\nnon-adiabatic coupling. We show experimental evidence that the mixing of the\\nnuclear wavepackets from the two electronic states at the avoided crossing\\nleads to ultrafast changes in the angular composition of the scattering\\npattern. This provides a novel means to study transitions in excited molecular\\nsystems. We reconstruct a movie of the nuclear probability density arising from\\nthis interference.\\n',\n",
       " '  The cutoff phenomenon was recently confirmed for random walks on Ramanujan\\ngraphs by the first author and Peres. In this work, we obtain analogs in higher\\ndimensions, for random walk operators on any Ramanujan complex associated with\\na simple group $G$ over a local field $F$. We show that if $T$ is any\\n$k$-regular $G$-equivariant operator on the Bruhat-Tits building with a simple\\ncombinatorial property (collision-free), the associated random walk on the\\n$n$-vertex Ramanujan complex has cutoff at time $\\\\log_k n$. The high\\ndimensional case, unlike that of graphs, requires tools from non-commutative\\nharmonic analysis and the infinite-dimensional representation theory of $G$.\\nVia these, we show that operators $T$ as above on Ramanujan complexes give rise\\nto Ramanujan digraphs with a special property ($r$-normal), implying cutoff.\\nApplications include geodesic flow operators, geometric implications, and a\\nconfirmation of the Riemann Hypothesis for the associated zeta functions over\\nevery group $G$, previously known for groups of type $\\\\widetilde A_n$ and\\n$\\\\widetilde C_2$.\\n',\n",
       " '  Let $\\\\ell$ denote a positive integer. A connected graph $\\\\G$ of diameter at\\nleast $\\\\ell$ is said to be $\\\\ell${\\\\it -distance-balanced} whenever for any pair\\nof vertices $u,v$ of $\\\\G$ such that $d(u,v)=\\\\ell$, the number of vertices\\ncloser to $u$ than to $v$ is equal to the number of vertices closer to $v$ than\\nto $u$. In this paper we present some basic properties of\\n$\\\\ell$-distance-balanced graphs and study in more detail\\n$\\\\ell$-distance-balanced graphs of diameter at most $3$. We also investigate\\nthe $\\\\ell$-distance-balanced property of some well known families of graphs\\nsuch as the generalized Petersen graphs.\\n',\n",
       " '  This paper proposes the use of a Spectral method to simulate diffusive\\nmoisture transfer through porous materials as a Reduced-Order Model (ROM). The\\nSpectral approach is an a priori method assuming a separated representation of\\nthe solution. The method is compared with both classical Euler implicit and\\nCrank-Nicolson schemes, considered as large original models. Their performance\\n- in terms of accuracy, complexity reduction and CPU time reduction - are\\ndiscussed for linear and nonlinear cases of moisture diffusive transfer through\\nsingle and multi-layered one-dimensional domains, considering highly\\nmoisture-dependent properties. Results show that the Spectral reduced-order\\nmodel approach enables to simulate accurately the field of interest.\\nFurthermore, numerical gains become particularly interesting for nonlinear\\ncases since the proposed method can drastically reduce the computer run time,\\nby a factor of 100, when compared to the traditional Crank-Nicolson scheme for\\none-dimensional applications.\\n',\n",
       " \"  We consider the $q$-totally asymmetric simple exclusion process ($q$-TASEP)\\nin the stationary regime and study the fluctuation of the position of a\\nparticle. We first observe that the problem can be studied as a limiting case\\nof an $N$-particle $q$-TASEP with a random initial condition and with particle\\ndependent hopping rate. Then we explain how this $N$-particle $q$-TASEP can be\\nencoded in a dynamics on a two-sided Gelfand-Tsetlin cone described by a\\ntwo-sided $q$-Whittaker process and present a Fredholm determinant formula for\\nthe $q$-Laplace transform of the position of a particle. Two main ingredients\\nin its derivation is the Ramanujan's bilateral summation formula and the Cauchy\\ndeterminant identity for the theta function with an extra parameter. Based on\\nthis we establish that the position of a particle obeys the universal\\nstationary KPZ distribution (the Baik-Rains distribution) in the long time\\nlimit.\\n\",\n",
       " \"  One of the biggest successes of the Cassini mission is the detection of small\\nmoons (moonlets) embedded in Saturn's rings which cause S-shaped density\\nstructures in their close vicinity, called propellers (Spahn and Sremcevic\\n2000; Tiscareno et al. 2006; Sremcevic et al. 2007). Here, we present\\nisothermal hydrodynamic simulations of moonlet-induced propellers in Saturn's A\\nring which denote a further development of the original model (Spahn and\\nSremcevic 2000). We find excellent agreement between these new hydrodynamic and\\ncorresponding N-body simulations. Furthermore, the hydrodynamic simulations\\nconfirm the predicted scaling laws (Spahn and Sremcevic 2000) and the\\nanalytical solution for the density in the propeller gaps (Sremcevic et al.\\n2002). Finally, this mean field approach allows us to simulate the pattern of\\nthe giant propeller Bleriot, which is too large to be modeled by direct N-body\\nsimulations. Our results are compared to two stellar occultation observations\\nby the Cassini Ultraviolet Imaging Spectrometer (UVIS), that intersect the\\npropeller Bleriot. Best fits to the UVIS optical depth profiles are achieved\\nfor a Hill radius of 590 m, which implies a moonlet diameter of about 860 m.\\nFurthermore, the model favours a kinematic shear viscosity of the surrounding\\nring material of $\\\\nu_0 = 340$ cm^2/s, a dispersion velocity in the range of\\n0.3 cm/s $< c_0 <$ 1.5 cm/s, and a fairly high bulk viscosity $7 < \\\\xi_0/\\\\nu_0\\n< 17$. These large transport values might be overestimated by our isothermal\\nring model and should be reviewed by an extended model including thermal\\nfluctuations.\\n\",\n",
       " '  We consider the problem of estimating means of two Gaussians in a 2-Gaussian\\nmixture, which is not balanced and is corrupted by noise of an arbitrary\\ndistribution. We present a robust algorithm to estimate the parameters,\\ntogether with upper bounds on the numbers of samples required for the estimate\\nto be correct, where the bounds are parametrised by the dimension, ratio of the\\nmixing coefficients, a measure of the separation of the two Gaussians, related\\nto Mahalanobis distance, and a condition number of the covariance matrix. In\\ntheory, this is the first sample-complexity result for imbalanced mixtures\\ncorrupted by adversarial noise. In practice, our algorithm outperforms the\\nvanilla Expectation-Maximisation (EM) algorithm in terms of estimation error.\\n',\n",
       " '  We present an approach using a combination of coupled channel scattering\\ncalculations with a machine- learning technique based on Gaussian Process\\nregression to determine the sensitivity of the rate constants for non-adiabatic\\ntransitions in inelastic atomic collisions to variations of the underlying\\nadiabatic interaction potentials. Using this approach, we improve the previous\\ncomputations of the rate constants for the fine-structure transitions in\\ncollisions of O(3Pj) with atomic H. We compute the error bars of the rate\\nconstants corresponding to 20 % variations of the ab initio potentials and show\\nthat this method can be used to determine which of the individual adiabatic\\npotentials are more or less important for the outcome of different\\nfine-structure changing collisions.\\n',\n",
       " '  In this paper a semi-supervised deep framework is proposed for the problem of\\n3D shape inverse rendering from a single 2D input image. The main structure of\\nproposed framework consists of unsupervised pre-trained components which\\nsignificantly reduce the need to labeled data for training the whole framework.\\nusing labeled data has the advantage of achieving to accurate results without\\nthe need to predefined assumptions about image formation process. Three main\\ncomponents are used in the proposed network: an encoder which maps 2D input\\nimage to a representation space, a 3D decoder which decodes a representation to\\na 3D structure and a mapping component in order to map 2D to 3D representation.\\nThe only part that needs label for training is the mapping part with not too\\nmany parameters. The other components in the network can be pre-trained\\nunsupervised using only 2D images or 3D data in each case. The way of\\nreconstructing 3D shapes in the decoder component, inspired by the model based\\nmethods for 3D reconstruction, maps a low dimensional representation to 3D\\nshape space with the advantage of extracting the basis vectors of shape space\\nfrom training data itself and is not restricted to a small set of examples as\\nused in predefined models. Therefore, the proposed framework deals directly\\nwith coordinate values of the point cloud representation which leads to achieve\\ndense 3D shapes in the output. The experimental results on several benchmark\\ndatasets of objects and human faces and comparing with recent similar methods\\nshows the power of proposed network in recovering more details from single 2D\\nimages.\\n',\n",
       " \"  Deep Neural Networks (DNN) are increasingly used in a variety of\\napplications, many of them with substantial safety and security concerns. This\\npaper introduces DeepCheck, a new approach for validating DNNs based on core\\nideas from program analysis, specifically from symbolic execution. The idea is\\nto translate a DNN into an imperative program, thereby enabling program\\nanalysis to assist with DNN validation. A basic translation however creates\\nprograms that are very complex to analyze. DeepCheck introduces novel\\ntechniques for lightweight symbolic analysis of DNNs and applies them in the\\ncontext of image classification to address two challenging problems in DNN\\nanalysis: 1) identification of important pixels (for attribution and\\nadversarial generation); and 2) creation of 1-pixel and 2-pixel attacks.\\nExperimental results using the MNIST data-set show that DeepCheck's lightweight\\nsymbolic analysis provides a valuable tool for DNN validation.\\n\",\n",
       " '  We consider the exploration/exploitation problem in reinforcement learning.\\nFor exploitation, it is well known that the Bellman equation connects the value\\nat any time-step to the expected value at subsequent time-steps. In this paper\\nwe consider a similar \\\\textit{uncertainty} Bellman equation (UBE), which\\nconnects the uncertainty at any time-step to the expected uncertainties at\\nsubsequent time-steps, thereby extending the potential exploratory benefit of a\\npolicy beyond individual time-steps. We prove that the unique fixed point of\\nthe UBE yields an upper bound on the variance of the posterior distribution of\\nthe Q-values induced by any policy. This bound can be much tighter than\\ntraditional count-based bonuses that compound standard deviation rather than\\nvariance. Importantly, and unlike several existing approaches to optimism, this\\nmethod scales naturally to large systems with complex generalization.\\nSubstituting our UBE-exploration strategy for $\\\\epsilon$-greedy improves DQN\\nperformance on 51 out of 57 games in the Atari suite.\\n',\n",
       " '  Though a large body of computer vision research has investigated developing\\ngeneric semantic representations, efforts towards developing a similar\\nrepresentation for 3D has been limited. In this paper, we learn a generic 3D\\nrepresentation through solving a set of foundational proxy 3D tasks:\\nobject-centric camera pose estimation and wide baseline feature matching. Our\\nmethod is based upon the premise that by providing supervision over a set of\\ncarefully selected foundational tasks, generalization to novel tasks and\\nabstraction capabilities can be achieved. We empirically show that the internal\\nrepresentation of a multi-task ConvNet trained to solve the above core problems\\ngeneralizes to novel 3D tasks (e.g., scene layout estimation, object pose\\nestimation, surface normal estimation) without the need for fine-tuning and\\nshows traits of abstraction abilities (e.g., cross-modality pose estimation).\\nIn the context of the core supervised tasks, we demonstrate our representation\\nachieves state-of-the-art wide baseline feature matching results without\\nrequiring apriori rectification (unlike SIFT and the majority of learned\\nfeatures). We also show 6DOF camera pose estimation given a pair local image\\npatches. The accuracy of both supervised tasks come comparable to humans.\\nFinally, we contribute a large-scale dataset composed of object-centric street\\nview scenes along with point correspondences and camera pose information, and\\nconclude with a discussion on the learned representation and open research\\nquestions.\\n',\n",
       " '  In this work we study the determinant of the Laplace-Beltrami operator on\\nrectangular tori of unit area. We will see that the square torus gives the\\nextremal determinant within this class of tori. The result is established by\\nstudying properties of the Dedekind eta function for special arguments and\\nrefined logarithmic convexity and concavity results of the classical Jacobi\\ntheta functions of one real variable are deeply involved.\\n',\n",
       " '  Under mass-action kinetics, biochemical reaction networks give rise to\\npolynomial autonomous dynamical systems whose parameters are often difficult to\\nestimate. We deal in this paper with the problem of identifying the kinetic\\nparameters of a class of biochemical networks which are abundant, such as\\nmultisite phosphorylation systems and phosphorylation cascades (for example,\\nMAPK cascades). For any system of this class we explicitly exhibit a single\\nspecies for each connected component of the associated digraph such that the\\nsuccessive total derivatives of its concentration allow us to identify all the\\nparameters occurring in the component. The number of derivatives needed is\\nbounded essentially by the length of the corresponding connected component of\\nthe digraph. Moreover, in the particular case of the cascades, we show that the\\nparameters can be identified from a bounded number of successive derivatives of\\nthe last product of the last layer. This theoretical result induces also a\\nheuristic interpolation-based identifiability procedure to recover the values\\nof the rate constants from exact measurements.\\n',\n",
       " '  Missing values widely exist in many real-world datasets, which hinders the\\nperforming of advanced data analytics. Properly filling these missing values is\\ncrucial but challenging, especially when the missing rate is high. Many\\napproaches have been proposed for missing value imputation (MVI), but they are\\nmostly heuristics-based, lacking a principled foundation and do not perform\\nsatisfactorily in practice. In this paper, we propose a probabilistic framework\\nbased on deep generative models for MVI. Under this framework, imputing the\\nmissing entries amounts to seeking a fixed-point solution between two\\nconditional distributions defined on the missing entries and latent variables\\nrespectively. These distributions are parameterized by deep neural networks\\n(DNNs) which possess high approximation power and can capture the nonlinear\\nrelationships between missing entries and the observed values. The learning of\\nweight parameters of DNNs is performed by maximizing an approximation of the\\nlog-likelihood of observed values. We conducted extensive evaluation on 13\\ndatasets and compared with 11 baselines methods, where our methods largely\\noutperforms the baselines.\\n',\n",
       " \"  This paper presents smoothed combined field integral equations for the\\nsolution of Dirichlet and Neumann exterior Helmholtz problems. The integral\\nequations introduced in this paper are smooth in the sense that they only\\ninvolve continuously differentiable integrands in both Dirichlet and Neumann\\ncases. These integral equations coincide with the well-known combined field\\nequations and are therefore uniquely solvable for all frequencies. In\\nparticular, a novel regularization of the hypersingular operator is obtained,\\nwhich, unlike regularizations based on Maue's integration-by-parts formula,\\ndoes not give rise to involved Cauchy principal value integrals. The smoothed\\nintegral operators and layer potentials, on the other hand, can be numerically\\nevaluated at target points that are arbitrarily close to the boundary without\\nseverely compromising their accuracy. A variety of numerical examples in two\\nspatial dimensions that consider three different Nyström discretizations for\\nsmooth domains and domains with corners---one of which is based on direct\\napplication of the trapezoidal rule---demonstrates the effectiveness of the\\nproposed integral approach. In certain aspects, this work extends to the\\nuniquely solvable Dirichlet and Neumann combined field integral equations, the\\nideas presented in the recent contribution R. Soc. Open Sci. 2(140520), 2015.\\n\",\n",
       " '  This paper considers unbalanced multiphase distribution systems with generic\\ntopology and different load models, and extends the Z-bus iterative load-flow\\nalgorithm based on a fixed-point interpretation of the AC load-flow equations.\\nExplicit conditions for existence and uniqueness of load-flow solutions are\\npresented. These conditions also guarantee convergence of the load-flow\\nalgorithm to the unique solution. The proposed methodology is applicable to\\ngeneric systems featuring (i) wye connections; (ii) ungrounded delta\\nconnections; (iii) a combination of wye-connected and delta-connected\\nsources/loads; and, (iv) a combination of line-to-line and\\nline-to-grounded-neutral devices at the secondary of distribution transformers.\\nFurther, a sufficient condition for the non-singularity of the load-flow\\nJacobian is proposed. Finally, linear load-flow models are derived, and their\\napproximation accuracy is analyzed. Theoretical results are corroborated\\nthrough experiments on IEEE test feeders.\\n',\n",
       " '  In this paper, we use the house price data ranging from January 2004 to\\nOctober 2016 to predict the average house price of November and December in\\n2016 for each district in Beijing, Shanghai, Guangzhou and Shenzhen. We apply\\nAutoregressive Integrated Moving Average model to generate the baseline while\\nLSTM networks to build prediction model. These algorithms are compared in terms\\nof Mean Squared Error. The result shows that the LSTM model has excellent\\nproperties with respect to predict time series. Also, stateful LSTM networks\\nand stack LSTM networks are employed to further study the improvement of\\naccuracy of the house prediction model.\\n',\n",
       " '  Robins et al. (2008, 2016) applied the theory of higher order influence\\nfunctions (HOIFs) to derive an estimator of the mean of an outcome Y in a\\nmissing data model with Y missing at random conditional on a vector X of\\ncontinuous covariates; their estimator, in contrast to previous estimators, is\\nsemiparametric efficient under minimal conditions. However, the Robins et al.\\n(2008, 2016) estimator depends on a non-parametric estimate of the density of\\nX. In this paper, we introduce a new HOIF estimator that has the same\\nasymptotic properties as their estimator but does not require nonparametric\\nestimation of a multivariate density, which is important because accurate\\nestimation of a high dimensional density is not feasible at the moderate sample\\nsizes often encountered in applications. We also show that our estimator can be\\ngeneralized to the entire class of functionals considered by Robins et al.\\n(2008) which include the average effect of a treatment on a response Y when a\\nvector X suffices to control confounding and the expected conditional variance\\nof a response Y given a vector X.\\n',\n",
       " '  We present an overview of scenarios where the observed Dark Matter (DM)\\nabundance consists of Feebly Interacting Massive Particles (FIMPs), produced\\nnon-thermally by the so-called freeze-in mechanism. In contrast to the usual\\nfreeze-out scenario, frozen-in FIMP DM interacts very weakly with the particles\\nin the visible sector and never attained thermal equilibrium with the\\nbaryon-photon fluid in the early Universe. Instead of being determined by its\\nannihilation strength, the DM abundance depends on the decay and annihilation\\nstrengths of particles in equilibrium with the baryon-photon fluid, as well as\\ncouplings in the DM sector. This makes frozen-in DM very difficult but not\\nimpossible to test. In this review, we present the freeze-in mechanism and its\\nvariations considered in the literature (dark freeze-out and reannihilation),\\ncompare them to the standard DM freeze-out scenario, discuss several aspects of\\nmodel building, and pay particular attention to observational properties and\\ngeneral testability of such feebly interacting DM.\\n',\n",
       " '  Seymour\\'s second neighbourhood conjecture asserts that every oriented graph\\nhas a vertex whose second out-neighbourhood is at least as large as its\\nout-neighbourhood. In this paper, we prove that the conjecture holds for\\nquasi-transitive oriented graphs, which is a superclass of tournaments and\\ntransitive acyclic digraphs. A digraph $D$ is called quasi-transitive is for\\nevery pair $xy,yz$ of arcs between distinct vertices $x,y,z$, $xz$ or $zx$\\n(\"or\" is inclusive here) is in $D$.\\n',\n",
       " '  We describe and analyze some Monte Carlo methods for manifolds in Euclidean\\nspace defined by equality and inequality constraints. First, we give an MCMC\\nsampler for probability distributions defined by un-normalized densities on\\nsuch manifolds. The sampler uses a specific orthogonal projection to the\\nsurface that requires only information about the tangent space to the manifold,\\nobtainable from first derivatives of the constraint functions, hence avoiding\\nthe need for curvature information or second derivatives. Second, we use the\\nsampler to develop a multi-stage algorithm to compute integrals over such\\nmanifolds. We provide single-run error estimates that avoid the need for\\nmultiple independent runs. Computational experiments on various test problems\\nshow that the algorithms and error estimates work in practice. The method is\\napplied to compute the entropies of different sticky hard sphere systems. These\\npredict the temperature or interaction energy at which loops of hard sticky\\nspheres become preferable to chains.\\n',\n",
       " '  Long-range low-power wireless communications, such as LoRa, are used in many\\nIoT and environmental monitoring applications. They typically increase the\\ncommunication range to several kilometers, at the cost of reducing the bitrate\\nto a few bits per seconds. Collisions further reduce the performance of these\\ncommunications. In this paper, we propose two algorithms to decode colliding\\nsignals: one algorithm requires the transmitters to be slightly desynchronized,\\nand the other requires the transmitters to be synchronized. To do so, we use\\nthe timing information to match the correct symbols to the correct\\ntransmitters. We show that our algorithms are able to significantly improve the\\noverall throughput of LoRa.\\n',\n",
       " '  Astrophysics and cosmology are rich with data. The advent of wide-area\\ndigital cameras on large aperture telescopes has led to ever more ambitious\\nsurveys of the sky. Data volumes of entire surveys a decade ago can now be\\nacquired in a single night and real-time analysis is often desired. Thus,\\nmodern astronomy requires big data know-how, in particular it demands highly\\nefficient machine learning and image analysis algorithms. But scalability is\\nnot the only challenge: Astronomy applications touch several current machine\\nlearning research questions, such as learning from biased data and dealing with\\nlabel and measurement noise. We argue that this makes astronomy a great domain\\nfor computer science research, as it pushes the boundaries of data analysis. In\\nthe following, we will present this exciting application area for data\\nscientists. We will focus on exemplary results, discuss main challenges, and\\nhighlight some recent methodological advancements in machine learning and image\\nanalysis triggered by astronomical applications.\\n',\n",
       " '  Access to collective excitations lies at the heart of our understanding of\\nquantum many-body systems. We study the Higgs and Goldstone modes in a\\nsupersolid quantum gas that is created by coupling a Bose-Einstein condensate\\nsymmetrically to two optical cavities. The cavity fields form a U(1)-symmetric\\norder parameter that can be modulated and monitored along both quadratures in\\nreal time. This enables us to measure the excitation energies across the\\nsuperfluid-supersolid phase transition, establish their amplitude and phase\\nnature, as well as characterize their dynamics from an impulse response.\\nFurthermore, we can give a tunable mass to the Goldstone mode at the crossover\\nbetween continuous and discrete symmetry by changing the coupling of the\\nquantum gas with either cavity.\\n',\n",
       " '  The increased availability of massive data sets provides a unique opportunity\\nto discover subtle patterns in their distributions, but also imposes\\noverwhelming computational challenges. To fully utilize the information\\ncontained in big data, we propose a two-step procedure: (i) estimate\\nconditional quantile functions at different levels in a parallel computing\\nenvironment; (ii) construct a conditional quantile regression process through\\nprojection based on these estimated quantile curves. Our general quantile\\nregression framework covers both linear models with fixed or growing dimension\\nand series approximation models. We prove that the proposed procedure does not\\nsacrifice any statistical inferential accuracy provided that the number of\\ndistributed computing units and quantile levels are chosen properly. In\\nparticular, a sharp upper bound for the former and a sharp lower bound for the\\nlatter are derived to capture the minimal computational cost from a statistical\\nperspective. As an important application, the statistical inference on\\nconditional distribution functions is considered. Moreover, we propose\\ncomputationally efficient approaches to conducting inference in the distributed\\nestimation setting described above. Those approaches directly utilize the\\navailability of estimators from sub-samples and can be carried out at almost no\\nadditional computational cost. Simulations confirm our statistical inferential\\ntheory.\\n',\n",
       " '  A novel approach is presented for group statistical analysis of diffusion\\nweighted MRI datasets through voxelwise Orientation Distribution Functions\\n(ODF). Recent advances in MRI acquisition make it possible to use high quality\\ndiffusion weighted protocols (multi-shell, large number of gradient directions)\\nfor routine in vivo study of white matter architecture. The dimensionality of\\nthese data sets is however often reduced to simplify statistical analysis.\\nWhile these approaches may detect large group differences, they do not fully\\ncapitalize on all acquired image volumes. Incorporation of all available\\ndiffusion information in the analysis however risks biasing the outcome by\\noutliers. Here we propose a statistical analysis method operating on the ODF,\\neither the diffusion ODF or fiber ODF. To avoid outlier bias and reliably\\ndetect voxelwise group differences and correlations with demographic or\\nbehavioral variables, we apply the Low-Rank plus Sparse (L + S) matrix\\ndecomposition on the voxelwise ODFs which separates the sparse individual\\nvariability in the sparse matrix S whilst recovering the essential ODF features\\nin the low-rank matrix L. We demonstrate the performance of this ODF L + S\\napproach by replicating the established negative association between global\\nwhite matter integrity and physical obesity in the Human Connectome dataset.\\nThe volume of positive findings agrees with and expands on the volume found by\\nTBSS, Connectivity based fixel enhancement and Connectometry. In the same\\ndataset we further localize the correlations of brain structure with\\nneurocognitive measures such as fluid intelligence and episodic memory. The\\npresented ODF L + S approach will aid in the full utilization of all acquired\\ndiffusion weightings leading to the detection of smaller group differences in\\nclinically relevant settings as well as in neuroscience applications.\\n',\n",
       " \"  The application of GNC devices on small robots is a game-changer that enables\\nthese robots to be mobile on low-gravity planetary surfaces and small bodies.\\nUse of reaction wheels enables these robots to roll, hop, summersault and rest\\non precarious/sloped surfaces that would otherwise not be possible with\\nconven-tional wheeled robots. We are extending this technology to enable robots\\nto climb off-world canyons, cliffs and caves. A single robot may slip and fall,\\nhowever, a multirobot system can work cooperatively by being interlinked using\\nspring-tethers and work much like a team of mountaineers to systematically\\nclimb a slope. A multirobot system as we will show in this paper can climb\\nsur-faces not possible with a single robot alone. We consider a team of four\\nrobots that are interlinked with tethers in an 'x' configuration. Each robot\\nsecures itself to a slope using spiny gripping actuators, and one by one each\\nrobot moves up-wards by crawling, rolling or hopping up the slope. If any one\\nof the robots loses grip, slips or falls, the remaining robots will be holding\\nit up as they are anchored. This distributed controls approach to cliff\\nclimbing enables the system to reconfigure itself where possible and avoid\\ngetting stuck at one hard to reach location. Instead, the risk is distributed\\nand through close cooperation, the robots can identify multiple trajectories to\\nclimb a cliff or rugged surface. The benefits can also be realized on\\nmilligravity surfaces such as asteroids. Too fast a jump can result in the\\nrobot flying off the surface into space. Having multiple robots anchored to the\\nsurface keeps the entire system secure. Our work combines dynamics and control\\nsimulation to evaluate the feasibility of our approach. The simulation results\\nshow a promising pathway towards advanced development of this technology on a\\nteam of real robots.\\n\",\n",
       " '  Clustering is an essential data mining tool that aims to discover inherent\\ncluster structure in data. For most applications, applying clustering is only\\nappropriate when cluster structure is present. As such, the study of\\nclusterability, which evaluates whether data possesses such structure, is an\\nintegral part of cluster analysis. However, methods for evaluating\\nclusterability vary radically, making it challenging to select a suitable\\nmeasure. In this paper, we perform an extensive comparison of measures of\\nclusterability and provide guidelines that clustering users can reference to\\nselect suitable measures for their applications.\\n',\n",
       " '  We prove in this paper the convergence of the Marker and cell (MAC) scheme\\nfor the dis-cretization of the steady-state and unsteady-state incompressible\\nNavier-Stokes equations in primitive variables on non-uniform Cartesian grids,\\nwithout any regularity assumption on the solution. A priori estimates on\\nsolutions to the scheme are proven ; they yield the existence of discrete\\nsolutions and the compactness of sequences of solutions obtained with family of\\nmeshes the space step of which tends to zero. We then establish that the limit\\nis a weak solution to the continuous problem.\\n',\n",
       " '  Let $\\\\sigma =\\\\{\\\\sigma_{i} | i\\\\in I\\\\}$ be a partition of the set of all primes\\n$\\\\Bbb{P}$ and $G$ a finite group. Let $\\\\sigma (G)=\\\\{\\\\sigma _{i} : \\\\sigma\\n_{i}\\\\cap \\\\pi (G)\\\\ne \\\\emptyset$. A set ${\\\\cal H}$ of subgroups of $G$ is said to\\nbe a complete Hall $\\\\sigma $-set of $G$ if every member $\\\\ne 1$ of ${\\\\cal H}$\\nis a Hall $\\\\sigma _{i}$-subgroup of $G$ for some $i\\\\in I$ and $\\\\cal H$ contains\\nexactly one Hall $\\\\sigma _{i}$-subgroup of $G$ for every $i$ such that $\\\\sigma\\n_{i}\\\\in \\\\sigma (G)$. We say that $G$ is $\\\\sigma$-full if $G$ possesses a\\ncomplete Hall $\\\\sigma $-set. A complete Hall $\\\\sigma $-set $\\\\cal H$ of $G$ is\\nsaid to be a $\\\\sigma$-basis of $G$ if every two subgroups $A, B \\\\in\\\\cal H$ are\\npermutable, that is, $AB=BA$. In this paper, we study properties of finite\\ngroups having a $\\\\sigma$-basis. In particular, we prove that if $G$ has a a\\n$\\\\sigma$-basis, then $G$ is generalized $\\\\sigma$-soluble, that is, $G$ has a\\ncomplete Hall $\\\\sigma $-set and for every chief factor $H/K$ of $G$ we have\\n$|\\\\sigma (H/K)|\\\\leq 2$. Moreover, answering to Problem 8.28 in [A.N. Skiba, On\\nsome results in the theory of finite partially soluble groups, Commun. Math.\\nStat., 4(3) (2016), 281--309], we prove the following Theorem A. Suppose that\\n$G$ is $\\\\sigma$-full. Then every complete Hall $\\\\sigma$-set of $G$ forms a\\n$\\\\sigma$-basis of $G$ if and only if $G$ is generalized $\\\\sigma$-soluble and\\nfor the automorphism group $G/C_{G}(H/K)$, induced by $G$ on any its chief\\nfactor $H/K$, we have either $\\\\sigma (H/K)=\\\\sigma (G/C_{G}(H/K))$ or $\\\\sigma\\n(H/K) =\\\\{\\\\sigma _{i}\\\\}$ and $G/C_{G}(H/K)$ is a $\\\\sigma _{i} \\\\cup \\\\sigma\\n_{j}$-group for some $i\\\\ne j$.\\n',\n",
       " '  Through seven publications this dissertation shows how anonymized mobile\\nphone data can contribute to the social good and provide insights into human\\nbehaviour on a large scale. The size of the datasets analysed ranges from 500\\nmillion to 300 billion phone records, covering millions of people. The key\\ncontributions are two-fold:\\n1. Big Data for Social Good: Through prediction algorithms the results show\\nhow mobile phone data can be useful to predict important socio-economic\\nindicators, such as income, illiteracy and poverty in developing countries.\\nSuch knowledge can be used to identify where vulnerable groups in society are,\\nreduce economic shocks and is a critical component for monitoring poverty rates\\nover time. Further, the dissertation demonstrates how mobile phone data can be\\nused to better understand human behaviour during large shocks in society,\\nexemplified by an analysis of data from the terror attack in Norway and a\\nnatural disaster on the south-coast in Bangladesh. This work leads to an\\nincreased understanding of how information spreads, and how millions of people\\nmove around. The intention is to identify displaced people faster, cheaper and\\nmore accurately than existing survey-based methods.\\n2. Big Data for efficient marketing: Finally, the dissertation offers an\\ninsight into how anonymised mobile phone data can be used to map out large\\nsocial networks, covering millions of people, to understand how products spread\\ninside these networks. Results show that by including social patterns and\\nmachine learning techniques in a large-scale marketing experiment in Asia, the\\nadoption rate is increased by 13 times compared to the approach used by\\nexperienced marketers. A data-driven and scientific approach to marketing,\\nthrough more tailored campaigns, contributes to less irrelevant offers for the\\ncustomers, and better cost efficiency for the companies.\\n',\n",
       " \"  Higher-order probabilistic programming languages allow programmers to write\\nsophisticated models in machine learning and statistics in a succinct and\\nstructured way, but step outside the standard measure-theoretic formalization\\nof probability theory. Programs may use both higher-order functions and\\ncontinuous distributions, or even define a probability distribution on\\nfunctions. But standard probability theory does not handle higher-order\\nfunctions well: the category of measurable spaces is not cartesian closed.\\nHere we introduce quasi-Borel spaces. We show that these spaces: form a new\\nformalization of probability theory replacing measurable spaces; form a\\ncartesian closed category and so support higher-order functions; form a\\nwell-pointed category and so support good proof principles for equational\\nreasoning; and support continuous probability distributions. We demonstrate the\\nuse of quasi-Borel spaces for higher-order functions and probability by:\\nshowing that a well-known construction of probability theory involving random\\nfunctions gains a cleaner expression; and generalizing de Finetti's theorem,\\nthat is a crucial theorem in probability theory, to quasi-Borel spaces.\\n\",\n",
       " '  We show that the stochastic evolution of an interacting system of the Higgs\\nand a spectator scalar field naturally gives rise to an enhanced probability of\\nsettling down at the electroweak vacuum at the end of inflation. Subsequent\\ndestabilization due to parametric resonance between the Higgs and the spectator\\nfield can be avoided in a wide parameter range. We further argue that the\\nspectator field can play the role of dark matter.\\n',\n",
       " '  Feature extraction and feature selection are the first tasks in\\npre-processing of input logs in order to detect cyber security threats and\\nattacks while utilizing machine learning. When it comes to the analysis of\\nheterogeneous data derived from different sources, these tasks are found to be\\ntime-consuming and difficult to be managed efficiently. In this paper, we\\npresent an approach for handling feature extraction and feature selection for\\nsecurity analytics of heterogeneous data derived from different network\\nsensors. The approach is implemented in Apache Spark, using its python API,\\nnamed pyspark.\\n',\n",
       " '  Undoubtedly, the MapReduce is the most powerful programming paradigm in\\ndistributed computing. The enhancement of the MapReduce is essential and it can\\nlead the computing faster. Therefore, here are many scheduling algorithms to\\ndiscuss based on their characteristics. Moreover, there are many shortcoming to\\ndiscover in this field. In this article, we present the state-of-the-art\\nscheduling algorithm to enhance the understanding of the algorithms. The\\nalgorithms are presented systematically such that there can be many future\\npossibilities in scheduling algorithm through this article. In this paper, we\\nprovide in-depth insight on the MapReduce scheduling algorithm. In addition, we\\ndiscuss various issues of MapReduce scheduler developed for large-scale\\ncomputing as well as heterogeneous environment.\\n',\n",
       " '  We present a methodology for generating Ising Hamiltonians of tunable\\ncomplexity and with a priori known ground states based on a decomposition of\\nthe model graph into edge-disjoint subgraphs. The idea is illustrated with a\\nspin-glass model defined on a cubic lattice, where subproblems, whose couplers\\nare restricted to the two values {-1,+1}, are specified on unit cubes and are\\nparametrized by their local degeneracy. The construction is shown to be\\nequivalent to a type of three-dimensional constraint satisfaction problem known\\nas the tiling puzzle. By varying the proportions of subproblem types, the\\nHamiltonian can span a dramatic range of typical computational complexity, from\\nfairly easy to many orders of magnitude more difficult than prototypical\\nbimodal and Gaussian spin glasses in three space dimensions. We corroborate\\nthis behavior via experiments with different algorithms and discuss\\ngeneralizations and extensions to different types of graphs.\\n',\n",
       " '  The Lobula Giant Movement Detector (LGMD) is a an identified neuron of the\\nlocust that detects looming objects and triggers its escape responses.\\nUnderstanding the neural principles and networks that lead to these fast and\\nrobust responses can lead to the design of efficient facilitate obstacle\\navoidance strategies in robotic applications. Here we present a neuromorphic\\nspiking neural network model of the LGMD driven by the output of a neuromorphic\\nDynamic Vision Sensor (DVS), which has been optimised to produce robust and\\nreliable responses in the face of the constraints and variability of its mixed\\nsignal analogue-digital circuits. As this LGMD model has many parameters, we\\nuse the Differential Evolution (DE) algorithm to optimise its parameter space.\\nWe also investigate the use of Self-Adaptive Differential Evolution (SADE)\\nwhich has been shown to ameliorate the difficulties of finding appropriate\\ninput parameters for DE. We explore the use of two biological mechanisms:\\nsynaptic plasticity and membrane adaptivity in the LGMD. We apply DE and SADE\\nto find parameters best suited for an obstacle avoidance system on an unmanned\\naerial vehicle (UAV), and show how it outperforms state-of-the-art Bayesian\\noptimisation used for comparison.\\n',\n",
       " '  We developed a new analytical experimental setup called AROMA (Astrochemistry\\nResearch of Organics with Molecular Analyzer) that combines laser\\ndesorption/ionization techniques with ion trap mass spectrometry. We report\\nhere on the ability of the apparatus to detect aromatic species in complex\\nmaterials of astrophysical interests and characterize their structures. A limit\\nof detection of 100 femto-grams has been achieved using pure polycyclic\\naromatic hydrocarbon (PAH) samples, which corresponds to 2x10^8 molecules in\\nthe case of coronene (C24H12). We detected the PAH distribution in the\\nMurchison meteorite, which is made of a complex mixture of extraterrestrial\\norganic compounds. In addition, collision induced dissociation experiments were\\nperformed on selected species detected in Murchison, which led to the first\\nfirm identification of pyrene and its methylated derivatives in this sample.\\n',\n",
       " '  Finite element models without simplifying assumptions can accurately describe\\nthe spatial and temporal distribution of heat in machine tools as well as the\\nresulting deformation. In principle, this allows to correct for displacements\\nof the Tool Centre Point and enables high precision manufacturing. However, the\\ncomputational cost of FEM models and restriction to generic algorithms in\\ncommercial tools like ANSYS prevents their operational use since simulations\\nhave to run faster than real-time. For the case where heat diffusion is slow\\ncompared to machine movement, we introduce a tailored implicit-explicit\\nmulti-rate time stepping method of higher order based on spectral deferred\\ncorrections. Using the open-source FEM library DUNE, we show that fully coupled\\nsimulations of the temperature field are possible in real-time for a machine\\nconsisting of a stock sliding up and down on rails attached to a stand.\\n',\n",
       " '  We present SCUBA-2 follow-up of 61 candidate high-redshift Planck sources. Of\\nthese, 10 are confirmed strong gravitational lenses and comprise some of the\\nbrightest such submm sources on the observed sky, while 51 are candidate\\nproto-cluster fields undergoing massive starburst events. With the accompanying\\nHerschel-SPIRE observations and assuming an empirical dust temperature prior of\\n$34^{+13}_{-9}$ K, we provide photometric redshift and far-IR luminosity\\nestimates for 172 SCUBA-2-selected sources within these Planck overdensity\\nfields. The redshift distribution of the sources peak between a redshift of 2\\nand 4, with one third of the sources having $S_{500}$/$S_{350} > 1$. For the\\nmajority of the sources, we find far-IR luminosities of approximately\\n$10^{13}\\\\,\\\\mathrm{L}_\\\\odot$, corresponding to star-formation rates of around\\n$1000$ M$_\\\\odot \\\\mathrm{yr}^{-1}$. For $S_{850}>8$ mJy sources, we show that\\nthere is up to an order of magnitude increase in star-formation rate density\\nand an increase in uncorrected number counts of $6$ for $S_{850}>8$ mJy when\\ncompared to typical cosmological survey fields. The sources detected with\\nSCUBA-2 account for only approximately $5$ per cent of the Planck flux at 353\\nGHz, and thus many more fainter sources are expected in these fields.\\n',\n",
       " \"  Unraveling the stratigraphic record is the key to understanding ancient\\nclimate and past climate changes on Mars. River deposits when placed in\\nstratigraphic order could constrain the number, magnitudes, and durations of\\nthe wettest climates in Mars history. We establish the stratigraphic context of\\nriver deposits in Aeolis Dorsa sedimentary basin, 10E of Gale crater. Here,\\nwind has exhumed a stratigraphic section of >=4 unconformity-bounded\\nsedimentary rock packages, recording >=3 distinct episodes of surface runoff.\\nEarly deposits (>700m thick) are embayed by river deposits (>400m), which are\\nin turn unconformably draped by fan-shaped deposits (<100m) which we interpret\\nas alluvial fans. Yardang-forming deposits (>900 m) unconformably drape all\\nprevious deposits. River deposits embay a dissected sedimentary-rock landscape,\\nand comprise >=2 distinguishable units. The total interval spanned by river\\ndeposits is >(1x10^6-2x10^7) yr; more if we include alluvial-fan deposits.\\nAlluvial-fan deposits unconformably postdate thrust faults which crosscut river\\ndeposits. We infer a relatively dry interval of >4x10^7 yr after river deposits\\nformed and before fan-shaped deposits formed. The time gap between the end of\\nriver deposition and the onset of yardang-forming deposits is constrained to\\n>10^8 yr by the density of impact craters embedded at the unconformity. We\\ncorrelate yardang-forming deposits to the upper layers of Gale crater's mound\\n(Mt. Sharp/Aeolis Mons), and fan-shaped deposits to Peace Vallis fan.\\nAlternations between periods of low vs. high mean obliquity may have modulated\\nerosion-deposition cycling in Aeolis. This is consistent with results from an\\nensemble of simulations of Solar System orbital evolution and the resulting\\nhistory of Mars obliquity. Almost all simulations yield intervals of\\ncontinuously low mean Mars obliquity that are long enough to match our\\nunconformity data.\\n\",\n",
       " '  Domestic Violence (DV) is considered as big social issue and there exists a\\nstrong relationship between DV and health impacts of the public. Existing\\nresearch studies have focused on social media to track and analyse real world\\nevents like emerging trends, natural disasters, user sentiment analysis,\\npolitical opinions, and health care. However there is less attention given on\\nsocial welfare issues like DV and its impact on public health. Recently, the\\nvictims of DV turned to social media platforms to express their feelings in the\\nform of posts and seek the social and emotional support, for sympathetic\\nencouragement, to show compassion and empathy among public. But, it is\\ndifficult to mine the actionable knowledge from large conversational datasets\\nfrom social media due to the characteristics of high dimensions, short, noisy,\\nhuge volume, high velocity, and so on. Hence, this paper will propose a novel\\nframework to model and discover the various themes related to DV from the\\npublic domain. The proposed framework would possibly provide unprecedentedly\\nvaluable information to the public health researchers, national family health\\norganizations, government and public with data enrichment and consolidation to\\nimprove the social welfare of the community. Thus provides actionable knowledge\\nby monitoring and analysing continuous and rich user generated content.\\n',\n",
       " \"  The edge partition model (EPM) is a fundamental Bayesian nonparametric model\\nfor extracting an overlapping structure from binary matrix. The EPM adopts a\\ngamma process ($\\\\Gamma$P) prior to automatically shrink the number of active\\natoms. However, we empirically found that the model shrinkage of the EPM does\\nnot typically work appropriately and leads to an overfitted solution. An\\nanalysis of the expectation of the EPM's intensity function suggested that the\\ngamma priors for the EPM hyperparameters disturb the model shrinkage effect of\\nthe internal $\\\\Gamma$P. In order to ensure that the model shrinkage effect of\\nthe EPM works in an appropriate manner, we proposed two novel generative\\nconstructions of the EPM: CEPM incorporating constrained gamma priors, and DEPM\\nincorporating Dirichlet priors instead of the gamma priors. Furthermore, all\\nDEPM's model parameters including the infinite atoms of the $\\\\Gamma$P prior\\ncould be marginalized out, and thus it was possible to derive a truly infinite\\nDEPM (IDEPM) that can be efficiently inferred using a collapsed Gibbs sampler.\\nWe experimentally confirmed that the model shrinkage of the proposed models\\nworks well and that the IDEPM indicated state-of-the-art performance in\\ngeneralization ability, link prediction accuracy, mixing efficiency, and\\nconvergence speed.\\n\",\n",
       " '  Human beings cannot be happy with any kind of tiredness based work, so they\\nfocused on machines to work on behalf of humans. The Internet-based latest\\ntechnology provides the platforms for human beings to relax and unburden\\nfeeling. The Internet of Things (IoT) field efficiently helps human beings with\\nsmart decisions through Machine-to-Machine (M2M) communication all over the\\nworld. It has been difficult to ignore the importance of the IoT field with the\\nnew development of applications such as a smartphone in the present era. The\\nIoT field sensor plays a vital role in sensing the intelligent object/things\\nand making an intelligent decision after sensing the objects. The rapid\\ndevelopment of new applications using smartphones in the world caused all users\\nof the IoT community to be faced with one major challenge of security in the\\nform of side channel attacks against highly intensive 3D printing systems. The\\nsmartphone formulated Intellectual property (IP) of side channel attacks\\ninvestigate against 3D printer in the physical domain through reconstructed\\nG-code file through primitive operations. The smartphone (Nexus 5) solved the\\nmain problems such as orientation fixing, model accuracy of frame size and\\nvalidate the feasibility and effectiveness in real case studies against the 3D\\nprinter. The 3D printing estimated value reached 20.2 billion of dollars in\\n2021. The thermal camera is used for exploring the side channel attacks after\\nreconstructing the objects against 3D printers. The researcher analyzed IoT\\nsecurity relevant issues which were avoided in future by enhanced strong\\nsecurity mechanism strategy, encryption, and machine learning-based algorithms,\\nlatest technologies, schemes and protocols utilized in an efficient way.\\nKeywords: - Internet of Things (IoT), Machine-to-Machine (M2M), Security, 3D\\nprinter, smartphone\\n',\n",
       " \"  We propose DeepBreath, a deep learning model which automatically recognises\\npeople's psychological stress level (mental overload) from their breathing\\npatterns. Using a low cost thermal camera, we track a person's breathing\\npatterns as temperature changes around his/her nostril. The paper's technical\\ncontribution is threefold. First of all, instead of creating hand-crafted\\nfeatures to capture aspects of the breathing patterns, we transform the\\nuni-dimensional breathing signals into two dimensional respiration variability\\nspectrogram (RVS) sequences. The spectrograms easily capture the complexity of\\nthe breathing dynamics. Second, a spatial pattern analysis based on a deep\\nConvolutional Neural Network (CNN) is directly applied to the spectrogram\\nsequences without the need of hand-crafting features. Finally, a data\\naugmentation technique, inspired from solutions for over-fitting problems in\\ndeep learning, is applied to allow the CNN to learn with a small-scale dataset\\nfrom short-term measurements (e.g., up to a few hours). The model is trained\\nand tested with data collected from people exposed to two types of cognitive\\ntasks (Stroop Colour Word Test, Mental Computation test) with sessions of\\ndifferent difficulty levels. Using normalised self-report as ground truth, the\\nCNN reaches 84.59% accuracy in discriminating between two levels of stress and\\n56.52% in discriminating between three levels. In addition, the CNN\\noutperformed powerful shallow learning methods based on a single layer neural\\nnetwork. Finally, the dataset of labelled thermal images will be open to the\\ncommunity.\\n\",\n",
       " '  The Bayesian expected power (BEP) has become increasingly popular in sample\\nsize determination and assessment of the probability of success (POS) for a\\nfuture trial. The BEP takes into consideration the uncertainty around the\\nparameters assumed by a power analysis and is thus more robust compared to the\\ntraditional power that assumes a single set of parameters. Current methods for\\nassessing BEP are often based in a parametric framework by imposing a model on\\nthe pilot data to derive and sample from the posterior distributions of the\\nparameters. Implementation of the model-based approaches can be analytically\\nchallenging and computationally costly especially for multivariate data sets;\\nit also runs the risk of generating misleading BEP if the model is\\nmis-specified. We propose an approach based on the Bayesian bootstrap technique\\n(BBS) to simulate future trials in the presence of individual-level pilot data,\\nbased on which the empirical BEP can be calculated. The BBS approach is\\nmodel-free with no assumptions about the distribution of the prior data and\\ncircumvents the analytical and computational complexity associated with\\nobtaining the posterior distribution of the parameters. Information from\\nmultiple pilot studies is also straightforward to combine. We also propose the\\ndouble bootstrap (BS2), a frequentist counterpart to the BBS, that shares\\nsimilar properties and achieves the same goal as the BBS for BEP assessment.\\nSimulation studies and case studies are presented to demonstrate the\\nimplementation of the BBS and BS2 techniques and to compare the BEP results\\nwith model-based approaches.\\n',\n",
       " '  In their precedent work, the authors constructed closed oriented hyperbolic\\nsurfaces with pseudo-Anosov homeomorphisms from certain class of integral\\nmatrices. In this paper, we present a very simple algorithm to compute the\\nTeichmueller polynomial corresponding to those surface homeomorphisms by first\\nconstructing an invariant track whose first homology group can be naturally\\nidentified with the first homology group of the surface, and computing its\\nAlexander polynomial.\\n',\n",
       " '  This paper presents a new 3D point cloud classification benchmark data set\\nwith over four billion manually labelled points, meant as input for data-hungry\\n(deep) learning methods. We also discuss first submissions to the benchmark\\nthat use deep convolutional neural networks (CNNs) as a work horse, which\\nalready show remarkable performance improvements over state-of-the-art. CNNs\\nhave become the de-facto standard for many tasks in computer vision and machine\\nlearning like semantic segmentation or object detection in images, but have no\\nyet led to a true breakthrough for 3D point cloud labelling tasks due to lack\\nof training data. With the massive data set presented in this paper, we aim at\\nclosing this data gap to help unleash the full potential of deep learning\\nmethods for 3D labelling tasks. Our semantic3D.net data set consists of dense\\npoint clouds acquired with static terrestrial laser scanners. It contains 8\\nsemantic classes and covers a wide range of urban outdoor scenes: churches,\\nstreets, railroad tracks, squares, villages, soccer fields and castles. We\\ndescribe our labelling interface and show that our data set provides more dense\\nand complete point clouds with much higher overall number of labelled points\\ncompared to those already available to the research community. We further\\nprovide baseline method descriptions and comparison between methods submitted\\nto our online system. We hope semantic3D.net will pave the way for deep\\nlearning methods in 3D point cloud labelling to learn richer, more general 3D\\nrepresentations, and first submissions after only a few months indicate that\\nthis might indeed be the case.\\n',\n",
       " '  We compute the Upsilon invariant of L-space cable knots $K_{p,q}$ in terms of\\n$p,\\\\Upsilon_K$ and $\\\\Upsilon_{T_{p,q}}$. The integral value of the Upsilon\\ninvariant gives a ${\\\\mathbb Q}$-valued knot concordance invariant. We also\\ncompute the integral values of the Upsilon of L-space cable knots.\\n',\n",
       " '  News reports shape the public perception of the critical social, political\\nand economical events around the world. Yet, the way in which emergent\\nphenomena are reported in the news makes the early prediction of such phenomena\\na challenging task. We propose a scalable community-based probabilistic\\nframework to model the spreading of news about events in online media. Our\\napproach exploits the latent community structure in the global news media and\\nuses the affiliation of the early adopters with a variety of communities to\\nidentify the events widely reported in the news at the early stage of their\\nspread. The time complexity of our approach is linear in the number of news\\nreports. It is also amenable to efficient parallelization. To demonstrate these\\nfeatures, the inference algorithm is parallelized for message passing paradigm\\nand tested on RPI Advanced Multiprocessing Optimized System (AMOS), one of the\\nfastest Blue Gene/Q supercomputers in the world. Thanks to the community-level\\nfeatures of the early adopters, the model gains an improvement of 20% in the\\nearly detection of the most massively reported events compared to the\\nfeature-based machine learning algorithm. Its parallelization scheme achieves\\norders of magnitude speedup.\\n',\n",
       " '  Global magnetic fields of flare stars can evolve rapidly, in time scale of\\nhundreds or dozens of days. We believe, that such changes result from rapid\\nsuperposition of local magnetic fields generated by differential rotation of\\nthose stars. We discuss possible mechanisms of generation and dissipation of\\nlocal and global magnetic fields in sample flare stars OT Ser and YZ CMi. We\\npropose mechanism of magnetic braking of these stars, in which differential\\nrotation generates local magnetic fields, and eventually energy accumulated in\\nlocal fields is radiated away by flares. We obtained estimates of the\\nrotational energy and the energy of the global magnetic field of OT Ser and YZ\\nCMi. We also show that the energy of the local magnetic fields dissipated\\nduring superflare of YZ CMi on 9 February 2008 (UT 20:22:00) did not influence\\nthe global magnetic field of this star.\\n',\n",
       " '  In this paper, we propose a convergent parallel best-response algorithm with\\nthe exact line search for the nondifferentiable nonconvex sparsity-regularized\\nrank minimization problem. On the one hand, it exhibits a faster convergence\\nthan subgradient algorithms and block coordinate descent algorithms. On the\\nother hand, its convergence to a stationary point is guaranteed, while ADMM\\nalgorithms only converge for convex problems. Furthermore, the exact line\\nsearch procedure in the proposed algorithm is performed efficiently in\\nclosed-form to avoid the meticulous choice of stepsizes, which is however a\\ncommon bottleneck in subgradient algorithms and successive convex approximation\\nalgorithms. Finally, the proposed algorithm is numerically tested.\\n',\n",
       " \"  A subfamily $\\\\{F_1,F_2,\\\\dots,F_{|P|}\\\\}\\\\subseteq {\\\\cal F}$ of sets is a copy\\nof a poset $P$ in ${\\\\cal F}$ if there exists a bijection $\\\\phi:P\\\\rightarrow\\n\\\\{F_1,F_2,\\\\dots,F_{|P|}\\\\}$ such that whenever $x \\\\le_P x'$ holds, then so does\\n$\\\\phi(x)\\\\subseteq \\\\phi(x')$. For a family ${\\\\cal F}$ of sets, let $c(P,{\\\\cal\\nF})$ denote the number of copies of $P$ in ${\\\\cal F}$, and we say that ${\\\\cal\\nF}$ is $P$-free if $c(P,{\\\\cal F})=0$ holds. For any two posets $P,Q$ let us\\ndenote by $La(n,P,Q)$ the maximum number of copies of $Q$ over all $P$-free\\nfamilies ${\\\\cal F} \\\\subseteq 2^{[n]}$, i.e. $\\\\max\\\\{c(Q,{\\\\cal F}): {\\\\cal F}\\n\\\\subseteq 2^{[n]}, c(P,{\\\\cal F})=0 \\\\}$.\\nThis generalizes the well-studied parameter $La(n,P)=La(n,P,P_1)$ where $P_1$\\nis the one element poset. The quantity $La(n,P)$ has been determined (precisely\\nor asymptotically) for many posets $P$, and in all known cases an\\nasymptotically best construction can be obtained by taking as many middle\\nlevels as possible without creating a copy of $P$.\\nIn this paper we consider the first instances of the problem of determining\\n$La(n,P,Q)$. We find its value when $P$ and $Q$ are small posets, like chains,\\nforks, the $N$ poset and diamonds. Already these special cases show that the\\nextremal families are completely different from those in the original $P$-free\\ncases: sometimes not middle or consecutive levels maximize $La(n,P,Q)$ and\\nsometimes no asymptotically extremal family is the union of levels.\\nFinally, we determine the maximum number of copies of complete multi-level\\nposets in $k$-Sperner families. The main tools for this are the profile\\npolytope method and two extremal set system problems that are of independent\\ninterest: we maximize the number of $r$-tuples $A_1,A_2,\\\\dots, A_r \\\\in {\\\\cal\\nA}$ over all antichains ${\\\\cal A}\\\\subseteq 2^{[n]}$ such that (i)\\n$\\\\cap_{i=1}^rA_i=\\\\emptyset$, (ii) $\\\\cap_{i=1}^rA_i=\\\\emptyset$ and\\n$\\\\cup_{i=1}^rA_i=[n]$.\\n\",\n",
       " \"  In reinforcement learning, it is common to let an agent interact for a fixed\\namount of time with its environment before resetting it and repeating the\\nprocess in a series of episodes. The task that the agent has to learn can\\neither be to maximize its performance over (i) that fixed period, or (ii) an\\nindefinite period where time limits are only used during training to diversify\\nexperience. In this paper, we provide a formal account for how time limits\\ncould effectively be handled in each of the two cases and explain why not doing\\nso can cause state-aliasing and invalidation of experience replay, leading to\\nsuboptimal policies and training instability. In case (i), we argue that the\\nterminations due to time limits are in fact part of the environment, and thus a\\nnotion of the remaining time should be included as part of the agent's input to\\navoid violation of the Markov property. In case (ii), the time limits are not\\npart of the environment and are only used to facilitate learning. We argue that\\nthis insight should be incorporated by bootstrapping from the value of the\\nstate at the end of each partial episode. For both cases, we illustrate\\nempirically the significance of our considerations in improving the performance\\nand stability of existing reinforcement learning algorithms, showing\\nstate-of-the-art results on several control tasks.\\n\",\n",
       " '  Existing nonconvex statistical optimization theory and methods crucially rely\\non the correct specification of the underlying \"true\" statistical models. To\\naddress this issue, we take a first step towards taming model misspecification\\nby studying the high-dimensional sparse phase retrieval problem with\\nmisspecified link functions. In particular, we propose a simple variant of the\\nthresholded Wirtinger flow algorithm that, given a proper initialization,\\nlinearly converges to an estimator with optimal statistical accuracy for a\\nbroad family of unknown link functions. We further provide extensive numerical\\nexperiments to support our theoretical findings.\\n',\n",
       " '  We present multi-wavelength radio observations obtained with the VLA of the\\nprotoplanetary disk surrounding the young brown dwarf 2MASS J04442713+2512164\\n(2M0444) in the Taurus star forming region. 2M0444 is the brightest known brown\\ndwarf disk at millimeter wavelengths, making this an ideal target to probe\\nradio emission from a young brown dwarf. Thermal emission from dust in the disk\\nis detected at 6.8 and 9.1 mm, whereas the 1.36 cm measured flux is dominated\\nby ionized gas emission. We combine these data with previous observations at\\nshorter sub-mm and mm wavelengths to test the predictions of dust evolution\\nmodels in gas-rich disks after adapting their parameters to the case of 2M0444.\\nThese models show that the radial drift mechanism affecting solids in a gaseous\\nenvironment has to be either completely made inefficient, or significantly\\nslowed down by very strong gas pressure bumps in order to explain the presence\\nof mm/cm-sized grains in the outer regions of the 2M0444 disk. We also discuss\\nthe possible mechanisms for the origin of the ionized gas emission detected at\\n1.36 cm. The inferred radio luminosity for this emission is in line with the\\nrelation between radio and bolometric luminosity valid for for more massive and\\nluminous young stellar objects, and extrapolated down to the very low\\nluminosity of the 2M0444 brown dwarf.\\n',\n",
       " \"  While Generative Adversarial Networks (GANs) have empirically produced\\nimpressive results on learning complex real-world distributions, recent work\\nhas shown that they suffer from lack of diversity or mode collapse. The\\ntheoretical work of Arora et al. suggests a dilemma about GANs' statistical\\nproperties: powerful discriminators cause overfitting, whereas weak\\ndiscriminators cannot detect mode collapse.\\nIn contrast, we show in this paper that GANs can in principle learn\\ndistributions in Wasserstein distance (or KL-divergence in many cases) with\\npolynomial sample complexity, if the discriminator class has strong\\ndistinguishing power against the particular generator class (instead of against\\nall possible generators). For various generator classes such as mixture of\\nGaussians, exponential families, and invertible neural networks generators, we\\ndesign corresponding discriminators (which are often neural nets of specific\\narchitectures) such that the Integral Probability Metric (IPM) induced by the\\ndiscriminators can provably approximate the Wasserstein distance and/or\\nKL-divergence. This implies that if the training is successful, then the\\nlearned distribution is close to the true distribution in Wasserstein distance\\nor KL divergence, and thus cannot drop modes. Our preliminary experiments show\\nthat on synthetic datasets the test IPM is well correlated with KL divergence,\\nindicating that the lack of diversity may be caused by the sub-optimality in\\noptimization instead of statistical inefficiency.\\n\",\n",
       " '  This paper brings together C*-algebras and algebraic topology in terms of\\nviewing a C*-algebraic invariant in terms of a topological spectrum. E-theory,\\nE(A,B), is a bivariant functor in the sense that is a cohomology functor in the\\nfirst variable and a homology functor in the second variable but underlying\\ngoes from the category of separable C*-algebras and *-homomorphisms to the\\ncategory of abelian groups and group homomorphisms. Here we create a\\ngeneralisation of a orthogonal spectrum to quasi-topological spaces for\\nE-theory. This includes a rich product structure in the context of graded\\nseparable C*-algebras.\\n',\n",
       " \"  In this paper, we present observations of cold (0-70 eV) plasma density in\\nthe magnetotail lobes. The observations and results are based on 16 years of\\nCluster observation of spacecraft potential measurements converted into local\\nplasma densities. Measurements from all four Cluster spacecraft have been used,\\nand the survey indicates a persistent asymmetry in lobe density, with\\nconsistently higher cold plasma densities in the northern lobe. External\\ninfluences, such as daily and seasonal variations in the Earth's tilt angle,\\ncan introduce temporary north-south asymmetries through asymmetric ionization\\nof the two hemispheres. Likewise, external drivers, such as the orientation of\\nthe interplanetary magnetic field can set up additional spatial asymmetries in\\noutflow and lobe filling. The persistent asymmetry reported in this paper is\\nalso influenced by these external factors but is mainly caused by differences\\nin magnetic field configuration in the Northern and Southern Hemisphere\\nionospheres.\\n\",\n",
       " \"  To satisfy increasing storage demands in both capacity and performance,\\nindustry has turned to multiple storage technologies, including Flash SSDs and\\nSMR disks. These devices employ a translation layer that conceals the\\nidiosyncrasies of their mediums and enables random access. Device translation\\nlayers are, however, inherently constrained: resources on the drive are scarce,\\nthey cannot be adapted to application requirements, and lack visibility across\\nmultiple devices. As a result, performance and durability of many storage\\ndevices is severely degraded.\\nIn this paper, we present SALSA: a translation layer that executes on the\\nhost and allows unmodified applications to better utilize commodity storage.\\nSALSA supports a wide range of single- and multi-device optimizations and,\\nbecause is implemented in software, can adapt to specific workloads. We\\ndescribe SALSA's design, and demonstrate its significant benefits using\\nmicrobenchmarks and case studies based on three applications: MySQL, the Swift\\nobject store, and a video server.\\n\",\n",
       " '  We present a survey of results on profinite semigroups and their link with\\nsymbolic dynamics. We develop a series of results, mostly due to Almeida and\\nCosta and we also include some original results on the Schützenberger groups\\nassociated to a uniformly recurrent set.\\n',\n",
       " '  We study ensembles of Rydberg atoms in a confined electromagnetic environment\\nsuch as provided by a microwave cavity. The competition between standard free\\nspace Ising type and cavity-mediated interactions leads to the emergence of\\ndifferent regimes where the particle-particle couplings range from the typical\\nvan der Waals $r^{-6}$ behavior to $r^{-3}$ and to $r$-independence. We apply a\\nRamsey spectroscopic technique to map the two-body interactions into a\\ncharacteristic signal such as intensity and contrast decay curves. As opposed\\nto previous treatments requiring high-densities for considerable contrast and\\nphase decay, the cavity scenario can exhibit similar behavior at much lower\\ndensities.\\n',\n",
       " '  In this paper, the idea of a new artificial intelligence based optimization\\nalgorithm, which is inspired from the nature of vortex, has been provided\\nbriefly. As also a bio-inspired computation algorithm, the idea is generally\\nfocused on a typical vortex flow / behavior in nature and inspires from some\\ndynamics that are occurred in the sense of vortex nature. Briefly, the\\nalgorithm is also a swarm-oriented evolutional problem solution approach;\\nbecause it includes many methods related to elimination of weak swarm members\\nand trying to improve the solution process by supporting the solution space via\\nnew swarm members. In order have better idea about success of the algorithm; it\\nhas been tested via some benchmark functions. At this point, the obtained\\nresults show that the algorithm can be an alternative to the literature in\\nterms of single-objective optimization solution ways. Vortex Optimization\\nAlgorithm (VOA) is the name suggestion by the authors; for this new idea of\\nintelligent optimization approach.\\n',\n",
       " '  Analogy completion has been a popular task in recent years for evaluating the\\nsemantic properties of word embeddings, but the standard methodology makes a\\nnumber of assumptions about analogies that do not always hold, either in recent\\nbenchmark datasets or when expanding into other domains. Through an analysis of\\nanalogies in the biomedical domain, we identify three assumptions: that of a\\nSingle Answer for any given analogy, that the pairs involved describe the Same\\nRelationship, and that each pair is Informative with respect to the other. We\\npropose modifying the standard methodology to relax these assumptions by\\nallowing for multiple correct answers, reporting MAP and MRR in addition to\\naccuracy, and using multiple example pairs. We further present BMASS, a novel\\ndataset for evaluating linguistic regularities in biomedical embeddings, and\\ndemonstrate that the relationships described in the dataset pose significant\\nsemantic challenges to current word embedding methods.\\n',\n",
       " '  Robot-assisted laparoscopic prostatectomy (RALP) is a treatment for prostate\\ncancer that involves complete or nerve sparing removal prostate tissue that\\ncontains cancer. After removal the bladder neck is successively sutured\\ndirectly with the urethra. The procedure is called urethrovesical anastomosis\\nand is one of the most dexterity demanding tasks during RALP. Two suturing\\ninstruments and a pair of needles are used in combination to perform a running\\nstitch during urethrovesical anastomosis. While robotic instruments provide\\nenhanced dexterity to perform the anastomosis, it is still highly challenging\\nand difficult to learn. In this paper, we presents a vision-guided needle\\ngrasping method for automatically grasping the needle that has been inserted\\ninto the patient prior to anastomosis. We aim to automatically grasp the\\nsuturing needle in a position that avoids hand-offs and immediately enables the\\nstart of suturing. The full grasping process can be broken down into: a needle\\ndetection algorithm; an approach phase where the surgical tool moves closer to\\nthe needle based on visual feedback; and a grasping phase through path planning\\nbased on observed surgical practice. Our experimental results show examples of\\nsuccessful autonomous grasping that has the potential to simplify and decrease\\nthe operational time in RALP by assisting a small component of urethrovesical\\nanastomosis.\\n',\n",
       " \"  In this document, the technical details of the JSNS$^2$ (J-PARC Sterile\\nNeutrino Search at J-PARC Spallation Neutron Source) experiment are described.\\nThe search for sterile neutrinos is currently one of the hottest topics in\\nneutrino physics. The JSNS$^2$ experiment aims to search for the existence of\\nneutrino oscillations with $\\\\Delta m^2$ near 1 eV$^2$ at the J-PARC Materials\\nand Life Science Experimental Facility (MLF). A 1 MW beam of 3 GeV protons\\nincident on a spallation neutron target produces an intense neutrino beam from\\nmuon decay at rest. Neutrinos come predominantly from $\\\\mu^+$ decay: $\\\\mu^{+}\\n\\\\to e^{+} + \\\\bar{\\\\nu}_{\\\\mu} + \\\\nu_{e}$. The experiment will search for\\n$\\\\bar{\\\\nu}_{\\\\mu}$ to $\\\\bar{\\\\nu}_{e}$ oscillations which are detected by the\\ninverse beta decay interaction $\\\\bar{\\\\nu}_{e} + p \\\\to e^{+} + n$, followed by\\ngammas from neutron capture on Gd. The detector has a fiducial volume of 17\\ntons and is located 24 meters away from the mercury target. JSNS$^2$ offers the\\nultimate direct test of the LSND anomaly.\\nIn addition to the sterile neutrino search, the physics program includes\\ncross section measurements with neutrinos with a few 10's of MeV from muon\\ndecay at rest and with monochromatic 236 MeV neutrinos from kaon decay at rest.\\nThese cross sections are relevant for our understanding of supernova explosions\\nand nuclear physics.\\n\",\n",
       " '  The warping sum $e(K)$ of a knot $K$ is the minimal value of the sum of the\\nwarping degrees of a minimal diagram of $K$ with both orientations. In this\\npaper, knots $K$ with $e(K) \\\\le 3$ are characterized, and some knots $K$ with\\n$e(K)=4$ are given.\\n',\n",
       " '  We deconstruct the performance of GANs into three components:\\n1. Formulation: we propose a perturbation view of the population target of\\nGANs. Building on this interpretation, we show that GANs can be viewed as a\\ngeneralization of the robust statistics framework, and propose a novel GAN\\narchitecture, termed as Cascade GANs, to provably recover meaningful\\nlow-dimensional generator approximations when the real distribution is\\nhigh-dimensional and corrupted by outliers.\\n2. Generalization: given a population target of GANs, we design a systematic\\nprinciple, projection under admissible distance, to design GANs to meet the\\npopulation requirement using finite samples. We implement our principle in\\nthree cases to achieve polynomial and sometimes near-optimal sample\\ncomplexities: (1) learning an arbitrary generator under an arbitrary\\npseudonorm; (2) learning a Gaussian location family under total variation\\ndistance, where we utilize our principle provide a new proof for the optimality\\nof Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian\\napproximation of a high-dimensional arbitrary distribution under Wasserstein\\ndistance. We demonstrate a fundamental trade-off in the approximation error and\\nstatistical error in GANs, and show how to apply our principle with empirical\\nsamples to predict how many samples are sufficient for GANs in order not to\\nsuffer from the discriminator winning problem.\\n3. Optimization: we demonstrate alternating gradient descent is provably not\\neven locally stable in optimizating the GAN formulation of PCA. We diagnose the\\nproblem as the minimax duality gap being non-zero, and propose a new GAN\\narchitecture whose duality gap is zero, where the value of the game is equal to\\nthe previous minimax value (not the maximin value). We prove the new GAN\\narchitecture is globally stable in optimization under alternating gradient\\ndescent.\\n',\n",
       " '  A connection, which shows the dependence of norming constants on boundary\\nconditions, was found using the Gelfand-Levitan method for the solution of\\ninverse Sturm-Liouville problem.\\n',\n",
       " '  Diffusion maps are a nonlinear manifold learning technique based on harmonic\\nanalysis of a diffusion process over the data. Out-of-sample extensions with\\ncomputational complexity $\\\\mathcal{O}(N)$, where $N$ is the number of points\\ncomprising the manifold, frustrate applications to online learning applications\\nrequiring rapid embedding of high-dimensional data streams. We propose landmark\\ndiffusion maps (L-dMaps) to reduce the complexity to $\\\\mathcal{O}(M)$, where $M\\n\\\\ll N$ is the number of landmark points selected using pruned spanning trees or\\nk-medoids. Offering $(N/M)$ speedups in out-of-sample extension, L-dMaps\\nenables the application of diffusion maps to high-volume and/or high-velocity\\nstreaming data. We illustrate our approach on three datasets: the Swiss roll,\\nmolecular simulations of a C$_{24}$H$_{50}$ polymer chain, and biomolecular\\nsimulations of alanine dipeptide. We demonstrate up to 50-fold speedups in\\nout-of-sample extension for the molecular systems with less than 4% errors in\\nmanifold reconstruction fidelity relative to calculations over the full\\ndataset.\\n',\n",
       " '  In this study, we analyzed the activity of monkey V1 neurons responding to\\ngrating stimuli of different orientations using inference methods for a\\ntime-dependent Ising model. The method provides optimal estimation of\\ntime-dependent neural interactions with credible intervals according to the\\nsequential Bayes estimation algorithm. Furthermore, it allows us to trace\\ndynamics of macroscopic network properties such as entropy, sparseness, and\\nfluctuation. Here we report that, in all examined stimulus conditions, pairwise\\ninteractions contribute to increasing sparseness and fluctuation. We then\\ndemonstrate that the orientation of the grating stimulus is in part encoded in\\nthe pairwise interactions of the neural populations. These results demonstrate\\nthe utility of the state-space Ising model in assessing contributions of neural\\ninteractions during stimulus processing.\\n',\n",
       " '  We prove the equivalence of two presentations of the Yangian\\n$Y(\\\\mathfrak{g})$ of a simple Lie algebra $\\\\mathfrak{g}$ and we also show the\\nequivalence with a third presentation when $\\\\mathfrak{g}$ is either an\\northogonal or a symplectic Lie algebra. As an application, we obtain an\\nexplicit correspondence between two versions of the classification theorem of\\nfinite-dimensional irreducible modules for orthogonal and symplectic Yangians.\\n',\n",
       " '  Recent breakthroughs in computer vision make use of large deep neural\\nnetworks, utilizing the substantial speedup offered by GPUs. For applications\\nrunning on limited hardware, however, high precision real-time processing can\\nstill be a challenge. One approach to solving this problem is training networks\\nwith binary or ternary weights, thus removing the need to calculate\\nmultiplications and significantly reducing memory size. In this work, we\\nintroduce LR-nets (Local reparameterization networks), a new method for\\ntraining neural networks with discrete weights using stochastic parameters. We\\nshow how a simple modification to the local reparameterization trick,\\npreviously used to train Gaussian distributed weights, enables the training of\\ndiscrete weights. Using the proposed training we test both binary and ternary\\nmodels on MNIST, CIFAR-10 and ImageNet benchmarks and reach state-of-the-art\\nresults on most experiments.\\n',\n",
       " '  Convolutional Neural Network is known as ConvNet have been extensively used\\nin many complex machine learning tasks. However, hyperparameters optimization\\nis one of a crucial step in developing ConvNet architectures, since the\\naccuracy and performance are reliant on the hyperparameters. This multilayered\\narchitecture parameterized by a set of hyperparameters such as the number of\\nconvolutional layers, number of fully connected dense layers & neurons, the\\nprobability of dropout implementation, learning rate. Hence the searching the\\nhyperparameter over the hyperparameter space are highly difficult to build such\\ncomplex hierarchical architecture. Many methods have been proposed over the\\ndecade to explore the hyperparameter space and find the optimum set of\\nhyperparameter values. Reportedly, Gird search and Random search are said to be\\ninefficient and extremely expensive, due to a large number of hyperparameters\\nof the architecture. Hence, Sequential model-based Bayesian Optimization is a\\npromising alternative technique to address the extreme of the unknown cost\\nfunction. The recent study on Bayesian Optimization by Snoek in nine\\nconvolutional network parameters is achieved the lowerest error report in the\\nCIFAR-10 benchmark. This article is intended to provide the overview of the\\nmathematical concept behind the Bayesian Optimization over a Gaussian prior.\\n',\n",
       " '  The local electronic states around a single As (Te, Se) vacancy are\\ninvestigated in order to shed light on the role of ligands in a series of\\niron-based superconductors. Such a vacancy can produce a local hopping\\ncorrection ranging from $-0.22$ eV to 0.12 eV and always induce two in-gap\\nresonance peaks in the local density of states (LDOS) at the fixed symmetrical\\nbias voltages, which are rather robust and irrelevant to the phase of\\nsuperconducting order parameter. The LDOS images near the defect predominantly\\npossess $0^o$ and $45^o$ stripes. These energy-dependent charge modulations\\ncreated by quasiparticle interference are originated in the nesting effect\\nbetween the inner (outer) hole Fermi surface around $\\\\Gamma$ point and the\\ninner (outer) electron Fermi surface around $M$ point.\\n',\n",
       " '  Quantum spin liquids (QSLs) are long-range entangled states of quantum\\nmagnets which lie beyond the Landau paradigm of classifying phases of matter\\nvia broken symmetries. A physical route to arriving at QSLs is via\\nfrustration-induced quantum melting of ordered states such as valence bond\\ncrystals or magnetic orders. Here, we show, using extensive exact\\ndiagonalization (ED) and density-matrix renormalization group (DMRG) studies of\\nconcrete $SU(2)$ invariant spin models on honeycomb, triangular and square\\nlattices, that chiral spin liquids (CSLs) emerge as descendants of triple-$Q$\\nspin crystals with tetrahedral magnetic order and a large scalar spin\\nchirality. Such ordered-to-CSL melting transitions may yield lattice\\nrealizations of effective Chern-Simons-Higgs field theories. Our work provides\\na distinct unifying perspective on the emergence of CSLs, and suggests that\\nmaterials with magnetic skyrmion crystal order might provide a good starting\\npoint to search for CSLs.\\n',\n",
       " \"  In the present article we introduce two new combinatorial interpretations of\\nthe $r$-Whitney numbers of the second kind obtained from the combinatorics of\\nthe differential operators associated to the grammar $G:=\\\\{ y\\\\rightarrow\\nyx^{m}, x\\\\rightarrow x\\\\}$. By specializing $m=1$ we obtain also a new\\ncombinatorial interpretation of the $r$-Stirling numbers of the second kind.\\nAgain, by specializing to the case $r=0$ we introduce a new generalization of\\nthe Stirling number of the second kind and through them a binomial type family\\nof polynomials that generalizes Touchard's. Moreover, we show several\\nwell-known identities involving the $r$-Dowling polynomials and the $r$-Whitney\\nnumbers using the combinatorial differential calculus. Finally we prove that\\nthe $r$-Dowling polynomials are a Sheffer family relative to the generalized\\nTouchard binomial family, study their umbral inverses, and introduce\\n$[m]$-Stirling numbers of the first kind. From the relation between umbral\\ncalculus and the Riordan matrices we give several new combinatorial identities\\ninvolving the $r$-Whitney number of both kinds, Bernoulli and Euler\\npolynomials.\\n\",\n",
       " '  Measuring the magnetoresistance (MR) of ultraclean {\\\\it GaAs} two-dimensional\\nholes in a large $r_s$ range of 20-50, two striking behaviors in relation to\\nthe spin-orbit coupling (SOC) emerge in response to strong electron-electron\\ninteraction. First, in exact correspondence to the zero-field\\nmetal-to-insulator transition (MIT), the sign of the MR switches from being\\npositive in the metallic regime to being negative in the insulating regime when\\nthe carrier density crosses the critical density $p_c$ of MIT ($r_s\\\\sim 39$).\\nSecond, as the SOC-driven correction $\\\\Delta\\\\rho$ to the MR decreases with\\nreducing carrier density (or the in-plane wave vector), it exhibits an upturn\\nin the close proximity just above $p_c$ where $r_s$ is beyond 30, indicating a\\nsubstantially enhanced SOC effect. This peculiar behavior echoes with a trend\\nof delocalization long suspected for the SOC-interaction interplay. Meanwhile,\\nfor $p<p_c$ or $r_s>40$, in contrast to the common belief that a magnet field\\nenhances Wigner crystallization, the negative MR is likely linked to enhanced\\ninteraction.\\n',\n",
       " '  Community detection is a challenging, yet crucial, problem while mining\\nlarge-scale graph structured data. Most existing approaches solve this problem\\nby mapping nodes into a vector space and performing unsupervised learning with\\nthe resulting embeddings. In cases where multiple types of connectivity\\npatterns exist for the set of nodes, commonly modeled as multilayer graphs, new\\nstrategies are required to model the inter-layer dependencies in order to\\nperform effective inferencing. In this paper, we focus on learning embeddings\\nfor each node of a multilayer graph through neural modeling techniques, such\\nthat the complex dependencies can be concisely encoded into low-dimensional\\nrepresentations. Referred to as multilayer graph embeddings, these\\nrepresentations can be utilized for discovering community structure in a\\nscalable fashion, even with a large number of layers. Furthermore, in order to\\nensure that the semantics that persist over a longer range in the network are\\nwell modeled, we propose to refine the multilayer embeddings via a proxy\\nclustering loss and a graph modularity measure. Using real-world datasets, we\\ndemonstrate that this algorithm generates scalable and robust representations,\\nand outperforms existing multilayer community detection approaches.\\n',\n",
       " '  We consider the framework of average aggregative games, where the cost\\nfunction of each agent depends on his own strategy and on the average\\npopulation strategy. We focus on the case in which the agents are coupled not\\nonly via their cost functions, but also via constraints coupling their\\nstrategies. We propose a distributed algorithm that achieves an almost Nash\\nequilibrium by requiring only local communications of the agents, as specified\\nby a sparse communication network. The proof of convergence of the algorithm\\nrelies on the auxiliary class of network aggregative games and exploits a novel\\nresult of parametric convergence of variational inequalities, which is\\napplicable beyond the context of games. We apply our theoretical findings to a\\nmulti-market Cournot game with transportation costs and maximum market\\ncapacity.\\n',\n",
       " '  Validation experiments of the two-dimensional inverse algorithm are performed\\nin a pulsed Poiseuille flow exposing shear reversal phases. The method is\\napplied to the three-segment electrodiffusion (ED) probe for which a specific\\nnondimensionalization process is suggested, allowing to better link\\nmeasurements from a real ED probe to the modeled one in the inverse problem.\\nThis approach provided a two-component wall shear rate in good agreement with\\nthe one obtained from laser Doppler anemometry (LDA) measurements, thus\\nvalidating the ability of ED probes to deal with high-amplitude unsteady flows.\\nThe classic linear velocity approximation ($u=sy$) in the probe vicinity is\\nalso investigated in such a flow.\\n',\n",
       " '  The chiral anomaly in Weyl semimetals states that the left- and right-handed\\nWeyl fermions, constituting the low energy description, are not individually\\nconserved, resulting, for example, in a negative magnetoresistance in such\\nmaterials. Recent experiments see strong indications of such an anomalous\\nresistance response; however, with a response that at strong fields is more\\nsharply peaked for parallel magnetic and electric fields than expected from\\nsimple theoretical considerations. Here, we uncover a mechanism, arising from\\nthe interplay between the angle-dependent Landau level structure and long-range\\nscalar disorder, that has the same phenomenology. In particular, we ana-\\nlytically show, and numerically confirm, that the internode scattering time\\ndecreases exponentially with the angle between the magnetic field and the Weyl\\nnode separation in the large field limit, while it is insensitive to this angle\\nat weak magnetic fields. Since, in the simplest approximation, the internode\\nscattering time is proportional to the anomaly-related conductivity, this\\nfeature may be related to the experimental observations of a sharply peaked\\nmagnetoresistance.\\n',\n",
       " \"  Sand seas on Titan may reflect the present and past climatic conditions.\\nUnderstanding the morphodynamics and physico-chemical properties of Titan's\\ndunes is therefore essential for a better comprehension of the climatic and\\ngeological history of the largest Saturn's moon. We derived quantitatively\\nsurface properties (texture, composition) from the modelling of microwave\\nbackscattered signal and Monte-Carlo inversion of despeckled Cassini/SAR data\\nover sand sea. We show that dunes and interdunes have significantly different\\nphysical properties. Dunes are globally more microwave absorbent than the\\ninterdunes. The inter-dunes present multi-scale roughness with a higher\\ndielectric constant than the dunes. Considering the composition, the interdunes\\nare in between the dunes and the radar bright inselbergs, suggesting the\\npresence of a shallow layer of non-mobilized sediment in between the dunes.\\nAdditionally potential secondary bedforms, such as ripples and avalanches, may\\nhave been detected. Our findings strongly suggest that sand seas evolve under\\ncurrent multi-directional wind regimes. Consequently sediment inventory and\\nclimatic conditions are being re-evaluated.\\n\",\n",
       " '  Different linguistic perspectives causes many diverse segmentation criteria\\nfor Chinese word segmentation (CWS). Most existing methods focus on improve the\\nperformance for each single criterion. However, it is interesting to exploit\\nthese different criteria and mining their common underlying knowledge. In this\\npaper, we propose adversarial multi-criteria learning for CWS by integrating\\nshared knowledge from multiple heterogeneous segmentation criteria. Experiments\\non eight corpora with heterogeneous segmentation criteria show that the\\nperformance of each corpus obtains a significant improvement, compared to\\nsingle-criterion learning. Source codes of this paper are available on Github.\\n',\n",
       " '  Image segmentation is the process of partitioning an image into a set of\\nmeaningful regions according to some criteria. Hierarchical segmentation has\\nemerged as a major trend in this regard as it favors the emergence of important\\nregions at different scales. On the other hand, many methods allow us to have\\nprior information on the position of structures of interest in the images. In\\nthis paper, we present a versatile hierarchical segmentation method that takes\\ninto account any prior spatial information and outputs a hierarchical\\nsegmentation that emphasizes the contours or regions of interest while\\npreserving the important structures in the image. An application of this method\\nto the weakly-supervised segmentation problem is presented.\\n',\n",
       " '  Genetic algorithms have been widely used in many practical optimization\\nproblems. Inspired by natural selection, operators, including mutation,\\ncrossover and selection, provide effective heuristics for search and black-box\\noptimization. However, they have not been shown useful for deep reinforcement\\nlearning, possibly due to the catastrophic consequence of parameter crossovers\\nof neural networks. Here, we present Genetic Policy Optimization (GPO), a new\\ngenetic algorithm for sample-efficient deep policy optimization. GPO uses\\nimitation learning for policy crossover in the state space and applies policy\\ngradient methods for mutation. Our experiments on MuJoCo tasks show that GPO as\\na genetic algorithm is able to provide superior performance over the\\nstate-of-the-art policy gradient methods and achieves comparable or higher\\nsample efficiency.\\n',\n",
       " '  The purpose of this paper is to advance the understanding of the conditions\\nthat give rise to flash crash contagion, particularly with respect to\\noverlapping asset portfolio crowding. To this end, we designed, implemented,\\nand assessed a hybrid micro-macro agent-based model, where price impact arises\\nendogenously through the limit order placement activity of algorithmic traders.\\nOur novel hybrid microscopic and macroscopic model allows us to quantify\\nsystemic risk not just in terms of system stability, but also in terms of the\\nspeed of financial distress propagation over intraday timescales. We find that\\nsystemic risk is strongly dependent on the behaviour of algorithmic traders, on\\nleverage management practices, and on network topology. Our results demonstrate\\nthat, for high-crowding regimes, contagion speed is a non-monotone function of\\nportfolio diversification. We also find the surprising result that, in certain\\ncircumstances, increased portfolio crowding is beneficial to systemic\\nstability. We are not aware of previous studies that have exhibited this\\nphenomenon, and our results establish the importance of considering non-uniform\\nasset allocations in future studies. Finally, we characterise the time window\\navailable for regulatory interventions during the propagation of flash crash\\ndistress, with results suggesting ex ante precautions may have higher efficacy\\nthan ex post reactions.\\n',\n",
       " '  Given a bounded strongly pseudoconvex domain $D$ in $\\\\mathbb{C}^n$ with\\nsmooth boundary, we give a characterization through products of functions in\\nweighted Bergman spaces of $(\\\\lambda,\\\\gamma)$-skew Carleson measures on $D$,\\nwith $\\\\lambda>0$ and $\\\\gamma>1-\\\\frac{1}{n+1}$.\\n',\n",
       " '  The superior temporal gyrus (STG) region of cortex critically contributes to\\nspeech recognition. In this work, we show that a proposed WaveNet, with limited\\navailable data, is able to reconstruct speech stimuli from STG intracranial\\nrecordings. We further investigate the impulse response of the fitted model for\\neach recording electrode and observe phoneme level temporospectral tuning\\nproperties for the recorded area of cortex. This discovery is consistent with\\nprevious studies implicating the posterior STG (pSTG) in a phonetic\\nrepresentation of speech and provides detailed acoustic features that certain\\nelectrode sites possibly extract during speech recognition.\\n',\n",
       " '  We calculate ionization energies and fundamental vibrational transitions for\\nH$_2^+$, D$_2^+$, and HD$^+$ molecular ions. The NRQED expansion for the energy\\nin terms of the fine structure constant $\\\\alpha$ is used. Previous calculations\\nof orders $m\\\\alpha^6$ and $m\\\\alpha^7$ are improved by including second-order\\ncontributions due to the vibrational motion of nuclei. Furthermore, we evaluate\\nthe largest corrections at the order $m\\\\alpha^8$. That allows to reduce the\\nfractional uncertainty to the level of $7\\\\cdot10^{-12}$ for fundamental\\ntransitions and to $4\\\\cdot10^{-12}$ for the ionization energies.\\n',\n",
       " \"  This work deals with the Mann's stochastic iteration algorithm under strong\\nmixing random errors. We establish the Fuk-Nagaev's inequalities that enable us\\nto prove the almost complete convergence with its corresponding rate of\\nconvergence. Moreover, these inequalities give us the possibility of\\nconstructing a confidence interval for the unique fixed point. Finally, to\\ncheck the feasibility and validity of our theoretical results, we consider some\\nnumerical examples, namely a classical example from astronomy.\\n\",\n",
       " '  To select the best algorithm for a new problem is an expensive and difficult\\ntask. However, there are automatic solutions to address this problem: using\\nMetalearning, which takes advantage of problem characteristics (i.e.\\nmetafeatures), one is able to predict the relative performance of algorithms.\\nIn the Collaborative Filtering scope, recent works have proposed diverse\\nmetafeatures describing several dimensions of this problem. Despite interesting\\nand effective findings, it is still unknown whether these are the most\\neffective metafeatures. Hence, this work proposes a new set of graph\\nmetafeatures, which approach the Collaborative Filtering problem from a Graph\\nTheory perspective. Furthermore, in order to understand whether metafeatures\\nfrom multiple dimensions are a better fit, we investigate the effects of\\ncomprehensive metafeatures. These metafeatures are a selection of the best\\nmetafeatures from all existing Collaborative Filtering metafeatures. The impact\\nof the most representative metafeatures is investigated in a controlled\\nexperimental setup. Another contribution we present is the use of a\\nPareto-Efficient ranking procedure to create multicriteria metatargets. These\\nnew rankings of algorithms, which take into account multiple evaluation\\nmeasures, allow to explore the algorithm selection problem in a fairer and more\\ndetailed way. According to the experimental results, the graph metafeatures are\\na good alternative to related work metafeatures. However, the results have\\nshown that the feature selection procedure used to create the comprehensive\\nmetafeatures is is not effective, since there is no gain in predictive\\nperformance. Finally, an extensive metaknowledge analysis was conducted to\\nidentify the most influential metafeatures.\\n',\n",
       " \"  Trigonometric formulas are derived for certain families of associated\\nLegendre functions of fractional degree and order, for use in approximation\\ntheory. These functions are algebraic, and when viewed as Gauss hypergeometric\\nfunctions, belong to types classified by Schwarz, with dihedral, tetrahedral,\\nor octahedral monodromy. The dihedral Legendre functions are expressed in terms\\nof Jacobi polynomials. For the last two monodromy types, an underlying\\n`octahedral' polynomial, indexed by the degree and order and having a\\nnon-classical kind of orthogonality, is identified, and recurrences for it are\\nworked out. It is a (generalized) Heun polynomial, not a hypergeometric one.\\nFor each of these families of algebraic associated Legendre functions, a\\nrepresentation of the rank-2 Lie algebra so(5,C) is generated by the ladder\\noperators that shift the degree and order of the corresponding solid harmonics.\\nAll such representations of so(5,C) are shown to have a common value for each\\nof its two Casimir invariants. The Dirac singleton representations of so(3,2)\\nare included.\\n\",\n",
       " '  This papers consists of two parts. The first is a critical review of prior\\nart on adversarial learning, identifying some significant limitations of\\nprevious works. The second part is an experimental study considering\\nadversarial active learning and an investigation of the efficacy of a mixed\\nsample selection strategy for combating an adversary who attempts to disrupt\\nthe classifier learning.\\n',\n",
       " '  Unintentional falls can cause severe injuries and even death, especially if\\nno immediate assistance is given. The aim of Fall Detection Systems (FDSs) is\\nto detect an occurring fall. This information can be used to trigger the\\nnecessary assistance in case of injury. This can be done by using either\\nambient-based sensors, e.g. cameras, or wearable devices. The aim of this work\\nis to study the technical aspects of FDSs based on wearable devices and\\nartificial intelligence techniques, in particular Deep Learning (DL), to\\nimplement an effective algorithm for on-line fall detection. The proposed\\nclassifier is based on a Recurrent Neural Network (RNN) model with underlying\\nLong Short-Term Memory (LSTM) blocks. The method is tested on the publicly\\navailable SisFall dataset, with extended annotation, and compared with the\\nresults obtained by the SisFall authors.\\n',\n",
       " '  Rule-based techniques to extract relational entities from documents allow\\nusers to specify desired entities with natural language questions, finite state\\nautomata, regular expressions and structured query language. They require\\nlinguistic and programming expertise and lack support for Arabic morphological\\nanalysis. We present a morphology-based entity and relational entity extraction\\nframework for Arabic (MERF). MERF requires basic knowledge of linguistic\\nfeatures and regular expressions, and provides the ability to interactively\\nspecify Arabic morphological and synonymity features, tag types associated with\\nregular expressions, and relations and code actions defined over matches of\\nsubexpressions. MERF constructs entities and relational entities from matches\\nof the specifications. We evaluated MERF with several case studies. The results\\nshow that MERF requires shorter development time and effort compared to\\nexisting application specific techniques and produces reasonably accurate\\nresults within a reasonable overhead in run time.\\n',\n",
       " '  Recent work in unsupervised representation learning has focused on learning\\ndeep directed latent-variable models. Fitting these models by maximizing the\\nmarginal likelihood or evidence is typically intractable, thus a common\\napproximation is to maximize the evidence lower bound (ELBO) instead. However,\\nmaximum likelihood training (whether exact or approximate) does not necessarily\\nresult in a good latent representation, as we demonstrate both theoretically\\nand empirically. In particular, we derive variational lower and upper bounds on\\nthe mutual information between the input and the latent variable, and use these\\nbounds to derive a rate-distortion curve that characterizes the tradeoff\\nbetween compression and reconstruction accuracy. Using this framework, we\\ndemonstrate that there is a family of models with identical ELBO, but different\\nquantitative and qualitative characteristics. Our framework also suggests a\\nsimple new method to ensure that latent variable models with powerful\\nstochastic decoders do not ignore their latent code.\\n',\n",
       " '  The original research question here is given by marketers in general, i.e.,\\nhow to explain the changes in the desired timescale of the market. Tangled\\nString, a sequence visualization tool based on the metaphor where contexts in a\\nsequence are compared to tangled pills in a string, is here extended and\\ndiverted to detecting stocks that trigger changes in the market and to\\nexplaining the scenario of contextual shifts in the market. Here, the\\nsequential data on the stocks of top 10 weekly increase rates in the First\\nSection of the Tokyo Stock Exchange for 12 years are visualized by Tangled\\nString. The changing in the prices of stocks is a mixture of various timescales\\nand can be explained in the time-scale set as desired by using TS. Also, it is\\nfound that the change points found by TS coincided by high precision with the\\nreal changes in each stock price. As TS has been created from the data-driven\\ninnovation platform called Innovators Marketplace on Data Jackets and is\\nextended to satisfy data users, this paper is as evidence of the contribution\\nof the market of data to data-driven innovations.\\n',\n",
       " \"  We consider a multi-adversary version of the supervisory control problem for\\ndiscrete-event systems, in which an adversary corrupts the observations\\navailable to the supervisor. The supervisor's goal is to enforce a specific\\nlanguage in spite of the opponent's actions and without knowing which adversary\\nit is playing against. This problem is motivated by applications to computer\\nsecurity in which a cyber defense system must make decisions based on reports\\nfrom sensors that may have been tampered with by an attacker. We start by\\nshowing that the problem has a solution if and only if the desired language is\\ncontrollable (in the Discrete event system classical sense) and observable in a\\n(novel) sense that takes the adversaries into account. For the particular case\\nof attacks that insert symbols into or remove symbols from the sequence of\\nsensor outputs, we show that testing the existence of a supervisor and building\\nthe supervisor can be done using tools developed for the classical DES\\nsupervisory control problem, by considering a family of automata with modified\\noutput maps, but without expanding the size of the state space and without\\nincurring on exponential complexity on the number of attacks considered., we\\nconstruct observers that are robust against attacks and lead to an automaton\\nrepresentation of the supervisor. We also develop a test for observability\\nunder such replacement-removal attacks by using the so-called product automata.\\n\",\n",
       " '  We present the design, characterization, and testing of a laboratory\\nprototype radiological search and localization system. The system, based on\\ntime-encoded imaging, uses the attenuation signature of neutrons in time,\\ninduced by the geometrical layout and motion of the system. We have\\ndemonstrated the ability to detect a ~1 mCi Cf-252 radiological source at 100 m\\nstandoff with 90% detection efficiency and 10% false positives against\\nbackground in 12 min. This same detection efficiency is met at 15 s for a 40 m\\nstandoff, and 1.2 s for a 20 m standoff.\\n',\n",
       " \"  Hashing is a basic tool for dimensionality reduction employed in several\\naspects of machine learning. However, the perfomance analysis is often carried\\nout under the abstract assumption that a truly random unit cost hash function\\nis used, without concern for which concrete hash function is employed. The\\nconcrete hash function may work fine on sufficiently random input. The question\\nis if it can be trusted in the real world when faced with more structured\\ninput.\\nIn this paper we focus on two prominent applications of hashing, namely\\nsimilarity estimation with the one permutation hashing (OPH) scheme of Li et\\nal. [NIPS'12] and feature hashing (FH) of Weinberger et al. [ICML'09], both of\\nwhich have found numerous applications, i.e. in approximate near-neighbour\\nsearch with LSH and large-scale classification with SVM.\\nWe consider mixed tabulation hashing of Dahlgaard et al.[FOCS'15] which was\\nproved to perform like a truly random hash function in many applications,\\nincluding OPH. Here we first show improved concentration bounds for FH with\\ntruly random hashing and then argue that mixed tabulation performs similar for\\nsparse input. Our main contribution, however, is an experimental comparison of\\ndifferent hashing schemes when used inside FH, OPH, and LSH.\\nWe find that mixed tabulation hashing is almost as fast as the\\nmultiply-mod-prime scheme ax+b mod p. Mutiply-mod-prime is guaranteed to work\\nwell on sufficiently random data, but we demonstrate that in the above\\napplications, it can lead to bias and poor concentration on both real-world and\\nsynthetic data. We also compare with the popular MurmurHash3, which has no\\nproven guarantees. Mixed tabulation and MurmurHash3 both perform similar to\\ntruly random hashing in our experiments. However, mixed tabulation is 40%\\nfaster than MurmurHash3, and it has the proven guarantee of good performance on\\nall possible input.\\n\",\n",
       " \"  This paper corrects the proof of the Theorem 2 from the Gower's paper\\n\\\\cite[page 5]{Gower:1982} as well as corrects the Theorem 7 from Gower's paper\\n\\\\cite{Gower:1986}. The first correction is needed in order to establish the\\nexistence of the kernel function used commonly in the kernel trick e.g. for\\n$k$-means clustering algorithm, on the grounds of distance matrix. The\\ncorrection encompasses the missing if-part proof and dropping unnecessary\\nconditions. The second correction deals with transformation of the kernel\\nmatrix into a one embeddable in Euclidean space.\\n\",\n",
       " '  Cosmic growth of large scale structure probes the entire history of cosmic\\nexpansion and gravitational coupling. To get a clear picture of the effects of\\nmodification of gravity we consider a deviation in the coupling strength\\n(effective Newton\\'s constant) at different redshifts, with different durations\\nand amplitudes. We derive, analytically and numerically, the impact on the\\ngrowth rate and growth amplitude. Galaxy redshift surveys can measure a product\\nof these through redshift space distortions and we connect the modified gravity\\nto the observable in a way that may provide a useful parametrization of the\\nability of future surveys to test gravity. In particular, modifications during\\nthe matter dominated era can be treated by a single parameter, the \"area\" of\\nthe modification, to an accuracy of $\\\\sim0.3\\\\%$ in the observables. We project\\nconstraints on both early and late time gravity for the Dark Energy\\nSpectroscopic Instrument and discuss what is needed for tightening tests of\\ngravity to better than 5% uncertainty.\\n',\n",
       " '  In this article, we study the Higgs $G$-bundles $(E,\\\\theta)$ on a compact\\nCalabi-Yau manifolds $X$. Our main result is that there is non-existence Higgs\\nfields $\\\\theta$ on a semistable Higgs $G$-bundle over a compact connected\\nCalabi-Yau surface. The vanish theorem can extends to higher dimensional\\nCalabi-Yau compact $n$-folds, but we should addition the principal $E$ with\\nvanishing Chern-classes. In particular, the $G$-bundle $E$ must be a semistable\\nbundle in both cases.\\n',\n",
       " '  In adversarial training, a set of models learn together by pursuing competing\\ngoals, usually defined on single data instances. However, in relational\\nlearning and other non-i.i.d domains, goals can also be defined over sets of\\ninstances. For example, a link predictor for the is-a relation needs to be\\nconsistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3)\\nhold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for\\nderiving an inconsistency loss, measuring the degree to which the model\\nviolates the assumptions on an adversarially-generated set of examples. The\\ntraining objective is defined as a minimax problem, where an adversary finds\\nthe most offending adversarial examples by maximising the inconsistency loss,\\nand the model is trained by jointly minimising a supervised loss and the\\ninconsistency loss on the adversarial examples. This yields the first method\\nthat can use function-free Horn clauses (as in Datalog) to regularise any\\nneural link predictor, with complexity independent of the domain size. We show\\nthat for several link prediction models, the optimisation problem faced by the\\nadversary has efficient closed-form solutions. Experiments on link prediction\\nbenchmarks indicate that given suitable prior knowledge, our method can\\nsignificantly improve neural link predictors on all relevant metrics.\\n',\n",
       " '  In this paper, the estimation problem for sparse reduced rank regression\\n(SRRR) model is considered. The SRRR model is widely used for dimension\\nreduction and variable selection with applications in signal processing,\\neconometrics, etc. The problem is formulated to minimize the least squares loss\\nwith a sparsity-inducing penalty considering an orthogonality constraint.\\nConvex sparsity-inducing functions have been used for SRRR in literature. In\\nthis work, a nonconvex function is proposed for better sparsity inducing. An\\nefficient algorithm is developed based on the alternating minimization (or\\nprojection) method to solve the nonconvex optimization problem. Numerical\\nsimulations show that the proposed algorithm is much more efficient compared to\\nthe benchmark methods and the nonconvex function can result in a better\\nestimation accuracy.\\n',\n",
       " '  The spin structure of wave functions is reflected in the magnetic structure\\nof the one-particle density matrix. Indeed, for single determinants we can use\\neither one to determine the other. In this work we discuss how one can simply\\nexamine the one-particle density matrix to faithfully determine whether the\\nspin magnetization density vector field is collinear, coplanar, or noncoplanar.\\nFor single determinants, this test suffices to distinguish collinear\\ndeterminants which are eigenfunctions of $\\\\hat{S}_{\\\\hat{n}}$ from noncollinear\\ndeterminants which are not. We also point out the close relationship between\\nnoncoplanar magnetism on the one hand and complex conjugation symmetry breaking\\non the other. Finally, we use these ideas to classify the various ways single\\ndeterminant wave functions break and respect symmetries of the Hamiltonian in\\nterms of their one-particle density matrix.\\n',\n",
       " '  We consider a group-theoretic analogue of the classic subset sum problem. It\\nis known that every virtually nilpotent group has polynomial time decidable\\nsubset sum problem. In this paper we use subgroup distortion to show that every\\npolycyclic non-virtually-nilpotent group has NP-complete subset sum problem.\\n',\n",
       " '  To shed light on the time evolution of local star formation episodes in M33,\\nwe study the association between 566 Giant Molecular Clouds (GMCs), identified\\nthrough the CO (J=2-1) IRAM-all-disk survey, and 630 Young Stellar Cluster\\nCandidates (YSCCs), selected via Spitzer-24~$\\\\mu$m emission. The spatial\\ncorrelation between YSCCs and GMCs is extremely strong, with a typical\\nseparation of 17~pc, less than half the CO(2--1) beamsize, illustrating the\\nremarkable physical link between the two populations. GMCs and YSCCs follow the\\nHI filaments, except in the outermost regions where the survey finds fewer GMCs\\nthan YSCCs, likely due to undetected, low CO-luminosity clouds. The GMCs have\\nmasses between 2$\\\\times 10^4$ and 2$\\\\times 10^6$ M$_\\\\odot$ and are classified\\naccording to different cloud evolutionary stages: inactive clouds are 32$\\\\%$ of\\nthe total, classified clouds with embedded and exposed star formation are\\n16$\\\\%$ and 52$\\\\%$ of the total respectively. Across the regular southern spiral\\narm, inactive clouds are preferentially located in the inner part of the arm,\\npossibly suggesting a triggering of star formation as the cloud crosses the\\narm. Some YSCCs are embedded star-forming sites while the majority have\\nGALEX-UV and H$\\\\alpha$ counterparts with estimated cluster masses and ages. The\\ndistribution of the non-embedded YSCC ages peaks around 5~Myrs with only a few\\nbeing as old as 8--10~Myrs. These age estimates together with the number of\\nGMCs in the various evolutionary stages lead us to conclude that 14~Myrs is a\\ntypical lifetime of a GMC in M33, prior to cloud dispersal. The inactive and\\nembedded phases are short, lasting about 4 and 2~Myrs respectively. This\\nunderlines that embedded YSCCs rapidly break out from the clouds and become\\npartially visible in H$\\\\alpha$ or UV long before cloud dispersal.\\n',\n",
       " \"  Compositor attribution, the clustering of pages in a historical printed\\ndocument by the individual who set the type, is a bibliographic task that\\nrelies on analysis of orthographic variation and inspection of visual details\\nof the printed page. In this paper, we introduce a novel unsupervised model\\nthat jointly describes the textual and visual features needed to distinguish\\ncompositors. Applied to images of Shakespeare's First Folio, our model predicts\\nattributions that agree with the manual judgements of bibliographers with an\\naccuracy of 87%, even on text that is the output of OCR.\\n\",\n",
       " '  We study the substructure content of the strong gravitational lens\\nRXJ1131-1231 through a forward modelling approach that relies on generating an\\nextensive suite of realistic simulations. We use a semi-analytic merger tree\\nprescription that allows us to stochastically generate substructure populations\\nwhose properties depend on the dark matter particle mass. These synthetic halos\\nare then used as lenses to produce realistic mock images that have the same\\nfeatures, e.g. luminous arcs, quasar positions, instrumental noise and PSF, as\\nthe data. We then analyse the data and the simulations in the same way with\\nsummary statistics that are sensitive to the signal being targeted and are able\\nto constrain models of dark matter statistically using Approximate Bayesian\\nComputing (ABC) techniques. In this work, we focus on the thermal relic mass\\nestimate and fix the semi-analytic descriptions of the substructure evolution\\nbased on recent literature. We are able, based on the HST data for\\nRXJ1131-1231, to rule out a warm dark matter thermal relic mass below 2 keV at\\nthe 2$\\\\sigma$ confidence level.\\n',\n",
       " '  When analyzing programs, large libraries pose significant challenges to\\nstatic points-to analysis. A popular solution is to have a human analyst\\nprovide points-to specifications that summarize relevant behaviors of library\\ncode, which can substantially improve precision and handle missing code such as\\nnative code. We propose ATLAS, a tool that automatically infers points-to\\nspecifications. ATLAS synthesizes unit tests that exercise the library code,\\nand then infers points-to specifications based on observations from these\\nexecutions. ATLAS automatically infers specifications for the Java standard\\nlibrary, and produces better results for a client static information flow\\nanalysis on a benchmark of 46 Android apps compared to using existing\\nhandwritten specifications.\\n',\n",
       " '  We find the exact Bloch oscillations in zigzag arrays of curved optical\\nwaveguides under the influence of arbitrary long-range coupling. The curvature\\ninduces a linear transverse potential gradient in the equations of the light\\nevolution. In the case of arrays with second-order coupling, steady states can\\nbe obtained as linear combinations of Bessel functions of integer index. The\\ncorresponding eigenvalues are equally spaced and form the well-known\\nWannier-Stark ladder, the spacing being independent of the second-order\\ncoupling. We also solve exactly the wave packet dynamics and compare it with\\nexperimental results. Accordingly we find that a broad optical pulse performs\\nBloch oscillations. Frequency doubling of the fundamental Bloch frequency sets\\nup at finite values of the second-order coupling. On the contrary when a single\\nwaveguide is initially excited, a breathing mode is activated with no signature\\nof Bloch oscillations. We present a generalization of our results to waveguide\\narrays subject to long-range coupling. In the general case the centroid of the\\nwave packet shows the occurrence of multiples of the Bloch frequency up to the\\norder of the interaction.\\n',\n",
       " '  We present and analyze three-dimensional data cubes of Neptune from the\\nOSIRIS integral-field spectrograph on the 10-m Keck telescope, from July 2009.\\nThese data have a spatial resolution of 0.035\"/pixel and spectral resolution of\\nR~3800 in the H and K broad bands. We focus our analysis on regions of\\nNeptune\\'s atmosphere that are near-infrared dark- that is, free of discrete\\nbright cloud features. We use a forward model coupled to a Markov chain Monte\\nCarlo algorithm to retrieve properties of Neptune\\'s aerosol structure and\\nmethane profile above ~4 bar in these near-infrared dark regions.\\nUsing a set of high signal-to-noise spectra in a cloud-free band from 2-12N,\\nwe find that Neptune\\'s cloud opacity is dominated by a compact, optically thick\\ncloud layer with a base near 3 bar and composed of low albedo, forward\\nscattering particles, with an assumed characteristic size of ~1$\\\\mu$m. Above\\nthis cloud, we require a vertically extended haze of smaller (~0.1 $\\\\mu$m)\\nparticles, which reaches from the upper troposphere (~0.6 bar) into the\\nstratosphere. The particles in this haze are brighter and more isotropically\\nscattering than those in the deep cloud. When we extend our analysis to 18\\ncloud-free locations from 20N to 87S, we observe that the optical depth in\\naerosols above 0.5 bar decreases by a factor of 2-3 or more at mid- and\\nhigh-southern latitudes relative to low latitudes.\\nWe also consider Neptune\\'s methane (CH$_4$) profile, and find that our\\nretrievals indicate a strong preference for a low methane relative humidity at\\npressures where methane is expected to condense. Our preferred solution at most\\nlocations is for a methane relative humidity below 10% near the tropopause in\\naddition to methane depletion down to 2.0-2.5 bar. We tentatively identify a\\ntrend of lower CH$_4$ columns above 2.5 bar at mid- and high-southern latitudes\\nover low latitudes.\\n',\n",
       " '  Applying machine learning in the health care domain has shown promising\\nresults in recent years. Interpretable outputs from learning algorithms are\\ndesirable for decision making by health care personnel. In this work, we\\nexplore the possibility of utilizing causal relationships to refine diagnostic\\nprediction. We focus on the task of diagnostic prediction using discomfort\\ndrawings, and explore two ways to employ causal identification to improve the\\ndiagnostic results. Firstly, we use causal identification to infer the causal\\nrelationships among diagnostic labels which, by itself, provides interpretable\\nresults to aid the decision making and training of health care personnel.\\nSecondly, we suggest a post-processing approach where the inferred causal\\nrelationships are used to refine the prediction accuracy of a multi-view\\nprobabilistic model. Experimental results show firstly that causal\\nidentification is capable of detecting the causal relationships among\\ndiagnostic labels correctly, and secondly that there is potential for improving\\npain diagnostics prediction accuracy using the causal relationships.\\n',\n",
       " '  We develop a model to compute the first-passage time of a random walker in a\\ncrowded environment. Hard-core particles with the same size and diffusion\\ncoefficient than the tracer diffuse, and the model allows to compute the first\\npassage time of the tracer on euclidian lattices. The result is compared to\\nclassical Nakazato-Kitahara model, and extends previous results obtained for\\npersistent random walker. The crowding in a confined media acts as a memory\\neffect, and thus lead to a persistent-like behavior.\\n',\n",
       " '  Let $p$ be a prime number. We develop a theory of $p$-adic Mahler measure of\\npolynomials and apply it to the study of $\\\\mathbb{Z}$-covers of rational\\nhomology 3-spheres branched over links. We obtain a $p$-adic analogue of the\\nasymptotic formula of the torsion homology growth and a balance formula among\\nthe leading coefficient of the Alexander polynomial, the $p$-adic entropy, and\\nthe Iwasawa $\\\\mu_p$-invariant. We also apply the purely $p$-adic theory of\\nBesser--Deninger to $\\\\mathbb{Z}$-covers of links. In addition, we study the\\nentropies of profinite cyclic covers of links. We examine various examples\\nthroughout the paper.\\n',\n",
       " '  It has been a long-standing problem to efficiently learn a halfspace using as\\nfew labels as possible in the presence of noise. In this work, we propose an\\nefficient Perceptron-based algorithm for actively learning homogeneous\\nhalfspaces under the uniform distribution over the unit sphere. Under the\\nbounded noise condition~\\\\cite{MN06}, where each label is flipped with\\nprobability at most $\\\\eta < \\\\frac 1 2$, our algorithm achieves a near-optimal\\nlabel complexity of\\n$\\\\tilde{O}\\\\left(\\\\frac{d}{(1-2\\\\eta)^2}\\\\ln\\\\frac{1}{\\\\epsilon}\\\\right)$ in time\\n$\\\\tilde{O}\\\\left(\\\\frac{d^2}{\\\\epsilon(1-2\\\\eta)^3}\\\\right)$. Under the adversarial\\nnoise condition~\\\\cite{ABL14, KLS09, KKMS08}, where at most a $\\\\tilde\\n\\\\Omega(\\\\epsilon)$ fraction of labels can be flipped, our algorithm achieves a\\nnear-optimal label complexity of $\\\\tilde{O}\\\\left(d\\\\ln\\\\frac{1}{\\\\epsilon}\\\\right)$\\nin time $\\\\tilde{O}\\\\left(\\\\frac{d^2}{\\\\epsilon}\\\\right)$. Furthermore, we show that\\nour active learning algorithm can be converted to an efficient passive learning\\nalgorithm that has near-optimal sample complexities with respect to $\\\\epsilon$\\nand $d$.\\n',\n",
       " \"  Massive co-located devices require new paradigms to allow proper network\\nconnectivity. Internet of things (IoT) is the paradigm that offers a solution\\nfor the inter-connectivity of devices, but in dense IoT networks time\\nsynchronization is a critical aspect. Further, the scalability is another\\ncrucial aspect. This paper focuses on synchronization for uncoordinated dense\\nnetworks without any external timing reference. Two synchronization methods are\\nproposed and compared: i) conventional synchronization that copes with the high\\ndensity of nodes by frame collision-avoidance methods (e.g., CSMA/CA) to avoid\\nthe superimposition (or collision) of synchronization signals; and ii)\\ndistributed synchronization that exploits the frames' collision to drive the\\nnetwork to a global synchronization. The distributed synchronization algorithm\\nallows the network to reach a timing synchronization status based on a common\\nbeacon with the same signature broadcasted by every device. The superimposition\\nof beacons from all the other devices enables the network synchronization,\\nrather than preventing it. Numerical analysis evaluates the synchronization\\nperformance based on the convergence time and synchronization dispersion, both\\non collision and non-collision scenario, by investigating the scalability of\\nthe network. Results prove that in dense network the ensemble of signatures\\nprovides remarkable improvements of synchronization performance compared to\\nconventional master-slave reference.\\n\",\n",
       " '  Computer science offers a large set of tools for prototyping, writing,\\nrunning, testing, validating, sharing and reproducing results, however\\ncomputational science lags behind. In the best case, authors may provide their\\nsource code as a compressed archive and they may feel confident their research\\nis reproducible. But this is not exactly true. James Buckheit and David Donoho\\nproposed more than two decades ago that an article about computational results\\nis advertising, not scholarship. The actual scholarship is the full software\\nenvironment, code, and data that produced the result. This implies new\\nworkflows, in particular in peer-reviews. Existing journals have been slow to\\nadapt: source codes are rarely requested, hardly ever actually executed to\\ncheck that they produce the results advertised in the article. ReScience is a\\npeer-reviewed journal that targets computational research and encourages the\\nexplicit replication of already published research, promoting new and\\nopen-source implementations in order to ensure that the original research can\\nbe replicated from its description. To achieve this goal, the whole publishing\\nchain is radically different from other traditional scientific journals.\\nReScience resides on GitHub where each new implementation of a computational\\nstudy is made available together with comments, explanations, and software\\ntests.\\n',\n",
       " '  We present initial results from the first systematic survey of luminous\\n$z\\\\sim 5.5$ quasars. Quasars at $z \\\\sim$ 5.5, the post-reionization epoch, are\\ncrucial tools to explore the evolution of intergalactic medium, quasar\\nevolution and the early super-massive black hole growth. However, it has been\\nvery challenging to select quasars at redshifts 5.3 $\\\\le z \\\\le$ 5.7 using\\nconventional color selections, due to their similar optical colors to late-type\\nstars, especially M dwarfs, resulting in a glaring redshift gap in quasar\\nredshift distributions. We develop a new selection technique for $z \\\\sim$ 5.5\\nquasars based on optical, near-IR and mid-IR photometric data from Sloan\\nDigital Sky Survey (SDSS), UKIRT InfraRed Deep Sky Surveys - Large Area Survey\\n(ULAS), VISTA Hemisphere Survey (VHS) and Wide field Infrared Survey Explorer\\n(WISE). From our pilot observations in SDSS-ULAS/VHS area, we have discovered\\n15 new quasars at 5.3 $\\\\le z \\\\le$ 5.7 and 6 new lower redshift quasars, with\\nSDSS z band magnitude brighter than 20.5. Including other two $z \\\\sim$ 5.5\\nquasars already published in our previous work, we now construct an uniform\\nquasar sample at 5.3 $\\\\le z \\\\le$ 5.7 with 17 quasars in a $\\\\sim$ 4800 square\\ndegree survey area. For further application in a larger survey area, we apply\\nour selection pipeline to do a test selection by using the new wide field J\\nband photometric data from a preliminary version of the UKIRT Hemisphere Survey\\n(UHS). We successfully discover the first UHS selected $z \\\\sim$ 5.5 quasar.\\n',\n",
       " '  Discriminant analysis is a useful classification method. Variable selection\\nfor discriminant analysis is becoming more and more im- portant in a\\nhigh-dimensional setting. This paper is concerned with the binary-class\\nproblems of main and interaction effects selection for the quadratic\\ndiscriminant analysis. We propose a new penalized quadratic discriminant\\nanalysis (QDA) for variable selection in binary classification. Under sparsity\\nassumption on the relevant variables, we conduct a penalized liner regression\\nto derive sparse QDA by plug- ging the main and interaction effects in the\\nmodel. Then the QDA problem is converted to a penalized sparse ordinary least\\nsquares op- timization by using the composite absolute penalties (CAP). Coor-\\ndinate descent algorithm is introduced to solve the convex penalized least\\nsquares. The penalized linear regression can simultaneously se- lect the main\\nand interaction effects, and also conduct classification. Compared with the\\nexisting methods of variable selection in QDA, the extensive simulation studies\\nand two real data analyses demon- strate that our proposed method works well\\nand is robust in the performance of variable selection and classification.\\n',\n",
       " '  In this paper we formulate a four parameter absolute continuous Geometric\\nMarshall-Olkin bivariate Pareto distribution and study its parameter estimation\\nthrough EM algorithm and also explore the bayesian analysis through slice cum\\nGibbs sampler approach. Numerical results are shown to verify the performance\\nof the algorithms. We illustrate the procedures through a real life data\\nanalysis.\\n',\n",
       " '  Let $T\\\\subset{\\\\mathbb R}^n$ be a fixed set. By a scaled copy of $T$ around\\n$x\\\\in{\\\\mathbb R}^n$ we mean a set of the form $x+rT$ for some $r>0$.\\nIn this survey paper we study results about the following type of problems:\\nHow small can a set be if it contains a scaled copy of $T$ around every point\\nof a set of given size? We will consider the cases when $T$ is circle or sphere\\ncentered at the origin, Cantor set in ${\\\\mathbb R}$, the boundary of a square\\ncentered at the origin, or more generally the $k$-skeleton ($0\\\\le k<n$) of an\\n$n$-dimensional cube centered at the origin or the $k$-skeleton of a more\\ngeneral polytope of ${\\\\mathbb R}^n$.\\nWe also study the case when we allow not only scaled copies but also scaled\\nand rotated copies and also the case when we allow only rotated copies.\\n',\n",
       " '  The nonlinear Hausdorff-Young inequality follows from the work of Christ and\\nKiselev. Later Muscalu, Tao, and Thiele asked if the constants can be chosen\\nindependently of the exponent. We show that the nonlinear Hausdorff-Young\\nquotient admits an even better upper bound than the linear one, provided that\\nthe function is sufficiently small in the $L^1$ norm. The proof combines\\nperturbative techniques with the sharpened version of the linear\\nHausdorff-Young inequality due to Christ.\\n',\n",
       " \"  We periodically kick a local region in a one-dimensional lattice and\\ndemonstrate, by studying wave packet dynamics, that the strength and the time\\nperiod of the kicking can be used as tuning parameters to control the\\ntransmission probability across the region. Interestingly, we can tune the\\ntransmission to zero which is otherwise impossible to do in a time-independent\\nsystem. We adapt the non-equilibrium Green's function method to take into\\naccount the effects of periodic driving; the results obtained by this method\\nagree with those found by wave packet dynamics if the time period is small. We\\ndiscover that Floquet bound states can exist in certain ranges of parameters;\\nwhen the driving frequency is decreased, these states get delocalized and turn\\ninto resonances by mixing with the Floquet bulk states. We extend these results\\nto incorporate the effects of local interactions at the driven site, and we\\nfind some interesting features in the transmission and the bound states.\\n\",\n",
       " '  We study superconducting properties of population-imbalanced ultracold Fermi\\nmixtures in the honeycomb lattice that can be effectively described by the\\nspin-imbalanced attractive Hubbard model in the presence of a Zeeman magnetic\\nfield. We use the mean-field theory approach to obtain ground state phase\\ndiagrams including some unconventional superconducting phases such as the\\nFulde--Ferrell--Larkin--Ovchinnikov (FFLO) phase. We show that this phase is\\ncharacterized by atypical behaviour of the Cooper pairs total momentum in the\\nexternal magnetic field. We show that the momentum changes its value as well as\\ndirection with change of the system parameters. We discuss the influence of van\\nHove singularities on the possibility of the reentrant FFLO phase occurrence,\\nwithout a BCS precursor.\\n',\n",
       " '  Context. It is still an open issue whether a self-gravitating accretion disk\\nfragments. There are many different physical and numerical explanations for\\nfragmentation, but simulations often show a non-convergent behavior for ever\\nbetter resolution.\\nAims. We investigate the influence of different numerical limiters in Godunov\\ntype schemes on the fragmentation boundary in self- gravitating disks.\\nMethods. We compare the linear and non-linear outcome in two-dimensional\\nshearingsheet simulations using the VANLEER and the SUPERBEE limiter.\\nResults. We show that choosing inappropriate limiting functions to handle\\nshock-capturing in Godunov type schemes can lead to an overestimation of the\\nsurface density in regions with shallow density gradients. The effect amplifies\\nitself on timescales comparable to the dynamical timescale even at high\\nresolutions. This is exactly the environment, where clumps are expected to\\nform. The effect is present without, but scaled up by, self-gravity and also\\ndoes not depend on cooling. Moreover it can be backtracked to a well known\\neffect called oversteepening. If the effect is also observed in the linear\\ncase, the fragmentation limit is shifted to larger values of the critical\\ncooling timescale.\\n',\n",
       " '  Stochastic optimization of continuous objectives is at the heart of modern\\nmachine learning. However, many important problems are of discrete nature and\\noften involve submodular objectives. We seek to unleash the power of stochastic\\ncontinuous optimization, namely stochastic gradient descent and its variants,\\nto such discrete problems. We first introduce the problem of stochastic\\nsubmodular optimization, where one needs to optimize a submodular objective\\nwhich is given as an expectation. Our model captures situations where the\\ndiscrete objective arises as an empirical risk (e.g., in the case of\\nexemplar-based clustering), or is given as an explicit stochastic model (e.g.,\\nin the case of influence maximization in social networks). By exploiting that\\ncommon extensions act linearly on the class of submodular functions, we employ\\nprojected stochastic gradient ascent and its variants in the continuous domain,\\nand perform rounding to obtain discrete solutions. We focus on the rich and\\nwidely used family of weighted coverage functions. We show that our approach\\nyields solutions that are guaranteed to match the optimal approximation\\nguarantees, while reducing the computational cost by several orders of\\nmagnitude, as we demonstrate empirically.\\n',\n",
       " '  We study a three-wave truncation of the high-order nonlinear Schrödinger\\nequation for deepwater waves (HONLS, also named Dysthe equation). We validate\\nour approach by comparing it to numerical simulation, distinguish the impact of\\nthe different fourth-order terms and classify the solutions according to their\\ntopology. This allows us to properly define the temporary spectral upshift\\noccurring in the nonlinear stage of Benjamin-Feir instability and provides a\\ntool for studying further generalizations of this model.\\n',\n",
       " '  While prior work on context-based music recommendation focused on fixed set\\nof contexts (e.g. walking, driving, jogging), we propose to use multiple\\nsensors and external data sources to describe momentary (ephemeral) context in\\na rich way with a very large number of possible states (e.g. jogging fast along\\nin downtown of Sydney under a heavy rain at night being tired and angry). With\\nour approach, we address the problems which current approaches face: 1) a\\nlimited ability to infer context from missing or faulty sensor data; 2) an\\ninability to use contextual information to support novel content discovery.\\n',\n",
       " '  In this paper we study constant scalar curvature equation (CSCK), a nonlinear\\nfourth order elliptic equation, and its weak solutions on Kähler manifolds.\\nWe first define a notion of weak solution of CSCK for an $L^\\\\infty$ Kähler\\nmetric. The main result is to show that such a weak solution (with uniform\\n$L^\\\\infty$ bound) is smooth. As an application, this answers in part a\\nconjecture of Chen regarding the regularity of $K$-energy minimizers. The new\\ntechnical ingredient is a $W^{2, 2}$ regularity result for the Laplacian\\nequation $\\\\Delta_g u=f$ on Kähler manifolds, where the metric has only\\n$L^\\\\infty$ coefficients. It is well-known that such a $W^{2, 2}$ regularity\\n($W^{2, p}$ regularity for any $p>1$) fails in general (except for dimension\\ntwo) for uniform elliptic equations of the form $a^{ij}\\\\partial^2_{ij}u=f$ for\\n$a^{ij}\\\\in L^\\\\infty$, without certain smallness assumptions on the local\\noscillation of $a^{ij}$. We observe that the Kähler condition plays an\\nessential role to obtain a $W^{2, 2}$ regularity for elliptic equations with\\nonly $L^\\\\infty$ elliptic coefficients on compact manifolds.\\n',\n",
       " '  We prove that a sequence of quasi-Fuchsian representations for which the\\ncritical exponent converges to the topological dimension of the boundary of the\\ngroup (larger than 2), converges up to subsequence and conjugacy to a totally\\ngeodesic representation.\\n',\n",
       " \"  In this contribution we analyze a parties' vote share distribution across the\\npolling stations during the Lithuanian parliamentary elections of 1992, 2008\\nand 2012. We find that the distribution is rather well fitted by the Beta\\ndistribution. To reproduce this empirical observation we propose a simple\\nmulti-state agent-based model of the voting behavior. In the proposed model\\nagents change the party they vote for either idiosyncratically or due to a\\nlinear recruitment mechanism. We use the model to reproduce the vote share\\ndistribution observed during the election of 1992. We discuss model extensions\\nneeded to reproduce the vote share distribution observed during the other\\nelections.\\n\",\n",
       " '  We derive a new formulation of the $3D$ compressible Euler equations with\\ndynamic entropy exhibiting remarkable null structures and regularity\\nproperties. Our results hold for an arbitrary equation of state (which yields\\nthe pressure in terms of the density and the entropy) in non-vacuum regions\\nwhere the speed of sound is positive. Our work is an extension of our prior\\njoint work with J. Luk, in which we derived a similar new formulation in the\\nspecial case of a barotropic fluid, that is, when the equation of state depends\\nonly on the density. The new formulation comprises covariant wave equations for\\nthe Cartesian components of the velocity and the logarithmic density coupled to\\na transport equation for the specific vorticity (defined to be vorticity\\ndivided by density), a transport equation for the entropy, and some additional\\ntransport-divergence-curl-type equations involving special combinations of the\\nderivatives of the solution variables. The good geometric structures in the\\nequations allow one to use the full power of the vectorfield method in treating\\nthe \"wave part\" of the system. In a forthcoming application, we will use the\\nnew formulation to give a sharp, constructive proof of finite-time shock\\nformation, tied to the intersection of acoustic \"wave\" characteristics, for\\nsolutions with nontrivial vorticity and entropy at the singularity. In the\\npresent article, we derive the new formulation and overview the central role\\nthat it plays in the proof of shock formation.\\n',\n",
       " '  Thanks to incredible advances in instrumentation, surveys like the Sloan\\nDigital Sky Survey have been able to find and catalog billions of objects,\\nranging from local M dwarfs to distant quasars. Machine learning algorithms\\nhave greatly aided in the effort to classify these objects; however, there are\\nregimes where these algorithms fail, where interesting oddities may be found.\\nWe present here an X-ray bright quasar misidentified as a red supergiant/X-ray\\nbinary, and a subsequent search of the SDSS quasar catalog for X-ray bright\\nstars misidentified as quasars.\\n',\n",
       " '  Tropical diseases like \\\\textit{Chikungunya} and \\\\textit{Zika} have come to\\nprominence in recent years as the cause of serious, long-lasting,\\npopulation-wide health problems. In large countries like Brasil, traditional\\ndisease prevention programs led by health authorities have not been\\nparticularly effective. We explore the hypothesis that monitoring and analysis\\nof social media content streams may effectively complement such efforts.\\nSpecifically, we aim to identify selected members of the public who are likely\\nto be sensitive to virus combat initiatives that are organised in local\\ncommunities. Focusing on Twitter and on the topic of Zika, our approach\\ninvolves (i) training a classifier to select topic-relevant tweets from the\\nTwitter feed, and (ii) discovering the top users who are actively posting\\nrelevant content about the topic. We may then recommend these users as the\\nprime candidates for direct engagement within their community. In this short\\npaper we describe our analytical approach and prototype architecture, discuss\\nthe challenges of dealing with noisy and sparse signal, and present encouraging\\npreliminary results.\\n',\n",
       " '  In this paper, we propose a generalized Gronwall inequality through the\\nfractional integral with respect to another function. The Cauchy-type problem\\nfor a nonlinear differential equation involving the $\\\\psi$-Hilfer fractional\\nderivative and the existence and uniqueness of solutions are discussed.\\nFinally, through generalized Gronwall inequality, we prove the continuous\\ndependence of data on the Cauchy-type problem.\\n',\n",
       " '  Power grids are undergoing major changes due to rapid growth in renewable\\nenergy resources and improvements in battery technology. While these changes\\nenhance sustainability and efficiency, they also create significant management\\nchallenges as the complexity of power systems increases. To tackle these\\nchallenges, decentralized Internet-of-Things (IoT) solutions are emerging,\\nwhich arrange local communities into transactive microgrids. Within a\\ntransactive microgrid, \"prosumers\" (i.e., consumers with energy generation and\\nstorage capabilities) can trade energy with each other, thereby smoothing the\\nload on the main grid using local supply. It is hard, however, to provide\\nsecurity, safety, and privacy in a decentralized and transactive energy system.\\nOn the one hand, prosumers\\' personal information must be protected from their\\ntrade partners and the system operator. On the other hand, the system must be\\nprotected from careless or malicious trading, which could destabilize the\\nentire grid. This paper describes Privacy-preserving Energy Transactions\\n(PETra), which is a secure and safe solution for transactive microgrids that\\nenables consumers to trade energy without sacrificing their privacy. PETra\\nbuilds on distributed ledgers, such as blockchains, and provides anonymity for\\ncommunication, bidding, and trading.\\n',\n",
       " '  Supervisor reduction procedure can be used to construct the reduced\\nsupervisor with a reduced number of states in discrete-event systems. The main\\nconcepts which are used in this procedure are control consistency of states,\\ncontrol cover, induced supervisor, and normality of the reduced supervisor\\nw.r.t. the original supervisor. In this paper, it is proved that the reduced\\nsupervisor, constructed by the proposed method in [9], preserves the\\nobservation properties, i.e. normality and relative observability, by self\\nlooping corresponding unobservable events at some states of the reduced\\nsupervisor. This property can be applied to find a natural projection, under\\nwhich the supervisor is relative observable.\\n',\n",
       " '  We investigate the influence of particle diffusion in the two-dimension\\ncontact process (CP) with a competitive dynamics in bipartite sublattices,\\nproposed in [Phys. Rev. E 84, 011125 (2011)]. The particle creation depends on\\nits first and second neighbors and the extinction increases according to the\\nlocal density. In contrast to the standard CP model, mean-field theory and\\nnumerical simulations predict three stable phases: inactive (absorbing), active\\nsymmetric and active asymmetric, signed by distinct sublattice particle\\noccupations. Our results from MFT and Monte Carlo simulations reveal that low\\ndiffusion rates do not destroy sublattice ordering, ensuring the maintenance of\\nthe asymmetric phase. On the other hand, for diffusion larger than a threshold\\nvalue Dc, the sublattice ordering is suppressed and only the usual active\\n(symmetric)-inactive transition is presented. We also show the critical\\nbehavior and universality classes are not affected by the diffusion.\\n',\n",
       " '  The Wasserstein probability metric has received much attention from the\\nmachine learning community. Unlike the Kullback-Leibler divergence, which\\nstrictly measures change in probability, the Wasserstein metric reflects the\\nunderlying geometry between outcomes. The value of being sensitive to this\\ngeometry has been demonstrated, among others, in ordinal regression and\\ngenerative modelling. In this paper we describe three natural properties of\\nprobability divergences that reflect requirements from machine learning: sum\\ninvariance, scale sensitivity, and unbiased sample gradients. The Wasserstein\\nmetric possesses the first two properties but, unlike the Kullback-Leibler\\ndivergence, does not possess the third. We provide empirical evidence\\nsuggesting that this is a serious issue in practice. Leveraging insights from\\nprobabilistic forecasting we propose an alternative to the Wasserstein metric,\\nthe Cramér distance. We show that the Cramér distance possesses all three\\ndesired properties, combining the best of the Wasserstein and Kullback-Leibler\\ndivergences. To illustrate the relevance of the Cramér distance in practice\\nwe design a new algorithm, the Cramér Generative Adversarial Network (GAN),\\nand show that it performs significantly better than the related Wasserstein\\nGAN.\\n',\n",
       " '  We study the temperature dependence of the electrical resistivity in a system\\ncomposed of critical spin chains interacting with three dimensional conduction\\nelectrons and driven to criticality via an external magnetic field. The\\nrelevant experimental system is Yb$_2$Pt$_2$Pb, a metal where itinerant\\nelectrons coexist with localized moments of Yb-ions which can be described in\\nterms of effective S = 1/2 spins with dominantly one-dimensional exchange\\ninteraction. The spin subsystem becomes critical in a relatively weak magnetic\\nfield, where it behaves like a Luttinger liquid. We theoretically examine a\\nKondo lattice with different effective space dimensionalities of the two\\ninteracting subsystems. We characterize the corresponding non-Fermi liquid\\nbehavior due to the spin criticality by calculating the electronic relaxation\\nrate and the dc resistivity and establish its quasi linear temperature\\ndependence.\\n',\n",
       " '  Geometry theorem proving forms a major and challenging component in the K-12\\nmathematics curriculum. A particular difficult task is to add auxiliary\\nconstructions (i.e, additional lines or points) to aid proof discovery.\\nAlthough there exist many intelligent tutoring systems proposed for geometry\\nproofs, few teach students how to find auxiliary constructions. And the few\\nexceptions are all limited by their underlying reasoning processes for\\nsupporting auxiliary constructions. This paper tackles these weaknesses of\\nprior systems by introducing an interactive geometry tutor, the Advanced\\nGeometry Proof Tutor (AGPT). It leverages a recent automated geometry prover to\\nprovide combined benefits that any geometry theorem prover or intelligent\\ntutoring system alone cannot accomplish. In particular, AGPT not only can\\nautomatically process images of geometry problems directly, but also can\\ninteractively train and guide students toward discovering auxiliary\\nconstructions on their own. We have evaluated AGPT via a pilot study with 78\\nhigh school students. The study results show that, on training students how to\\nfind auxiliary constructions, there is no significant perceived difference\\nbetween AGPT and human tutors, and AGPT is significantly more effective than\\nthe state-of-the-art geometry solver that produces human-readable proofs.\\n',\n",
       " '  We present the analysis and computational results for the inclination\\nrelative effect of moonlets of triple asteroidal systems. Perturbations on\\nmoonlets due to the primarys non-sphericity gravity, the solar gravity, and\\nmoonlets relative gravity are discussed. The inclination vector for each\\nmoonlet follows a periodic elliptical motion; the motion period depends on the\\nmoonlets semi-major axis and the primarys J2 perturbations. Perturbation on\\nmoonlets from the Solar gravity and moonlets relative gravity makes the motion\\nof the x component of the inclination vector of moonlet 1 and the y component\\nof the inclination vector of moonlet 2 to be periodic.The mean motion of x\\ncomponent and the y component of the inclination vector of each moonlet forms\\nan ellipse. However, the instantaneous motion of x component and the y\\ncomponent of the inclination vector may be an elliptical disc due to the\\ncoupling effect of perturbation forces. Furthermore, the x component of the\\ninclination vector of moonlet 1 and the y component of the inclination vector\\nof moonlet 2 form a quasi-periodic motion. Numerical calculation of dynamical\\nconfigurations of two triple asteroidal systems (216) Kleopatra and (153591)\\n2001 SN263 validates the conclusion.\\n',\n",
       " '  Threshold of the transverse mode coupling instability is calculated in\\nframeworks of the square well model at arbitrary value of space charge tune\\nshift. A new method of calculation is developed beyond the traditional\\nexpansion technique. The square, resistive, and exponential wakes are\\ninvestigated. It is shown that the instability threshold goes up without limit\\nwhen the tune shift increases. A resemblance of the results to conventional\\ncase of the parabolic potential well is demonstrated and explained.\\n',\n",
       " '  We study vector portal dark matter models where the mediator couples only to\\nleptons. In spite of the lack of tree-level couplings to colored states,\\nradiative effects generate interactions with quark fields that could give rise\\nto a signal in current and future experiments. We identify such experimental\\nsignatures: scattering of nuclei in dark matter direct detection; resonant\\nproduction of lepton-antilepton pairs at the Large Hadron Collider; and\\nhadronic final states in dark matter indirect searches. Furthermore, radiative\\neffects also generate an irreducible mass mixing between the vector mediator\\nand the $Z$ boson, severely bounded by ElectroWeak Precision Tests. We use\\ncurrent experimental results to put bounds on this class of models, accounting\\nfor both radiatively induced and tree-level processes. Remarkably, the former\\noften overwhelm the latter.\\n',\n",
       " '  Let $X=(X_t)_{t \\\\ge 0}$ be a stochastic process which has an (not necessarily\\nstationary) independent increment on a probability space $(\\\\Omega,\\n\\\\mathbb{P})$. In this paper, we study the following Cauchy problem related to\\nthe stochastic process $X$:\\n$\\\\label{main eqn} \\\\frac{\\\\partial u}{\\\\partial t}(t,x) = \\\\cA(t)u(t,x) +f(t,x),\\n\\\\quad u(0,\\\\cdot)=0, \\\\quad (t,x) \\\\in (0,T) \\\\times \\\\mathbf{R}^d, \\\\end{align}\\nwhere $f \\\\in L_p( (0,T) ; L_p(\\\\mathbf{R}^d))=L_p( (0,T) ; L_p)$ and\\n\\\\begin{align*} \\\\cA(t)u(t,x) = \\\\lim_{h \\\\downarrow\\n0}\\\\frac{\\\\mathbb{E}\\\\left[u(t,x+X_{t+h}-X_t)-u(t,x)\\\\right]}{h}$. We provide a\\nsufficient condition on $X$ to guarantee the unique solvability of equation\\n(\\\\ref{ab main}) in $L_p\\\\left( [0,T] ; H^\\\\phi_{p}\\\\right)$, where $H^\\\\phi_{p}$ is\\na $\\\\phi$-potential space on $\\\\mathbf{R}^d$ . Furthemore we show that for this\\nsolution, \\\\| u\\\\|_{L_p\\\\left( [0,T] ; H^\\\\phi_{p}\\\\right)} \\\\leq N \\\\|f\\\\|_{L_p\\\\left(\\n[0,T] ; L_p\\\\right)}, where $N$ is independent of $u$ and $f$.\\n',\n",
       " '  Deep learning is a hierarchical inference method formed by subsequent\\nmultiple layers of learning able to more efficiently describe complex\\nrelationships. In this work, Deep Gaussian Mixture Models are introduced and\\ndiscussed. A Deep Gaussian Mixture model (DGMM) is a network of multiple layers\\nof latent variables, where, at each layer, the variables follow a mixture of\\nGaussian distributions. Thus, the deep mixture model consists of a set of\\nnested mixtures of linear models, which globally provide a nonlinear model able\\nto describe the data in a very flexible way. In order to avoid\\noverparameterized solutions, dimension reduction by factor models can be\\napplied at each layer of the architecture thus resulting in deep mixtures of\\nfactor analysers.\\n',\n",
       " '  In this paper, we use variational recurrent neural network to investigate the\\nanomaly detection problem on graph time series. The temporal correlation is\\nmodeled by the combination of recurrent neural network (RNN) and variational\\ninference (VI), while the spatial information is captured by the graph\\nconvolutional network. In order to incorporate external factors, we use feature\\nextractor to augment the transition of latent variables, which can learn the\\ninfluence of external factors. With the target function as accumulative ELBO,\\nit is easy to extend this model to on-line method. The experimental study on\\ntraffic flow data shows the detection capability of the proposed method.\\n',\n",
       " '  In contrast to conventional, univariate analysis, various types of\\nmultivariate analysis have been applied to functional magnetic resonance\\nimaging (fMRI) data. In this paper, we compare two contemporary approaches for\\nmultivariate regression on task-based fMRI data: linear regression with ridge\\nregularization and non-linear symbolic regression using genetic programming.\\nThe data for this project is representative of a contemporary fMRI experimental\\ndesign for visual stimuli. Linear and non-linear models were generated for 10\\nsubjects, with another 4 withheld for validation. Model quality is evaluated by\\ncomparing $R$ scores (Pearson product-moment correlation) in various contexts,\\nincluding single run self-fit, within-subject generalization, and\\nbetween-subject generalization. Propensity for modelling strategies to overfit\\nis estimated using a separate resting state scan. Results suggest that neither\\nmethod is objectively or inherently better than the other.\\n',\n",
       " '  Given a graded $E_1$-module over an $E_2$-algebra in spaces, we construct an\\naugmented semi-simplicial space up to higher coherent homotopy over it, called\\nits canonical resolution, whose graded connectivity yields homological\\nstability for the graded pieces of the module with respect to constant and\\nabelian coefficients. We furthermore introduce a notion of coefficient systems\\nof finite degree in this context and show that, without further assumptions,\\nthe corresponding twisted homology groups stabilize as well. This generalizes a\\nframework of Randal-Williams and Wahl for families of discrete groups.\\nIn many examples, the canonical resolution recovers geometric resolutions\\nwith known connectivity bounds. As a consequence, we derive new twisted\\nhomological stability results for e.g. moduli spaces of high-dimensional\\nmanifolds, unordered configuration spaces of manifolds with labels in a\\nfibration, and moduli spaces of manifolds equipped with unordered embedded\\ndiscs. This in turn implies representation stability for the ordered variants\\nof the latter examples.\\n',\n",
       " '  Connected and autonomous vehicles (CAVs) have recently attracted a\\nsignificant amount of attention both from researchers and industry. Numerous\\nstudies targeting algorithms, software frameworks, and applications on the CAVs\\nscenario have emerged. Meanwhile, several pioneer efforts have focused on the\\nedge computing system and architecture design for the CAVs scenario and\\nprovided various heterogeneous platform prototypes for CAVs. However, a\\nstandard and comprehensive application benchmark for CAVs is missing, hindering\\nthe study of these emerging computing systems. To address this challenging\\nproblem, we present CAVBench, the first benchmark suite for the edge computing\\nsystem in the CAVs scenario. CAVBench is comprised of six typical applications\\ncovering four dominate CAVs scenarios and takes four datasets as standard\\ninput. CAVBench provides quantitative evaluation results via application and\\nsystem perspective output metrics. We perform a series of experiments and\\nacquire three systemic characteristics of the applications in CAVBench. First,\\nthe operation intensity of the applications is polarized, which explains why\\nheterogeneous hardware is important for a CAVs computing system. Second, all\\napplications in CAVBench consume high memory bandwidth, so the system should be\\nequipped with high bandwidth memory or leverage good memory bandwidth\\nmanagement to avoid the performance degradation caused by memory bandwidth\\ncompetition. Third, some applications have worse data/instruction locality\\nbased on the cache miss observation, so the computing system targeting these\\napplications should optimize the cache architecture. Last, we use the CAVBench\\nto evaluate a typical edge computing platform and present the quantitative and\\nqualitative analysis of the benchmarking results.\\n',\n",
       " '  We report on the fragmentation of the water molecule by $1$ MeV H$^{+}$,\\nHe$^{+}$ and 650 keV N$^{+}$ ion impact. The fragment-ion energy spectra were\\nmeasured by an electrostatic spectrometer at different observation angles. The\\nobtained double-differential fragmentation cross sections for N$^{+}$ is found\\nto be more than an order of magnitude higher, than that for H$^{+}$. The\\nrelative ratios of the fragmentation channels are also different for the three\\nprojectiles. Additional fragmentation channels were observed in the spectra for\\nHe$^{+}$ and for N$^{+}$ impact, which are missing in the case of H$^{+}$. From\\nthe analysis of the kinetic energy of the fragments, the maximum observed\\ndegree of ionization was found to be $q\\\\rm{_{max}}=3$, $4$, and $5$ for\\nH${^+}$, He${^+}$ and N${^+}$ impact, respectively. Absolute multiple\\nionization cross sections have been determined. They are compared with the\\npredictions of the classical trajectory Monte Carlo and\\ncontinuum-distorted-wave eikonal-initial-state theories. At lower degrees of\\nionization, theories provide reasonable agreement with experiment. The\\nsystematic overestimation of the cross section by the theories towards higher\\ndegrees of ionization indicates the failure of the independent particle model.\\n',\n",
       " '  This paper is a complement of our recent works on the semilinear Tricomi\\nequations in [8] and[9].\\n',\n",
       " '  We propose a new globalization strategy that can be used in unconstrained\\noptimization algorithms to support rapid convergence from remote starting\\npoints. Our approach is based on using multiple points at each iteration to\\nbuild a representative model of the objective function. Using the new\\ninformation gathered from those multiple points, a local step is gradually\\nimproved by updating its direction as well as its length. We give a global\\nconvergence result and also provide parallel implementation details accompanied\\nwith a numerical study. Our numerical study shows that the proposed algorithm\\nis a promising alternative as a globalization strategy.\\n',\n",
       " '  In this paper, pattern division multiple access with large-scale antenna\\narray (LSA-PDMA) is proposed as a novel non-orthogonal multiple access (NOMA)\\nscheme. In the proposed scheme, pattern is designed in both beam domain and\\npower domain in a joint manner. At the transmitter, pattern mapping utilizes\\npower allocation to improve the system sum rate and beam allocation to enhance\\nthe access connectivity and realize the integration of LSA into multiple access\\nspontaneously. At the receiver, hybrid detection of spatial filter (SF) and\\nsuccessive interference cancellation (SIC) is employed to separate the\\nsuperposed multiple-domain signals. Furthermore, we formulate the sum rate\\nmaximization problem to obtain the optimal pattern mapping policy, and the\\noptimization problem is proved to be convex through proper mathematical\\nmanipulations. Simulation results show that the proposed LSA-PDMA scheme\\nachieves significant performance gain on system sum rate compared to both the\\northogonal multiple access scheme and the power-domain NOMA scheme.\\n',\n",
       " '  Pyramids are the greatest architectural achievement of ancient civilization,\\nso people all over the world are curious as to the purpose of such huge\\nconstructions. No other structure has been studied as thoroughly, nor have so\\nmany books and articles been written about it. We created a computer model of\\nthe pyramid. To validate the model, we compare our calculations with the\\nexperimental data of Luis W. Alvarez. The fact that the Egyptians set up 2.5\\nmillion stone blocks without any purpose seems to be unimaginable. Therefore,\\nwe attempt to examine the internal structure of the pyramid using muon\\ntomography. With our measurements we performed and verified a calibration of\\nthe attenuation of muons for primary beam momenta of 2.5 GeV/c and 3 GeV/c at\\nthe T9 experimental area of CERN.\\n',\n",
       " '  The Bradley-Terry model assigns probabilities for the outcome of paired\\ncomparison experiments based on strength parameters associated with the objects\\nbeing compared. We consider different proposed choices of prior parameter\\ndistributions for Bayesian inference of the strength parameters based on the\\npaired comparison results. We evaluate them according to four desiderata\\nmotivated by the use of inferred Bradley-Terry parameters to rate teams on the\\nbasis of outcomes of a set of games: invariance under interchange of teams,\\ninvariance under interchange of winning and losing, normalizability and\\ninvariance under elimination of teams. We consider various proposals which fail\\nto satisfy one or more of these desiderata, and illustrate two proposals which\\nsatisfy them. Both are one-parameter independent distributions for the\\nlogarithms of the team strengths: 1) Gaussian and 2) Type III generalized\\nlogistic.\\n',\n",
       " '  The methodology of automatic detection of the event basis of information\\noperations, reflected in thematic information flows, is described. The\\npresented methodology is based on the technologies for identifying information\\noperations, the formation of the terminological basis of the subject area, the\\napplication of cluster analysis with cluster centroids, determined by analyzing\\nthe terminology of the information flow. The clusters formed in this way\\nreflect the main events occurring during the information operations and reveal\\nthe technique for their implementation.\\n',\n",
       " '  Active Search has become an increasingly useful tool in information retrieval\\nproblems where the goal is to discover as many target elements as possible\\nusing only limited label queries. With the advent of big data, there is a\\ngrowing emphasis on the scalability of such techniques to handle very large and\\nvery complex datasets.\\nIn this paper, we consider the problem of Active Search where we are given a\\nsimilarity function between data points. We look at an algorithm introduced by\\nWang et al. [2013] for Active Search over graphs and propose crucial\\nmodifications which allow it to scale significantly. Their approach selects\\npoints by minimizing an energy function over the graph induced by the\\nsimilarity function on the data. Our modifications require the similarity\\nfunction to be a dot-product between feature vectors of data points, equivalent\\nto having a linear kernel for the adjacency matrix. With this, we are able to\\nscale tremendously: for $n$ data points, the original algorithm runs in\\n$O(n^2)$ time per iteration while ours runs in only $O(nr + r^2)$ given\\n$r$-dimensional features.\\nWe also describe a simple alternate approach using a weighted-neighbor\\npredictor which also scales well. In our experiments, we show that our method\\nis competitive with existing semi-supervised approaches. We also briefly\\ndiscuss conditions under which our algorithm performs well.\\n',\n",
       " '  A new generator of univariate continuous distributions, with two additional\\nparameters, called the Log-Lindley generated family is introduced. Some special\\ndistributions in the new family are presented. Some mathematical properties of\\nthe new family are studied. The maximum likelihood method to estimate model\\nparameters is employed. The potentiality of the new generator is illustrated\\nusing a real data set.\\n',\n",
       " '  There are (at least) four ways that an agent can acquire information\\nconcerning the state of the universe: via observation, control, prediction, or\\nvia retrodiction, i.e., memory. Each of these four ways of acquiring\\ninformation seems to rely on a different kind of physical device (resp., an\\nobservation device, a control device, etc.). However it turns out that certain\\nmathematical structure is common to those four types of device. Any device that\\npossesses a certain subset of that structure is known as an \"inference device\"\\n(ID).\\nHere I review some of the properties of IDs, including their relation with\\nTuring machines, and (more loosely) quantum mechanics. I also review the bounds\\nof the joint abilities of any set of IDs to know facts about the physical\\nuniverse that contains them. These bounds constrain the possible properties of\\nany universe that contains agents who can acquire information concerning that\\nuniverse.\\nI then extend this previous work on IDs, by adding to the definition of IDs\\nsome of the other mathematical structure that is common to the four ways of\\nacquiring information about the universe but is not captured in the (minimal)\\ndefinition of IDs. I discuss these extensions of IDs in the context of\\nepistemic logic (especially possible worlds formalisms like Kripke structures\\nand Aumann structures). In particular, I show that these extensions of IDs are\\nnot subject to the problem of logical omniscience that plagues many previously\\nstudied forms of epistemic logic.\\n',\n",
       " '  Additive manufacturing of polymer bonded magnets is a recently developed\\ntechnique, for single-unit production, and for structures that have been\\nimpossible to manufacture previously. Also new possibilities to create a\\nspecific stray field around the magnet are triggered. The current work presents\\na method to 3D print polymer bonded magnets with a variable magnetic compound\\ndensity distribution. A low-cost, end-user 3D printer with a mixing extruder is\\nused to mix permanent magnetic filaments with pure PA12 filaments. The magnetic\\nfilaments are compounded, extruded, and characterized for the printing process.\\nTo deduce the quality of the manufactured magnets with a variable compound\\ndensity, an inverse stray field framework is used. The effectiveness of the\\nprinting process and the simulation method is shown. It can also be used to\\nmanufacture magnets that produce a predefined stray field in a given region.\\nExamples for sensor applications are presented. This setup and simulation\\nframework allows the design and manufacturing of polymer bonded permanent\\nmagnets which are impossible to create with conventional methods.\\n',\n",
       " \"  It is currently unclear why adversarial examples are easy to construct for\\ndeep networks that are otherwise successful with respect to their training\\ndomain. However, it is suspected that these adversarial examples lie within\\nsome small perturbation from the network's decision boundaries or exist in\\nlow-density regions with respect to the training distribution. Using persistent\\nhomology, we find that deep networks effectively have ``holes'' in their\\nactivation graphs, making them blind to regions of the input space that can be\\nexploited by adversarial examples. These holes are effectively dense in the\\ninput space, making it easy to find a perturbed image that can be\\nmisclassified. By studying the topology of network activation, we find global\\npatterns in the form of activation subgraphs which can both reliably determine\\nwhether an example is adversarial and can recover the true category of the\\nexample well above chance, implying that semantic information about the input\\nis embedded globally via the activation pattern in deep networks.\\n\",\n",
       " '  The DsTau project proposes to study tau-neutrino production in high-energy\\nproton interactions. The outcome of this experiment are prerequisite for\\nmeasuring the $\\\\nu_\\\\tau$ charged-current cross section that has never been well\\nmeasured. Precisely measuring the cross section would enable testing of lepton\\nuniversality in $\\\\nu_\\\\tau$ scattering and it also has practical implications\\nfor neutrino oscillation experiments and high-energy astrophysical $\\\\nu_\\\\tau$\\nobservations. $D_s$ mesons, the source of tau neutrinos, following high-energy\\nproton interactions will be studied by a novel approach to detect the\\ndouble-kink topology of the decays $D_s \\\\rightarrow \\\\tau\\\\nu_\\\\tau$ and\\n$\\\\tau\\\\rightarrow\\\\nu_\\\\tau X$. Directly measuring $D_s\\\\rightarrow \\\\tau$ decays\\nwill provide an inclusive measurement of the $D_s$ production rate and decay\\nbranching ratio to $\\\\tau$. The momentum reconstruction of $D_s$ will be\\nperformed by combining topological variables. This project aims to detect 1,000\\n$D_s \\\\rightarrow \\\\tau$ decays in $2.3 \\\\times 10^8$ proton interactions in\\ntungsten target to study the differential production cross section of $D_s$\\nmesons. To achieve this, state-of-the-art emulsion detectors with a\\nnanometric-precision readout will be used. The data generated by this project\\nwill enable the $\\\\nu_\\\\tau$ cross section from DONUT to be re-evaluated, and\\nthis should significantly reduce the total systematic uncertainty. Furthermore,\\nthese results will provide essential data for future $\\\\nu_\\\\tau$ experiments\\nsuch as the $\\\\nu_\\\\tau$ program in the SHiP project at CERN. In addition, the\\nanalysis of $2.3 \\\\times 10^8$ proton interactions, combined with the expected\\nhigh yield of $10^5$ charmed decays as by-products, will enable the extraction\\nof additional physical quantities.\\n',\n",
       " '  The variation of spectral subspaces for linear self-adjoint operators under\\nan additive bounded semidefinite perturbation is considered. A variant of the\\nDavis-Kahan $ \\\\sin2\\\\Theta $ theorem from [SIAM J. Numer. Anal. 7 (1970), 1--46]\\nadapted to this situation is proved. Under a certain additional geometric\\nassumption on the separation of the spectrum of the unperturbed operator, this\\nleads to a sharp estimate on the norm of the difference of the spectral\\nprojections associated with isolated components of the spectrum of the\\nperturbed and perturbed operators, respectively. Without this additional\\ngeometric assumption on the isolated components of the spectrum of the\\nunperturbed operator, a corresponding estimate is obtained by transferring the\\noptimization approach for general perturbations in [J. Anal. Math., to appear;\\narXiv:1310.4360 (2013)] to the present situation.\\n',\n",
       " '  By modeling macro-economical indicators using digital traces of human\\nactivities on mobile or social networks, we can provide important insights to\\nprocesses previously assessed via paper-based surveys or polls only. We\\ncollected aggregated workday activity timelines of US counties from the\\nnormalized number of messages sent in each hour on the online social network\\nTwitter. In this paper, we show how county employment and unemployment\\nstatistics are encoded in the daily rhythm of people by decomposing the\\nactivity timelines into a linear combination of two dominant patterns. The\\nmixing ratio of these patterns defines a measure for each county, that\\ncorrelates significantly with employment ($0.46\\\\pm0.02$) and unemployment rates\\n($-0.34\\\\pm0.02$). Thus, the two dominant activity patterns can be linked to\\nrhythms signaling presence or lack of regular working hours of individuals. The\\nanalysis could provide policy makers a better insight into the processes\\ngoverning employment, where problems could not only be identified based on the\\nnumber of officially registered unemployed, but also on the basis of the\\ndigital footprints people leave on different platforms.\\n',\n",
       " '  {Context}. The HIFI instrument on the Herschel Space Observatory performed\\nover 9100 astronomical observations, almost 900 of which were calibration\\nobservations in the course of the nearly four-year Herschel mission. The data\\nfrom each observation had to be converted from raw telemetry into calibrated\\nproducts and were included in the Herschel Science Archive. {Aims}. The HIFI\\npipeline was designed to provide robust conversion from raw telemetry into\\ncalibrated data throughout all phases of the HIFI missions. Pre-launch\\nlaboratory testing was supported as were routine mission operations. {Methods}.\\nA modular software design allowed components to be easily added, removed,\\namended and/or extended as the understanding of the HIFI data developed during\\nand after mission operations. {Results}. The HIFI pipeline processed data from\\nall HIFI observing modes within the Herschel automated processing environment\\nas well as within an interactive environment. The same software can be used by\\nthe general astronomical community to reprocess any standard HIFI observation.\\nThe pipeline also recorded the consistency of processing results and provided\\nautomated quality reports. Many pipeline modules were in use since the HIFI\\npre-launch instrument level testing. {Conclusions}. Processing in steps\\nfacilitated data analysis to discover and address instrument artefacts and\\nuncertainties. The availability of the same pipeline components from pre-launch\\nthroughout the mission made for well-understood, tested, and stable processing.\\nA smooth transition from one phase to the next significantly enhanced\\nprocessing reliability and robustness.\\n',\n",
       " '  New tilings of certain subsets of $\\\\mathbb{R}^{M}$ are studied, tilings\\nassociated with fractal blow-ups of certain similitude iterated function\\nsystems (IFS). For each such IFS with attractor satisfying the open set\\ncondition, our construction produces a usually infinite family of tilings that\\nsatisfy the following properties: (1) the prototile set is finite; (2) the\\ntilings are repetitive (quasiperiodic); (3) each family contains\\nself-similartilings, usually infinitely many; and (4) when the IFS is rigid in\\nan appropriate sense, the tiling has no non-trivial symmetry; in particular the\\ntiling is non-periodic.\\n',\n",
       " '  BaMn$_{2}$As$_{2}$ is an antiferromagnetic insulator where a metal-insulator\\ntransition occurs with hole doping via the substitution of Ba with K. The\\nmetal-insulator transition causes only a small suppression of the Néel\\ntemperature ($T_\\\\mathrm{N}$) and the ordered moment, suggesting that doped\\nholes interact weakly with the Mn spin system. Powder inelastic neutron\\nscattering measurements were performed on three different powder samples of\\nBa$_{1-x}$K$_{x}$Mn$_{2}$As$_{2}$ with $x=$0, 0.125 and 0.25 to study the\\neffect of hole doping and metallization on the spin dynamics of these\\ncompounds. We compare the neutron intensities to a linear spin wave theory\\napproximation to the $J_{1}-J_{2}-J_{c}$ Heisenberg model. Hole doping is found\\nto introduce only minor modifications to the exchange energies and spin gap.\\nThe changes observed in the exchange constants are consistent with the small\\ndrop of $T_\\\\mathrm{N}$ with doping.\\n',\n",
       " '  Low dimensional embeddings that capture the main variations of interest in\\ncollections of data are important for many applications. One way to construct\\nthese embeddings is to acquire estimates of similarity from the crowd. However,\\nsimilarity is a multi-dimensional concept that varies from individual to\\nindividual. Existing models for learning embeddings from the crowd typically\\nmake simplifying assumptions such as all individuals estimate similarity using\\nthe same criteria, the list of criteria is known in advance, or that the crowd\\nworkers are not influenced by the data that they see. To overcome these\\nlimitations we introduce Context Embedding Networks (CENs). In addition to\\nlearning interpretable embeddings from images, CENs also model worker biases\\nfor different attributes along with the visual context i.e. the visual\\nattributes highlighted by a set of images. Experiments on two noisy crowd\\nannotated datasets show that modeling both worker bias and visual context\\nresults in more interpretable embeddings compared to existing approaches.\\n',\n",
       " '  We characterize a close connection between the continuous-time quantum-walk\\nmodel and a discrete-time quantum-walk version, based on the staggered model\\nwith Hamiltonians in a class of Cayley graphs, which can be considered as a\\ndiscretization of continuous-time quantum walks. This connection provides\\nexamples of perfect state transfer and instantaneous uniform mixing in the\\nstaggered model. On the other hand, we provide some more examples of perfect\\nstate transfer and instantaneous uniform mixing in the staggered model that\\ncannot be reproduced by the continuous-time model.\\n',\n",
       " '  This paper explores the uniqueness of ESA Rosetta mission operations from the\\nAlice instrument point of view, documents lessons learned, and suggests\\noperations ideas for future missions. The Alice instrument mounted on the\\nRosetta orbiter is an imaging spectrograph optimized for cometary\\nfar-ultraviolet (FUV) spectroscopy with the scientific objectives of measuring\\nproperties of the escaping gas and dust, and studying the surface properties,\\nincluding searching for exposed ices. We describe the operations processes\\nduring the comet encounter period, the many interfaces to contend with, the\\nconstraints that impacted Alice, and how the Alice science goals of measuring\\nthe cometary gas characteristics and their evolution were achieved. We provide\\ndetails that are relevant to the use and interpretation of Alice data and\\npublished results. All these flight experiences and lessons learned will be\\nuseful for future cometary missions that include ultraviolet spectrographs in\\nparticular, and multi-instrument international payloads in general.\\n',\n",
       " '  The successive projection algorithm (SPA) can quickly solve a nonnegative\\nmatrix factorization problem under a separability assumption. Even if noise is\\nadded to the problem, SPA is robust as long as the perturbations caused by the\\nnoise are small. In particular, robustness against noise should be high when\\nhandling the problems arising from real applications. The preconditioner\\nproposed by Gillis and Vavasis (2015) makes it possible to enhance the noise\\nrobustness of SPA. Meanwhile, an additional computational cost is required. The\\nconstruction of the preconditioner contains a step to compute the top-$k$\\ntruncated singular value decomposition of an input matrix. It is known that the\\ndecomposition provides the best rank-$k$ approximation to the input matrix; in\\nother words, a matrix with the smallest approximation error among all matrices\\nof rank less than $k$. This step is an obstacle to an efficient implementation\\nof the preconditioned SPA.\\nTo address the cost issue, we propose a modification of the algorithm for\\nconstructing the preconditioner. Although the original algorithm uses the best\\nrank-$k$ approximation, instead of it, our modification uses an alternative.\\nIdeally, this alternative should have high approximation accuracy and low\\ncomputational cost. To ensure this, our modification employs a rank-$k$\\napproximation produced by an SPA based algorithm. We analyze the accuracy of\\nthe approximation and evaluate the computational cost of the algorithm. We then\\npresent an empirical study revealing the actual performance of the SPA based\\nrank-$k$ approximation algorithm and the modified preconditioned SPA.\\n',\n",
       " '  Fluorescent paramagnetic defects in solids have become attractive systems for\\nquantum information processing in the recent years. One of the leading\\ncontenders is the negatively charged nitrogen-vacancy defect in diamond with\\nvisible emission but alternative solution in technologically mature host is an\\nimmediate quest for many applications in this field. It has been recently found\\nthat various polytypes of silicon carbide (SiC), that are standard\\nsemiconductors with wafer scale technology, can host nitrogen-vacancy defect\\n(NV) that could be an alternative qubit candidate with emission in the near\\ninfrared region. However, it is much less known about this defect than its\\ncounterpart in diamond. The inequivalent sites within a polytype and the\\npolytype variations offer a family of NV defects. However, there is an\\ninsufficient knowledge on the magneto-optical properties of these\\nconfigurations. Here we carry out density functional theory calculations, in\\norder to characterize the numerous forms of NV defects in the most common\\npolytypes of SiC including 3C, 4H and 6H, and we also provide new experimental\\ndata in 4H SiC. Our calculations mediate the identification of individual NV\\nqubits in SiC polytypes. In addition, we discuss the formation of NV defects in\\nSiC with providing detailed ionization energies of NV defect in SiC which\\nreveals the critical optical excitation energies for ionizing this qubits in\\nSiC. Our calculations unravel the challenges to produce NV defects in SiC with\\na desirable spin bath.\\n',\n",
       " '  We present three-band simultaneous observations of a weak-line T-Tauri star\\nCVSO~30 (PTFO~8-8695), which is one of the youngest objects having a candidate\\ntransiting planet. The data were obtained with the Multicolor Simultaneous\\nCamera for studying Atmospheres of Transiting exoplanets (MuSCAT) on the 188 cm\\ntelescope at Okayama Astrophysical Observatory in Japan. We observed the fading\\nevent in the $g^{\\\\prime}_2$-, $r^{\\\\prime}_2$-, and $z_{\\\\rm s,2}$-bands\\nsimultaneously. As a result, we find a significant wavelength dependence of\\nfading depths of about 3.1\\\\%, 1.7\\\\%, 1.0\\\\% for the $g^{\\\\prime}_2$-,\\n$r^{\\\\prime}_2$-, and $z_{\\\\rm s,2}$-bands, respectively. A cloudless H/He\\ndominant atmosphere of a hot Jupiter cannot explain this large wavelength\\ndependence. Additionally, we rule out a scenario by the occultation of the\\ngravity-darkened host star. Thus our result is in favor of the fading origin as\\ncircumstellar dust clump or occultation of an accretion hotspot.\\n',\n",
       " '  Helical liquids have been experimentally detected in both nanowires and\\nultracold atomic chains as the result of strong spin-orbit interactions. In\\nboth cases the inner degrees of freedom can be considered as an additional\\nspace dimension, providing an interpretation of these systems as synthetic\\nladders, with artificial magnetic fluxes determined by the spin-orbit terms. In\\nthis work, we characterize the helical state which appears at filling\\n$\\\\nu=1/2$: this state is generated by a gap arising in the spin sector of the\\ncorresponding Luttinger liquid and it can be interpreted as the one-dimensional\\n(1D) limit of a fractional quantum Hall state of bosonic pairs of fermions. We\\nstudy its main features, focusing on entanglement properties and correlation\\nfunctions. The techniques developed here provide a key example for the study of\\nsimilar quasi-1D systems beyond the semiclassical approximation commonly\\nadopted in the description of the Laughlin-like states.\\n',\n",
       " '  Starting from a so-called flat exact semisimple bihamiltonian structures of\\nhydrodynamic type, we arrive at a Frobenius manifold structure and a tau\\nstructure for the associated principal hierarchy. We then classify the\\ndeformations of the principal hierarchy which possess tau structures.\\n',\n",
       " '  The mechanisms of localization of Jahn-Teller deformations and vibronic\\nwavefunctions in isotope substituted dynamical Jahn-Teller systems are\\nelucidated. It is found that the localization in the trough is of potential\\ntype in the case of strong vibronic coupling, while it becomes of kinetic type\\nin the case of intermediate and weak coupling. It is shown that the vibronic\\nlevels in the linear $E\\\\otimes e$-problem remain double degenerate upon\\narbitrary isotope substitution on the reasons similar to time reversal symmetry\\nin which the role of spin is played by orbital pseudospin.\\n',\n",
       " '  We present an instance segmentation algorithm trained and applied to a CCTV\\nrecording of beef cattle during a winter finishing period. A fully\\nconvolutional network was transformed into an instance segmentation network\\nthat learns to label each instance of an animal separately. We introduce a\\nconceptually simple framework that the network uses to output a single\\nprediction for every animal. These results are a contribution towards behaviour\\nanalysis in winter finishing beef cattle for early detection of animal\\nwelfare-related problems.\\n',\n",
       " '  We consider the hash function $h(x) = ((ax+b) \\\\bmod p) \\\\bmod n$ where $a,b$\\nare chosen uniformly at random from $\\\\{0,1,\\\\ldots,p-1\\\\}$. We prove that when we\\nuse $h(x)$ in hashing with chaining to insert $n$ elements into a table of size\\n$n$ the expected length of the longest chain is\\n$\\\\tilde{O}\\\\!\\\\left(n^{1/3}\\\\right)$. The proof also generalises to give the same\\nbound when we use the multiply-shift hash function by Dietzfelbinger et al.\\n[Journal of Algorithms 1997].\\n',\n",
       " '  Given a text and a pattern over two types of symbols called constants and\\nvariables, the parameterized pattern matching problem is to find all\\noccurrences of substrings of the text that the pattern matches by substituting\\na variable in the text for each variable in the pattern, where the substitution\\nshould be injective. The function matching problem is a variant of it that\\nlifts the injection constraint. In this paper, we discuss variants of those\\nproblems, where one can substitute a constant or a variable for each variable\\nof the pattern. We give two kinds of algorithms for both problems, a\\nconvolution-based method and an extended KMP-based method, and analyze their\\ncomplexity.\\n',\n",
       " '  In the time series analysis field, there is not a unique recipe for studying\\nsignal similarities. On the other hand, averaging signals of the same nature is\\nan essential tool in the analysis of different kinds of data. Here we propose a\\nmethod to align and average segments of time series with similar patterns. A\\nsimple implementation based on \\\\textit{python} code is provided for the\\nprocedure. The analysis was inspired by the study of canary sound syllables,\\nbut it is possible to apply it in semi periodic signals of different nature and\\nnot necessarily related to sounds.\\n',\n",
       " '  Many combinatorial optimization problems can be mapped to finding the ground\\nstates of the corresponding Ising Hamiltonians. The physical systems that can\\nsolve optimization problems in this way, namely Ising machines, have been\\nattracting more and more attention recently. Our work shows that Ising machines\\ncan be realized using almost any nonlinear self-sustaining oscillators with\\nlogic values encoded in their phases. Many types of such oscillators are\\nreadily available for large-scale integration, with potentials in high-speed\\nand low-power operation. In this paper, we describe the operation and mechanism\\nof oscillator-based Ising machines. The feasibility of our scheme is\\ndemonstrated through several examples in simulation and hardware, among which a\\nsimulation study reports average solutions exceeding those from state-of-art\\nIsing machines on a benchmark combinatorial optimization problem of size 2000.\\n',\n",
       " '  The growth of data, the need for scalability and the complexity of models\\nused in modern machine learning calls for distributed implementations. Yet, as\\nof today, distributed machine learning frameworks have largely ignored the\\npossibility of arbitrary (i.e., Byzantine) failures. In this paper, we study\\nthe robustness to Byzantine failures at the fundamental level of stochastic\\ngradient descent (SGD), the heart of most machine learning algorithms. Assuming\\na set of $n$ workers, up to $f$ of them being Byzantine, we ask how robust can\\nSGD be, without limiting the dimension, nor the size of the parameter space.\\nWe first show that no gradient descent update rule based on a linear\\ncombination of the vectors proposed by the workers (i.e, current approaches)\\ntolerates a single Byzantine failure. We then formulate a resilience property\\nof the update rule capturing the basic requirements to guarantee convergence\\ndespite $f$ Byzantine workers. We finally propose Krum, an update rule that\\nsatisfies the resilience property aforementioned. For a $d$-dimensional\\nlearning problem, the time complexity of Krum is $O(n^2 \\\\cdot (d + \\\\log n))$.\\n',\n",
       " '  We study the general and connected stable ranks for C*-algebras. We estimate\\nthese ranks for pullbacks of C*-algebras, and for tensor products by\\ncommutative C*-algebras. Finally, we apply these results to determine these\\nranks for certain commutative C*-algebras, and non-commutative CW-complexes.\\n',\n",
       " '  Given simple undirected graph G = (V, E), the Maximum Clique Problem(MCP) is\\nthat of finding a maximum-cardinality subset Q of V such that any two vertices\\nin Q are adjacent. We present a modified local search algorithm for this\\nproblem. Our algorithm build some maximal solution and can determine in\\npolynomial time if a maximal solution can be improved by replacing a single\\nvertex with k, k > 1, others. We test our algorithms on DIMACS[5], Sloane[15],\\nBHOSLIB[1], Iovanella[8] and our random instances.\\n',\n",
       " '  In this paper the conditions are investigated for the occurrence of the\\nso-called macroscopic irreversibility property and the related phenomenon of\\ndecay to kinetic equilibrium which may characterize the $1-$body probability\\ndensity function (PDF) associated with hard-sphere systems. The problem is set\\nin the framework of the axiomatic \"ab initio\" approach to classical statistical\\nmechanics recently developed [Tessarotto \\\\textit{et al}., 2013-2017] and the\\nrelated establishment of an exact kinetic equation realized by Master equation\\nfor the same kinetic PDF. As shown in the paper the task involves the\\nintroduction of a suitable functional of the $1-$body PDF here identified with\\nthe \\\\textit{Master kinetic information}. The goal is to show that, provided the\\nsame PDF is realized in terms of an arbitrary suitably-smooth particular\\nsolution of the Master kinetic equation the two properties indicated above are\\nindeed realized and that the same functional is unrelated either with the\\nBoltzmann-Shannon entropy and the Fisher information.\\n',\n",
       " '  In this paper we analyze the gate activation signals inside the gated\\nrecurrent neural networks, and find the temporal structure of such signals is\\nhighly correlated with the phoneme boundaries. This correlation is further\\nverified by a set of experiments for phoneme segmentation, in which better\\nresults compared to standard approaches were obtained.\\n',\n",
       " '  In this paper, we provide for the first time an automated,\\ncorrect-by-construction, controller synthesis scheme for a class of infinite\\ndimensional stochastic systems, namely, retarded jump-diffusion systems. First,\\nwe construct finite dimensional abstractions approximately bisimilar to\\noriginal retarded jump-diffusion systems having some stability property,\\nnamely, incremental input-to-state stability. Second, we construct finite\\nabstractions approximately bisimilar to constructed finite dimensional\\nabstractions. Both types of abstractions are derived without any state-space\\ndiscretization. By using the transitivity property of approximate bisimulation\\nrelations, we establish that the constructed finite abstractions are also\\napproximately bisimilar to original retarded jump-diffusion systems with a\\nprecision that can be chosen a-priori. Given those finite abstractions, one can\\nsynthesize controllers for original systems satisfying high-level logic\\nrequirements in a systematic way. Moreover, we provide sufficient conditions\\nfor the proposed notion of incremental stability in terms of the existence of\\nincremental Lyapunov functions which reduce to linear matrix inequalities (LMI)\\nfor the linear systems. Finally, the effectiveness of the results is\\nillustrated by synthesizing a controller regulating the temperatures in a\\nten-room building modeled as a delayed jump-diffusion system.\\n',\n",
       " \"  On October 2016 the South Korean cyber military unit was the victim of a\\nsuccessful cyber attack that allowed access to internal networks. Per usual\\nwith large scale attacks against South Korean entities, the hack was\\nimmediately attributed to North Korea. Also, per other large-scale cyber\\nsecurity incidents, the same types of 'evidence' were used for attribution\\npurposes. Disclosed methods of attribution provide weak evidence, and the\\nprocedure Korean organizations tend to use for information disclosure lead many\\nto question any conclusions. We will analyze and discuss a number of issues\\nwith the current way that South Korean organizations disclose cyber attack\\ninformation to the public. A time line of events and disclosures will be\\nconstructed and analyzed in the context of appropriate measures for cyber\\nwarfare. Finally, we will examine the South Korean cyber military attack in\\nterms previously proposed cyber warfare response guidelines. Specifically,\\nwhether any of the guidelines can be applied to this real-world case, and if\\nso, is South Korea justified in declaring war based on the most recent cyber\\nattack.\\n\",\n",
       " '  We carried out the deep spectroscopic observations of the nearby cluster\\nA2151 with AF2/WYFFOS@WHT. The caustic technique enables us to identify 360\\nmembers brighter than $M_r = -16$ and within 1.3$R_{200}$. We separated the\\nmembers into subsamples according to photometrical and dynamical properties\\nsuch as colour, local environment and infall time. The completeness of the\\ncatalogue and our large sample allow us to analyse the velocity dispersion and\\nthe luminosity functions of the identified populations. We found evidence of a\\ncluster still in its collapsing phase. The LF of the red population of A2151\\nshows a deficit of dwarf red galaxies. Moreover, the normalized LFs of the red\\nand blue populations of A2151 are comparable to the red and blue LFs of the\\nfield, even if the blue galaxies start dominating one magnitude fainter and the\\nred LF is well represented by a single Schechter function rather than a double\\nSchechter function. We discuss how the evolution of cluster galaxies depends on\\ntheir mass: bright and intermediate galaxies are mainly affected by dynamical\\nfriction and internal/mass quenching, while the evolution of dwarfs is driven\\nby environmental processes which need time and a hostile cluster environment to\\nremove the gas reservoirs and halt the star formation.\\n',\n",
       " '  What do we really mean by a \"good\" scientific journal? Do we care more about\\nthe short-time impact of our papers, or about the chance that they will still\\nbe read and cited on the long run? Here I show that, by regarding a journal as\\na \"virtual scientist\" that can be attributed a time-dependent Hirsch h-index,\\nwe can introduce a parameter that, arguably, better captures the \"persistency\"\\nof a scientific publication. Curiously, however, this parameter seems to depend\\nabove all on the \"thickness\" of a journal.\\n',\n",
       " '  This work presents and compares efficient implementations of high-order\\ndiscontinuous Galerkin methods: a modal matrix-free discontinuous Galerkin (DG)\\nmethod, a hybridizable discontinuous Galerkin (HDG) method, and a primal\\nformulation of HDG, applied to the implicit solution of unsteady compressible\\nflows. The matrix-free implementation allows for a reduction of the memory\\nfootprint of the solver when dealing with implicit time-accurate\\ndiscretizations. HDG reduces the number of globally-coupled degrees of freedom\\nrelative to DG, at high order, by statically condensing element-interior\\ndegrees of freedom from the system in favor of face unknowns. The primal\\nformulation further reduces the element-interior degrees of freedom by\\neliminating the gradient as a separate unknown. This paper introduces a\\n$p$-multigrid preconditioner implementation for these discretizations and\\npresents results for various flow problems. Benefits of the $p$-multigrid\\nstrategy relative to simpler, less expensive, preconditioners are observed for\\nstiff systems, such as those arising from low-Mach number flows at high-order\\napproximation. The $p$-multigrid preconditioner also shows excellent\\nscalability for parallel computations. Additional savings in both speed and\\nmemory occur with a matrix-free/reduced version of the preconditioner.\\n',\n",
       " '  The fast-paced evolution of Android APIs has posed a challenging task for\\nAndroid app developers. To leverage the newly and frequently released APIs from\\nAndroid, developers often must spend considerable effort on API migrations.\\nPrior research work and Android official documentation typically provide enough\\ninformation to guide developers in identifying both the changed API calls that\\nneed to be migrated and the corresponding API calls in the new version of\\nAndroid (what to migrate). However, the API migration task is still challenging\\nsince developers lack the knowledge of how to migrate the API calls. In\\naddition to the official documentation, there exist code examples, such as\\nGoogle Samples, that illustrate the usage of APIs. We posit that by analyzing\\nthe changes of API usage in code examples, we may be able to learn API\\nmigration patterns to assist developers with API migrations.\\nIn this paper, we propose an approach that automatically learns API migration\\npatterns from code examples and applies these patterns to the source code of\\nAndroid apps for API migration. To evaluate our approach, we migrate API calls\\nin open source Android apps by learning API migration patterns from both public\\nand manually generated code examples. We find that our approach can\\nsuccessfully learn API migration patterns and provide API migration assistance\\nin 71 out of 80 cases. In particular, our approach can either automatically\\nmigrate API calls with little to no extra modifications needed or provide\\nguidance to assist with the migrations. Our approach can be adopted by Android\\ndevelopers to reduce the effort they spend on regularly migrating Android APIs.\\n',\n",
       " '  Non-rigid registration is challenging because it is ill-posed with high\\ndegrees of freedom and is thus sensitive to noise and outliers. We propose a\\nrobust non-rigid registration method using reweighted sparsities on position\\nand transformation to estimate the deformations between 3-D shapes. We\\nformulate the energy function with dual sparsities on both the data term and\\nthe smoothness term, and define the smoothness constraint using local rigidity.\\nThe dual-sparsity based non-rigid registration model is enhanced with a\\nreweighting scheme, and solved by transferring the model into some alternating\\noptimized subproblems which have exact solutions and guaranteed convergence.\\nExperimental results on both public datasets and real scanned datasets show\\nthat our method outperforms the state-of-the-art methods and is more robust to\\nnoise and outliers than conventional non-rigid registration methods.\\n',\n",
       " \"  We use the large deviation approach to sum rules pioneered by Gamboa, Nagel\\nand Rouault to prove higher order sum rules for orthogonal polynomials on the\\nunit circle. In particular, we prove one half of a conjectured sum rule of\\nLukic in the case of two singular points, one simple and one double. This is\\nimportant because it is known that the conjecture of Simon fails in exactly\\nthis case, so this paper provides support for the idea that Lukic's replacement\\nfor Simon's conjecture might be true.\\n\",\n",
       " '  Unconventional superconductivity frequently emerges as the transition\\ntemperature of a magnetic phase, typically antiferromagnetic, is suppressed\\ncontinuously toward zero temperature. Here, we report contrary behavior in\\npressurized CeRhGe3, a non-centrosymmetric heavy fermion compound. We find that\\nits pressure-tuned antiferromagnetic transition temperature (TN) appears to\\navoid a continuous decrease to zero temperature by terminating abruptly above a\\ndome of pressure-induced superconductivity. Near 21.5 GPa, evidence for TN\\nsuddenly vanishes, the electrical resistance becomes linear in temperature and\\nthe superconducting transition reaches a maximum. In light of X-ray absorption\\nspectroscopy measurements, these characteristics appear to be related to a\\npressured-induced Ce valence instability, which reveals as a sharp increase in\\nthe rate of change of Ce valence with applied pressure.\\n',\n",
       " '  With an abundance of research papers in deep learning, reproducibility or\\nadoption of the existing works becomes a challenge. This is due to the lack of\\nopen source implementations provided by the authors. Further, re-implementing\\nresearch papers in a different library is a daunting task. To address these\\nchallenges, we propose a novel extensible approach, DLPaper2Code, to extract\\nand understand deep learning design flow diagrams and tables available in a\\nresearch paper and convert them to an abstract computational graph. The\\nextracted computational graph is then converted into execution ready source\\ncode in both Keras and Caffe, in real-time. An arXiv-like website is created\\nwhere the automatically generated designs is made publicly available for 5,000\\nresearch papers. The generated designs could be rated and edited using an\\nintuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our\\napproach, we create a simulated dataset with over 216,000 valid design\\nvisualizations using a manually defined grammar. Experiments on the simulated\\ndataset show that the proposed framework provide more than $93\\\\%$ accuracy in\\nflow diagram content extraction.\\n',\n",
       " '  The adoption of automated, data-driven decision making in an ever expanding\\nrange of applications has raised concerns about its potential unfairness\\ntowards certain social groups. In this context, a number of recent studies have\\nfocused on defining, detecting, and removing unfairness from data-driven\\ndecision systems. However, the existing notions of fairness, based on parity\\n(equality) in treatment or outcomes for different social groups, tend to be\\nquite stringent, limiting the overall decision making accuracy. In this paper,\\nwe draw inspiration from the fair-division and envy-freeness literature in\\neconomics and game theory and propose preference-based notions of fairness --\\ngiven the choice between various sets of decision treatments or outcomes, any\\ngroup of users would collectively prefer its treatment or outcomes, regardless\\nof the (dis)parity as compared to the other groups. Then, we introduce\\ntractable proxies to design margin-based classifiers that satisfy these\\npreference-based notions of fairness. Finally, we experiment with a variety of\\nsynthetic and real-world datasets and show that preference-based fairness\\nallows for greater decision accuracy than parity-based fairness.\\n',\n",
       " '  In an era where accumulating data is easy and storing it inexpensive, feature\\nselection plays a central role in helping to reduce the high-dimensionality of\\nhuge amounts of otherwise meaningless data. In this paper, we propose a\\ngraph-based method for feature selection that ranks features by identifying the\\nmost important ones into arbitrary set of cues. Mapping the problem on an\\naffinity graph-where features are the nodes-the solution is given by assessing\\nthe importance of nodes through some indicators of centrality, in particular,\\nthe Eigen-vector Centrality (EC). The gist of EC is to estimate the importance\\nof a feature as a function of the importance of its neighbors. Ranking central\\nnodes individuates candidate features, which turn out to be effective from a\\nclassification point of view, as proved by a thoroughly experimental section.\\nOur approach has been tested on 7 diverse datasets from recent literature\\n(e.g., biological data and object recognition, among others), and compared\\nagainst filter, embedded and wrappers methods. The results are remarkable in\\nterms of accuracy, stability and low execution time.\\n',\n",
       " '  Recurrent Neural Networks (RNNs), which are a powerful scheme for modeling\\ntemporal and sequential data need to capture long-term dependencies on datasets\\nand represent them in hidden layers with a powerful model to capture more\\ninformation from inputs. For modeling long-term dependencies in a dataset, the\\ngating mechanism concept can help RNNs remember and forget previous\\ninformation. Representing the hidden layers of an RNN with more expressive\\noperations (i.e., tensor products) helps it learn a more complex relationship\\nbetween the current input and the previous hidden layer information. These\\nideas can generally improve RNN performances. In this paper, we proposed a\\nnovel RNN architecture that combine the concepts of gating mechanism and the\\ntensor product into a single model. By combining these two concepts into a\\nsingle RNN, our proposed models learn long-term dependencies by modeling with\\ngating units and obtain more expressive and direct interaction between input\\nand hidden layers using a tensor product on 3-dimensional array (tensor) weight\\nparameters. We use Long Short Term Memory (LSTM) RNN and Gated Recurrent Unit\\n(GRU) RNN and combine them with a tensor product inside their formulations. Our\\nproposed RNNs, which are called a Long-Short Term Memory Recurrent Neural\\nTensor Network (LSTMRNTN) and Gated Recurrent Unit Recurrent Neural Tensor\\nNetwork (GRURNTN), are made by combining the LSTM and GRU RNN models with the\\ntensor product. We conducted experiments with our proposed models on word-level\\nand character-level language modeling tasks and revealed that our proposed\\nmodels significantly improved their performance compared to our baseline\\nmodels.\\n',\n",
       " '  Universal Dependencies (UD) offer a uniform cross-lingual syntactic\\nrepresentation, with the aim of advancing multilingual applications. Recent\\nwork shows that semantic parsing can be accomplished by transforming syntactic\\ndependencies to logical forms. However, this work is limited to English, and\\ncannot process dependency graphs, which allow handling complex phenomena such\\nas control. In this work, we introduce UDepLambda, a semantic interface for UD,\\nwhich maps natural language to logical forms in an almost language-independent\\nfashion and can process dependency graphs. We perform experiments on question\\nanswering against Freebase and provide German and Spanish translations of the\\nWebQuestions and GraphQuestions datasets to facilitate multilingual evaluation.\\nResults show that UDepLambda outperforms strong baselines across languages and\\ndatasets. For English, it achieves a 4.9 F1 point improvement over the\\nstate-of-the-art on GraphQuestions. Our code and data can be downloaded at\\nthis https URL.\\n',\n",
       " '  This paper considers online convex optimization with time-varying constraint\\nfunctions. Specifically, we have a sequence of convex objective functions\\n$\\\\{f_t(x)\\\\}_{t=0}^{\\\\infty}$ and convex constraint functions\\n$\\\\{g_{t,i}(x)\\\\}_{t=0}^{\\\\infty}$ for $i \\\\in \\\\{1, ..., k\\\\}$. The functions are\\ngradually revealed over time. For a given $\\\\epsilon>0$, the goal is to choose\\npoints $x_t$ every step $t$, without knowing the $f_t$ and $g_{t,i}$ functions\\non that step, to achieve a time average at most $\\\\epsilon$ worse than the best\\nfixed-decision that could be chosen with hindsight, subject to the time average\\nof the constraint functions being nonpositive. It is known that this goal is\\ngenerally impossible. This paper develops an online algorithm that solves the\\nproblem with $O(1/\\\\epsilon^2)$ convergence time in the special case when all\\nconstraint functions are nonpositive over a common subset of $\\\\mathbb{R}^n$.\\nSimilar performance is shown in an expected sense when the common subset\\nassumption is removed but the constraint functions are assumed to vary\\naccording to a random process that is independent and identically distributed\\n(i.i.d.) over time slots $t \\\\in \\\\{0, 1, 2, \\\\ldots\\\\}$. Finally, in the special\\ncase when both the constraint and objective functions are i.i.d. over time\\nslots $t$, the algorithm is shown to come within $\\\\epsilon$ of optimality with\\nrespect to the best (possibly time-varying) causal policy that knows the full\\nprobability distribution.\\n',\n",
       " '  Image classification datasets are often imbalanced, characteristic that\\nnegatively affects the accuracy of deep-learning classifiers. In this work we\\npropose balancing GAN (BAGAN) as an augmentation tool to restore balance in\\nimbalanced datasets. This is challenging because the few minority-class images\\nmay not be enough to train a GAN. We overcome this issue by including during\\nthe adversarial training all available images of majority and minority classes.\\nThe generative model learns useful features from majority classes and uses\\nthese to generate images for minority classes. We apply class conditioning in\\nthe latent space to drive the generation process towards a target class. The\\ngenerator in the GAN is initialized with the encoder module of an autoencoder\\nthat enables us to learn an accurate class-conditioning in the latent space. We\\ncompare the proposed methodology with state-of-the-art GANs and demonstrate\\nthat BAGAN generates images of superior quality when trained with an imbalanced\\ndataset.\\n',\n",
       " '  Non-invasive magnetic field sensing using optically - detected magnetic\\nresonance of nitrogen-vacancy (NV) centers in diamond was used to study spatial\\ndistribution of the magnetic induction upon penetration and expulsion of weak\\nmagnetic fields in several representative superconductors. Vector magnetic\\nfields were measured on the surface of conventional, Pb and Nb, and\\nunconventional, LuNi$_2$B$_2$C, Ba$_{0.6}$K$_{0.4}$Fe$_2$As$_2$,\\nBa(Fe$_{0.93}$Co$_{0.07}$)$_2$As$_2$, and CaKFe$_4$As$_4$, superconductors,\\nwith diffraction - limited spatial resolution using variable - temperature\\nconfocal system. Magnetic induction profiles across the crystal edges were\\nmeasured in zero-field-cooled (ZFC) and field-cooled (FC) conditions. While all\\nsuperconductors show nearly perfect screening of magnetic fields applied after\\ncooling to temperatures well below the superconducting transition, $T_c$, a\\nrange of very different behaviors was observed for Meissner expulsion upon\\ncooling in static magnetic field from above $T_c$. Substantial conventional\\nMeissner expulsion is found in LuNi$_2$B$_2$C, paramagnetic Meissner effect\\n(PME) is found in Nb, and virtually no expulsion is observed in iron-based\\nsuperconductors. In all cases, good correlation with macroscopic measurements\\nof total magnetic moment is found. Our measurements of the spatial distribution\\nof magnetic induction provide insight into microscopic physics of the Meissner\\neffect.\\n',\n",
       " \"  In a standard cluster analysis, such as k-means, in addition to clusters\\nlocations and distances between them, it's important to know if they are\\nconnected or well separated from each other. The main focus of this paper is\\ndiscovering the relations between the resulting clusters. We propose a new\\nmethod which is based on pairwise overlapping k-means clustering, that in\\naddition to means of clusters provides the graph structure of their relations.\\nThe proposed method has a set of parameters that can be tuned in order to\\ncontrol the sensitivity of the model and the desired relative size of the\\npairwise overlapping interval between means of two adjacent clusters, i.e.,\\nlevel of overlapping. We present the exact formula for calculating that\\nparameter. The empirical study presented in the paper demonstrates that our\\napproach works well not only on toy data but also compliments standard\\nclustering results with a reasonable graph structure on real datasets, such as\\nfinancial indices and restaurants.\\n\",\n",
       " \"  Differences between men and women have intrigued generations of social\\nscientists, who have found that the two sexes behave differently in settings\\nrequiring competition, risk taking, altruism, honesty, as well as many others.\\nYet, little is known about whether there are gender differences in cooperative\\nbehavior. Previous evidence is mixed and inconclusive. Here I shed light on\\nthis topic by analyzing the totality of studies that my research group has\\nconducted since 2013. This is a dataset of 10,951 observations coming from\\n7,322 men and women living in the US, recruited through Amazon Mechanical Turk,\\nand who passed four comprehension questions to make sure they understand the\\ncooperation problem (a one-shot prisoner's dilemma). The analysis demonstrates\\nthat women are more cooperative than men. The effect size is small (about 4\\npercentage points, and this might explain why previous studies failed to detect\\nit) but highly significant (p<.0001).\\n\",\n",
       " '  On an asymptotically flat manifold $M^n$ with nonnegative scalar curvature,\\nwith outer minimizing boundary $\\\\Sigma$, we prove a Penrose-like inequality in\\ndimensions $ n < 8$, under suitable assumptions on the mean curvature and the\\nscalar curvature of $ \\\\Sigma$.\\n',\n",
       " '  We give results and observations which allow the application of the\\nlogarithmic tensor category theory of Lepowsky, Zhang and the author\\n([HLZ1]--[HLZ9]) to more general vertex (operator) algebras and their module\\ncategories than those studied in a paper by the author ([H3]).\\n',\n",
       " '  How big is the risk that a few initial failures of nodes in a network amplify\\nto large cascades that span a substantial share of all nodes? Predicting the\\nfinal cascade size is critical to ensure the functioning of a system as a\\nwhole. Yet, this task is hampered by uncertain or changing parameters and\\nmissing information. In infinitely large networks, the average cascade size can\\noften be well estimated by established approaches building on local tree\\napproximations and mean field approximations. Yet, as we demonstrate, in finite\\nnetworks, this average does not even need to be a likely outcome. Instead, we\\nfind broad and even bimodal cascade size distributions. This phenomenon\\npersists for system sizes up to $10^{7}$ and different cascade models, i.e. it\\nis relevant for most real systems. To show this, we derive explicit closed-form\\nsolutions for the full probability distribution of the final cascade size. We\\nfocus on two topological limit cases, the complete network representing a dense\\nnetwork with a very narrow degree distribution, and the star network\\nrepresenting a sparse network with a inhomogeneous degree distribution. Those\\ntopologies are of great interest, as they either minimize or maximize the\\naverage cascade size and are common motifs in many real world networks.\\n',\n",
       " '  In this paper, we study the cooperative robust output regulation problem for\\ndiscrete-time linear multi-agent systems with both communication and input\\ndelays by distributed internal model approach. We first introduce the\\ndistributed internal model for discrete-time multi-agent systems with both\\ncommunication and input delays. Then, we define so-called auxiliary system and\\nauxiliary augmented system. Finally, we solve our problem by showing, under\\nsome standard assumptions, that if a distributed state feedback control or a\\ndistributed output feedback control solves the robust output regulation problem\\nof the auxiliary system, then the same control law solves the cooperative\\nrobust output regulation problem of the original multi-agent systems.\\n',\n",
       " '  We introduce the Dense Basis method for Spectral Energy Distribution (SED)\\nfitting. It accurately recovers traditional SED parameters, including M$_*$,\\nSFR and dust attenuation, and reveals previously inaccessible information about\\nthe number and duration of star formation episodes and the timing of stellar\\nmass assembly, as well as uncertainties in these quantities. This is done using\\nbasis Star Formation Histories (SFHs) chosen by comparing the goodness-of-fit\\nof mock galaxy SEDs to the goodness-of-reconstruction of their SFHs. We train\\nand validate the method using a sample of realistic SFHs at $z =1$ drawn from\\nstochastic realisations, semi-analytic models, and a cosmological\\nhydrodynamical galaxy formation simulation. The method is then applied to a\\nsample of 1100 CANDELS GOODS-S galaxies at $1<z<1.5$ to illustrate its\\ncapabilities at moderate S/N with 15 photometric bands. Of the six\\nparametrizations of SFHs considered, we adopt linear-exponential,\\nbessel-exponential, lognormal and gaussian SFHs and reject the traditional\\nparametrizations of constant (Top-Hat) and exponential SFHs. We quantify the\\nbias and scatter of each parametrization. $15\\\\%$ of galaxies in our CANDELS\\nsample exhibit multiple episodes of star formation, with this fraction\\ndecreasing above $M_*>10^{9.5}M_\\\\odot$. About $40\\\\%$ of the CANDELS galaxies\\nhave SFHs whose maximum occurs at or near the epoch of observation. The Dense\\nBasis method is scalable and offers a general approach to a broad class of\\ndata-science problems.\\n',\n",
       " '  Attractive Bose-Einstein condensates can host two types of macroscopic\\nself-bound states of different nature: bright solitons and quantum liquid\\ndroplets. Here, we investigate the connection between them with a Bose-Bose\\nmixture confined in an optical waveguide. We develop a simple theoretical model\\nto show that, depending on atom number and interaction strength, solitons and\\ndroplets can be smoothly connected or remain distinct states coexisting only in\\na bi-stable region. We experimentally measure their spin composition, extract\\ntheir density for a broad range of parameters and map out the boundary of the\\nregion separating solitons from droplets.\\n',\n",
       " '  We consider the composition optimization with two expected-value functions in\\nthe form of $\\\\frac{1}{n}\\\\sum\\\\nolimits_{i = 1}^n F_i(\\\\frac{1}{m}\\\\sum\\\\nolimits_{j\\n= 1}^m G_j(x))+R(x)$, { which formulates many important problems in statistical\\nlearning and machine learning such as solving Bellman equations in\\nreinforcement learning and nonlinear embedding}. Full Gradient or classical\\nstochastic gradient descent based optimization algorithms are unsuitable or\\ncomputationally expensive to solve this problem due to the inner expectation\\n$\\\\frac{1}{m}\\\\sum\\\\nolimits_{j = 1}^m G_j(x)$. We propose a duality-free based\\nstochastic composition method that combines variance reduction methods to\\naddress the stochastic composition problem. We apply SVRG and SAGA based\\nmethods to estimate the inner function, and duality-free method to estimate the\\nouter function. We prove the linear convergence rate not only for the convex\\ncomposition problem, but also for the case that the individual outer functions\\nare non-convex while the objective function is strongly-convex. We also provide\\nthe results of experiments that show the effectiveness of our proposed methods.\\n',\n",
       " '  We show time hierarchies for reasonable semantic classes without advice by\\neliminating the constant bits of advice in previous results.The elimination is\\ndone by a contrapositive argument that for any reasonable computational\\nmodel,let $\\\\text{CTIME}(f(n))/{g(n)}$ denote the set of all languages decide by\\nmachines running in time $O(f(n))$ with advice of $g(n)$ bits in that model, if\\n$\\\\text{CTIME}(t(n))\\\\subseteq \\\\text{CTIME}(T(n))/{A(n)}$ then\\n$\\\\text{CTIME}(t(n))/a \\\\subseteq \\\\text{CTIME}(T(n))/{a+2^aA(n)}$ where $a$ is a\\nconstant integer.\\n',\n",
       " \"  When a robot is operating in a dynamic environment, it cannot be assumed that\\na tool required to solve a given task will always be available. In case of a\\nmissing tool, an ideal response would be to find a substitute to complete the\\ntask. In this paper, we present a proof of concept of a grounded\\nknowledge-based approach to tool substitution. In order to validate the\\nsuitability of a substitute, we conducted experiments involving 22 substitution\\nscenarios. The substitutes computed by the proposed approach were validated on\\nthe basis of the experts' choices for each scenario. Our evaluation showed, in\\n20 out of 22 scenarios (91%), the approach identified the same substitutes as\\nexperts.\\n\",\n",
       " '  We present a simple analysis of the design of a passive miniature resonant\\noptical gyroscope. By combining the requirements on the angular random walk and\\nthe bias stability, we end up with simple expressions of the minimum diameter\\nof the ring waveguide cavity and the maximum power that should be used to probe\\nit. Using state-of-the-art performances of photonic integrated circuit and\\nwhispering gallery mode technologies in terms of propagation losses and mode\\nsize, we show that tactical grade gyroscope performances can be achieved with a\\ndiameter of a few cm provided the detrimental influence of Kerr effect is\\nmitigated, using for instance an active control of the unbalance in the\\nintensities. We further extend the analysis to medium performance gyroscope and\\ngive some hints on the efforts to be made to potentially demonstrate a\\nminiature resonant optical gyroscope with this level of performance.\\n',\n",
       " '  Optimal and Learning Control for Autonomous Robots has been taught in the\\nRobotics, Systems and Controls Masters at ETH Zurich with the aim to teach\\noptimal control and reinforcement learning for closed loop control problems\\nfrom a unified point of view. The starting point is the formulation of of an\\noptimal control problem and deriving the different types of solutions and\\nalgorithms from there. These lecture notes aim at supporting this unified view\\nwith a unified notation wherever possible, and a bit of a translation help to\\ncompare the terminology and notation in the different fields. The course\\nassumes basic knowledge of Control Theory, Linear Algebra and Stochastic\\nCalculus.\\n',\n",
       " '  We show that a jammed packing of disks with generic radii, in a generic\\ncontainer, is such that the minimal number of contacts occurs and there is only\\none dimension of equilibrium stresses. We also point out some connections to\\npackings with different radii and results in the theory of circle packings\\nwhose graph forms a triangulation of a given topological surface. We also point\\nout a counterexample, due to F. Nazarov, to a previous conjecture that that\\ntriangulated packings with fixed numbers of disks with fixed numbers of disks\\nfor each radius claiming that such packings were the most dense.\\n',\n",
       " '  An important application of intelligent vehicles is advance detection of\\ndangerous events such as collisions. This problem is framed as a problem of\\noptimal alarm choice given predictive models for vehicle location and motion.\\nTechniques for real-time collision detection are surveyed and grouped into\\nthree classes: random Monte Carlo sampling, faster deterministic\\napproximations, and machine learning models trained by simulation. Theoretical\\nguarantees on the performance of these collision detection techniques are\\nprovided where possible, and empirical analysis is provided for two example\\nscenarios. Results validate Monte Carlo sampling as a robust solution despite\\nits simplicity.\\n',\n",
       " '  DeConvNet, Guided BackProp, LRP, were invented to better understand deep\\nneural networks. We show that these methods do not produce the theoretically\\ncorrect explanation for a linear model. Yet they are used on multi-layer\\nnetworks with millions of parameters. This is a cause for concern since linear\\nmodels are simple neural networks. We argue that explanation methods for neural\\nnets should work reliably in the limit of simplicity, the linear models. Based\\non our analysis of linear models we propose a generalization that yields two\\nexplanation techniques (PatternNet and PatternAttribution) that are\\ntheoretically sound for linear models and produce improved explanations for\\ndeep networks.\\n',\n",
       " '  In this paper we study the behaviour of the Neumann data of Dirichlet\\neigenfunctions on simplices. We prove that the $L^2$ norm of the\\n(semi-classical) Neumann data on each face is equal to $2/n$ times the\\n$(n-1)$-dimensional volume of the face divided by the volume of the simplex.\\nThis is a generalization of \\\\cite{Chr-tri} to higher dimensions. Again it is\\n{\\\\it not} an asymptotic, but an exact formula. The proof is by simple\\nintegrations by parts and linear algebra.\\nWe also consider the following inverse problem: do the {\\\\it norms} of the\\nNeumann data on a simplex determine a constant coefficient elliptic operator?\\nThe answer is yes in dimension 2 and no in higher dimensions.\\n',\n",
       " '  Motivated by theoretical expectations that Nuclear Star Clusters (NSCs) in\\ngalactic centers may provide a favorable environment for super-massive black\\nholes to form and/or efficiently grow, we set out to measure the fraction of\\nnearby nucleated galaxies that also host an Active Galactic Nucleus (AGN). We\\ntargeted a distance-limited sample of 98 objects with the Chandra X-ray\\nTelescope, down to a uniform X-ray luminosity threshold of $\\\\sim$10$^{38}$ erg\\ns$^{-1}$. The sample is composed of 47 late-types and 51 early-types, enabling\\nus to further investigate the active fraction as a function of galactic\\nmorphology. After correcting for contamination to the nuclear X-ray signal from\\nbright X-ray binaries, we measure an active fraction $f$=11.2$\\\\%^{+7.4}_{-4.9}$\\n(1$\\\\sigma$ C.L.) across the whole sample, in agreement with previous estimates\\nbased on an heterogeneous combination of optical, X-ray and radio diagnostics,\\nby Seth et al. (2008). After accounting for the different stellar mass\\ndistributions in our samples, we find no statistically significant difference\\nin the active fraction of early- vs. late-type nucleated galaxies, with\\n$f$=10.6$\\\\%^{+11.9}_{-4.9}$ and 10.8$\\\\%^{+11.3}_{-6.3}$, respectively. For the\\nearly-type nucleated galaxies, we are able to carry out a controlled comparison\\nwith a parent sample of non-nucleated galaxies covering the same stellar mass\\nrange, finding again no statistically significant difference in the active\\nfraction. Taken at face value, our findings suggest that the presence of a NSC\\ndoes not facilitate nor enhance accretion-powered emission from a nuclear\\nsuper-massive black hole. This is true even for late-type nucleated galaxies,\\nhome to bluer NSCs and arguably larger gas reservoirs.\\n',\n",
       " '  Two integrable $U(1)$-invariant peakon equations are derived from the NLS\\nhierarchy through the tri-Hamiltonian splitting method. A Lax pair, a recursion\\noperator, a bi-Hamiltonian formulation, and a hierarchy of symmetries and\\nconservation laws are obtained for both peakon equations. These equations are\\nalso shown to arise as potential flows in the NLS hierarchy by applying the NLS\\nrecursion operator to flows generated by space translations and $U(1)$-phase\\nrotations on a potential variable. Solutions for both equations are derived\\nusing a peakon ansatz combined with an oscillatory temporal phase. This yields\\nthe first known example of a peakon breather. Spatially periodic counterparts\\nof these solutions are also obtained.\\n',\n",
       " \"  This paper presents a quantitative study of the evolution of the ejecta cloud\\nreleased from a hypervelocity impact on a binary asteroid. We performed\\nnumerical simulations of the post-impact dynamics of the ejecta cloud in the\\nframework of the current mission scenario of AIDA mission project. A grid\\nsearch of launching sites of ejecta was defined over the globe of Didymoon, and\\nconsidering a wide range of possible ejection speeds, we determined the\\ndependency of ejecta fate on launching sites (projectile impact sites) and\\nspeeds. This range allows us to track all the complex cases that include\\ndifferent types of dynamical fates. Two major mechanisms are found to be\\nworking broadly during the post-ejection evolution of the ejecta cloud: 1)\\nejecta on mean motion resonance orbits with Didymoon produce long-term\\nquasi-periodic showers onto Didymoon over at least a couple of weeks after the\\nprojectile impact, 2) ejecta on non-resonant orbits produce a rapid and high\\nre-accretion flux. This rapid and high flux occurs just once because ejecta on\\nsuch orbits leave the system unless they experience a collision during their\\nfirst encounter. For the second part of this study, we performed full-scale\\nsimulations of the ejecta cloud released from 6 hypothetical impact sites. We\\nconsidered two kinds of material composing Didymoon's subsurface and then\\ncombined a power-law size distribution of the ejecta with an ejection speed\\ndistribution. We find that the ejecta cloud evolution can be divided in two\\nperiods. It starts with a first violent period (<10 hr) with fast re-accretion\\nor ejection from the system. A second period is found to be more sensitive to\\nthe launching site than the first one. During this second period, ejecta will\\neither re-accrete or being ejected from the system, depending both on their\\nsizes and on their average survival time in close proximity of the binary\\ncomponents.\\n\",\n",
       " '  Since the mid-1920s, different strands of research used stars as \"physics\\nlaboratories\" for investigating the nature of matter under extreme densities\\nand pressures, impossible to realize on Earth. To trace this process this paper\\nis following the evolution of the concept of a dense core in stars, which was\\nimportant both for an understanding of stellar evolution and as a testing\\nground for the fast-evolving field of nuclear physics. In spite of the divide\\nbetween physicists and astrophysicists, some key actors working in the\\ncross-fertilized soil of overlapping but different scientific cultures\\nformulated models and tentative theories that gradually evolved into more\\nrealistic and structured astrophysical objects. These investigations culminated\\nin the first contact with general relativity in 1939, when J. Robert\\nOppenheimer and his students George Volkoff and Hartland Snyder systematically\\napplied the theory to the dense core of a collapsing neutron star. This\\npioneering application of Einstein\\'s theory to an astrophysical compact object\\ncan be regarded as a milestone in the path eventually leading to the emergence\\nof relativistic astrophysics in the early 1960s.\\n',\n",
       " '  In this paper, we consider the usual linear regression model in the case\\nwhere the error process is assumed strictly stationary. We use a result from\\nHannan, who proved a Central Limit Theorem for the usual least square estimator\\nunder general conditions on the design and on the error process. We show that\\nfor a large class of designs, the asymptotic covariance matrix is as simple as\\nthe i.i.d. case. We then estimate the covariance matrix using an estimator of\\nthe spectral density whose consistency is proved under very mild conditions. As\\nan application, we show how to modify the usual Fisher tests in this dependent\\ncontext, in such a way that the type-$I$ error rate remains asymptotically\\ncorrect, and we illustrate the performance of this procedure through different\\nsets of simulations.\\n',\n",
       " '  THz radiation promises breakthrough advances in compact advanced accelerators\\ndue to the high frequency and GV/m fields achievable, orders of magnitude\\nlarger than in conventional radiofrequency (RF) based accelerators. Compared to\\nlaser-driven schemes, the large phase acceptances of THz-driven accelerators\\nare advantageous for operation with sizable charge. Despite burgeoning\\nresearch, THz sources, particularly laser-based ones, cannot yet compete with\\nthe efficiency of RF amplifiers for high average current accelerators.\\nNevertheless, THz-based phase space manipulation is of immediate interest for a\\nvariety of applications, including generation and diagnostics of ultrashort\\nbunches for electron diffraction/microscopy and compact free-electron laser\\napplications.\\nThe challenge of maintaining overlap and synchronism between an electron beam\\nand short laser-generated THz pulse has so far limited interactions to the few\\nmm scale. We discuss a novel scheme for simultaneous group and phase velocity\\nmatching of nearly single-cycle THz radiation with a relativistic electron beam\\nfor meter-scale interaction. We demonstrate energy modulations of up to 150 keV\\nusing modest THz pulse energies (up to 1 uJ). We apply this large and efficient\\nenergy exchange for beam compression and time-stamping of a relativistic beam,\\npaving the way towards realizing the unique opportunities enabled by\\nlaser-based THz accelerators.\\n',\n",
       " \"  The paper presents an investigation of estimating treatment effect using\\ndifferent matching methods. The study proposed a new method which is\\ncomputationally efficient and convenient in implication-'largest caliper\\nmatching' and compared the performance with other five popular matching methods\\nby simulation. The bias, empirical standard deviation and the mean square error\\nof the estimates in the simulation are checked under different treatment\\nprevalence and different distributions of covariates. A Monte Carlo simulation\\nstudy and a real data example are employed to measure the performance of these\\nmethods. It is shown that matched samples improve estimation of the population\\ntreatment effect in a wide range of settings. It reduces the bias if the data\\ncontains the selection on observables and treatment imbalances. Also, findings\\nabout the relative performance of the different matching methods are provided\\nto help practitioners determine which method should be used under certain\\nsituations.\\n\",\n",
       " '  The usual main objection against any attempt in finding a physical cause for\\nthe planet distance distribution is based on the assumption that similar\\ndistance distribution could be obtained by sequences of random numbers. This\\nassumption was stated by Lecar in an old paper (1973). We show here how this\\nassumption is incorrect and how his visual comparison method is inappropriate.\\n',\n",
       " '  Time-resolved angiography with interleaved stochastic trajectories (TWIST)\\nhas been widely used for dynamic contrast enhanced MRI (DCE-MRI). To achieve\\nhighly accelerated acquisitions, TWIST combines the periphery of the k-space\\ndata from several adjacent frames to reconstruct one temporal frame. However,\\nthis view-sharing scheme limits the true temporal resolution of TWIST.\\nMoreover, the k-space sampling patterns have been specially designed for a\\nspecific generalized autocalibrating partial parallel acquisition (GRAPPA)\\nfactor so that it is not possible to reduce the number of view-sharing once the\\nk-data is acquired. To address these issues, this paper proposes a novel\\nk-space deep learning approach for parallel MRI. In particular, we have\\ndesigned our neural network so that accurate k-space interpolations are\\nperformed simultaneously for multiple coils by exploiting the redundancies\\nalong the coils and images. Reconstruction results using in vivo TWIST data set\\nconfirm that the proposed method can immediately generate high-quality\\nreconstruction results with various choices of view- sharing, allowing us to\\nexploit the trade-off between spatial and temporal resolution in time-resolved\\nMR angiography.\\n',\n",
       " '  The theoretical proposal of chiral fermions in topological semimetals has led\\nto a significant effort towards their experimental realization. In particular,\\nthe Fermi surfaces of chiral semimetals carry quantized Chern numbers, making\\nthem an attractive platform for the observation of exotic transport and optical\\nphenomena. While the simplest example of a chiral fermion in condensed matter\\nis a conventional $|C|=1$ Weyl fermion, recent theoretical works have proposed\\na number of unconventional chiral fermions beyond the Standard Model which are\\nprotected by unique combinations of topology and crystalline symmetries.\\nHowever, materials candidates for experimentally probing the transport and\\nresponse signatures of these unconventional fermions have thus far remained\\nelusive. In this paper, we propose the RhSi family in space group (SG) $\\\\#$198\\nas the ideal platform for the experimental examination of unconventional chiral\\nfermions. We find that RhSi is a filling-enforced semimetal that features near\\nits Fermi surface a chiral double six-fold-degenerate spin-1 Weyl node at $R$\\nand a previously uncharacterized four-fold-degenerate chiral fermion at\\n$\\\\Gamma$. Each unconventional fermion displays Chern number $\\\\pm4$ at the Fermi\\nlevel. We also show that RhSi displays the largest possible momentum separation\\nof compensative chiral fermions, the largest proposed topologically nontrivial\\nenergy window, and the longest possible Fermi arcs on its surface. We conclude\\nby proposing signatures of an exotic bulk photogalvanic response in RhSi.\\n',\n",
       " '  In this paper we prove the following. Let $\\\\Sigma$ be an $n$--dimensional\\nclosed hyperbolic manifold and let $g$ be a Riemannian metric on $\\\\Sigma \\\\times\\n\\\\mathbb{S}^1$. Given an upper bound on the volumes of unit balls in the\\nRiemannian universal cover $(\\\\widetilde{\\\\Sigma\\\\times\\n\\\\mathbb{S}^1},\\\\widetilde{g})$, we get a lower bound on the area of the\\n$\\\\mathbb{Z}_2$--homology class $[\\\\Sigma \\\\times \\\\ast]$ on $\\\\Sigma \\\\times\\n\\\\mathbb{S}^1$, proportional to the hyperbolic area of $\\\\Sigma$. The theorem is\\nbased on a theorem of Guth and is analogous to a theorem of Kronheimer and\\nMrowka involving scalar curvature.\\n',\n",
       " '  We use a stochastic birth-death model for a population of cells to estimate\\nthe normal tissue complication probability (NTCP) under a particular\\nradiotherapy protocol. We specifically allow for interaction between cells, via\\na nonlinear logistic growth model. To capture some of the effects of intrinsic\\nnoise in the population we develop several approximations of NTCP, using\\nKramers-Moyal expansion techniques. These approaches provide an approximation\\nto the first and second moments of a general first-passage time problem in the\\nlimit of large, but finite populations. We use this method to study NTCP in a\\nsimple model of normal cells and in a model of normal and damaged cells. We\\nalso study a combined model of normal tissue cells and tumour cells. Based on\\nexisting methods to calculate tumour control probabilities, and our procedure\\nto approximate NTCP, we estimate the probability of complication free tumour\\ncontrol.\\n',\n",
       " '  Three new infrared bands of the weakly-bound He-OCS complex are studied,\\nusing tunable lasers to probe a pulsed supersonic slit jet expansion. They\\ncorrespond to the (0400) <-- (0000), (1001)<-- (0000), and (0401) <-- (0000)\\ntransitions of OCS at 2105, 2918, and 2937 cm-1, respectively. The latter band\\nis about 7900 times weaker than the previously studied OCS nu1 fundamental.\\nVibrational shifts relative to the free OCS monomer are found to be additive.\\nSince carbonyl sulfide has previously been shown to be a valuable probe of\\nsuperfluid quantum solvation effects in helium clusters and droplets, the\\npresent results could be useful for future studies of vibrational effects in\\nsuch systems.\\n',\n",
       " '  Polarimetric observations of celestial sources in the hard X-ray band stand\\nto provide new information on emission mechanisms and source geometries. PoGO+\\nis a Compton scattering polarimeter (20-150 keV) optimised for the observation\\nof the Crab (pulsar and wind nebula) and Cygnus X-1 (black hole binary), from a\\nstratospheric balloon-borne platform launched from the Esrange Space Centre in\\nsummer 2016. Prior to flight, the response of the polarimeter has been studied\\nwith polarised and unpolarised X-rays allowing a Geant4-based simulation model\\nto be validated. The expected modulation factor for Crab observations is found\\nto be $M_{\\\\mathrm{Crab}}=(41.75\\\\pm0.85)\\\\%$, resulting in an expected Minimum\\nDetectable Polarisation (MDP) of $7.3\\\\%$ for a 7 day flight. This will allow a\\nmeasurement of the Crab polarisation parameters with at least $5\\\\sigma$\\nstatistical significance assuming a polarisation fraction $\\\\sim20\\\\%$ $-$ a\\nsignificant improvement over the PoGOLite Pathfinder mission which flew in 2013\\nand from which the PoGO+ design is developed.\\n',\n",
       " '  Esports has emerged as a popular genre for players as well as spectators,\\nsupporting a global entertainment industry. Esports analytics has evolved to\\naddress the requirement for data-driven feedback, and is focused on\\ncyber-athlete evaluation, strategy and prediction. Towards the latter, previous\\nwork has used match data from a variety of player ranks from hobbyist to\\nprofessional players. However, professional players have been shown to behave\\ndifferently than lower ranked players. Given the comparatively limited supply\\nof professional data, a key question is thus whether mixed-rank match datasets\\ncan be used to create data-driven models which predict winners in professional\\nmatches and provide a simple in-game statistic for viewers and broadcasters.\\nHere we show that, although there is a slightly reduced accuracy, mixed-rank\\ndatasets can be used to predict the outcome of professional matches, with\\nsuitably optimized configurations.\\n',\n",
       " '  Universal characteristics of road networks and traffic patterns can help to\\nforecast and control traffic congestion. The antipersistence of traffic flow\\ntime series has been found for many data sets, but its relevance for congestion\\nhas been overseen. Based on empirical data from motorways in Germany, we study\\nhow antipersistence of traffic flow time-series impacts the duration of traffic\\ncongestion on a wide range of time scales. We find a large number of short\\nlasting traffic jams, which implies a large risk for rear-end collisions.\\n',\n",
       " '  Fast radio bursts are astronomical radio flashes of unknown physical nature\\nwith durations of milliseconds. Their dispersive arrival times suggest an\\nextragalactic origin and imply radio luminosities orders of magnitude larger\\nthan any other kind of known short-duration radio transient. Thus far, all FRBs\\nhave been detected with large single-dish telescopes with arcminute\\nlocalizations, and attempts to identify their counterparts (source or host\\ngalaxy) have relied on contemporaneous variability of field sources or the\\npresence of peculiar field stars or galaxies. These attempts have not resulted\\nin an unambiguous association with a host or multi-wavelength counterpart. Here\\nwe report the sub-arcsecond localization of FRB 121102, the only known\\nrepeating burst source, using high-time-resolution radio interferometric\\nobservations that directly image the bursts themselves. Our precise\\nlocalization reveals that FRB 121102 originates within 100 mas of a faint 180\\nuJy persistent radio source with a continuum spectrum that is consistent with\\nnon-thermal emission, and a faint (25th magnitude) optical counterpart. The\\nflux density of the persistent radio source varies by tens of percent on day\\ntimescales, and very long baseline radio interferometry yields an angular size\\nless than 1.7 mas. Our observations are inconsistent with the fast radio burst\\nhaving a Galactic origin or its source being located within a prominent\\nstar-forming galaxy. Instead, the source appears to be co-located with a\\nlow-luminosity active galactic nucleus or a previously unknown type of\\nextragalactic source. [Truncated] If other fast radio bursts have similarly\\nfaint radio and optical counterparts, our findings imply that direct\\nsub-arcsecond localizations of FRBs may be the only way to provide reliable\\nassociations.\\n',\n",
       " '  We design a non-commutative version of the Peterson-Gorenstein-Zierler\\ndecoding algorithm for a class of codes that we call skew RS codes. These codes\\nare left ideals of a quotient of a skew polynomial ring, which endow them of a\\nsort of non-commutative cyclic structure. Since we work over an arbitrary\\nfield, our techniques may be applied both to linear block codes and\\nconvolutional codes. In particular, our decoding algorithm applies for block\\ncodes beyond the classical cyclic case.\\n',\n",
       " '  A multivariable measurement error model $AX \\\\approx B$ is considered. Here\\n$A$ and $B$ are input and output matrices of measurements and $X$ is a\\nrectangular matrix of fixed size to be estimated. The errors in $[A,B]$ are\\nrow-wise independent, but within each row the errors may be correlated. Some of\\nthe columns are observed without errors and the error covariance matrices may\\ndiffer from row to row. The total covariance structure of the errors is known\\nup to a scalar factor. The fully weighted total least squares estimator of $X$\\nis studied. We give conditions for asymptotic normality of the estimator, as\\nthe number of rows in $A$ is increasing. We provide that the covariance\\nstructure of the limiting Gaussian random matrix is nonsingular.\\n',\n",
       " '  The recovery of structured signals from a few linear measurements is a\\ncentral point in both compressed sensing (CS) and discrete tomography. In CS\\nthe signal structure is described by means of a low complexity model e.g.\\nco-/sparsity. The CS theory shows that any signal/image can be undersampled at\\na rate dependent on its intrinsic complexity. Moreover, in such undersampling\\nregimes, the signal can be recovered by sparsity promoting convex\\nregularization like $\\\\ell_1$- or total variation (TV-) minimization. Precise\\nrelations between many low complexity measures and the sufficient number of\\nrandom measurements are known for many sparsity promoting norms. However, a\\nprecise estimate of the undersampling rate for the TV seminorm is still\\nlacking. We address this issue by: a) providing dual certificates testing\\nuniqueness of a given cosparse signal with bounded signal values, b)\\napproximating the undersampling rates via the statistical dimension of the TV\\ndescent cone and c) showing empirically that the provided rates also hold for\\ntomographic measurements.\\n',\n",
       " '  The paper proposes an on-line monitoring framework for continuous real-time\\nsafety/security in learning-based control systems (specifically application to\\na unmanned ground vehicle). We monitor validity of mappings from sensor inputs\\nto actuator commands, controller-focused anomaly detection (CFAM), and from\\nactuator commands to sensor inputs, system-focused anomaly detection (SFAM).\\nCFAM is an image conditioned energy based generative adversarial network\\n(EBGAN) in which the energy based discriminator distinguishes between proper\\nand anomalous actuator commands. SFAM is based on an action condition video\\nprediction framework to detect anomalies between predicted and observed\\ntemporal evolution of sensor data. We demonstrate the effectiveness of the\\napproach on our autonomous ground vehicle for indoor environments and on\\nUdacity dataset for outdoor environments.\\n',\n",
       " '  We investigate the effects of the in-plane biaxial strain and charge doping\\non the charge density wave (CDW) order of monolayer $1T$-TiSe$_2$ by using the\\nfirst-principles calculations. Our results show that the tensile strain can\\nsignificantly enhance the CDW order, while both compressive strain and charge\\ndoping (electrons and holes) suppress the CDW instability. The tensile strain\\nmay provide an effective method for obtaining higher CDW transition temperature\\non the basis of monolayer $1T$-TiSe$_2$. We also discuss the potential\\nsuperconductivity in charge-doped monolayer $1T$-TiSe$_2$. Controllable\\nelectronic phase transition from CDW state to metallic state or even\\nsuperconducting state can be realized in monolayer $1T$-TiSe$_2$, which makes\\n$1T$-TiSe$_2$ possess a promising application in controllable switching\\nelectronic devices based on CDW.\\n',\n",
       " '  A suitable piece of software is presented to connect Abaqus, a sophisticated\\nfinite element package, with Matlab, the most comprehensive program for\\nmathematical analysis. This interface between these well-known codes not only\\nbenefits from the image processing and the integrated graph-plotting features\\nof Matlab but also opens up new opportunities in results post-processing,\\nstatistical analysis and mathematical optimization, among many other\\npossibilities. The software architecture and usage are appropriately described\\nand two problems of particular engineering significance are addressed to\\ndemonstrate its capabilities. Firstly, the software is employed to assess\\ncleavage fracture through a novel 3-parameter Weibull probabilistic framework.\\nThen, its potential to create and train neural networks is used to identify\\ndamage parameters through a hybrid experimental-numerical scheme, and model\\ncrack propagation in structural materials by means of a cohesive zone approach.\\nThe source code, detailed documentation and a large number of tutorials can be\\nfreely downloaded from www.abaqus2matlab.com.\\n',\n",
       " '  The spin Hall effect (SHE), which converts a charge current into a transverse\\nspin current, has long been believed to be a phenomenon induced by the\\nspin--orbit coupling. Here, we propose an alternative mechanism to realize the\\nintrinsic SHE through a chiral magnetic structure that breaks the spin rotation\\nsymmetry. No spin--orbit coupling is needed even when the scalar spin chirality\\nvanishes, different from the case of the topological Hall effect. In known\\nchiral antiferromagnetic compounds Mn$_3X$ ($X=$ Ga, Ge, and Sn), for example,\\nwe indeed obtain large spin Hall conductivities based on \\\\textit{ab initio}\\ncalculations. Apart further developing the conceptual understanding of the SHE,\\nour work suggests an alternative strategy to design spin Hall materials without\\ninvolving heavy elements, which may be advantageous for technological\\napplications.\\n',\n",
       " '  Motivated by the forensic problem of determining the strength of evidence of\\na continuously distributed measurement of evidence, in the situation of\\ncomposite hypotheses of the prosecutor and the defence concerning a parameter\\nof a parametric model, we consider empirical Bayes methods with a prescribed\\nquantile value for the prior distribution.\\nFirstly we derive the strength of evidence for nonparametric priors. It turns\\nout that we get the by now more or less accepted strength of evidence as the\\nratio of two suprema,\\n$\\\\sup_{\\\\theta\\\\geq\\\\theta_0}f(x|\\\\theta)/\\\\sup_{\\\\theta<\\\\theta_0}f(x|\\\\theta)$. Here\\nthe hypotheses of the prosecutor and defence are given by $H_p: \\\\theta\\\\geq\\n\\\\theta_0$ and $H_d:\\\\theta<\\\\theta_0$. The evidence is seen as a measurement $x$\\nwhich is a realization of a random variable with a density $f(x|\\\\theta)$.\\nSecondly we consider a similar parametric empirical Bayes method with a\\nquantile restriction on the prior where the prior distribution is assumed to be\\nnormal. Some interesting strength of evidence functions are derived for this\\nsituation.\\n',\n",
       " '  Let $\\\\{X_n: n\\\\in \\\\mathbb{N}\\\\}$ be a linear process with bounded probability\\ndensity function $f(x)$. We study the estimation of the quadratic functional\\n$\\\\int_{\\\\mathbb{R}} f^2(x)\\\\, dx$. With a Fourier transform on the kernel\\nfunction and the projection method, it is shown that, under certain mild\\nconditions, the estimator \\\\[ \\\\frac{2}{n(n-1)h_n} \\\\sum_{1\\\\le i<j\\\\le\\nn}K\\\\left(\\\\frac{X_i-X_j}{h_n}\\\\right) \\\\] has similar asymptotical properties as\\nthe i.i.d. case studied in Giné and Nickl (2008) if the linear process\\n$\\\\{X_n: n\\\\in \\\\mathbb{N}\\\\}$ has the defined short range dependence. We also\\nprovide an application to $L^2_2$ divergence and the extension to multivariate\\nlinear processes. The simulation study for linear processes with Gaussian and\\n$\\\\alpha$-stable innovations confirms our theoretical results. As an\\nillustration, we estimate the $L^2_2$ divergences among the density functions\\nof average annual river flows for four rivers and obtain promising results.\\n',\n",
       " '  In this paper, we propose the primal-dual method of multipliers (PDMM) for\\ndistributed optimization over a graph. In particular, we optimize a sum of\\nconvex functions defined over a graph, where every edge in the graph carries a\\nlinear equality constraint. In designing the new algorithm, an augmented\\nprimal-dual Lagrangian function is constructed which smoothly captures the\\ngraph topology. It is shown that a saddle point of the constructed function\\nprovides an optimal solution of the original problem. Further under both the\\nsynchronous and asynchronous updating schemes, PDMM has the convergence rate of\\nO(1/K) (where K denotes the iteration index) for general closed, proper and\\nconvex functions. Other properties of PDMM such as convergence speeds versus\\ndifferent parameter- settings and resilience to transmission failure are also\\ninvestigated through the experiments of distributed averaging.\\n',\n",
       " '  The ^1{\\\\Sigma}^+ electronic ground states of MgLi^+ and CaLi^+ molecular ions\\nare investigated for their spectroscopic constants and properties such as the\\ndipole- and quadrupole moments, and static dipole polarizabilities. The\\nquadrupole moments and the static dipole polarizabilities for these ions have\\nbeen calculated and reported here, for the first time. The maximum possible\\nerror bars, arising due to the finite basis set and the exclusion of higher\\ncorrelation effects beyond partial triples, are quoted for reliability.\\nFurther, the adiabatic effects such as diagonal Born-Oppenheimer corrections\\nare also calculated for these molecules. The vibrational energies, the\\nwavefunctions, and the relevant vibrational parameters are obtained by solving\\nthe vibrational Schrödinger equation using the potential energy curve and the\\npermanent dipole moment curve of the molecular electronic ground state.\\nThereafter, spontaneous and black-body radiation induced transition rates are\\ncalculated to obtain the lifetimes of the vibrational states. The lifetime of\\nrovibronic ground state for MgLi^+ , at room temperature, is found to be 2.81 s\\nand for CaLi^+ it is 3.19 s. It has been observed that the lifetime of the\\nhighly excited vibrational state is several times larger than (comparable to)\\nthat of the vibrational ground state of MgLi^+ (CaLi^+ ). In addition, a few\\nlow-lying electronic excited states of {\\\\Sigma} and {\\\\Pi} symmetries have been\\ninvestigated for their electronic and vibrational properties, using EOM-CCSD\\nmethod together with the QZ basis sets.\\n',\n",
       " '  Deep Convolutional Neural Networks (DCNNs) are showing impressive\\nperformances in biomedical semantic segmentation. However, current DCNNs\\nusually use down-sampling layers to achieve significant receptive field\\nincreasing and to gain abstract semantic information. These down-sampling\\nlayers decrease the spatial dimension of feature maps as well, which is harmful\\nfor semantic segmentation. Atrous convolution is an alternative for the\\ndown-sampling layer. It could increase the receptive field significantly but\\nalso maintain the spatial dimension of feature maps. In this paper, firstly, an\\natrous rate setting is proposed to achieve the largest and fully-covered\\nreceptive field with a minimum number of layers. Secondly, six atrous blocks,\\nthree shortcut connections and four normalization methods are explored to\\nselect the optimal atrous block, shortcut connection and normalization method.\\nFinally, a new and dimensionally lossless DCNN - Atrous Convolutional Neural\\nNetwork (ACNN) is proposed with using cascaded atrous II-blocks, residual\\nlearning and Fine Group Normalization (FGN). The Right Ventricle (RV), Left\\nVentricle (LV) and aorta data are used for the validation. The results show\\nthat the proposed ACNN achieves comparable segmentation Dice Similarity\\nCoefficients (DSCs) with U-Net, optimized U-Net and the hybrid network, but\\nuses much less parameters. This advantage is considered to benefit from the\\ndimensionally lossless feature maps.\\n',\n",
       " '  For long wavelengths three-dimensional connected metallic wire meshes are\\nimpenetrable by light and have an electromagnetic response similar to that of\\nan electron gas below the plasma frequency. Surprisingly, here it is shown that\\nwhen two opaque metallic meshes are spatially-interlaced the combined structure\\nenables an anomalous light tunneling in the long wavelength regime. The effect\\nis due to the destructive interference of the waves scattered by the two wire\\nmeshes, which leads to a Fano-type resonance.\\n',\n",
       " '  In this paper, we consider a finite network of unmanned aerial vehicles\\n(UAVs) serving a given region. Modeling this network as a uniform binomial\\npoint process (BPP), we derive the downlink coverage probability of a reference\\nreceiver located at an arbitrary position on the ground assuming Nakagami-$m$\\nfading for all wireless links. The reference receiver is assumed to connect to\\nits closest transmitting node as is usually the case in cellular systems. After\\nderiving the distribution of distances from the reference receiver to the\\nserving and interfering nodes, we derive an exact expression for downlink\\ncoverage probability in terms of the derivative of Laplace transform of\\ninterference power distribution. In the downlink of this system, it is not\\nunusual to encounter scenarios in which the line-of-sight (LOS) component is\\nsignificantly stronger than the reflected multipath components. To emulate such\\nscenarios, we also derive the coverage probability in the absence of fading\\nfrom the results of Nakagami-$m$ fading by taking the limit $m \\\\to \\\\infty$.\\nUsing asymptotic expansion of incomplete gamma function, we concretely show\\nthat this limit reduces to a redundant condition. Consequently, we derive an\\naccurate coverage probability approximation for this case using dominant\\ninterferer-based approach in which the effect of dominant interferer is exactly\\ncaptured and the residual interference from other interferers is carefully\\napproximated. We then derive the bounds of the approximate coverage probability\\nusing Berry-Esseen theorem. Our analyses reveal several useful trends in\\ncoverage probability as a function of height of the transmitting nodes and the\\nlocation of reference receiver on the ground.\\n',\n",
       " '  We present a linear time algorithm for computing a cycle separator in a\\nplanar graph that is (arguably) simpler than previously known algorithms. Our\\nalgorithm builds on, and is somewhat similar to, previous algorithms for\\ncomputing separators. The main new ingredient is a specific layered\\ndecomposition of the planar graph constructed differently from previous\\nBFS-based layerings.\\n',\n",
       " '  An NP-hard graph problem may be intractable for general graphs but it could\\nbe efficiently solvable using dynamic programming for graphs with bounded width\\n(or depth or some other structural parameter). Dynamic programming is a\\nwell-known approach used for finding exact solutions for NP-hard graph problems\\nbased on tree decompositions. It has been shown that there exist algorithms\\nusing linear time in the number of vertices and single exponential time in the\\nwidth (depth or other parameters) of a given tree decomposition for many\\nconnectivity problems. Employing dynamic programming on a tree decomposition\\nusually uses exponential space. In 2010, Lokshtanov and Nederlof introduced an\\nelegant framework to avoid exponential space by algebraization. Later, Fürer\\nand Yu modified the framework in a way that even works when the underlying set\\nis dynamic, thus applying it to tree decompositions. In this work, we design\\nspace-efficient algorithms to solve the Hamiltonian Cycle and the Traveling\\nSalesman problems, using polynomial space while the time complexity is only\\nslightly increased. This might be inevitable since we are reducing the space\\nusage from an exponential amount (in dynamic programming solution) to\\npolynomial. We give an algorithm to solve Hamiltonian cycle in time\\n$\\\\mathcal{O}((4w)^d\\\\, nM(n\\\\log{n}))$ using $\\\\mathcal{O}(dn\\\\log{n})$ space,\\nwhere $M(r)$ is the time complexity to multiply two integers, each of which\\nbeing represented by at most $r$ bits. Then, we solve the more general\\nTraveling Salesman problem in time $\\\\mathcal{O}((4w)^d poly(n))$ using space\\n$\\\\mathcal{O}(\\\\mathcal{W}dn\\\\log{n})$, where $w$ and $d$ are the width and the\\ndepth of the given tree decomposition and $\\\\mathcal{W}$ is the sum of weights.\\nFurthermore, this algorithm counts the number of Hamiltonian Cycles.\\n',\n",
       " '  This paper introduces a fast and numerically stable algorithm for the\\nsolution of fourth-order linear boundary value problems on an interval. This\\ntype of equation arises in a variety of settings in physics and signal\\nprocessing. However, current methods of solution involve discretizing the\\ndifferential equation directly by finite elements or finite differences, and\\nconsequently suffer from the poor conditioning introduced by such schemes. Our\\nnew method instead reformulates the equation as a collection of second-kind\\nintegral equations defined on local subdomains. Each such equation can be\\nstably discretized. The boundary values of these local solutions are matched by\\nsolving a banded linear system. The method of deferred corrections is then used\\nto increase the accuracy of the scheme. Deferred corrections requires applying\\nthe integral operator to a function on the entire domain, for which we provide\\nan algorithm with linear cost. We illustrate the performance of our method on\\nseveral numerical examples.\\n',\n",
       " '  The full development of mono- or multi-dimensional time-resolved spectroscopy\\ntechniques incorporating optical activity signals has been strongly hampered by\\nthe challenge of identifying the small chiral signals over the large achiral\\nbackground. Here we propose a new methodology to isolate chiral signals\\nremoving the achiral background from two commonly used configurations for\\nperforming two dimensional optical spectroscopy, known as BOXCARS and GRadient\\nAssisted Photon Echo Spectroscopy (GRAPES). It is found that in both cases an\\nachiral signal from an isotropic system can be completely eliminated by small\\nmanipulations of the relative angles between the linear polarizations of the\\nfour input laser pulses. Starting from the formulation of a perturbative\\nexpansion of the signal in the angle between the beams and the propagation\\naxis, we derive analytic expressions that can be used to estimate how to change\\nthe polarization angles of the four pulses to minimize achiral contributions in\\nthe studied configurations. The generalization to any other possible\\nexperimental configurations has also been discussed. %We derive analytic\\nexpressions to changes required to the polarizations in terms of a perturbative\\nexpansion in the angle between the beams and the colinear axis. We also\\nnumerically estimate higher order coefficients which cover arbitrarily large\\nangles and thus any experimental configuration.\\n',\n",
       " '  With a growing number of social apps, people have become increasingly willing\\nto share their everyday photos and events on social media platforms, such as\\nFacebook, Instagram, and WeChat. In social media data mining, post popularity\\nprediction has received much attention from both data scientists and\\npsychologists. Existing research focuses more on exploring the post popularity\\non a population of users and including comprehensive factors such as temporal\\ninformation, user connections, number of comments, and so on. However, these\\nframeworks are not suitable for guiding a specific user to make a popular post\\nbecause the attributes of this user are fixed. Therefore, previous frameworks\\ncan only answer the question \"whether a post is popular\" rather than \"how to\\nbecome famous by popular posts\". In this paper, we aim at predicting the\\npopularity of a post for a specific user and mining the patterns behind the\\npopularity. To this end, we first collect data from Instagram. We then design a\\nmethod to figure out the user environment, representing the content that a\\nspecific user is very likely to post. Based on the relevant data, we devise a\\nnovel dual-attention model to incorporate image, caption, and user environment.\\nThe dual-attention model basically consists of two parts, explicit attention\\nfor image-caption pairs and implicit attention for user environment. A\\nhierarchical structure is devised to concatenate the explicit attention part\\nand implicit attention part. We conduct a series of experiments to validate the\\neffectiveness of our model and investigate the factors that can influence the\\npopularity. The classification results show that our model outperforms the\\nbaselines, and a statistical analysis identifies what kind of pictures or\\ncaptions can help the user achieve a relatively high \"likes\" number.\\n',\n",
       " '  The impact of liquid drops on a heated solid surface is of great importance\\nin many engineering applications. This paper describes the simulation of the\\ndrop-wall interaction using the smoothed particle hydrodynamics (SPH) method.\\nThe SPH method is a Lagrangian mesh-free method that can be used to solve the\\nfluid equations. A vaporization model based on the SPH formulation was also\\ndeveloped and implemented. A parametric study was conducted to characterize the\\neffects of impact velocity and wall temperature on the impact outcome. The\\npresent numerical method was able to predict different outcomes, such as\\ndeposition, splash, breakup, and rebound (i.e., Leidenfrost phenomenon). The\\npresent numerical method was used to construct a regime diagram for describing\\nthe impact of an iso-octane drop on a heated surface at various Weber numbers\\nand wall temperatures.\\n',\n",
       " '  In this paper we apply active learning algorithms for dynamic pricing in a\\nprominent e-commerce website. Dynamic pricing involves changing the price of\\nitems on a regular basis, and uses the feedback from the pricing decisions to\\nupdate prices of the items. Most popular approaches to dynamic pricing use a\\npassive learning approach, where the algorithm uses historical data to learn\\nvarious parameters of the pricing problem, and uses the updated parameters to\\ngenerate a new set of prices. We show that one can use active learning\\nalgorithms such as Thompson sampling to more efficiently learn the underlying\\nparameters in a pricing problem. We apply our algorithms to a real e-commerce\\nsystem and show that the algorithms indeed improve revenue compared to pricing\\nalgorithms that use passive learning.\\n',\n",
       " '  We give a characterisation of Bieberbach manifolds which are geodesic\\nboundaries of a compact flat manifold, and discuss the low dimensional cases,\\nup to dimension 4.\\n',\n",
       " '  Neural samplers such as variational autoencoders (VAEs) or generative\\nadversarial networks (GANs) approximate distributions by transforming samples\\nfrom a simple random source---the latent space---to samples from a more complex\\ndistribution represented by a dataset. While the manifold hypothesis implies\\nthat the density induced by a dataset contains large regions of low density,\\nthe training criterions of VAEs and GANs will make the latent space densely\\ncovered. Consequently points that are separated by low-density regions in\\nobservation space will be pushed together in latent space, making stationary\\ndistances poor proxies for similarity. We transfer ideas from Riemannian\\ngeometry to this setting, letting the distance between two points be the\\nshortest path on a Riemannian manifold induced by the transformation. The\\nmethod yields a principled distance measure, provides a tool for visual\\ninspection of deep generative models, and an alternative to linear\\ninterpolation in latent space. In addition, it can be applied for robot\\nmovement generalization using previously learned skills. The method is\\nevaluated on a synthetic dataset with known ground truth; on a simulated robot\\narm dataset; on human motion capture data; and on a generative model of\\nhandwritten digits.\\n',\n",
       " '  For a commutative Noetherian ring R of dimension d and a commutative\\ncancellative monoid M, the elementary action on unimodular n-rows over the\\nmonoid ring R[M] is transitive for n>=max(d+2,3). The starting point is the\\ncase of polynomial rings, considered by A. Suslin in the 1970s. The main result\\ncompletes a project, initiated in the early 1990s, and suggests a new direction\\nin the study of K-theory of monoid rings.\\n',\n",
       " \"  In this paper, we establish existence and multiplicity of solutions for the\\nfollowing class of quasilinear field equation $$ -\\\\Delta\\nu+V(x)u-\\\\Delta_{p}u+W'(u)=0, \\\\,\\\\,\\\\, \\\\mbox{in} \\\\,\\\\,\\\\, \\\\mathbb{R}^{N}, \\\\eqno{(P)}\\n$$ where $u=(u_1,u_2,...,u_{N+1})$, $p>N \\\\geq 2$, $W$ is a singular function\\nand $V$ is a positive continuous function.\\n\",\n",
       " '  The t-distribution has many useful applications in robust statistical\\nanalysis. The parameter estimation of the t-distribution is carried out using\\nML estimation method, and the ML estimates are obtained via the EM algorithm.\\nIn this study, we consider an alternative estimation method for all the\\nparameters of the multivariate-t distribution using the MLq estimation method.\\nWe adapt the EM algorithm to obtain the MLq estimates for all the parameters.\\nWe provide a small simulation study to illustrate the performance of the MLq\\nestimators over the ML estimators and observe that the MLq estimators have\\nconsiderable superiority over the ML estimators.\\n',\n",
       " '  The paper is a suggested experiment in effectively teaching subjects in\\nComputer Science. The paper addresses effective content-delivery with the help\\nof a university intranet. The proposal described herein is for teaching a\\nsubject like Combinatorics and Graph Theory - the main idea is to supplement\\nlectures with a teacher-moderated online forum against an associated intranet\\nportal.\\nKeywords and phrases -computer-assisted learning; learning portal; active\\nlearning; OEIS; intranet portal; undergraduate teaching; Combinatorics and\\nGraph theory\\n',\n",
       " '  In this paper, we will look at actions on complex flag varieties $G/P$ of the\\ntorus $\\\\hat{T}=\\\\bigcap\\\\limits_{\\\\alpha\\\\in\\\\Delta\\\\setminus\\\\Delta_P}\\\\ker(\\\\alpha)$,\\nand under reasonable assumptions, we will give a description of the set\\n$X^{us}$ of unstable points for $\\\\hat{T}$-linearized invertible sheaves. We\\nwill investigate the case where $P$ is a maximal parabolic subgroup, and show\\nthat $X^{us}$ can be written as a disjoint union of a Schubert variety and an\\nopposite Schubert variety, and we deduce the vanishing of cohomology groups\\n$H^i(Y,{\\\\cal M})$ for invertible sheaves ${\\\\cal M}$ on the quotient variety $Y$\\nfor $i$ in a range given by the codimension of $X^{us}$.\\n',\n",
       " '  The probability that a user will click a search result depends both on its\\nrelevance and its position on the results page. The position based model\\nexplains this behavior by ascribing to every item an attraction probability,\\nand to every position an examination probability. To be clicked, a result must\\nbe both attractive and examined. The probabilities of an item-position pair\\nbeing clicked thus form the entries of a rank-$1$ matrix. We propose the\\nlearning problem of a Bernoulli rank-$1$ bandit where at each step, the\\nlearning agent chooses a pair of row and column arms, and receives the product\\nof their Bernoulli-distributed values as a reward. This is a special case of\\nthe stochastic rank-$1$ bandit problem considered in recent work that proposed\\nan elimination based algorithm Rank1Elim, and showed that Rank1Elim\\'s regret\\nscales linearly with the number of rows and columns on \"benign\" instances.\\nThese are the instances where the minimum of the average row and column rewards\\n$\\\\mu$ is bounded away from zero. The issue with Rank1Elim is that it fails to\\nbe competitive with straightforward bandit strategies as $\\\\mu \\\\rightarrow 0$.\\nIn this paper we propose Rank1ElimKL which simply replaces the (crude)\\nconfidence intervals of Rank1Elim with confidence intervals based on\\nKullback-Leibler (KL) divergences, and with the help of a novel result\\nconcerning the scaling of KL divergences we prove that with this change, our\\nalgorithm will be competitive no matter the value of $\\\\mu$. Experiments with\\nsynthetic data confirm that on benign instances the performance of Rank1ElimKL\\nis significantly better than that of even Rank1Elim, while experiments with\\nmodels derived from real data confirm that the improvements are significant\\nacross the board, regardless of whether the data is benign or not.\\n',\n",
       " '  We prove that all endo-$p$-permutation modules for a finite group are\\nliftable from characteristic $p>0$ to characteristic $0$.\\n',\n",
       " \"  Capturing the temporal dynamics of user preferences over items is important\\nfor recommendation. Existing methods mainly assume that all time steps in\\nuser-item interaction history are equally relevant to recommendation, which\\nhowever does not apply in real-world scenarios where user-item interactions can\\noften happen accidentally. More importantly, they learn user and item dynamics\\nseparately, thus failing to capture their joint effects on user-item\\ninteractions. To better model user and item dynamics, we present the\\nInteracting Attention-gated Recurrent Network (IARN) which adopts the attention\\nmodel to measure the relevance of each time step. In particular, we propose a\\nnovel attention scheme to learn the attention scores of user and item history\\nin an interacting way, thus to account for the dependencies between user and\\nitem dynamics in shaping user-item interactions. By doing so, IARN can\\nselectively memorize different time steps of a user's history when predicting\\nher preferences over different items. Our model can therefore provide\\nmeaningful interpretations for recommendation results, which could be further\\nenhanced by auxiliary features. Extensive validation on real-world datasets\\nshows that IARN consistently outperforms state-of-the-art methods.\\n\",\n",
       " '  When solving k-in-a-Row games, the Hales-Jewett pairing strategy [4] is a\\nwell-known strategy to prove that specific positions are (at most) a draw. It\\nrequires two empty squares per possible winning line (group) to be marked,\\ni.e., with a coverage ratio of 2.0. In this paper we present a new strategy,\\ncalled Set Matching. A matching set consists of a set of nodes (the markers), a\\nset of possible winning lines (the groups), and a coverage set indicating how\\nall groups are covered after every first initial move. This strategy needs less\\nthan two markers per group. As such it is able to prove positions in k-in-a-Row\\ngames to be draws, which cannot be proven using the Hales-Jewett pairing\\nstrategy. We show several efficient configurations with their matching sets.\\nThese include Cycle Configurations, BiCycle Configurations, and PolyCycle\\nConfigurations involving more than two cycles. Depending on configuration, the\\ncoverage ratio can be reduced to 1.14. Many examples in the domain of solving\\nk-in-a-Row games are given, including the direct proof (without further\\ninvestigation) that the empty 4 x 4 board is a draw for 4-in-a-Row.\\n',\n",
       " '  The increase in the number of researchers coupled with the ease of publishing\\nand distribution of scientific papers (due to technological advancements) has\\nresulted in a dramatic increase in astronomy literature. This has likely led to\\nthe predicament that the body of the literature is too large for traditional\\nhuman consumption and that related and crucial knowledge is not discovered by\\nresearchers. In addition to the increased production of astronomical\\nliterature, recent decades have also brought several advancements in\\ncomputational linguistics. Especially, the machine-aided processing of\\nliterature dissemination might make it possible to convert this stream of\\npapers into a coherent knowledge set. In this paper, we present the application\\nof computational linguistics techniques to astronomy literature. In particular,\\nwe developed a tool that will find similar articles purely based on text\\ncontent from an input paper. We find that our technique performs robustly in\\ncomparison with other tools recommending articles given a reference paper\\n(known as recommender system). Our novel tool shows the great power in\\ncombining computational linguistics with astronomy literature and suggests that\\nadditional research in this endeavor will likely produce even better tools that\\nwill help researchers cope with the vast amounts of knowledge being produced.\\n',\n",
       " \"  In this paper, we study the notion of admissibility for randomised strategies\\nin concurrent games. Intuitively, an admissible strategy is one where the\\nplayer plays `as well as possible', because there is no other strategy that\\ndominates it, i.e., that wins (almost surely) against a super set of\\nadversarial strategies. We prove that admissible strategies always exist in\\nconcurrent games, and we characterise them precisely. Then, when the objectives\\nof the players are omega-regular, we show how to perform assume-admissible\\nsynthesis, i.e., how to compute admissible strategies that win (almost surely)\\nunder the hypothesis that the other players play admissible\\n\",\n",
       " '  In this paper the sensor noise of two geophone configurations (L-22D and L-4C\\ngeophones from Sercel with custom built amplifiers) was measured by performing\\ntwo huddle tests. It is shown that the accuracy of the results can be\\nsignificantly improved by performing the huddle test in a seismically quiet\\nenvironment and by using a large number of reference sensors to remove the\\nseismic foreground signal from the data. Using these two techniques, the\\nmeasured sensor noise of the two geophone configurations matched calculated\\npredictions remarkably well in the bandwidth of interest (0.01 Hz to 100 Hz).\\nLow noise operational amplifiers OPA188 were utilized to amplify the L-4C\\ngeophone to give a sensor that was characterized to be near Johnson noise\\nlimited in the bandwidth of interest with a noise value of $10^{-11}\\n\\\\text{m}/\\\\sqrt{\\\\text{Hz}}$ at 1 Hz.\\n',\n",
       " '  We propose a new audio signal encryption scheme based on the chaotic Hénon\\nmap. The scheme mainly comprises two phases: one is the preprocessing stage\\nwhere the audio signal is transformed into a data by the lifting wavelet scheme\\nand the other in which the transformed data is encrypted by chaotic data set\\nand hyperbolic functions. Furthermore, we use dynamic keys and consider the key\\nspace size to be large enough to resist any kind of cryptographic attacks. A\\nstatistical investigation is also made to test the security and the efficiency\\nof the proposed scheme.\\n',\n",
       " '  We employ random geometric digraphs to construct semi-parametric classifiers.\\nThese data-random digraphs are from parametrized random digraph families called\\nproximity catch digraphs (PCDs). A related geometric digraph family, class\\ncover catch digraph (CCCD), has been used to solve the class cover problem by\\nusing its approximate minimum dominating set. CCCDs showed relatively good\\nperformance in the classification of imbalanced data sets, and although CCCDs\\nhave a convenient construction in $\\\\mathbb{R}^d$, finding minimum dominating\\nsets is NP-hard and its probabilistic behaviour is not mathematically tractable\\nexcept for $d=1$. On the other hand, a particular family of PCDs, called\\n\\\\emph{proportional-edge} PCDs (PE-PCDs), has mathematical tractable minimum\\ndominating sets in $\\\\mathbb{R}^d$; however their construction in higher\\ndimensions may be computationally demanding. More specifically, we show that\\nthe classifiers based on PE-PCDs are prototype-based classifiers such that the\\nexact minimum number of prototypes (equivalent to minimum dominating sets) are\\nfound in polynomial time on the number of observations. We construct two types\\nof classifiers based on PE-PCDs. One is a family of hybrid classifiers depend\\non the location of the points of the training data set, and another type is a\\nfamily of classifiers solely based on class covers. We assess the\\nclassification performance of our PE-PCD based classifiers by extensive Monte\\nCarlo simulations, and compare them with that of other commonly used\\nclassifiers. We also show that, similar to CCCD classifiers, our classifiers\\nare relatively better in classification in the presence of class imbalance.\\n',\n",
       " '  We study the interplay of spin-orbit coupling (SOC) and strong p-wave\\ninteraction to the scattering property of spin-1/2 ultracold Fermi gases. Based\\non a two-channel square-well potential generating p-wave resonance, we show\\nthat the presence of an isotropic SOC, even for its length much longer than the\\npotential range, can greatly modify the p-wave short-range boundary\\ncondition(BC). As a result, the conventional p-wave BC cannot predict the\\ninduced molecules near p-wave resonance, which can be fully destroyed to vanish\\ndue to strong interference between s- and p-wave channels. By analyzing the\\nintrinsic reasons for the breakdown of conventional BC, we propose a new p-wave\\nBC that can excellently reproduce the exact molecule solutions and also equally\\napply for a wide class of single-particle potentials besides SOC. This work\\nreveals the significant effect of SOC to both the short- and long-range\\nproperties of fermions near p-wave resonance, paving the way for future\\nexploring interesting few- and many-body physics in such system.\\n',\n",
       " '  The partial information decomposition (PID) is perhaps the leading proposal\\nfor resolving information shared between a set of sources and a target into\\nredundant, synergistic, and unique constituents. Unfortunately, the PID\\nframework has been hindered by a lack of a generally agreed-upon, multivariate\\nmethod of quantifying the constituents. Here, we take a step toward rectifying\\nthis by developing a decomposition based on a new method that quantifies unique\\ninformation. We first develop a broadly applicable method---the dependency\\ndecomposition---that delineates how statistical dependencies influence the\\nstructure of a joint distribution. The dependency decomposition then allows us\\nto define a measure of the information about a target that can be uniquely\\nattributed to a particular source as the least amount which the source-target\\nstatistical dependency can influence the information shared between the sources\\nand the target. The result is the first measure that satisfies the core axioms\\nof the PID framework while not satisfying the Blackwell relation, which depends\\non a particular interpretation of how the variables are related. This makes a\\nkey step forward to a practical PID.\\n',\n",
       " '  We propose a deep learning based method, the Deep Ritz Method, for\\nnumerically solving variational problems, particularly the ones that arise from\\npartial differential equations. The Deep Ritz method is naturally nonlinear,\\nnaturally adaptive and has the potential to work in rather high dimensions. The\\nframework is quite simple and fits well with the stochastic gradient descent\\nmethod used in deep learning. We illustrate the method on several problems\\nincluding some eigenvalue problems.\\n',\n",
       " \"  In this exploratory study we assessed how attitudes of children with autism\\nspectrum disorder (ASD) towards robots together with children's autism-related\\nsocial impairments are linked to indicators of children's preference of an\\ninteraction with a robot over an interaction with a person. We found that\\nchildren with ASD have overall positive attitudes towards robots and that they\\noften prefer interacting with a robot than with a person. Several of children's\\nattitudes were linked to children's longer gazes towards a robot compared to a\\nperson. Autism-related social impairments were linked to more repetitive and\\nstereotyped behaviors and to a shorter gaze duration in the interaction with\\nthe robot compared to the person. These preliminary results contribute to\\nbetter understand factors that might help determine sub-groups of children with\\nASD for whom robots could be particularly useful.\\n\",\n",
       " '  It is shown that the finite-dimensional simple representations of the super\\nJordan plane $B$ are one-dimensional. The indecomposable representations of\\ndimension $2$ and $3$ of $B$ are classified. Two families of indecomposable\\nrepresentations of $B$ of arbitrary dimension are presented.\\n',\n",
       " '  In this work, we use the numerical renormalization group (NRG) theory to\\nstudy the thermodynamics of the two-impurity Anderson model. Two different\\nmethods are used to estimate the effect of the Dzyaloshiskii-Moriya (DM)\\ninteraction on the variation of the Kondo temperature. When the\\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction is vanishing, the two\\ndifferent estimations give different tendency. If we use the peak of the\\nspecific heat to identify the variation of the Kondo temperature versus the\\nDzyaloshiskii-Moriya interaction, we get an almost linear function. However, if\\nwe use the low temperature universal curve of the impurity entropy, we get a\\nquadratic function. These results indicate that the previous debates about the\\ninfluence of the spin-orbit coupling on the Kondo temperature may come from the\\ndifferent definitions of the Kondo temperature. When the RKKY interaction is\\nferromagnetic, there are two stages of the Kondo screening. Both the two\\nestimations demonstrate that the second stage of the Kondo temperature is\\nexponentially dependent on the DM interaction. There results are dramatically\\ndifferent from those calculated via perturbation theory.\\n',\n",
       " \"  The discovery of radionuclides like 60Fe with half-lives of million years in\\ndeep-sea crusts and sediments offers the unique possibility to date and locate\\nnearby supernovae. We want to quantitatively establish that the 60Fe\\nenhancement is the result of several supernovae which are also responsible for\\nthe formation of the Local Bubble, our Galactic habitat. We performed\\nthree-dimensional hydrodynamic adaptive mesh refinement simulations (with\\nresolutions down to subparsec scale) of the Local Bubble and the neighbouring\\nLoop I superbubble in different homogeneous, self-gravitating environments. For\\nsetting up the Local and Loop I superbubble, we took into account the time\\nsequence and locations of the generating core-collapse supernova explosions,\\nwhich were derived from the mass spectrum of the perished members of certain\\nstellar moving groups. The release of 60Fe and its subsequent turbulent mixing\\nprocess inside the superbubble cavities was followed via passive scalars, where\\nthe yields of the decaying radioisotope were adjusted according to recent\\nstellar evolution calculations. The models are able to reproduce both the\\ntiming and the intensity of the 60Fe excess observed with rather high\\nprecision, provided that the external density does not exceed 0.3 cm-3 on\\naverage. Thus the two best-fit models presented here were obtained with\\nbackground media mimicking the classical warm ionised and warm neutral medium.\\nWe also found that 60Fe (which is condensed onto dust grains) can be delivered\\nto Earth via two physical mechanisms: either through individual fast-paced\\nsupernova blast waves, which cross the Earth's orbit sometimes even twice as a\\nresult of reflection from the Local Bubble's outer shell, or, alternatively,\\nthrough the supershell of the Local Bubble itself, injecting the 60Fe content\\nof all previous supernovae at once, but over a longer time range.\\n\",\n",
       " \"  Due to the rapid innovation of technology and the desire to find and employ\\nbiomarkers for neurodegenerative disease, high-dimensional data classification\\nproblems are routinely encountered in neuroimaging studies. To avoid\\nover-fitting and to explore relationships between disease and potential\\nbiomarkers, feature learning and selection plays an important role in\\nclassifier construction and is an important area in machine learning. In this\\narticle, we review several important feature learning and selection techniques\\nincluding lasso-based methods, PCA, the two-sample t-test, and stacked\\nauto-encoders. We compare these approaches using a numerical study involving\\nthe prediction of Alzheimer's disease from Magnetic Resonance Imaging.\\n\",\n",
       " '  Spectral decomposition of the Koopman operator is attracting attention as a\\ntool for the analysis of nonlinear dynamical systems. Dynamic mode\\ndecomposition is a popular numerical algorithm for Koopman spectral analysis;\\nhowever, we often need to prepare nonlinear observables manually according to\\nthe underlying dynamics, which is not always possible since we may not have any\\na priori knowledge about them. In this paper, we propose a fully data-driven\\nmethod for Koopman spectral analysis based on the principle of learning Koopman\\ninvariant subspaces from observed data. To this end, we propose minimization of\\nthe residual sum of squares of linear least-squares regression to estimate a\\nset of functions that transforms data into a form in which the linear\\nregression fits well. We introduce an implementation with neural networks and\\nevaluate performance empirically using nonlinear dynamical systems and\\napplications.\\n',\n",
       " '  We apply the vectorized Non-negative Matrix Factorization (NMF) method to\\npost-processing of direct imaging data for exoplanetary systems such as\\ncircumstellar disks. NMF is an iterative approach, which first creates a\\nnon-orthogonal and non-negative basis of components using given reference\\nimages, then models a target with the components. The constructed model is then\\nrescaled with a factor to compensate for the contribution from a disk. We\\ncompare NMF with existing methods (classical reference differential imaging\\nmethod, and the Karhunen-Loève image projection algorithm) using synthetic\\ncircumstellar disks, and demonstrate the superiority of NMF: with no need for\\nprior selection of references, NMF can detect fainter circumstellar disks,\\nbetter preserve low order disk morphology, and does not require forward\\nmodeling. As an application to a well-known disk example, we process the\\narchival Hubble Space Telescope (HST) STIS coronagraphic observations of\\nHD~181327 with different methods and compare them. NMF is able to extract some\\ncircumstellar material inside the primary ring for the first time. In the\\nappendix, we mathematically investigate the stability of NMF components during\\niteration, and the linearity of NMF modeling.\\n',\n",
       " '  Traditionally, multi-layer neural networks use dot product between the output\\nvector of previous layer and the incoming weight vector as the input to\\nactivation function. The result of dot product is unbounded, thus increases the\\nrisk of large variance. Large variance of neuron makes the model sensitive to\\nthe change of input distribution, thus results in poor generalization, and\\naggravates the internal covariate shift which slows down the training. To bound\\ndot product and decrease the variance, we propose to use cosine similarity or\\ncentered cosine similarity (Pearson Correlation Coefficient) instead of dot\\nproduct in neural networks, which we call cosine normalization. We compare\\ncosine normalization with batch, weight and layer normalization in\\nfully-connected neural networks as well as convolutional networks on the data\\nsets of MNIST, 20NEWS GROUP, CIFAR-10/100 and SVHN. Experiments show that\\ncosine normalization achieves better performance than other normalization\\ntechniques.\\n',\n",
       " '  Recently, Recurrent Neural Networks (RNNs) have been applied to the task of\\nsession-based recommendation. These approaches use RNNs to predict the next\\nitem in a user session based on the previ- ously visited items. While some\\napproaches consider additional item properties, we argue that item dwell time\\ncan be used as an implicit measure of user interest to improve session-based\\nitem recommen- dations. We propose an extension to existing RNN approaches that\\ncaptures user dwell time in addition to the visited items and show that\\nrecommendation performance can be improved. Additionally, we investigate the\\nusefulness of a single validation split for model selection in the case of\\nminor improvements and find that in our case the best model is not selected and\\na fold-like study with different validation sets is necessary to ensure the\\nselection of the best model.\\n',\n",
       " '  Recently, Deshpande et al. introduced a new measure of the complexity of a\\nBoolean function. We call this measure the \"goal value\" of the function. The\\ngoal value of $f$ is defined in terms of a monotone, submodular utility\\nfunction associated with $f$. As shown by Deshpande et al., proving that a\\nBoolean function $f$ has small goal value can lead to a good approximation\\nalgorithm for the Stochastic Boolean Function Evaluation problem for $f$. Also,\\nif $f$ has small goal value, it indicates a close relationship between two\\nother measures of the complexity of $f$, its average-case decision tree\\ncomplexity and its average-case certificate complexity. In this paper, we\\nexplore the goal value measure in detail. We present bounds on the goal values\\nof arbitrary and specific Boolean functions, and present results on properties\\nof the measure. We compare the goal value measure to other, previously studied,\\nmeasures of the complexity of Boolean functions. Finally, we discuss a number\\nof open questions provoked by our work.\\n',\n",
       " '  By analyzing a paradigmatic example of the theory of dissipative systems --\\nthe classical and quantum dissipative standard map -- we are able to explain\\nthe main features of the decay to the quantum equilibrium state. The classical\\nisoperiodic stable structures typically present in the parameter space of these\\nkind of systems play a fundamental role. In fact, we have found that the period\\nof stable structures that are near in this space determines the phase of the\\nleading eigenstates of the corresponding quantum superoperator. Moreover, the\\neigenvectors show a strong localization on the corresponding periodic orbits\\n(limit cycles). We show that this sort of scarring phenomenon (an established\\nproperty of Hamiltonian and projectively open systems) is present in the\\ndissipative case and it is of extreme simplicity.\\n',\n",
       " '  A novel semantic approach to data selection and compression is presented for\\nthe dynamic adaptation of IoT data processing and transmission within \"wireless\\nislands\", where a set of sensing devices (sensors) are interconnected through\\none-hop wireless links to a computational resource via a local access point.\\nThe core of the proposed technique is a cooperative framework where local\\nclassifiers at the mobile nodes are dynamically crafted and updated based on\\nthe current state of the observed system, the global processing objective and\\nthe characteristics of the sensors and data streams. The edge processor plays a\\nkey role by establishing a link between content and operations within the\\ndistributed system. The local classifiers are designed to filter the data\\nstreams and provide only the needed information to the global classifier at the\\nedge processor, thus minimizing bandwidth usage. However, the better the\\naccuracy of these local classifiers, the larger the energy necessary to run\\nthem at the individual sensors. A formulation of the optimization problem for\\nthe dynamic construction of the classifiers under bandwidth and energy\\nconstraints is proposed and demonstrated on a synthetic example.\\n',\n",
       " '  The electron-cyclotron maser is a process that generates intense and coherent\\nradio emission in plasma. In this paper, we present a comprehensive parametric\\ninvestigation on the electron-cyclotron-maser instability driven by non-thermal\\nring-beam electrons with intrinsic Alfvén waves which pervade the solar\\natmosphere and interplanetary space. It is found that both forward propagating\\nand backward propagating waves can be excited in the fast ordinary (O) and\\nextraordinary (X) electromagnetic modes. The growth rates of X1 mode are almost\\nalways weakened by Alfvén waves. The average pitch-angle $\\\\phi_0$ of\\nelectrons is a key parameter for the effect of Alfvén waves on the growth\\nrate of modes O1, O2 and X2. For a beam-dominated electron distribution\\n($\\\\phi_0 \\\\lesssim 30^\\\\circ$ ), the growth rates of the maser instability for\\nO1, O2 and X2 modes are enhanced with the increase of Alfvén wave energy\\ndensity. In other conditions, the growth rates of O1, O2 and X2 modes weakened\\nwith increasing Alfvén wave intensity, except that the growth of O1 mode may\\nalso be enhanced by Alfvén waves for a ring distribution. The results may be\\nimportant for us in analyzing the mechanism of radio bursts with various fine\\nstructures observed in space and astrophysical plasmas.\\n',\n",
       " '  News reports in media contain records of a wide range of socio-economic and\\npolitical events in time. Using a publicly available, large digital database of\\nnews records, and aggregating them over time, we study the network of ethnic\\nconflicts and human rights violations. Complex network analyses of the events\\nand the involved actors provide important insights on the engaging actors,\\ngroups, establishments and sometimes nations, pointing at their long range\\neffect over space and time. We find power law decays in distributions of actor\\nmentions, co-actor mentions and degrees and dominance of influential actors and\\ngroups. Most influential actors or groups form a giant connected component\\nwhich grows in time, and is expected to encompass all actors globally in the\\nlong run. We demonstrate how targeted removal of actors may help stop spreading\\nunruly events. We study the cause-effect relation between types of events, and\\nour quantitative analysis confirm that ethnic conflicts lead to human rights\\nviolations, while it does not support the converse.\\n',\n",
       " '  We consider a general stationary solution and derive the general laws for\\naccretion of rotating perfect fluids. For non-degenerate and degenerate Fermi\\nand Bose fluids we derive new effects that mimic the center-of-mass-energy\\neffect of two colliding particle in the vicinity of horizons. Non-degenerate\\nfluids see their chemical potential grow arbitrarily and ultra-relativistic\\nFermi fluids see their specific enthalpy and Fermi momentum grow arbitrarily\\ntoo while the latter vanishes gradually for non-relativistic Fermi fluids. For\\ndegenerate Bose fluids two scenarios remain possible as the fluid approaches a\\nhorizon: a) The Bose-Einstein condensation ceases or b) the temperature drops\\ngradually down to zero.\\n',\n",
       " \"  In online communities, antisocial behavior such as trolling disrupts\\nconstructive discussion. While prior work suggests that trolling behavior is\\nconfined to a vocal and antisocial minority, we demonstrate that ordinary\\npeople can engage in such behavior as well. We propose two primary trigger\\nmechanisms: the individual's mood, and the surrounding context of a discussion\\n(e.g., exposure to prior trolling behavior). Through an experiment simulating\\nan online discussion, we find that both negative mood and seeing troll posts by\\nothers significantly increases the probability of a user trolling, and together\\ndouble this probability. To support and extend these results, we study how\\nthese same mechanisms play out in the wild via a data-driven, longitudinal\\nanalysis of a large online news discussion community. This analysis reveals\\ntemporal mood effects, and explores long range patterns of repeated exposure to\\ntrolling. A predictive model of trolling behavior shows that mood and\\ndiscussion context together can explain trolling behavior better than an\\nindividual's history of trolling. These results combine to suggest that\\nordinary people can, under the right circumstances, behave like trolls.\\n\",\n",
       " '  The design of IoT systems could benefit from the combination of two different\\nanalyses. We perform a first analysis to approximate how data flow across the\\nsystem components, while the second analysis checks their communication\\nsoundness. We show how the combination of these two analyses yields further\\nbenefits hardly achievable by separately using each of them. We exploit two\\nindependently developed tools for the analyses.\\nFirstly, we specify IoT systems in IoT-LySa, a simple specification language\\nfeaturing asynchronous multicast communication of tuples. The values carried by\\nthe tuples are drawn from a term-algebra obtained by a parametric signature.\\nThe analysis of communication soundness is supported by ChorGram, a tool\\ndeveloped to verify the compatibility of communicating finite-state machines.\\nIn order to combine the analyses we implement an encoding of IoT-LySa processes\\ninto communicating machines. This encoding is not completely straightforward\\nbecause IoT-LySa has multicast communications with data, while communication\\nmachines are based on point-to-point communications where only finitely many\\nsymbols can be exchanged. To highlight the benefits of our approach we appeal\\nto a simple yet illustrative example.\\n',\n",
       " '  Expression quantitative trait loci (eQTL) analysis identifies genetic markers\\nassociated with the expression of a gene. Most existing eQTL analyses and\\nmethods investigate association in a single, readily available tissue, such as\\nblood. Joint analysis of eQTL in multiple tissues has the potential to improve,\\nand expand the scope of, single-tissue analyses. Large-scale collaborative\\nefforts such as the Genotype-Tissue Expression (GTEx) program are currently\\ngenerating high quality data in a large number of tissues. However,\\ncomputational constraints limit genome-wide multi-tissue eQTL analysis. We\\ndevelop an integrative method under a hierarchical Bayesian framework for eQTL\\nanalysis in a large number of tissues. The model fitting procedure is highly\\nscalable, and the computing time is a polynomial function of the number of\\ntissues. Multi-tissue eQTLs are identified through a local false discovery rate\\napproach, which rigorously controls the false discovery rate. Using simulation\\nand GTEx real data studies, we show that the proposed method has superior\\nperformance to existing methods in terms of computing time and the power of\\neQTL discovery. We provide a scalable method for eQTL analysis in a large\\nnumber of tissues. The method enables the identification of eQTL with different\\nconfigurations and facilitates the characterization of tissue specificity.\\n',\n",
       " '  The MOLLER experiment proposed at the Thomas Jefferson National Accelerator\\nFacility plans a precision low energy determination of the weak mixing angle\\nvia the measurement of the parity-violating asymmetry in the scattering of high\\nenergy longitudinally polarized electrons from electrons bound in a liquid\\nhydrogen target (M{\\\\o}ller scattering). A relative measure of the scattering\\nrate is planned to be obtained by intercepting the M{\\\\o}ller scattered\\nelectrons with a circular array of thin fused silica tiles attached to air\\nlight guides, which facilitate the transport of Cherenkov photons generated\\nwithin the tiles to photomultiplier tubes (PMTs). The scattered flux will also\\npass through the light guides of downstream tiles, generating additional\\nCherenkov as well as scintillation light and is a potential background. In\\norder to estimate the rate of these backgrounds, a gas-filled tube detector was\\ndesigned and deployed in an electron beam at the MAMI facility at Johannes\\nGutenberg University, Mainz, Germany. Described in this paper is the design of\\na detector to measure separately the scintillation and Cherenkov responses of\\ngas mixtures from relativistic electrons, the results of studies of several gas\\nmixtures with comparisons to simulations, and conclusions about the\\nimplications for the design of the MOLLER detector apparatus.\\n',\n",
       " '  ALICE (Adaptive Learning for Interdisciplinary Collaborative Environments) is\\nan open-source web based adaptive learning system designed for\\ninterdisciplinary instruction. ALICE has the potential to transform education\\nby empowering transdisciplinary knowledge acquisition. This is particularly\\nimportant in fields that accept newcomers with diverse scholastic backgrounds,\\ne.g. Systems Biology. With traditional interdisciplinary instruction, the\\ninstructor must cover pre-requisite information from multiple disciplines to\\nensure all students begin at a common baseline - slowing the learning process.\\nWith ALICE, students follow a personalized syllabus based on their previous\\nknowledge and work towards individual goals. Implementing an adaptive learning\\nsystem in an interdisciplinary course requires careful considerations of the\\ninstructional design. Structuring material, formulating assessments, and other\\ninstructional design aspects must be carefully considered. These considerations\\nare detailed through the exploration of a case study implementing ALICE in a\\ngraduate level Systems Biology course.\\n',\n",
       " '  Generalizing the classical work of Atiyah and Hirzebruch on non-algebraic\\nclasses, recently Quick proved the existence of torsion non-algebraic elements\\nin the Brown-Peterson tower. We construct non-torsion non-algebraic elements in\\nthe Brown-Peterson tower for the prime number 2.\\n',\n",
       " '  The analysis of log data generated by online educational systems is an\\nimportant task for improving the systems, and furthering our knowledge of how\\nstudents learn. This paper uses previously unseen log data from Edulab, the\\nlargest provider of digital learning for mathematics in Denmark, to analyse the\\nsessions of its users, where 1.08 million student sessions are extracted from a\\nsubset of their data. We propose to model students as a distribution of\\ndifferent underlying student behaviours, where the sequence of actions from\\neach session belongs to an underlying student behaviour. We model student\\nbehaviour as Markov chains, such that a student is modelled as a distribution\\nof Markov chains, which are estimated using a modified k-means clustering\\nalgorithm. The resulting Markov chains are readily interpretable, and in a\\nqualitative analysis around 125,000 student sessions are identified as\\nexhibiting unproductive student behaviour. Based on our results this student\\nrepresentation is promising, especially for educational systems offering many\\ndifferent learning usages, and offers an alternative to common approaches like\\nmodelling student behaviour as a single Markov chain often done in the\\nliterature.\\n',\n",
       " '  This paper studies the zero error capacity of the Nearest Neighbor Error\\n(NNE) channels with a multilevel alphabet. In the NNE channels, a transmitted\\nsymbol is a $d$-tuple of elements in $\\\\{0,1,2,\\\\dots, n-1 \\\\}$. It is assumed\\nthat only one element error to a nearest neighbor element in a transmitted\\nsymbol can occur. The NNE channels can be considered as a special type of\\nlimited magnitude error channels, and it is closely related to error models for\\nflash memories. In this paper, we derive a lower bound of the zero error\\ncapacity of the NNE channels based on a result of the perfect Lee codes. An\\nupper bound of the zero error capacity of the NNE channels is also derived from\\na feasible solution of a linear programming problem defined based on the\\nconfusion graphs of the NNE channels. As a result, a concise formula of the\\nzero error capacity is obtained using the lower and upper bounds.\\n',\n",
       " '  FinFETs have replaced the conventional bulk CMOS transistors in the sub-20nm\\ntechnology. One of the key issues to consider is, the vulnerability of FinFET\\nbased circuits to multiple node charge collection due to neutron-induced\\nstrikes. In this paper, we perform a device simulation based characterization\\nstudy on representative layouts of 14nm bulk FinFETs in order to study the\\nextent to which multiple transistors are affected. We find that multiple\\ntransistors do get affected and the impact can last up to five transistors away\\n(~200nm). We show that the potential of source/drain regions in the\\nneighborhood of the strike is a significant contributing factor. In the case of\\nmulti-fin FinFETs, the charge collected per fin is seen to reduce as the number\\nof fins increase. Thus, smaller FinFETs are susceptible to high amounts of\\ncharge collection.\\n',\n",
       " \"  Recently, the idea of taking ensemble average over gravity models has been\\nintroduced. Based on this idea, we study the ensemble average over\\n(effectively) all the gravity models (constructed from Ricci scalar) dubbing\\nthe name über-gravity which is a {\\\\it{fixed point}} in the model space. The\\nüber-gravity has interesting universal properties, independent from the\\nchoice of basis: $i)$ it mimics Einstein-Hilbert gravity for high-curvature\\nregime, $ii)$ it predicts stronger gravitational force for an\\nintermediate-curvature regime, $iii)$ surprisingly, for low-curvature regime,\\ni.e. $R<R_0$ where $R$ is Ricci scalar and $R_0$ is a given scale, the\\nLagrangian vanishes automatically and $iiii)$ there is a sharp transition\\nbetween low- and intermediate-curvature regimes at $R=R_0$. We show that the\\nüber-gravity response is robust to all values of vacuum energy, $\\\\rho_{vac}$\\nwhen there is no other matter. So as a toy model, über-gravity, gives a way\\nto think about the hierarchy problems e.g. the cosmological constant problem.\\nDue to the transition at $R=R_0$ there is a chance for über-gravity to bypass\\nWeinberg's no-go theorem. The cosmology of this model is also promising because\\nof its non-trivial predictions for small curvature scales in comparison to\\n$\\\\Lambda$CDM model.\\n\",\n",
       " '  We introduce a novel data-driven approach to discover and decode features in\\nthe neural code coming from large population neural recordings with minimal\\nassumptions, using cohomological feature extraction. We apply our approach to\\nneural recordings of mice moving freely in a box, where we find a circular\\nfeature. We then observe that the decoded value corresponds well to the head\\ndirection of the mouse. Thus we capture head direction cells and decode the\\nhead direction from the neural population activity without having to process\\nthe behaviour of the mouse. Interestingly, the decoded values convey more\\ninformation about the neural activity than the tracked head direction does,\\nwith differences that have some spatial organization. Finally, we note that the\\nresidual population activity, after the head direction has been accounted for,\\nretains some low-dimensional structure which is correlated with the speed of\\nthe mouse.\\n',\n",
       " \"  We propose an under-approximate reachability analysis algorithm for programs\\nrunning under the POWER memory model, in the spirit of the work on\\ncontext-bounded analysis intitiated by Qadeer et al. in 2005 for detecting bugs\\nin concurrent programs (supposed to be running under the classical SC model).\\nTo that end, we first introduce a new notion of context-bounding that is\\nsuitable for reasoning about computations under POWER, which generalizes the\\none defined by Atig et al. in 2011 for the TSO memory model. Then, we provide a\\npolynomial size reduction of the context-bounded state reachability problem\\nunder POWER to the same problem under SC: Given an input concurrent program P,\\nour method produces a concurrent program P' such that, for a fixed number of\\ncontext switches, running P' under SC yields the same set of reachable states\\nas running P under POWER. The generated program P' contains the same number of\\nprocesses as P, and operates on the same data domain. By leveraging the\\nstandard model checker CBMC, we have implemented a prototype tool and applied\\nit on a set of benchmarks, showing the feasibility of our approach.\\n\",\n",
       " '  We consider a finite-horizon linear-quadratic optimal control problem where\\nonly a limited number of control messages are allowed for sending from the\\ncontroller to the actuator. To restrict the number of control actions computed\\nand transmitted by the controller, we employ a threshold-based event-triggering\\nmechanism that decides whether or not a control message needs to be calculated\\nand delivered. Due to the nature of threshold-based event-triggering\\nalgorithms, finding the optimal control sequence requires minimizing a\\nquadratic cost function over a non-convex domain. In this paper, we firstly\\nprovide an exact solution to the non-convex problem mentioned above by solving\\nan exponential number of quadratic programs. To reduce computational\\ncomplexity, we, then, propose two efficient heuristic algorithms based on\\ngreedy search and the Alternating Direction Method of Multipliers (ADMM)\\nmethod. Later, we consider a receding horizon control strategy for linear\\nsystems controlled by event-triggered controllers, and we also provide a\\ncomplete stability analysis of receding horizon control that uses finite\\nhorizon optimization in the proposed class. Numerical examples testify to the\\nviability of the presented design technique.\\n',\n",
       " '  Ensembling multiple predictions is a widely-used technique to improve the\\naccuracy of various machine learning tasks. One obvious drawback of the\\nensembling is its higher execution cost during inference. In this paper, we\\nfirst describe our insights on relationship between the probability of the\\nprediction and the effect of ensembling with current deep neural networks;\\nensembling does not help mispredictions for inputs predicted with a high\\nprobability even when there is a non-negligible number of mispredicted inputs.\\nThis finding motivates us to develop a new technique called adaptive ensemble\\nprediction, which achieves the benefits of ensembling with much smaller\\nadditional execution costs. If the prediction for an input reaches a high\\nenough probability on the basis of the confidence level, we stop ensembling for\\nthis input to avoid wasting computation power. We evaluated the adaptive\\nensembling by using various datasets and showed that it reduces the computation\\ncost significantly while achieving similar accuracy to the naive ensembling. We\\nalso showed that our statistically rigorous confidence-level-based termination\\ncondition reduces the burden of the task-dependent parameter tuning compared to\\nthe naive termination based on the pre-defined threshold in addition to\\nyielding a better accuracy with the same cost.\\n',\n",
       " \"  Robot-assisted dressing offers an opportunity to benefit the lives of many\\npeople with disabilities, such as some older adults. However, robots currently\\nlack common sense about the physical implications of their actions on people.\\nThe physical implications of dressing are complicated by non-rigid garments,\\nwhich can result in a robot indirectly applying high forces to a person's body.\\nWe present a deep recurrent model that, when given a proposed action by the\\nrobot, predicts the forces a garment will apply to a person's body. We also\\nshow that a robot can provide better dressing assistance by using this model\\nwith model predictive control. The predictions made by our model only use\\nhaptic and kinematic observations from the robot's end effector, which are\\nreadily attainable. Collecting training data from real world physical\\nhuman-robot interaction can be time consuming, costly, and put people at risk.\\nInstead, we train our predictive model using data collected in an entirely\\nself-supervised fashion from a physics-based simulation. We evaluated our\\napproach with a PR2 robot that attempted to pull a hospital gown onto the arms\\nof 10 human participants. With a 0.2s prediction horizon, our controller\\nsucceeded at high rates and lowered applied force while navigating the garment\\naround a persons fist and elbow without getting caught. Shorter prediction\\nhorizons resulted in significantly reduced performance with the sleeve catching\\non the participants' fists and elbows, demonstrating the value of our model's\\npredictions. These behaviors of mitigating catches emerged from our deep\\npredictive model and the controller objective function, which primarily\\npenalizes high forces.\\n\",\n",
       " \"  The triad census is an important approach to understand local structure in\\nnetwork science, providing comprehensive assessments of the observed relational\\nconfigurations between triples of actors in a network. However, researchers are\\noften interested in combinations of relational and categorical nodal\\nattributes. In this case, it is desirable to account for the label, or color,\\nof the nodes in the triad census. In this paper, we describe an efficient\\nalgorithm for constructing the colored triad census, based, in part, on\\nexisting methods for the classic triad census. We evaluate the performance of\\nthe algorithm using empirical and simulated data for both undirected and\\ndirected graphs. The results of the simulation demonstrate that the proposed\\nalgorithm reduces computational time many-fold over the naive approach. We also\\napply the colored triad census to the Zachary karate club network dataset. We\\nsimultaneously show the efficiency of the algorithm, and a way to conduct a\\nstatistical test on the census by forming a null distribution from 1,000\\nrealizations of a mixing-matrix conditioned graph and comparing the observed\\ncolored triad counts to the expected. From this, we demonstrate the method's\\nutility in our discussion of results about homophily, heterophily, and\\nbridging, simultaneously gained via the colored triad census. In sum, the\\nproposed algorithm for the colored triad census brings novel utility to social\\nnetwork analysis in an efficient package.\\n\",\n",
       " '  The millimeter-wave (mmWave) communication is envisioned to provide orders of\\nmagnitude capacity improvement. However, it is challenging to realize a\\nsufficient link margin due to high path loss and blockages. To address this\\ndifficulty, in this paper, we explore the potential gain of ultra-densification\\nfor enhancing mmWave communications from a network-level perspective. By\\ndeploying the mmWave base stations (BSs) in an extremely dense and amorphous\\nfashion, the access distance is reduced and the choice of serving BSs is\\nenriched for each user, which are intuitively effective for mitigating the\\npropagation loss and blockages. Nevertheless, co-channel interference under\\nthis model will become a performance-limiting factor. To solve this problem, we\\npropose a large-scale channel state information (CSI) based interference\\ncoordination approach. Note that the large-scale CSI is highly\\nlocation-dependent, and can be obtained with a quite low cost. Thus, the\\nscalability of the proposed coordination framework can be guaranteed.\\nParticularly, using only the large-scale CSI of interference links, a\\ncoordinated frequency resource block allocation problem is formulated for\\nmaximizing the minimum achievable rate of the users, which is uncovered to be a\\nNP-hard integer programming problem. To circumvent this difficulty, a greedy\\nscheme with polynomial-time complexity is proposed by adopting the bisection\\nmethod and linear integer programming tools. Simulation results demonstrate\\nthat the proposed coordination scheme based on large-scale CSI only can still\\noffer substantial gains over the existing methods. Moreover, although the\\nproposed scheme is only guaranteed to converge to a local optimum, it performs\\nwell in terms of both user fairness and system efficiency.\\n',\n",
       " '  We study the problem of sampling from a distribution where the negative\\nlogarithm of the target density is $L$-smooth everywhere and $m$-strongly\\nconvex outside a ball of radius $R$, but potentially non-convex inside this\\nball. We study both overdamped and underdamped Langevin MCMC and prove upper\\nbounds on the time required to obtain a sample from a distribution that is\\nwithin $\\\\epsilon$ of the target distribution in $1$-Wasserstein distance. For\\nthe first-order method (overdamped Langevin MCMC), the time complexity is\\n$\\\\tilde{\\\\mathcal{O}}\\\\left(e^{cLR^2}\\\\frac{d}{\\\\epsilon^2}\\\\right)$, where $d$ is\\nthe dimension of the underlying space. For the second-order method (underdamped\\nLangevin MCMC), the time complexity is\\n$\\\\tilde{\\\\mathcal{O}}\\\\left(e^{cLR^2}\\\\frac{\\\\sqrt{d}}{\\\\epsilon}\\\\right)$ for some\\nexplicit positive constant $c$. Surprisingly, the convergence rate is only\\npolynomial in the dimension $d$ and the target accuracy $\\\\epsilon$. It is\\nhowever exponential in the problem parameter $LR^2$, which is a measure of\\nnon-logconcavity of the target distribution.\\n',\n",
       " '  The Sachdev-Ye-Kitaev (SYK) model has become increasingly of great interest\\nin studying exotic non-fermi liquid states without quasiparticle excitations,\\nholography duality to Einstein gravity, and quantum chaos. However, the\\nunnatural form of its Hamiltonian, including its strong randomness and fully\\nnonlocal fermion interaction, makes its experimental investigation an\\nintractable challenge. A promising solution to overcome this challenge is\\nquantum simulation, whose role will be more pronounced particularly in the\\nfuture when more qubits can be handled. We have enough control to demonstrate a\\nfirst step towards quantum simulation of this system. We observed the fermion\\nparing instability of the non-Fermi liquid state and the chaotic-nonchaotic\\ntransition at simulated temperatures, as was predicted by previous theory.\\nThese results demonstrate the feasibility of experimentally simulating the SYK\\nmodel. It opens a new experimental avenue towards investigating the key\\nfeatures of non-Fermi liquid states, as well as the quantum chaotic systems and\\nthe AdS/CFT duality, thanks to the rich physics of the SYK model.\\n',\n",
       " '  A standard belief on emerging collective behavior is that it emerges from\\nsimple individual rules. Most of the mathematical research on such collective\\nbehavior starts from imperative individual rules, like always go to the center.\\nBut how could an (optimal) individual rule emerge during a short period within\\nthe group lifetime, especially if communication is not available. We argue that\\nsuch rules can actually emerge in a group in a short span of time via\\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\\npunishments. We consider the gathering problem: several agents (social animals,\\nswarming robots...) must gather around a same position, which is not determined\\nin advance. They must do so without communication on their planned decision,\\njust by looking at the position of other agents. We present the first\\nexperimental evidence that a gathering behavior can be learned without\\ncommunication in a partially observable environment. The learned behavior has\\nthe same properties as a self-stabilizing distributed algorithm, as processes\\ncan gather from any initial state (and thus tolerate any transient failure).\\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\\\%\\nof agents without significant impact on the behavior.\\n',\n",
       " '  Smartwatches enable many novel applications and are fast gaining popularity.\\nHowever, the presence of a diverse set of on-board sensors provides an\\nadditional attack surface to malicious software and services on these devices.\\nIn this paper, we investigate the feasibility of key press inference attacks on\\nhandheld numeric touchpads by using smartwatch motion sensors as a\\nside-channel. We consider different typing scenarios, and propose multiple\\nattack approaches to exploit the characteristics of the observed wrist\\nmovements for inferring individual key presses. Experimental evaluation using\\ncommercial off-the-shelf smartwatches and smartphones show that key press\\ninference using smartwatch motion sensors is not only fairly accurate, but also\\ncomparable with similar attacks using smartphone motion sensors. Additionally,\\nhand movements captured by a combination of both smartwatch and smartphone\\nmotion sensors yields better inference accuracy than either device considered\\nindividually.\\n',\n",
       " '  We study the cosmological dynamics of D-BIonic and DBI scalar field, which is\\ncoupled to matter fluid. For the exponential potential and the exponential\\ncouplings, we find a new analytic scaling solution yielding the accelerated\\nexpansion of the Universe. Since it is shown to be an attractor for some range\\nof the coupling parameters, the density parameter of matter fluid can be the\\nobserved value, as in the coupled quintessence with a canonical scalar field.\\nContrary to the usual coupled quintessence, where the value of matter couple\\ngiving observed density parameter is too large to satisfy observational\\nconstraint from CMB, we show that the D-BIonic theory can give similar solution\\nwith much smaller value of matter coupling. As a result, together with the fact\\nthat the D-BIonic theory has a screening mechanism, the D-BIonic theory can\\nsolve the so-called coincidence problem as well as the dark energy problem.\\n',\n",
       " '  In 1932, Paul Erdos asked whether a random walk constructed from a binary\\nsequence can achieve the lowest possible deviation (lowest discrepancy), for\\nthe sequence itself and for all its subsequences formed by homogeneous\\narithmetic progressions. Although avoiding low discrepancy is impossible for\\ninfinite sequences, as recently proven by Terence Tao, attempts were made to\\nconstruct such sequences with finite lengths. We recognize that such\\nconstructed sequences (we call these \"Erdos sequences\") exhibit certain\\nhallmarks of randomness at the local level: they show roughly equal frequencies\\nof subsequences, and at the same time exclude the trivial periodic patterns.\\nFor the human DNA we examine the frequency of a set of Erdos motifs of\\nlength-10 using three nucleotides-to-binary mappings. The particular length-10\\nErdos sequence is derived by the length-11 Mathias sequence and is identical\\nwith the first 10 digits of the Thue-Morse sequence, underscoring the fact that\\nboth are deficient in periodicities. Our calculations indicate that: (1) the\\npurine (A and G)/pyridimine (C and T) based Erdos motifs are greatly\\nunderrepresented in the human genome, (2) the strong(G and C)/weak(A and T)\\nbased Erdos motifs are slightly overrepresented, (3) the densities of the two\\nare negatively correlated, (4) the Erdos motifs based on all three mappings\\nbeing combined are slightly underrepresented, and (5) the strong/weak based\\nErdos motifs are greatly overrepresented in the human messenger RNA sequences.\\n',\n",
       " \"  The appearance of rogue waves in deep sea is investigated using the modified\\nnonlinear Schrödinger (MNLS) equation in one spatial-dimension with random\\ninitial conditions that are assumed to be normally distributed, with a spectrum\\napproximating realistic conditions of a uni-directional sea state. It is shown\\nthat one can use the incomplete information contained in this spectrum as prior\\nand supplement this information with the MNLS dynamics to reliably estimate the\\nprobability distribution of the sea surface elevation far in the tail at later\\ntimes. Our results indicate that rogue waves occur when the system hits\\nunlikely pockets of wave configurations that trigger large disturbances of the\\nsurface height. The rogue wave precursors in these pockets are wave patterns of\\nregular height but with a very specific shape that is identified explicitly,\\nthereby allowing for early detection. The method proposed here combines Monte\\nCarlo sampling with tools from large deviations theory that reduce the\\ncalculation of the most likely rogue wave precursors to an optimization problem\\nthat can be solved efficiently. This approach is transferable to other problems\\nin which the system's governing equations contain random initial conditions\\nand/or parameters.\\n\",\n",
       " '  Given a centrally symmetric convex body $K \\\\subset \\\\mathbb{R}^d$ and a\\npositive number $\\\\lambda$, we consider, among all ellipsoids $E \\\\subset\\n\\\\mathbb{R}^d$ of volume $\\\\lambda$, those that best approximate $K$ with respect\\nto the symmetric difference metric, or equivalently that maximize the volume of\\n$E\\\\cap K$: these are the maximal intersection (MI) ellipsoids introduced by\\nArtstein-Avidan and Katzin. The question of uniqueness of MI ellipsoids (under\\nthe obviously necessary assumption that $\\\\lambda$ is between the volumes of the\\nJohn and the Loewner ellipsoids of $K$) is open in general. We provide a\\npositive answer to this question in dimension $d=2$. Therefore we obtain a\\ncontinuous $1$-parameter family of ellipses interpolating between the John and\\nthe Loewner ellipses of $K$. In order to prove uniqueness, we show that the\\narea $I_K(E)$ of the intersection $K \\\\cap E$ is a strictly quasiconcave\\nfunction of the ellipse $E$, with respect to the natural affine structure on\\nthe set of ellipses of area $\\\\lambda$. The proof relies on smoothening $K$,\\nputting it in general position, and obtaining uniform estimates for certain\\nderivatives of the function $I_K(.)$. Finally, we provide a characterization of\\nmaximal intersection positions, that is, the situation where the MI ellipse of\\n$K$ is the unit disk, under the assumption that the two boundaries are\\ntransverse.\\n',\n",
       " '  We offer an alternative and shorter proof to a result by Jan J.Ub{\\\\o}e about\\nmonotonicity properties of a one-dimensional function that appeared in the\\nMathematical Intelligencer in 2015. Our proof is based on reducing the problem\\nto symmetry properties of a two-dimensional surface.\\n',\n",
       " '  We investigate residue-type indices for germs of holomorphic foliations in\\nthe plane and characterize second type foliations - those not containing\\ntangent saddle-nodes in the reduction of singularities - by an expression\\ninvolving the Baum-Bott, variation and polar excess indices. These local\\nresults are applied in the study of logarithmic foliations on compact complex\\nsurfaces.\\n',\n",
       " '  We count the number of distinct (scattered) subwords occurring in the base-b\\nexpansion of the non-negative integers. More precisely, we consider the\\nsequence $(S_b(n))_{n\\\\ge 0}$ counting the number of positive entries on each\\nrow of a generalization of the Pascal triangle to binomial coefficients of\\nbase-$b$ expansions. By using a convenient tree structure, we provide\\nrecurrence relations for $(S_b(n))_{n\\\\ge 0}$ leading to the $b$-regularity of\\nthe latter sequence. Then we deduce the asymptotics of the summatory function\\nof the sequence $(S_b(n))_{n\\\\ge 0}$.\\n',\n",
       " '  A modern notion of integrability is that of multidimensional consistency\\n(MDC), which classically implies the coexistence of (commuting) dynamical flows\\nin several independent variables for one and the same dependent variable. This\\nproperty holds for both continuous dynamical systems as well as for discrete\\nones defined in discrete space-time. Possibly the simplest example in the\\ndiscrete case is that of a linear quadrilateral lattice equation, which can be\\nviewed as a linearised version of the well-known lattice potential Korteweg-de\\nVries (KdV) equation. In spite of the linearity, the MDC property is\\nnon-trivial in terms of the parameters of the system. The Lagrangian aspects of\\nsuch equations, and their nonlinear analogues, has led to the notion of\\nLagrangian multiform structures, where the Lagrangians are no longer scalar\\nfunctions (or volume forms) but genuine forms in a multidimensional space of\\nindependent variables. The variational principle involves variations not only\\nwith respect to the field variables, but also with respect to the geometry in\\nthe space of independent variables. In this paper we consider a quantum\\nanalogue of this new variational principle by means of quantum propagators (or\\nequivalently Feynman path integrals). In the case of quadratic Lagrangians\\nthese can be evaluated in terms of Gaussian integrals. We study also periodic\\nreductions of the lattice leading to discrete multi-time dynamical commuting\\nmappings, the simplest example of which is the discrete harmonic oscillator,\\nwhich surprisingly reveals a rich integrable structure behind it. On the basis\\nof this study we propose a new quantum variational principle in terms of\\nmultiform path integrals.\\n',\n",
       " '  An inner de Sitter region is glued smoothly and consistently with an outer\\nReissner-Nordström (RN) spacetime on a spherical thin-shell. Mass and\\ncharge of the outer RN spacetime are defined by the de Sitter and shell\\nparameters. Radius of the shell plays the role of a cut-off which by virtue of\\nregular de Sitter inside removes the singularity at $r=0.$ The topology of\\ninner de Sitter with the radius of the thin-shell becomes compact. For\\nstability the perturbed shell is shown to satisfy a modified polytropic\\nequation of state which has vanishing mass and pressure on the unperturbed\\nshell as dictated by the junction conditions.\\n',\n",
       " '  The Class 0 protostar, L483, has been observed in various molecular lines in\\nthe 1.2 mm band at a sub-arcsecond resolution with ALMA. An infalling-rotating\\nenvelope is traced by the CS line, while a very compact component with a broad\\nvelocity width is observed for the CS, SO, HNCO, NH$_2$CHO, and HCOOCH$_3$\\nlines. Although this source is regarded as the warm carbon-chain chemistry\\n(WCCC) candidate source at a 1000 au scale, complex organic molecules\\ncharacteristic of hot corinos such as NH$_2$CHO and HCOOCH$_3$ are detected in\\nthe vicinity of the protostar. Thus, both hot corino chemistry and WCCC are\\nseen in L483. Although such a mixed chemical character source has been\\nrecognized as an intermediate source in previous single-dish observations, we\\nhere report the first spatially-resolved detection. A kinematic structure of\\nthe infalling-rotating envelope is roughly explained by a simple ballistic\\nmodel with the protostellar mass of 0.1--0.2 $M_\\\\odot$ and the radius of the\\ncentrifugal barrier (a half of the centrifugal radius) of 30--200 au, assuming\\nthe inclination angle of 80\\\\degr\\\\ (0\\\\degr\\\\ for a face-on). The broad line\\nemission observed in the above molecules most likely comes from the disk\\ncomponent inside the centrifugal barrier. Thus, a drastic chemical change is\\nseen around the centrifugal barrier.\\n',\n",
       " '  In this note we observe that one can contact embed all contact 3-manifolds\\ninto a Stein fillable contact structure on the twisted $S^3$-bundle over $S^2$\\nand also into a unique overtwisted contact structure on $S^3\\\\times S^2$. These\\nresults are proven using \"spun embeddings\" and Lefschetz fibrations.\\n',\n",
       " '  We empirically verify that the market capitalisations of coins and tokens in\\nthe cryptocurrency universe follow power-law distributions with significantly\\ndifferent values, with the tail exponent falling between 0.5 and 0.7 for coins,\\nand between 1.0 and 1.3 for tokens. We provide a rationale for this, based on a\\nsimple proportional growth with birth & death model previously employed to\\ndescribe the size distribution of firms, cities, webpages, etc. We empirically\\nvalidate the model and its main predictions, in terms of proportional growth\\n(Gibrat\\'s law) of the coins and tokens. Estimating the main parameters of the\\nmodel, the theoretical predictions for the power-law exponents of coin and\\ntoken distributions are in remarkable agreement with the empirical estimations,\\ngiven the simplicity of the model. Our results clearly characterize coins as\\nbeing \"entrenched incumbents\" and tokens as an \"explosive immature ecosystem\",\\nlargely due to massive and exuberant Initial Coin Offering activity in the\\ntoken space. The theory predicts that the exponent for tokens should converge\\nto 1 in the future, reflecting a more reasonable rate of new entrants\\nassociated with genuine technological innovations.\\n',\n",
       " '  The spectral radius of the adjacency matrix can impact both algorithmic\\nefficiency as well as the stability of solutions to an underlying dynamical\\nprocess. Although much research has considered the distribution of the spectral\\nradius for undirected random graph models, as symmetric adjacency matrices are\\namenable to spectral analysis, very little work has focused on directed graphs.\\nConsequently, we provide novel concentration results for the spectral radius of\\nthe directed Chung-Lu random graph model. We emphasize that our concentration\\nresults are applicable both asymptotically and to networks of finite size.\\nSubsequently, we extend our concentration results to a generalization of the\\ndirected Chung-Lu model that allows for community structure.\\n',\n",
       " '  Thin films of cerium dioxide (CeO2) were deposited by atomic layer deposition\\n(ALD) at 250 °C on both Si and TiN substrates. The ALD growth produces\\nCeO2 films with polycrystalline cubic phase on both substrates. However, the\\nfilms show a preferential orientation along <200> crystallographic direction\\nfor CeO2/Si or <111> for CeO2/TiN, as revealed by X-ray diffraction.\\nAdditionally, CeO2 films differ in interface roughness depending on the\\nsubstrate. Furthermore, the relative concentration of Ce3+ is 22.0% in CeO2/Si\\nand around 18% in CeO2/TiN, as obtained by X-ray photoelectron spectroscopy\\n(XPS). Such values indicate a ~10% off-stoichiometry and are indicative of the\\npresence of oxygen vacancies in the films. Nonetheless, CeO2 bandgap energy and\\nrefractive index at 550 nm are 3.54+/-0.63 eV and 2.3 for CeO2/Si, and\\n3.63+/-0.18 eV and 2.4 for CeO2/TiN, respectively. Our results extend the\\nknowledge on the structural and chemical properties of ALD-deposited CeO2\\neither on Si or TiN substrates, underlying films differences and similarities,\\nthus contributing to boost the use of CeO2 through ALD deposition as foreseen\\nin a wide number of applications.\\n',\n",
       " '  A method has been developed for the analysis of images of sentinel lymph\\nnodes generated by a spectral scanning device. The aim is to classify the\\nnodes, excised during surgery for breast cancer, as normal or metastatic. The\\ndata from one node constitute spectra at 86 wavelengths for each pixel of a\\n20*20 grid. For the analysis, the spectra are reduced to scores on two factors,\\none derived externally from a linear discriminant analysis using spectra taken\\nmanually from known normal and metastatic tissue, and one derived from the node\\nunder investigation to capture variability orthogonal to the external factor.\\nThen a three-group mixture model (normal, metastatic, non-nodal background)\\nusing multivariate t distributions is fitted to the scores, with external data\\nbeing used to specify informative prior distributions for the parameters of the\\nthree distributions. A Markov random field prior imposes smoothness on the\\nimage generated by the model. Finally, the node is classified as metastatic if\\nany one pixel in this smoothed image is classified as metastatic. The model\\nparameters were tuned on a training set of nodes, and then the tuned model was\\ntested on a separate validation set of nodes, achieving satisfactory\\nsensitivity and specificity. The aim in developing the analysis was to allow\\nflexibility in the way each node is modelled whilst still using external\\ninformation. The Bayesian framework employed is ideal for this.\\n',\n",
       " '  We present a report of the MEG II experiment, the upgrade of MEG, whose goal\\nis to search for the forbidden decay \\\\megc\\\\ with increased precision. After\\nhaving briefly reviewed the motivation for such a search and the current limit\\ndue to MEG, we present the conceptual design of the detector detailing for each\\nsubdetector the motivations and the extent of the upgrade and the expected\\nresolution improvements. Novel subdetectors and calibration hardware are\\nintroduced. We conclude with the expected sensitivity of the MEGII experiment.\\n',\n",
       " '  The Generative Adversarial Networks (GANs) have demonstrated impressive\\nperformance for data synthesis, and are now used in a wide range of computer\\nvision tasks. In spite of this success, they gained a reputation for being\\ndifficult to train, what results in a time-consuming and human-involved\\ndevelopment process to use them.\\nWe consider an alternative training process, named SGAN, in which several\\nadversarial \"local\" pairs of networks are trained independently so that a\\n\"global\" supervising pair of networks can be trained against them. The goal is\\nto train the global pair with the corresponding ensemble opponent for improved\\nperformances in terms of mode coverage. This approach aims at increasing the\\nchances that learning will not stop for the global pair, preventing both to be\\ntrapped in an unsatisfactory local minimum, or to face oscillations often\\nobserved in practice. To guarantee the latter, the global pair never affects\\nthe local ones.\\nThe rules of SGAN training are thus as follows: the global generator and\\ndiscriminator are trained using the local discriminators and generators,\\nrespectively, whereas the local networks are trained with their fixed local\\nopponent.\\nExperimental results on both toy and real-world problems demonstrate that\\nthis approach outperforms standard training in terms of better mitigating mode\\ncollapse, stability while converging and that it surprisingly, increases the\\nconvergence speed as well.\\n',\n",
       " \"  It is widely believed that the backpropagation algorithm is essential for\\nlearning good feature detectors in early layers of artificial neural networks,\\nso that these detectors are useful for the task performed by the higher layers\\nof that neural network. At the same time, the traditional form of\\nbackpropagation is biologically implausible. In the present paper we propose an\\nunusual learning rule, which has a degree of biological plausibility, and which\\nis motivated by Hebb's idea that change of the synapse strength should be local\\n- i.e. should depend only on the activities of the pre and post synaptic\\nneurons. We design a learning algorithm that utilizes global inhibition in the\\nhidden layer, and is capable of learning early feature detectors in a\\ncompletely unsupervised way. These learned lower layer feature detectors can be\\nused to train higher layer weights in a usual supervised way so that the\\nperformance of the full network is comparable to the performance of standard\\nfeedforward networks trained end-to-end with a backpropagation algorithm.\\n\",\n",
       " '  We define an admissibility condition for abstractions expressed using angelic\\nsemantics and show that these conditions allow us to accelerate planning while\\npreserving the ability to find the optimal motion plan. We then derive\\nadmissible abstractions for two motion planning domains with continuous state.\\nWe extract upper and lower bounds on the cost of concrete motion plans using\\nlocal metric and topological properties of the problem domain. These bounds\\nguide the search for a plan while maintaining performance guarantees. We show\\nthat abstraction can dramatically reduce the complexity of search relative to a\\ndirect motion planner. Using our abstractions, we find near-optimal motion\\nplans in planning problems involving $10^{13}$ states without using a separate\\ntask planner.\\n',\n",
       " \"  Internet of Things (IoT) applications typically collect and analyse personal\\ndata that can be used to derive sensitive information about individuals.\\nHowever, thus far, privacy concerns have not been explicitly considered in\\nsoftware engineering processes when designing IoT applications. In this paper,\\nwe explore how a Privacy-by-Design (PbD) framework, formulated as a set of\\nguidelines, can help software engineers to design privacy-aware IoT\\napplications. We studied the utility of our proposed PbD framework by studying\\nhow software engineers use it to design IoT applications. We also explore the\\nchallenges in using set of guidelines to influence the IoT applications design\\nprocess. This paper also highlights the benefits of providing a framework that\\nhelps software engineers explicitly consider privacy for IoT applications and\\nalso surfaced a number of challenges associated with our approach. Our studies\\nshow that PbD framework significantly increase both novice and expert software\\nengineers' ability to design privacy aware IoT applications.\\n\",\n",
       " '  We evaluate two methods of signalling abrupt direction changes of a robotic\\nplatform using a Mixed Reality avatar. The \"Body\" method uses gaze, gesture and\\ntorso direction to point to upcoming waypoints. The \"Path\" method visualises\\nthe change in direction using an angled path on the ground. We compare these\\ntwo methods using a controlled user study and show that each method has its\\nstrengths depending on the situation. Overall the \"Path\" method was slightly\\nmore accurate in communicating the direction change of the robot but\\nparticipants overall preferred the \"Body\" method.\\n',\n",
       " '  The magnetic field response of the Mott-insulating honeycomb iridate\\nNa$_{2}$IrO$_{3}$ is investigated using torque magnetometry measurements in\\nmagnetic fields up to 60 tesla. A peak-dip structure is observed in the torque\\nresponse at magnetic fields corresponding to an energy scale close to the\\nzigzag ordering ($\\\\approx 15~K$) temperature. Using exact diagonalization\\ncalculations, we show that such a distinctive signature in the torque response\\nconstrains the effective spin models for these classes of Kitaev materials to\\nones with dominant ferromagnetic Kitaev interactions, while alternative models\\nwith dominant antiferromagnetic Kitaev interactions are excluded. We further\\nshow that at high magnetic fields, long range spin correlation functions decay\\nrapidly, signaling a transition to a long-sought-after field-induced quantum\\nspin liquid beyond the peak-dip structure. Kitaev systems are thus revealed to\\nbe excellent candidates for field-induced quantum spin liquids, similar physics\\nhaving been suggested in another Kitaev material $\\\\alpha-$RuCl$_{3}$.\\n',\n",
       " '  The spin polarization of electrons from multiphoton ionization of Xe by 395\\nnm circularly polarized laser pulses at $6\\\\cdot10^{13}$ W/cm$^2$ has been\\nmeasured. At this photon energy of 3.14 eV the above threshold ionization peaks\\nconnected to Xe$^+$ ions in the ground state ($J=3/2$, ionization potential\\n$I_p=12.1$ eV) and the first exicted state ($J=1/2$, $I_p=13.4$ eV) are clearly\\nseparated in the electron energy distribution. These two combs of ATI peaks\\nshow opposite spin polarizations. The magnitude of the spin polarization is a\\nfactor of two higher for the $J=1/2$ than for the $J=3/2$ final ionic state. In\\nturn the data show that the ionization probability is strongly dependent on the\\nsign of the magnetic quantum number.\\n',\n",
       " '  It has been demonstrated that deep neural networks are prone to noisy\\nexamples particular adversarial samples during inference process. The gap\\nbetween robust deep learning systems in real world applications and vulnerable\\nneural networks is still large. Current adversarial training strategies improve\\nthe robustness against adversarial samples. However, these methods lead to\\naccuracy reduction when the input examples are clean thus hinders the\\npracticability. In this paper, we investigate an approach that protects the\\nneural network classification from the adversarial samples and improves its\\naccuracy when the input examples are clean. We demonstrate the versatility and\\neffectiveness of our proposed approach on a variety of different networks and\\ndatasets.\\n',\n",
       " '  In this paper, a simple method is proposed to extend the photon energy range\\nof a soft x-ray self-seeding free-electron laser (FEL). A normal monochromator\\nis first applied to purify the FEL spectrum and provide a coherent seeding\\nsignal. This coherent signal then interacts with the electron beam in the\\nfollowing reverse tapered undulator section to generate strong coherent\\nmicrobunchings while maintain the good quality of the electron beam. After\\nthat, the pre-bunched electron beam is sent into the third undulator section\\nwhich resonates at a target high harmonic of the seed to amplify the coherent\\nradiation at shorter wavelength. Three dimensional simulations have been\\nperformed and the results demonstrate that the photon energy gap between 1.5\\nkeV and 4.5 keV of the self-seeding scheme can be fully covered and 100\\nGW-level peak power can be achieved by using the proposed technique.\\n',\n",
       " \"  Nowadays, computation is playing an increasingly more important role in the\\nfuture generation of computer and communication networks, as exemplified by the\\nrecent progress in software defined networking (SDN) for wired networks as well\\nas cloud radio access networks (C-RAN) and mobile cloud computing (MCC) for\\nwireless networks. This paper proposes a unified concept, i.e., computation\\ndiversity, to describe the impact and diverse forms of the computation\\nresources on both wired and wireless communications. By linking the computation\\nresources to the communication networks based on quality of service (QoS)\\nrequirements, we can show how computation resources influence the networks.\\nMoreover, by analyzing the different functionalities of computation resources\\nin SDN, C-RAN, and MCC, we can show diverse and flexible form that the\\ncomputation resources present in different networks. The study of computation\\ndiversity can provide guidance to the future networks design, i.e., how to\\nallocate the resources jointly between computation (e.g., CPU capacity) and\\ncommunication (e.g., bandwidth), and thereby saving system energy and increase\\nusers' experiences.\\n\",\n",
       " '  A central issue in the theory of extreme values focuses on suitable\\nconditions such that the well-known results for the limiting distributions of\\nthe maximum of i.i.d. sequences can be applied to stationary ones. In this\\ncontext, the extremal index appears as a key parameter to capture the effect of\\ntemporal dependence on the limiting distribution of the maxima. The\\nmultivariate extremal index corresponds to a generalization of this concept to\\na multivariate context and affects the tail dependence structure within the\\nmarginal sequences and between them. As it is a function, the inference becomes\\nmore difficult, and it is therefore important to obtain characterizations,\\nnamely bounds based on the marginal dependence that are easier to estimate. In\\nthis work we present two decompositions that emphasize different types of\\ninformation contained in the multivariate extremal index, an upper limit better\\nthan those found in the literature and we analyze its role in dependence on the\\nlimiting model of the componentwise maxima of a stationary sequence. We will\\nillustrate the results with examples of recognized interest in applications.\\n',\n",
       " '  We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for\\nsolving the Gross-Pitaevskii (GP) equation for a Bose-Einstein condensate in\\none, two, and three spatial dimensions, optimized for use with GNU and Intel\\ncompilers. We use the split-step Crank-Nicolson algorithm for imaginary- and\\nreal-time propagation, which enables efficient calculation of stationary and\\nnon-stationary solutions, respectively. The present OpenMP programs are\\ndesigned for computers with multi-core processors and optimized for compiling\\nwith both commercially-licensed Intel Fortran and popular free open-source GNU\\nFortran compiler. The programs are easy to use and are elaborated with helpful\\ncomments for the users. All input parameters are listed at the beginning of\\neach program. Different output files provide physical quantities such as\\nenergy, chemical potential, root-mean-square sizes, densities, etc. We also\\npresent speedup test results for new versions of the programs.\\n',\n",
       " '  We provide precise formulations and proofs of two theorems from Darboux\\'s\\nlectures on orthogonal systems. These results provide local existence and\\nuniqueness of solutions to certain types of first order PDE systems where each\\nequation contains a single derivative for which it is solved: \\\\[\\\\frac{\\\\partial\\nu_i}{\\\\partial x_j}(x)=f_{ij}(x,u(x)).\\\\] The data prescribe values for the\\nunknowns $u_i$ along certain hyperplanes through a given point $\\\\bar x$.\\nThe first theorem applies to determined systems (the number of equations\\nequals the number unknowns), and a unique, local solution is obtained via\\nPicard iteration. While Darboux\\'s statement of the theorem leaves unspecified\\n\"certaines conditions de continuité,\" it is clear from his proof that he\\nassumes Lipschitz continuity of the maps $f_{ij}$. On the other hand, he did\\nnot address the regularity of the data. We provide a precise formulation and\\nproof of his first theorem.\\nThe second theorem is more involved and applies to overdetermined systems of\\nthe same general form. Under the appropriate integrability conditions, Darboux\\nused his first theorem to treat the cases with two and three independent\\nvariables. We provide a proof for any number of independent variables.\\nWhile the systems are rather special, they do appear in applications; e.g.,\\nthe second theorem contains the classical Frobenius theorem on overdetermined\\nsystems as a special case. The key aspect of the proofs is that they apply to\\nnon-analytic situations. In an analytic setup the results are covered by the\\ngeneral Cartan-Kähler theorem.\\n',\n",
       " '  In this paper, we present a method for identifying infeasible, unbounded, and\\npathological conic programs based on Douglas-Rachford splitting, or\\nequivalently ADMM. When an optimization program is infeasible, unbounded, or\\npathological, the iterates of Douglas-Rachford splitting diverge. Somewhat\\nsurprisingly, such divergent iterates still provide useful information, which\\nour method uses for identification. In addition, for strongly infeasible\\nproblems the method produces a separating hyperplane and informs the user on\\nhow to minimally modify the given problem to achieve strong feasibility. As a\\nfirst-order method, the proposed algorithm relies on simple subroutines, and\\ntherefore is simple to implement and has low per-iteration cost.\\n',\n",
       " '  This paper studies identification, estimation, and inference of quantile\\ntreatment effects in the fuzzy regression kink design with a binary treatment\\nvariable. We first show the identification of conditional quantile treatment\\neffects given the event of local compliance. We then propose a bootstrap method\\nof uniform inference for the local quantile process. This bootstrap method is\\nfast and is robust against common optimal choices of bandwidth parameters. We\\nprovide practical guidelines as well as a formal theory. Simulation studies\\nshow accurate coverage probabilities for tests of uniform treatment\\nsignificance and treatment heterogeneity.\\n',\n",
       " '  Generalized linear models (GLMs) arise in high-dimensional machine learning,\\nstatistics, communications and signal processing. In this paper we analyze GLMs\\nwhen the data matrix is random, as relevant in problems such as compressed\\nsensing, error-correcting codes or benchmark models in neural networks. We\\nevaluate the mutual information (or \"free entropy\") from which we deduce the\\nBayes-optimal estimation and generalization errors. Our analysis applies to the\\nhigh-dimensional limit where both the number of samples and the dimension are\\nlarge and their ratio is fixed. Non-rigorous predictions for the optimal errors\\nexisted for special cases of GLMs, e.g. for the perceptron, in the field of\\nstatistical physics based on the so-called replica method. Our present paper\\nrigorously establishes those decades old conjectures and brings forward their\\nalgorithmic interpretation in terms of performance of the generalized\\napproximate message-passing algorithm. Furthermore, we tightly characterize,\\nfor many learning problems, regions of parameters for which this algorithm\\nachieves the optimal performance, and locate the associated sharp phase\\ntransitions separating learnable and non-learnable regions. We believe that\\nthis random version of GLMs can serve as a challenging benchmark for\\nmulti-purpose algorithms. This paper is divided in two parts that can be read\\nindependently: The first part (main part) presents the model and main results,\\ndiscusses some applications and sketches the main ideas of the proof. The\\nsecond part (supplementary informations) is much more detailed and provides\\nmore examples as well as all the proofs.\\n',\n",
       " \"  Recommendation is the task of improving customer experience through\\npersonalized recommendation based on users' past feedback. In this paper, we\\ninvestigate the most common scenario: the user-item (U-I) matrix of implicit\\nfeedback. Even though many recommendation approaches are designed based on\\nimplicit feedback, they attempt to project the U-I matrix into a low-rank\\nlatent space, which is a strict restriction that rarely holds in practice. In\\naddition, although misclassification costs from imbalanced classes are\\nsignificantly different, few methods take the cost of classification error into\\naccount. To address aforementioned issues, we propose a robust framework by\\ndecomposing the U-I matrix into two components: (1) a low-rank matrix that\\ncaptures the common preference, and (2) a sparse matrix that detects the\\nuser-specific preference of individuals. A cost-sensitive learning model is\\nembedded into the framework. Specifically, this model exploits different costs\\nin the loss function for the observed and unobserved instances. We show that\\nthe resulting non-smooth convex objective can be optimized efficiently by an\\naccelerated projected gradient method with closed-form solutions. Morever, the\\nproposed algorithm can be scaled up to large-sized datasets after a relaxation.\\nThe theoretical result shows that even with a small fraction of 1's in the U-I\\nmatrix $M\\\\in\\\\mathbb{R}^{n\\\\times m}$, the cost-sensitive error of the proposed\\nmodel is upper bounded by $O(\\\\frac{\\\\alpha}{\\\\sqrt{mn}})$, where $\\\\alpha$ is a\\nbias over imbalanced classes. Finally, empirical experiments are extensively\\ncarried out to evaluate the effectiveness of our proposed algorithm.\\nEncouraging experimental results show that our algorithm outperforms several\\nstate-of-the-art algorithms on benchmark recommendation datasets.\\n\",\n",
       " \"  When modeling network data using a latent position model, it is typical to\\nassume that all nodes' latent positions are independently and identically\\ndistributed. However, this assumption implies the average node degree grows\\nlinearly with the number of nodes, which is inappropriate when the graph is\\nthought to be sparse. We propose an alternative assumption--- that the latent\\npositions are generated according to a Poisson point process--- and show that\\nit is compatible with various levels of sparsity. Unlike other sparse latent\\nposition models, our approach also defines a projective family of probability\\ndistributions, ensuring statistical inference and prediction are well-defined\\nfor networks of different sizes. We establish conditions for consistently\\ninferring the latent positions in a latent position network model, and compare\\nour results to those of existing frameworks for modeling sparse graphs.\\n\",\n",
       " '  This work is about recognizing human activities occurring in videos at\\ndistinct semantic levels, including individual actions, interactions, and group\\nactivities. The recognition is realized using a two-level hierarchy of Long\\nShort-Term Memory (LSTM) networks, forming a feed-forward deep architecture,\\nwhich can be trained end-to-end. In comparison with existing architectures of\\nLSTMs, we make two key contributions giving the name to our approach as\\nConfidence-Energy Recurrent Network -- CERN. First, instead of using the common\\nsoftmax layer for prediction, we specify a novel energy layer (EL) for\\nestimating the energy of our predictions. Second, rather than finding the\\ncommon minimum-energy class assignment, which may be numerically unstable under\\nuncertainty, we specify that the EL additionally computes the p-values of the\\nsolutions, and in this way estimates the most confident energy minimum. The\\nevaluation on the Collective Activity and Volleyball datasets demonstrates: (i)\\nadvantages of our two contributions relative to the common softmax and\\nenergy-minimization formulations and (ii) a superior performance relative to\\nthe state-of-the-art approaches.\\n',\n",
       " '  A diverse white matter network and finely tuned neuronal membrane properties\\nallow the brain to transition seamlessly between cognitive states. However, it\\nremains unclear how static structural connections guide the temporal\\nprogression of large-scale brain activity patterns in different cogni- tive\\nstates. Here, we deploy an unsupervised machine learning algorithm to define\\nbrain states as time point level activity patterns from functional magnetic\\nresonance imaging data acquired dur- ing passive visual fixation (rest) and an\\nn-back working memory task. We find that brain states are composed of\\ninterdigitated functional networks and exhibit context-dependent dynamics.\\nUsing diffusion-weighted imaging acquired from the same subjects, we show that\\nstructural connectivity constrains the temporal progression of brain states. We\\nalso combine tools from network control theory with geometrically conservative\\nnull models to demonstrate that brains are wired to sup- port states of high\\nactivity in default mode areas, while requiring relatively low energy. Finally,\\nwe show that brain state dynamics change throughout development and explain\\nworking mem- ory performance. Overall, these results elucidate the structural\\nunderpinnings of cognitively and developmentally relevant spatiotemporal brain\\ndynamics.\\n',\n",
       " '  The polyhedron projection for 360-degree video is becoming more and more\\npopular since it can lead to much less geometry distortion compared with the\\nequirectangular projection. However, in the polyhedron projection, we can\\nobserve very obvious texture discontinuity in the area near the face boundary.\\nSuch a texture discontinuity may lead to serious quality degradation when\\nmotion compensation crosses the discontinuous face boundary. To solve this\\nproblem, in this paper, we first propose to fill the corresponding neighboring\\nfaces in the suitable positions as the extension of the current face to keep\\napproximated texture continuity. Then a co-projection-plane based 3-D padding\\nmethod is proposed to project the reference pixels in the neighboring face to\\nthe current face to guarantee exact texture continuity. Under the proposed\\nscheme, the reference pixel is always projected to the same plane with the\\ncurrent pixel when performing motion compensation so that the texture\\ndiscontinuity problem can be solved. The proposed scheme is implemented in the\\nreference software of High Efficiency Video Coding. Compared with the existing\\nmethod, the proposed algorithm can significantly improve the rate-distortion\\nperformance. The experimental results obviously demonstrate that the texture\\ndiscontinuity in the face boundary can be well handled by the proposed\\nalgorithm.\\n',\n",
       " '  Interbank lending and borrowing occur when financial institutions seek to\\nsettle and refinance their mutual positions over time and circumstances. This\\ninteractive process involves money creation at the aggregate level.\\nCoordination mismatch on interbank credit may trigger systemic crises. This\\nhappened when, since summer 2007, interbank credit coordination did not longer\\nwork smoothly across financial institutions, eventually requiring exceptional\\nmonetary policies by central banks, and guarantee and bailout interventions by\\ngovernments. Our article develops an interacting heterogeneous agents-based\\nmodel of interbank credit coordination under minimal institutions. First, we\\nexplore the link between interbank credit coordination and the money generation\\nprocess. Contrary to received understanding, interbank credit has the capacity\\nto make the monetary system unbound. Second, we develop simulation analysis on\\nimperfect interbank credit coordination, studying impact of interbank dynamics\\non financial stability and resilience at individual and aggregate levels.\\nSystemically destabilizing forces prove to be related to the working of the\\nbanking system over time, especially interbank coordination conditions and\\ncircumstances.\\n',\n",
       " '  A $k$-ranking of a directed graph $G$ is a labeling of the vertex set of $G$\\nwith $k$ positive integers such that every directed path connecting two\\nvertices with the same label includes a vertex with a larger label in between.\\nThe rank number of $G$ is defined to be the smallest $k$ such that $G$ has a\\n$k$-ranking. We find the largest possible directed graph that can be obtained\\nfrom a directed path or a directed cycle by attaching new edges to the vertices\\nsuch that the new graphs have the same rank number as the original graphs. The\\nadjacency matrix of the resulting graph is embedded in the Sierpiński\\ntriangle.\\nWe present a connection between the number of edges that can be added to\\npaths and the Stirling numbers of the second kind. These results are\\ngeneralized to create directed graphs which are unions of directed paths and\\ndirected cycles that maintain the rank number of a base graph of a directed\\npath or a directed cycle.\\n',\n",
       " '  Chondrules in primitive meteorites likely formed by recrystallisation of dust\\naggregates that were flash-heated to nearly complete melting. Chondrules may\\nrepresent the building blocks of rocky planetesimals and protoplanets in the\\ninner regions of protoplanetary discs, but the source of ubiquitous thermal\\nprocessing of their dust aggregate precursors remains elusive. Here we\\ndemonstrate that escape of positrons released in the decay of the short-lived\\nradionuclide $^{26}$Al leads to a large-scale charging of dense pebble\\nstructures, resulting in neutralisation by lightning discharge and\\nflash-heating of dust and pebbles. This charging mechanism is similar to a\\nnuclear battery where a radioactive source charges a capacitor. We show that\\nthe nuclear battery effect operates in circumplanetesimal pebble discs. The\\nextremely high pebble densities in such discs are consistent with conditions\\nduring chondrule heating inferred from the high abundance of sodium within\\nchondrules. The sedimented mid-plane layer of the protoplanetary disc may also\\nbe prone to charging by the emission of positrons, if the mass density of small\\ndust there is at least an order of magnitude above the gas density. Our results\\nimply that the decay energy of $^{26}$Al can be harvested to drive intense\\nlightning activity in protoplanetary discs. The total energy stored in positron\\nemission is comparable to the energy needed to melt all solids in the\\nprotoplanetary disc. The efficiency of transferring the positron energy to the\\nelectric field nevertheless depends on the relatively unknown distribution and\\nscale-dependence of pebble density gradients in circumplanetesimal pebble discs\\nand in the protoplanetary disc mid-plane layer.\\n',\n",
       " '  Despite years of research, understanding of the space radiation environment\\nand the risk it poses to long-duration astronauts remains limited. There is a\\ndisparity between research results and observed empirical effects seen in human\\nastronaut crews, likely due to the numerous factors that limit terrestrial\\nsimulation of the complex space environment and extrapolation of human clinical\\nconsequences from varied animal models. Given the intended future of human\\nspaceflight, with efforts now to rapidly expand capabilities for human missions\\nto the moon and Mars, there is a pressing need to improve upon the\\nunderstanding of the space radiation risk, predict likely clinical outcomes of\\ninterplanetary radiation exposure, and develop appropriate and effective\\nmitigation strategies for future missions. To achieve this goal, the space\\nradiation and aerospace community must recognize the historical limitations of\\nradiation research and how such limitations could be addressed in future\\nresearch endeavors. We have sought to highlight the numerous factors that limit\\nunderstanding of the risk of space radiation for human crews and to identify\\nways in which these limitations could be addressed for improved understanding\\nand appropriate risk posture regarding future human spaceflight.\\n',\n",
       " '  We describe the Customer LifeTime Value (CLTV) prediction system deployed at\\nASOS.com, a global online fashion retailer. CLTV prediction is an important\\nproblem in e-commerce where an accurate estimate of future value allows\\nretailers to effectively allocate marketing spend, identify and nurture high\\nvalue customers and mitigate exposure to losses. The system at ASOS provides\\ndaily estimates of the future value of every customer and is one of the\\ncornerstones of the personalised shopping experience. The state of the art in\\nthis domain uses large numbers of handcrafted features and ensemble regressors\\nto forecast value, predict churn and evaluate customer loyalty. Recently,\\ndomains including language, vision and speech have shown dramatic advances by\\nreplacing handcrafted features with features that are learned automatically\\nfrom data. We detail the system deployed at ASOS and show that learning feature\\nrepresentations is a promising extension to the state of the art in CLTV\\nmodelling. We propose a novel way to generate embeddings of customers, which\\naddresses the issue of the ever changing product catalogue and obtain a\\nsignificant improvement over an exhaustive set of handcrafted features.\\n',\n",
       " '  In this paper, we propose a solution of fractional logistic equation by using\\nproperties of Mittag-Leffler function.\\n',\n",
       " \"  Let $(M,g)$ be a compact, 2-dimensional Riemannian manifold with nonpositive\\nsectional curvature. Let $\\\\Delta_g$ be the Laplace-Beltrami operator\\ncorresponding to the metric $g$ on $M$, and let $e_\\\\lambda$ be $L^2$-normalized\\neigenfunctions of $\\\\Delta_g$ with eigenvalue $\\\\lambda$, i.e. \\\\[ -\\\\Delta_g\\ne_\\\\lambda = \\\\lambda^2 e_\\\\lambda. \\\\] We prove \\\\[ \\\\left| \\\\int_{\\\\mathbb R} b(t)\\ne_\\\\lambda (\\\\gamma(t)) \\\\, dt \\\\right| = o(1) \\\\quad \\\\text{ as } \\\\lambda \\\\to \\\\infty\\n\\\\] where $b$ is a smooth, compactly supported function on $\\\\mathbb R$ and\\n$\\\\gamma$ is a curve parametrized by arc-length whose geodesic curvature\\n$\\\\kappa(\\\\gamma(t))$ avoids two critical curvatures $\\\\mathbf\\nk(\\\\gamma'^\\\\perp(t))$ and $\\\\mathbf k(-\\\\gamma'^{\\\\perp}(t))$ for each $t \\\\in\\n\\\\operatorname{supp} b$. $\\\\mathbf k(v)$ denotes the curvature of a circle with\\ncenter taken to infinity along the geodesic ray in direction $-v$.\\n\",\n",
       " '  We study the problem of identifying a probability distribution for some given\\nrandomly sampled data in the limit, in the context of algorithmic learning\\ntheory as proposed recently by Vinanyi and Chater. We show that there exists a\\ncomputable partial learner for the computable probability measures, while by\\nBienvenu, Monin and Shen it is known that there is no computable learner for\\nthe computable probability measures. Our main result is the characterization of\\nthe oracles that compute explanatory learners for the computable (continuous)\\nprobability measures as the high oracles. This provides an analogue of a\\nwell-known result of Adleman and Blum in the context of learning computable\\nprobability distributions. We also discuss related learning notions such as\\nbehaviorally correct learning and orther variations of explanatory learning, in\\nthe context of learning probability distributions from data.\\n',\n",
       " '  In this paper we consider the $15$-dimensional homogeneous variety of Picard\\nnumber one ${\\\\rm F}_4(4)$, and provide a characterization of it in terms of its\\nvarieties of minimal rational tangents.\\n',\n",
       " '  This paper presents a new result on strong-consistency, in the trace norm, of\\na diagonal componentwise parameter estimator of the autocorrelation operator of\\nan autoregressive process of order one (ARH(1) process), allowing\\nstrong-consistency of the associated plug-in predictor. These results are\\nderived, when the eigenvectors of the autocovariance operator are unknown, and\\nthe autocorrelation operator does not admit a diagonal spectral representation\\nwith respect to the eigenvectors of the autocovariance operator.\\n',\n",
       " '  From what is known today about the elementary particles of matter, and the\\nforces that control their behavior, it may be observed that still a host of\\nobstacles must be overcome that are standing in the way of further progress of\\nour understanding. Most researchers conclude that drastically new concepts must\\nbe investigated, new starting points are needed, older structures and theories,\\nin spite of their successes, will have to be overthrown, and new,\\nsuperintelligent questions will have to be asked and investigated. In short,\\nthey say that we shall need new physics. Here, we argue in a different manner.\\nToday, no prototype, or toy model, of any so-called Theory of Everything\\nexists, because the demands required of such a theory appear to be conflicting.\\nThe demands that we propose include locality, special and general relativity,\\ntogether with a fundamental finiteness not only of the forces and amplitudes,\\nbut also of the set of Nature\\'s dynamical variables. We claim that the two\\nremaining ingredients that we have today, Quantum Field Theory and General\\nRelativity, indeed are coming a long way towards satisfying such elementary\\nrequirements. Putting everything together in a Grand Synthesis is like solving\\na gigantic puzzle. We argue that we need the correct analytical tools to solve\\nthis puzzle. Finally, it seems to be obvious that this solution will give room\\nneither for \"Divine Intervention\", nor for \"Free Will\", an observation that,\\nall by itself, can be used as a clue. We claim that this reflects on our\\nunderstanding of the deeper logic underlying quantum mechanics.\\n',\n",
       " '  Short term unpredictability is discovered numerically for high Reynolds\\nnumber fluid flows under periodic boundary conditions. Furthermore, the\\nabundance of the short term unpredictability is also discovered. These\\ndiscoveries support our theory that fully developed turbulence is constantly\\ndriven by such short term unpredictability.\\n',\n",
       " '  We present a new Bayesian algorithm making use of Markov Chain Monte Carlo\\nsampling that allows us to simultaneously estimate the unknown continuum level\\nof each quasar in an ensemble of high-resolution spectra, as well as their\\ncommon probability distribution function (PDF) for the transmitted Ly$\\\\alpha$\\nforest flux. This fully automated PDF regulated continuum fitting method models\\nthe unknown quasar continuum with a linear Principal Component Analysis (PCA)\\nbasis, with the PCA coefficients treated as nuisance parameters. The method\\nallows one to estimate parameters governing the thermal state of the\\nintergalactic medium (IGM), such as the slope of the temperature-density\\nrelation $\\\\gamma-1$, while marginalizing out continuum uncertainties in a fully\\nBayesian way. Using realistic mock quasar spectra created from a simplified\\nsemi-numerical model of the IGM, we show that this method recovers the\\nunderlying quasar continua to a precision of $\\\\simeq7\\\\%$ and $\\\\simeq10\\\\%$ at\\n$z=3$ and $z=5$, respectively. Given the number of principal component spectra,\\nthis is comparable to the underlying accuracy of the PCA model itself. Most\\nimportantly, we show that we can achieve a nearly unbiased estimate of the\\nslope $\\\\gamma-1$ of the IGM temperature-density relation with a precision of\\n$\\\\pm8.6\\\\%$ at $z=3$, $\\\\pm6.1\\\\%$ at $z=5$, for an ensemble of ten mock\\nhigh-resolution quasar spectra. Applying this method to real quasar spectra and\\ncomparing to a more realistic IGM model from hydrodynamical simulations would\\nenable precise measurements of the thermal and cosmological parameters\\ngoverning the IGM, albeit with somewhat larger uncertainties given the\\nincreased flexibility of the model.\\n',\n",
       " '  Age-dependent dynamics is an important characteristic of many infectious\\ndiseases. Age-group epidemic models describe the infection dynamics in\\ndifferent age-groups by allowing to set distinct parameter values for each.\\nHowever, such models are highly nonlinear and may have a large number of\\nunknown parameters. Thus, parameter estimation of age-group models, while\\nbecoming a fundamental issue for both the scientific study and policy making in\\ninfectious diseases, is not a trivial task in practice. In this paper, we\\nexamine the estimation of the so called next-generation matrix using incidence\\ndata of a single entire outbreak, and extend the approach to deal with\\nrecurring outbreaks. Unlike previous studies, we do not assume any constraints\\nregarding the structure of the matrix. A novel two-stage approach is developed,\\nwhich allows for efficient parameter estimation from both statistical and\\ncomputational perspectives. Simulation studies corroborate the ability to\\nestimate accurately the parameters of the model for several realistic\\nscenarios. The model and estimation method are applied to real data of\\ninfluenza-like-illness in Israel. The parameter estimates of the key relevant\\nepidemiological parameters and the recovered structure of the estimated\\nnext-generation matrix are in line with results obtained in previous studies.\\n',\n",
       " '  We interpret the construction of relative Cuntz-Pimsner algebras of\\ncorrespondences in terms of the correspondence bicategory, as a reflector into\\na certain sub-bicategory. This generalises a previous characterisation of\\nabsolute Cuntz-Pimsner algebras of proper correspondences as colimits in the\\ncorrespondence bicategory.\\n',\n",
       " '  We study the dynamical thermal conductivity of the two-dimensional Kitaev\\nspin-model on the honeycomb lattice. We find a strongly temperature dependent\\nlow-frequency spectral intensity as a direct consequence of fractionalization\\nof spins into mobile Majorana matter and a static $\\\\mathbb{Z}_{2}$ gauge field.\\nThe latter acts as an emergent thermally activated disorder, leading to the\\nappearance of a pseudogap which partially closes in the thermodynamic limit,\\nindicating a dissipative heat conductor. Our analysis is based on complementary\\ncalculations of the current correlation function, comprising exact\\ndiagonalization by means of a complete summation over all gauge sectors, as\\nwell as a phenomenological mean-field treatment of thermal gauge fluctuations,\\nvalid at intermediate and high temperatures. The results will also be\\ncontrasted against the conductivity discarding gauge fluctuations.\\n',\n",
       " '  Let $M$ be a compact complex manifold admitting a Kähler structure. A\\nconformally Kähler, Einstein-Maxwell metric (cKEM metric for short) is a\\nHermitian metric $\\\\tilde{g}$ on $M$ with constant scalar curvature such that\\nthere is a positive smooth function $f$ with $g = f^2 \\\\tilde{g}$ being a\\nKähler metric and $f$ being a Killing Hamiltonian potential with respect to\\n$g$. Fixing a Kähler class, we characterize such Killing vector fields whose\\nHamiltonian function $f$ with respect to some Kähler metric $g$ in the fixed\\nKähler class gives a cKEM metric $\\\\tilde{g} = f^{-2}g$. The characterization\\nis described in terms of critical points of certain volume functional. The\\nconceptual idea is similar to the cases of Kähler-Ricci solitons and\\nSasaki-Einstein metrics in that the derivative of the volume functional gives\\nrise to a natural obstruction to the existence of cKEM metrics. However, unlike\\nthe Kähler-Ricci soliton case and Sasaki-Einstein case, the functional is\\nneither convex nor proper in general, and often has more than one critical\\npoints. The last observation matches well with the ambitoric examples studied\\nearlier by LeBrun and Apostolov-Maschler.\\n',\n",
       " '  This paper discusses the approach taken by the UWaterloo team to arrive at a\\nsolution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of\\nSemEval 2017. The paper describes the document vectorization and sentiment\\nscore prediction techniques used, as well as the design and implementation\\ndecisions taken while building the system for this task. The system uses text\\nvectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled\\nwith regression model variants to predict the sentiment scores. Amongst the\\nmethods examined, unigrams and bigrams coupled with simple linear regression\\nobtained the best baseline accuracy. The paper also explores data augmentation\\nmethods to supplement the training dataset. This system was designed for\\nSubtask 2 (News Statements and Headlines).\\n',\n",
       " '  We consider the technologically relevant costs of operating a reliable bit\\nthat can be erased rapidly. We find that both erasing and reliability times are\\nnon-monotonic in the underlying friction, leading to a trade-off between\\nerasing speed and bit reliability. Fast erasure is possible at the expense of\\nlow reliability at moderate friction, and high reliability comes at the expense\\nof slow erasure in the underdamped and overdamped limits. Within a given class\\nof bit parameters and control strategies, we define \"optimal\" designs of bits\\nthat meet the desired reliability and erasing time requirements with the lowest\\noperational work cost. We find that optimal designs always saturate the bound\\non the erasing time requirement, but can exceed the required reliability time\\nif critically damped. The non-trivial geometry of the reliability and erasing\\ntime-scales allows us to exclude large regions of parameter space as\\nsub-optimal. We find that optimal designs are either critically damped or close\\nto critical damping under the erasing procedure.\\n',\n",
       " \"  We consider the positions and velocities of electrons and spinning nuclei and\\ndemonstrate that these particles harbour hidden momentum when located in an\\nelectromagnetic field. This hidden momentum is present in all atoms and\\nmolecules, however it is ultimately cancelled by the momentum of the\\nelectromagnetic field. We point out that an electron vortex in an electric\\nfield might harbour a comparatively large hidden momentum and recognise the\\nphenomenon of 'hidden hidden momentum'.\\n\",\n",
       " '  Software Engineering as an industry is highly diverse in terms of development\\nmethods and practices. Practitioners employ a myriad of methods and tend to\\nfurther tailor them by e.g. omitting some practices or rules. This diversity in\\ndevelopment methods poses a challenge for software engineering education,\\ncreating a gap between education and industry. General theories such as the\\nEssence Theory of Software Engineering can help bridge this gap by presenting\\nsoftware engineering students with higher-level frameworks upon which to build\\nan understanding of software engineering methods and practical project work. In\\nthis paper, we study Essence in an educational setting to evaluate its\\nusefulness for software engineering students while also investigating barriers\\nto its adoption in this context. To this end, we observe 102 student teams\\nutilize Essence in practical software engineering projects during a semester\\nlong, project-based course.\\n',\n",
       " '  Labeling training data is increasingly the largest bottleneck in deploying\\nmachine learning systems. We present Snorkel, a first-of-its-kind system that\\nenables users to train state-of-the-art models without hand labeling any\\ntraining data. Instead, users write labeling functions that express arbitrary\\nheuristics, which can have unknown accuracies and correlations. Snorkel\\ndenoises their outputs without access to ground truth by incorporating the\\nfirst end-to-end implementation of our recently proposed machine learning\\nparadigm, data programming. We present a flexible interface layer for writing\\nlabeling functions based on our experience over the past year collaborating\\nwith companies, agencies, and research labs. In a user study, subject matter\\nexperts build models 2.8x faster and increase predictive performance an average\\n45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in\\nthis new setting and propose an optimizer for automating tradeoff decisions\\nthat gives up to 1.8x speedup per pipeline execution. In two collaborations,\\nwith the U.S. Department of Veterans Affairs and the U.S. Food and Drug\\nAdministration, and on four open-source text and image data sets representative\\nof other deployments, Snorkel provides 132% average improvements to predictive\\nperformance over prior heuristic approaches and comes within an average 3.60%\\nof the predictive performance of large hand-curated training sets.\\n',\n",
       " '  Autoignition experiments for n-butanol have been performed using a heated\\nrapid compression machine at compressed pressures of 15 and 30 bar, in the\\ncompressed temperature range of 675-925 K, and for equivalence ratios of 0.5,\\n1.0, and 2.0. Over the conditions studied, the ignition delay decreases\\nmonotonically as temperature increases, and the autoignition response exhibits\\nsingle-stage characteristics. A non-linear fit to the experimental data is\\nperformed and the reactivity, in terms of the inverse of ignition delay, shows\\nnearly second order dependence on the initial oxygen mole fraction and slightly\\ngreater than first order dependence on initial fuel mole fraction and\\ncompressed pressure. Experimentally measured ignition delays are also compared\\nto simulations using several reaction mechanisms available in the literature.\\nAgreement between simulated and experimental ignition delay is found to be\\nunsatisfactory. Sensitivity analysis is performed on one recent mechanism and\\nindicates that uncertainties in the rate coefficients of parent fuel\\ndecomposition reactions play a major role in causing the poor agreement. Path\\nanalysis of the fuel decomposition reactions supports this conclusion and also\\nhighlights the particular importance of certain pathways. Further experimental\\ninvestigations of the fuel decomposition, including speciation measurements,\\nare required.\\n',\n",
       " '  It has been shown in recent years that the stochastic block model (SBM) is\\nsometimes undetectable in the sparse limit, i.e., that no algorithm can\\nidentify a partition correlated with the partition used to generate an\\ninstance, if the instance is sparse enough and infinitely large. In this\\ncontribution, we treat the finite case explicitly, using arguments drawn from\\ninformation theory and statistics. We give a necessary condition for\\nfinite-size detectability in the general SBM. We then distinguish the concept\\nof average detectability from the concept of instance-by-instance detectability\\nand give explicit formulas for both definitions. Using these formulas, we prove\\nthat there exist large equivalence classes of parameters, where widely\\ndifferent network ensembles are equally detectable with respect to our\\ndefinitions of detectability. In an extensive case study, we investigate the\\nfinite-size detectability of a simplified variant of the SBM, which encompasses\\na number of important models as special cases. These models include the\\nsymmetric SBM, the planted coloring model, and more exotic SBMs not previously\\nstudied. We conclude with three appendices, where we study the interplay of\\nnoise and detectability, establish a connection between our\\ninformation-theoretic approach and random matrix theory, and provide proofs of\\nsome of the more technical results.\\n',\n",
       " '  With ever growing data volume and model size, an error-tolerant,\\ncommunication efficient, yet versatile distributed algorithm has become vital\\nfor the success of many large-scale machine learning applications. In this work\\nwe propose m-PAPG, an implementation of the flexible proximal gradient\\nalgorithm in model parallel systems equipped with the partially asynchronous\\ncommunication protocol. The worker machines communicate asynchronously with a\\ncontrolled staleness bound $s$ and operate at different frequencies. We\\ncharacterize various convergence properties of m-PAPG: 1) Under a general\\nnon-smooth and non-convex setting, we prove that every limit point of the\\nsequence generated by m-PAPG is a critical point of the objective function; 2)\\nUnder an error bound condition, we prove that the function value decays\\nlinearly for every $s$ steps; 3) Under the Kurdyka-${\\\\L}$ojasiewicz inequality,\\nwe prove that the sequences generated by m-PAPG converge to the same critical\\npoint, provided that a proximal Lipschitz condition is satisfied.\\n',\n",
       " '  The \"digital Michelangelo project\" was a seminal computer vision project in\\nthe early 2000\\'s that pushed the capabilities of acquisition systems and\\ninvolved multiple people from diverse fields, many of whom are now leaders in\\nindustry and academia. Reviewing this project with modern eyes provides us with\\nthe opportunity to reflect on several issues, relevant now as then to the field\\nof computer vision and research in general, that go beyond the technical\\naspects of the work.\\nThis article was written in the context of a reading group competition at the\\nweek-long International Computer Vision Summer School 2017 (ICVSS) on Sicily,\\nItaly. To deepen the participants understanding of computer vision and to\\nfoster a sense of community, various reading groups were tasked to highlight\\nimportant lessons which may be learned from provided literature, going beyond\\nthe contents of the paper. This report is the winning entry of this guided\\ndiscourse (Fig. 1). The authors closely examined the origins, fruits and most\\nimportantly lessons about research in general which may be distilled from the\\n\"digital Michelangelo project\". Discussions leading to this report were held\\nwithin the group as well as with Hao Li, the group mentor.\\n',\n",
       " '  We investigate particle production à la Schwinger mechanism in an\\nexpanding, flat de Sitter patch as is relevant for the inflationary epoch of\\nour universe. Defining states and particle content in curved spacetime is\\ncertainly not a unique process. There being different prescriptions on how that\\ncan be done, we have used the Schrödinger formalism to define instantaneous\\nparticle content of the state etc. This allows us to go past the adiabatic\\nregime to which the effect has been restricted in the previous studies and\\nbring out its multifaceted nature in different settings. Each of these settings\\ngives rise to contrasting features and behaviour as per the effect of electric\\nfield and expansion rate on the instantaneous mean particle number. We also\\nquantify the degree of classicality of the process during its evolution using a\\n\"classicality parameter\" constructed out of parameters of the Wigner function\\nto obtain information about the quantum to classical transition in this case.\\n',\n",
       " '  Computing the extensions between Verma modules is in general a very difficult\\nproblem. Using Soergel bimodules, one can construct a graded version of the\\nprincipal block of Category $\\\\mathcal{O}$ for any finite coxeter group. In this\\nsetting, we compute the extensions between Verma modules for dihedral groups.\\n',\n",
       " '  \\\\textbf{GalRotpy} is an educational \\\\verb+Python3+-based visual tool, which\\nis useful to undestand how is the contribution of each mass component to the\\ngravitational potential of disc-like galaxies by means of their rotation curve.\\nBesides, \\\\textbf{GalRotpy} allows the user to perform a parametric fit of a\\ngiven rotation curve, which relies on a MCMC procedure implemented by using\\n\\\\verb+emcee+ package. Here the gravitational potential of disc-like galaxies is\\nbuilt from the contribution of a Miyamoto-Nagai potential model for the\\nbulge/core and the thin/thick disc, an exponential disc, together with the NFW\\n(Navarro-Frenk- White) potential or the Burkert (cored density profile)\\npotential for the Dark Matter halo, where each contribution is implemented by\\nusing \\\\verb+galpy+ package. We summarize the properties of each contribution to\\nthe rotation curve involved, and then describe how \\\\textbf{GalRotpy} is\\nimplemented along with its capabilities. Finally we present the\\ncharacterization of two galaxies, NGC6361 and M33, and show that the results\\nfor M33 provided by \\\\textbf{GalRotpy} are consistent with those found in the\\nliterature.\\n',\n",
       " '  Deep learning hyper-parameter optimization is a tough task. Finding an\\nappropriate network configuration is a key to success, however most of the\\ntimes this labor is roughly done. In this work we introduce a novel library to\\ntackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly\\ndescribe its architecture and present a set of use examples. This is an open\\nsource project developed under the GNU GPL v3 license and it is freely\\navailable at this https URL\\n',\n",
       " '  In previous work the authors introduced a new class of modular quasi-Hopf\\nalgebras $D^{\\\\omega}(G, A)$ associated to a finite group $G$, a central\\nsubgroup $A$, and a $3$-cocycle $\\\\omega\\\\in Z^3(G, C^x)$. In the present paper\\nwe propose a description of the class of orbifold models of rational vertex\\noperator algebras whose module category is tensor equivalent to $D^{\\\\omega}(G,\\nA)$-mod. The paper includes background on quasi-Hopf algebras and a discussion\\nof some relevant orbifolds.\\n',\n",
       " '  Superhydrophobic surfaces demonstrate promising potential for skin friction\\nreduction in naval and hydrodynamic applications. Recent developments of\\nsuperhydrophobic surfaces aiming for scalable applications use random\\ndistribution of roughness, such as spray coating and etched process. However,\\nmost of previous analyses of the interaction between flows and superhydrophobic\\nsurfaces studied periodic geometries that are economically feasible only in\\nlab-scale experiments. We conduct direct numerical simulations of turbulent\\nflows over randomly patterned interfaces considering a range of texture widths\\n$w^+\\\\approx 4-26$, and solid fractions $\\\\phi_s=11\\\\%$ to $25\\\\%$. Slip and\\nno-slip boundary conditions are implemented in a pattern, modeling the presence\\nof gas-liquid interfaces and solid elements. Our results indicate that slip of\\nrandomly distributed textures under turbulent flows are about $30\\\\%$ less than\\nthose of surfaces with aligned features of the same size. In the small texture\\nsize limit $w^+\\\\approx 4$, the slip length of the randomly distributed textures\\nin turbulent flows is well described by a previously introduced Stokes flow\\nsolution of randomly distributed shear-free holes. By comparing DNS results for\\npatterned slip and no-slip boundary against the corresponding homogenized slip\\nlength boundary conditions, we show that turbulent flows over randomly\\ndistributed posts can be represented by an isotropic slip length in streamwise\\nand spanwise direction. The average pressure fluctuation on gas pocket is\\nsimilar to that of the aligned features with the same texture size and gas\\nfraction, but the maximum interface deformation at the leading edge of the\\nroughness element is about twice larger when the textures are randomly\\ndistributed.\\n',\n",
       " '  How cooperation can evolve between players is an unsolved problem of biology.\\nHere we use Hamiltonian dynamics of models of the Ising type to describe\\npopulations of cooperating and defecting players to show that the equilibrium\\nfraction of cooperators is given by the expectation value of a thermal\\nobservable akin to a magnetization. We apply the formalism to the Public Goods\\ngame with three players, and show that a phase transition between cooperation\\nand defection occurs that is equivalent to a transition in one-dimensional\\nIsing crystals with long-range interactions. We then investigate the effect of\\npunishment on cooperation and find that punishment plays the role of a magnetic\\nfield that leads to an \"alignment\" between players, thus encouraging\\ncooperation. We suggest that a thermal Hamiltonian picture of the evolution of\\ncooperation can generate other insights about the dynamics of evolving groups\\nby mining the rich literature of critical dynamics in low-dimensional spin\\nsystems.\\n',\n",
       " '  We present a detailed study of the low temperature and high magnetic field\\nphases in the chemical substitution series URu$_2$Si$_{2-x}$P$_x$ using\\nelectrical transport and magnetization in pulsed magnetic fields up to 65T.\\nWithin the hidden order region (0 $\\\\ x$$\\\\ $ 0.035) the high field ordering is\\nrobust even as the hidden order temperature is suppressed. Earlier work shows\\nthat for 0.035 $\\\\ x$ $\\\\ $ 0.26 there is a Kondo lattice with a no-ordered state\\nthat is replaced by antiferromagnetism for 0.26 $\\\\ x$ 0.5. We observe a\\nsimplified continuation of the high field ordering in the no-order $x$-region\\nand an enhancement of the high field state upon the destruction of the\\nantiferromagnetism with magnetic field. These results closely resemble what is\\nseen for URu$_{2-x}$Rh$_x$Si$_2$\\\\footnote{The concentration in this paper is\\ndefined as URu$_{2-x}$Rh$_x$Si$_2$ while the chemical formula in the literature\\nis given as U(Ru$_{1-x}$Rh$_x$)$_2$Si$_2$ [24-26]}, from which we infer that\\ncharge tuning uniformly controls the ground state of URu$_2$Si$_2$, regardless\\nof whether s/p or d-electrons are replaced. This provides guidance for\\ndetermining the specific factors that lead to hidden order versus magnetism in\\nthis family of materials.\\n',\n",
       " '  The radio-quiet quasar Q2059-360 at redshift $z=3.08$ is known to be close to\\na small Lyman $\\\\alpha$ blob (LAB) and to be absorbed by a proximate damped\\nLy$\\\\alpha$ (PDLA) system.\\nHere, we present the Multi Unit Spectroscopic Explorer (MUSE) integral field\\nspectroscopy follow-up of this quasi-stellar object (QSO). Our primary goal is\\nto characterize this LAB in detail by mapping it both spatially and spectrally\\nusing the Ly$\\\\alpha$ line, and by looking for high-ionization lines to\\nconstrain the emission mechanism.\\nCombining the high sensitivity of the MUSE integral field spectrograph\\nmounted on the Yepun telescope at ESO-VLT with the natural coronagraph provided\\nby the PDLA, we map the LAB down to the QSO position, after robust subtraction\\nof QSO light in the spectral domain.\\nIn addition to confirming earlier results for the small bright component of\\nthe LAB, we unveil a faint filamentary emission protruding to the south over\\nabout 80 pkpc (physical kpc); this results in a total size of about 120 pkpc.\\nWe derive the velocity field of the LAB (assuming no transfer effects) and map\\nthe Ly$\\\\alpha$ line width. Upper limits are set to the flux of the N V $\\\\lambda\\n1238-1242$, C IV $\\\\lambda 1548-1551$, He II $\\\\lambda 1640$, and C III] $\\\\lambda\\n1548-1551$ lines. We have discovered two probable Ly$\\\\alpha$ emitters at the\\nsame redshift as the LAB and at projected distances of 265 kpc and 207 kpc from\\nthe QSO; their Ly$\\\\alpha$ luminosities might well be enhanced by the QSO\\nradiation. We also find an emission line galaxy at $z=0.33$ near the line of\\nsight to the QSO.\\nThis LAB shares the same general characteristics as the 17 others surrounding\\nradio-quiet QSOs presented previously. However, there are indications that it\\nmay be centered on the PDLA galaxy rather than on the QSO.\\n',\n",
       " \"  We demonstrate how methods in Functional Programming can be used to implement\\na computer algebra system. As a proof-of-concept, we present the\\ncomputational-algebra package. It is a computer algebra system implemented as\\nan embedded domain-specific language in Haskell, a purely functional\\nprogramming language. Utilising methods in functional programming and prominent\\nfeatures of Haskell, this library achieves safety, composability, and\\ncorrectness at the same time. To demonstrate the advantages of our approach, we\\nhave implemented advanced Gröbner basis algorithms, such as Faugère's\\n$F_4$ and $F_5$, in a composable way.\\n\",\n",
       " '  Given a convolutional neural network (CNN) that is pre-trained for object\\nclassification, this paper proposes to use active question-answering to\\nsemanticize neural patterns in conv-layers of the CNN and mine part concepts.\\nFor each part concept, we mine neural patterns in the pre-trained CNN, which\\nare related to the target part, and use these patterns to construct an And-Or\\ngraph (AOG) to represent a four-layer semantic hierarchy of the part. As an\\ninterpretable model, the AOG associates different CNN units with different\\nexplicit object parts. We use an active human-computer communication to\\nincrementally grow such an AOG on the pre-trained CNN as follows. We allow the\\ncomputer to actively identify objects, whose neural patterns cannot be\\nexplained by the current AOG. Then, the computer asks human about the\\nunexplained objects, and uses the answers to automatically discover certain CNN\\npatterns corresponding to the missing knowledge. We incrementally grow the AOG\\nto encode new knowledge discovered during the active-learning process. In\\nexperiments, our method exhibits high learning efficiency. Our method uses\\nabout 1/6-1/3 of the part annotations for training, but achieves similar or\\nbetter part-localization performance than fast-RCNN methods.\\n',\n",
       " \"  Despite incredible recent advances in machine learning, building machine\\nlearning applications remains prohibitively time-consuming and expensive for\\nall but the best-trained, best-funded engineering organizations. This expense\\ncomes not from a need for new and improved statistical models but instead from\\na lack of systems and tools for supporting end-to-end machine learning\\napplication development, from data preparation and labeling to\\nproductionization and monitoring. In this document, we outline opportunities\\nfor infrastructure supporting usable, end-to-end machine learning applications\\nin the context of the nascent DAWN (Data Analytics for What's Next) project at\\nStanford.\\n\",\n",
       " '  A linear stochastic continuity equation with non-regular coefficients is\\nconsidered. We prove existence and uniqueness of strong solution, in the\\nprobabilistic sense, to the Cauchy problem when the vector field has low\\nregularity, in which the classical DiPerna-Lions-Ambrosio theory of uniqueness\\nof distributional solutions does not apply. We solve partially the open problem\\nthat is the case when the vector-field has random dependence. In addition, we\\nprove a stability result for the solutions.\\n',\n",
       " '  In determining when a four-dimensional ellipsoid can be symplectically\\nembedded into a ball, McDuff and Schlenk found an infinite sequence of \"ghost\"\\nobstructions that generate an infinite \"ghost staircase\" determined by the even\\nindex Fibonacci numbers. The ghost obstructions are not visible for the\\nfour-dimensional embedding problem because strictly stronger obstructions also\\nexist. We show that in contrast, the embedding constraints associated to the\\nghost obstructions are sharp for the stabilized problem; moreover, the\\ncorresponding optimal embeddings are given by symplectic folding. The proof\\nintroduces several ideas of independent interest, namely: (i) an improved\\nversion of the index inequality familiar from the theory of embedded contact\\nhomology (ECH), (ii) new applications of relative intersection theory in the\\ncontext of neck stretching analysis, (iii) a new approach to estimating the ECH\\ngrading of multiply covered elliptic orbits in terms of areas and continued\\nfractions, and (iv) a new technique for understanding the ECH of ellipsoids by\\nconstructing explicit bijections between certain sets of lattice points.\\n',\n",
       " '  Large-scale networks are widely used to represent object relationships in\\nmany real world applications. The occurrence of large-scale networks presents\\nsignificant computational challenges to process, analyze, and extract\\ninformation from such networks. Network summarization techniques are commonly\\nused to reduce the computational load while attempting to maintain the basic\\nstructural properties of the original network. Previous works have primarily\\nfocused on some type of network partitioning strategies with\\napplication-dependent regularizations, most often resulting in strongly\\nconnected clusters.\\nIn this paper, we introduce a novel perspective regarding the network\\nsummarization problem based on concepts from spectral graph theory. We propose\\na new distance measurement to characterize the spectral differences between the\\noriginal and coarsened networks. We rigorously justify the spectral distance\\nwith the interlacing theorem as well the results from the stochastic block\\nmodel. We provide an efficient algorithm to generate the coarsened networks\\nthat maximally preserves the spectral properties of the original network. Our\\nproposed network summarization framework allows the flexibility to generate a\\nset of coarsened networks with significantly different structures preserved\\nfrom different aspects of the original network, which distinguishes our work\\nfrom others. We conduct extensive experimental tests on a variety of\\nlarge-scale networks, both from real-world applications and the random graph\\nmodel. We show that our proposed algorithms consistently perform better results\\nin terms of the spectral measurements and running time compared to previous\\nnetwork summarization algorithms.\\n',\n",
       " '  This paper presents a method for fitting a copula-driven generalized linear\\nmixed models. For added flexibility, the skew-normal copula is adopted for\\nfitting. The correlation matrix of the skew-normal copula is used to capture\\nthe dependence structure within units, while the fixed and random effects\\ncoefficients are estimated through the mean of the copula. For estimation, a\\nMonte Carlo expectation-maximization algorithm is developed. Simulations are\\nshown alongside a real data example from the Framingham Heart Study.\\n',\n",
       " '  The proven efficacy of learning-based control schemes strongly motivates\\ntheir application to robotic systems operating in the physical world. However,\\nguaranteeing correct operation during the learning process is currently an\\nunresolved issue, which is of vital importance in safety-critical systems. We\\npropose a general safety framework based on Hamilton-Jacobi reachability\\nmethods that can work in conjunction with an arbitrary learning algorithm. The\\nmethod exploits approximate knowledge of the system dynamics to guarantee\\nconstraint satisfaction while minimally interfering with the learning process.\\nWe further introduce a Bayesian mechanism that refines the safety analysis as\\nthe system acquires new evidence, reducing initial conservativeness when\\nappropriate while strengthening guarantees through real-time validation. The\\nresult is a least-restrictive, safety-preserving control law that intervenes\\nonly when (a) the computed safety guarantees require it, or (b) confidence in\\nthe computed guarantees decays in light of new observations. We prove\\ntheoretical safety guarantees combining probabilistic and worst-case analysis\\nand demonstrate the proposed framework experimentally on a quadrotor vehicle.\\nEven though safety analysis is based on a simple point-mass model, the\\nquadrotor successfully arrives at a suitable controller by policy-gradient\\nreinforcement learning without ever crashing, and safely retracts away from a\\nstrong external disturbance introduced during flight.\\n',\n",
       " '  We introduce a geometric property complementary-finite asymptotic dimension\\n(coas- dim). Similar with asymptotic dimension, we prove the corresponding\\ncoarse invariant theorem, union theorem and Hurewicz-type theorem.\\n',\n",
       " '  Phytoplankton plays an important role in marine ecosystem. It is defined as a\\nbiological factor to assess marine quality. The identification of phytoplankton\\nspecies has a high potential for monitoring environmental, climate changes and\\nfor evaluating water quality. However, phytoplankton species identification is\\nnot an easy task owing to their variability and ambiguity due to thousands of\\nmicro and pico-plankton species. Therefore, the aim of this paper is to build a\\nframework for identifying phytoplankton species and to perform a comparison on\\ndifferent features types and classifiers. We propose a new features type\\nextracted from raw signals of phytoplankton species. We then analyze the\\nperformance of various classifiers on the proposed features type as well as two\\nother features types for finding the robust one. Through experiments, it is\\nfound that Random Forest using the proposed features gives the best\\nclassification results with average accuracy up to 98.24%.\\n',\n",
       " '  In this paper, we consider reinforcement learning of Markov Decision\\nProcesses (MDP) with peak constraints, where an agent chooses a policy to\\noptimize an objective and at the same time satisfy additional constraints. The\\nagent has to take actions based on the observed states, reward outputs, and\\nconstraint-outputs, without any knowledge about the dynamics, reward functions,\\nand/or the knowledge of the constraint-functions. We introduce a game theoretic\\napproach to construct reinforcement learning algorithms where the agent\\nmaximizes an unconstrained objective that depends on the simulated action of\\nthe minimizing opponent which acts on a finite set of actions and the output\\ndata of the constraint functions (rewards). We show that the policies obtained\\nfrom maximin Q-learning converge to the optimal policies. To the best of our\\nknowledge, this is the first time learning algorithms guarantee convergence to\\noptimal stationary policies for the MDP problem with peak constraints for both\\ndiscounted and expected average rewards.\\n',\n",
       " \"  GPUs are becoming first-class compute citizens and are being tasked to\\nperform increasingly complex work. Modern GPUs increasingly support\\nprogrammability- enhancing features such as shared virtual memory and hardware\\ncache coherence, enabling them to run a wider variety of programs. But a key\\naspect of general-purpose programming where GPUs are still found lacking is the\\nability to invoke system calls. We explore how to directly invoke generic\\nsystem calls in GPU programs. We examine how system calls should be meshed with\\nprevailing GPGPU programming models where thousands of threads are organized in\\na hierarchy of execution groups: Should a system call be invoked at the\\nindividual GPU task, or at different execution group levels? What are\\nreasonable ordering semantics for GPU system calls across these hierarchy of\\nexecution groups? To study these questions, we implemented GENESYS -- a\\nmechanism to allow GPU pro- grams to invoke system calls in the Linux operating\\nsystem. Numerous subtle changes to Linux were necessary, as the existing kernel\\nassumes that only CPUs invoke system calls. We analyze the performance of\\nGENESYS using micro-benchmarks and three applications that exercise the\\nfilesystem, networking, and memory allocation subsystems of the kernel. We\\nconclude by analyzing the suitability of all of Linux's system calls for the\\nGPU.\\n\",\n",
       " \"  We propose a computational model of neuron, called firing cell (FC),\\nproperties of which cover such phenomena as attenuation of receptors for\\nexternal stimuli, delay and decay of postsynaptic potentials, modification of\\ninternal weights due to propagation of postsynaptic potentials through the\\ndendrite, modification of properties of the analog memory for each input due to\\na pattern of short-time synaptic potentiation or long-time synaptic\\npotentiation (LTP), output-spike generation when the sum of all inputs exceeds\\na threshold, and refraction. The cell may take one of the three forms:\\nexcitatory, inhibitory, and receptory. The computer simulations showed that,\\ndepending on the phase of input signals, the artificial neuron's output\\nfrequency may demonstrate various chaotic behaviors.\\n\",\n",
       " '  This paper demonstrates the use of genetic algorithms for evolving a\\ngrandmaster-level evaluation function for a chess program. This is achieved by\\ncombining supervised and unsupervised learning. In the supervised learning\\nphase the organisms are evolved to mimic the behavior of human grandmasters,\\nand in the unsupervised learning phase these evolved organisms are further\\nimproved upon by means of coevolution.\\nWhile past attempts succeeded in creating a grandmaster-level program by\\nmimicking the behavior of existing computer chess programs, this paper presents\\nthe first successful attempt at evolving a state-of-the-art evaluation function\\nby learning only from databases of games played by humans. Our results\\ndemonstrate that the evolved program outperforms a two-time World Computer\\nChess Champion.\\n',\n",
       " '  We have developed ultra-low-background NaI(Tl) crystals to reproduce the DAMA\\nresults with the ultimate goal of achieving purity levels that are comparable\\nto or better than those of the DAMA/LIBRA crystals. Even though the achieved\\nbackground level does not approach that of DAMA/LIBRA, it is crucial to have a\\nquantitative understanding of the backgrounds. We have studied background\\nsimulations toward a deeper understanding of the backgrounds and developed\\nbackground models for a 9.16-kg NaI(Tl) crystal used in the test arrangement.\\nIn this paper we describe the contributions of background sources\\nquantitatively by performing Geant4 Monte Carlo simulations that are fitted to\\nthe measured data to quantify the unknown fractions of the background\\ncompositions. In the fitted results, the overall simulated background spectrum\\nwell describes the measured data with a 9.16-kg NaI(Tl) crystal and shows that\\nthe background sources are dominated by surface $^{210}$Pb and internal\\n$^{40}$K in the 2 to 6-keV energy interval, which produce 2.4 counts/day/keV/kg\\n(dru) and 0.5 dru, respectively.\\n',\n",
       " '  Gas-solid multiphase flows are prone to develop an instability known as\\nclustering. Two-fluid models, which treat the particulate phase as a continuum,\\nare known to reproduce the qualitative features of this instability, producing\\nhighly-dynamic, spatiotemporal patterns. However, it is unknown whether such\\nsimulations are truly aperiodic or a type of complex periodic behavior. By\\nshowing that the system possesses a sensitive dependence on initial conditions\\nand a positive largest Lyapunov exponent, $\\\\lambda_1 \\\\approx 1/\\\\tau$, we\\nprovide a tentative answer: continuum predictions of clustering are chaotic. We\\nfurther demonstrate that the chaotic behavior is dimensionally dependent, a\\nconclusion which unifies previous results and strongly suggests that the\\nchaotic behavior is not a result of the fundamental kinematic instability, but\\nof the secondary (inherently multidimensional) instability.\\n',\n",
       " '  In the study of Markov chain mixing times, analysis has centered on the\\nperformance from a worst-case starting state. Here, in the context of Glauber\\ndynamics for the one-dimensional Ising model, we show how new ideas from\\ninformation percolation can be used to establish mixing times from other\\nstarting states. At high temperatures we show that the alternating initial\\ncondition is asymptotically the fastest one, and, surprisingly, its mixing time\\nis faster than at infinite temperature, accelerating as the inverse-temperature\\n$\\\\beta$ ranges from 0 to $\\\\beta_0=\\\\frac12\\\\mathrm{arctanh}(\\\\frac13)$. Moreover,\\nthe dominant test function depends on the temperature: at $\\\\beta<\\\\beta_0$ it is\\nautocorrelation, whereas at $\\\\beta>\\\\beta_0$ it is the Hamiltonian.\\n',\n",
       " '  In this paper, we examine the problem of robotic manipulation of granular\\nmedia. We evaluate multiple predictive models used to infer the dynamics of\\nscooping and dumping actions. These models are evaluated on a task that\\ninvolves manipulating the media in order to deform it into a desired shape. Our\\nbest performing model is based on a highly-tailored convolutional network\\narchitecture with domain-specific optimizations, which we show accurately\\nmodels the physical interaction of the robotic scoop with the underlying media.\\nWe empirically demonstrate that explicitly predicting physical mechanics\\nresults in a policy that out-performs both a hand-crafted dynamics baseline,\\nand a \"value-network\", which must otherwise implicitly predict the same\\nmechanics in order to produce accurate value estimates.\\n',\n",
       " '  We show that in Lorentzian manifolds, sectional curvature bounds of the form\\n$\\\\mathcal{R}\\\\le K\\\\,$, as defined by Andersson and Howard, are closely tied to\\nspace-time convex and $\\\\lambda$-convex ($\\\\lambda>0$) functions, as defined by\\nGibbons and Ishibashi. Among the consequences are a natural construction of\\nsuch functions, and an analogue, that applies to domains of a new type, of a\\ntheorem of Alías, Bessa and deLira ruling out trapped submanifolds.\\n',\n",
       " \"  Image denoising techniques are essential to reducing noise levels and\\nenhancing diagnosis reliability in low-dose computed tomography (CT). Machine\\nlearning based denoising methods have shown great potential in removing the\\ncomplex and spatial-variant noises in CT images. However, some residue\\nartifacts would appear in the denoised image due to complexity of noises. A\\ncascaded training network was proposed in this work, where the trained CNN was\\napplied on the training dataset to initiate new trainings and remove artifacts\\ninduced by denoising. A cascades of convolutional neural networks (CNN) were\\nbuilt iteratively to achieve better performance with simple CNN structures.\\nExperiments were carried out on 2016 Low-dose CT Grand Challenge datasets to\\nevaluate the method's performance.\\n\",\n",
       " '  In this paper, we study a dynamic version of the sharing problem, in which a\\ndynamic system cost function composed of time-variant local costs of subsystems\\nand a shared time-variant cost of the whole system is minimized. A dynamic\\nalternating direction method of multipliers (ADMM) is proposed to track the\\nvarying optimal points of the dynamic optimization problem in an online manner.\\nWe analyze the convergence properties of the dynamic ADMM and show that, under\\nseveral standard technical assumptions, the iterations of the dynamic ADMM\\nconverge linearly to some neighborhoods of the time-varying optimal points. The\\nsizes of these neighborhoods depend on the drifts of the dynamic objective\\nfunctions: the more drastically the dynamic objective function evolves across\\ntime, the larger the sizes of these neighborhoods. We also investigate the\\nimpact of the drifts on the steady state convergence behaviors of the dynamic\\nADMM. Finally, two numerical examples, namely a dynamic sharing problem and the\\ndynamic least absolute shrinkage and selection operator (LASSO), are presented\\nto corroborate the effectiveness of the proposed dynamic ADMM. It is observed\\nthat the dynamic ADMM can track the time-varying optimal points quickly and\\naccurately. For the dynamic LASSO, the dynamic ADMM has competitive performance\\ncompared to the benchmark offline optimizor while the former possesses\\nsignificant computational advantage over the latter.\\n',\n",
       " '  We propose a new approach for metric learning by framing it as learning a\\nsparse combination of locally discriminative metrics that are inexpensive to\\ngenerate from the training data. This flexible framework allows us to naturally\\nderive formulations for global, multi-task and local metric learning. The\\nresulting algorithms have several advantages over existing methods in the\\nliterature: a much smaller number of parameters to be estimated and a\\nprincipled way to generalize learned metrics to new testing data points. To\\nanalyze the approach theoretically, we derive a generalization bound that\\njustifies the sparse combination. Empirically, we evaluate our algorithms on\\nseveral datasets against state-of-the-art metric learning methods. The results\\nare consistent with our theoretical findings and demonstrate the superiority of\\nour approach in terms of classification performance and scalability.\\n',\n",
       " '  Neuronal assemblies, loosely defined as subsets of neurons with reoccurring\\nspatio-temporally coordinated activation patterns, or \"motifs\", are thought to\\nbe building blocks of neural representations and information processing. We\\nhere propose LeMoNADe, a new exploratory data analysis method that facilitates\\nhunting for motifs in calcium imaging videos, the dominant microscopic\\nfunctional imaging modality in neurophysiology. Our nonparametric method\\nextracts motifs directly from videos, bypassing the difficult intermediate step\\nof spike extraction. Our technique augments variational autoencoders with a\\ndiscrete stochastic node, and we show in detail how a differentiable\\nreparametrization and relaxation can be used. An evaluation on simulated data,\\nwith available ground truth, reveals excellent quantitative performance. In\\nreal video data acquired from brain slices, with no ground truth available,\\nLeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses\\nfor more focused biological investigations.\\n',\n",
       " '  We show that dispersive propagation of light followed by phase detection has\\nproperties that can be exploited for extracting features from the waveforms.\\nThis discovery is spearheading development of a new class of physics-inspired\\nalgorithms for feature extraction from digital images with unique properties\\nand superior dynamic range compared to conventional algorithms. In certain\\ncases, these algorithms have the potential to be an energy efficient and\\nscalable substitute to synthetically fashioned computational techniques in\\npractice today.\\n',\n",
       " '  This paper proposes Monte Carlo Action Programming, a programming language\\nframework for autonomous systems that act in large probabilistic state spaces\\nwith high branching factors. It comprises formal syntax and semantics of a\\nnondeterministic action programming language. The language is interpreted\\nstochastically via Monte Carlo Tree Search. Effectiveness of the approach is\\nshown empirically.\\n',\n",
       " \"  This article considers two variants of a shortest path problem for a car-like\\nrobot visiting a set of waypoints. The sequence of waypoints to be visited is\\nspecified in the first variant while the robot is allowed to visit the\\nwaypoints in any sequence in the second variant. Field of view constraints are\\nalso placed when the robot arrives at a waypoint, i.e., the orientation of the\\nrobot at any waypoint is restricted to belong to a given interval of angles at\\nthe waypoint. The shortest path problem is first solved for two waypoints with\\nthe field of view constraints using Pontryagin's minimum principle. Using the\\nresults for the two point problem, tight lower and upper bounds on the length\\nof the shortest path are developed for visiting n points by relaxing the\\nrequirement that the arrival angle must be equal to the departure angle of the\\nrobot at each waypoint. Theoretical bounds are also provided on the length of\\nthe feasible solutions obtained by the proposed algorithm. Simulation results\\nverify the performance of the bounds for instances with 20 waypoints.\\n\",\n",
       " \"  The predominant structural protein in vertebrates is collagen, which plays a\\nkey role in extracellular matrix and connective tissue mechanics. Despite its\\nprevalence and physical importance in biology, the mechanical properties of\\nmolecular collagen are far from established. The flexibility of its triple\\nhelix is unresolved, with descriptions from different experimental techniques\\nranging from flexible to semirigid. Furthermore, it is unknown how collagen\\ntype (homo- vs. heterotrimeric) and source (tissue-derived vs. recombinant)\\ninfluence flexibility. Using SmarTrace, a chain tracing algorithm we devised,\\nwe performed statistical analysis of collagen conformations collected with\\natomic force microscopy (AFM) to determine the protein's mechanical properties.\\nOur results show that types I, II and III collagens - the key fibrillar\\nvarieties - exhibit molecular flexibilities that are very similar. However,\\ncollagen conformations are strongly modulated by salt, transitioning from\\ncompact to extended as KCl concentration increases, in both neutral and acidic\\npH. While analysis with a standard worm-like chain model suggests that the\\npersistence length of collagen can attain almost any value within the\\nliterature range, closer inspection reveals that this modulation of collagen's\\nconformational behavior is not due to changes in flexibility, but rather arises\\nfrom the induction of curvature (either intrinsic or induced by interactions\\nwith the mica surface). By modifying standard polymer theory to include innate\\ncurvature, we show that collagen behaves as an equilibrated curved worm-like\\nchain (cWLC) in two dimensions. Analysis within the cWLC model shows that\\ncollagen's curvature depends strongly on pH and salt, while its persistence\\nlength does not. Thus, we find that triple-helical collagen is well described\\nas semiflexible, irrespective of source, type, pH and salt environment.\\n\",\n",
       " '  The goal of this paper is to analyze the geometric properties of deep neural\\nnetwork classifiers in the input space. We specifically study the topology of\\nclassification regions created by deep networks, as well as their associated\\ndecision boundary. Through a systematic empirical investigation, we show that\\nstate-of-the-art deep nets learn connected classification regions, and that the\\ndecision boundary in the vicinity of datapoints is flat along most directions.\\nWe further draw an essential connection between two seemingly unrelated\\nproperties of deep networks: their sensitivity to additive perturbations in the\\ninputs, and the curvature of their decision boundary. The directions where the\\ndecision boundary is curved in fact remarkably characterize the directions to\\nwhich the classifier is the most vulnerable. We finally leverage a fundamental\\nasymmetry in the curvature of the decision boundary of deep nets, and propose a\\nmethod to discriminate between original images, and images perturbed with small\\nadversarial examples. We show the effectiveness of this purely geometric\\napproach for detecting small adversarial perturbations in images, and for\\nrecovering the labels of perturbed images.\\n',\n",
       " \"  Many undergraduate students of engineering and the exact sciences have\\ndifficulty with their mathematics courses due to insufficient proficiency in\\nwhat we in this paper have termed clear thinking. We believe that this lack of\\nproficiency is one of the primary causes underlying the common difficulties\\nstudents face, leading to mistakes like the improper use of definitions and the\\nimproper phrasing of definitions, claimes and proofs. We further argue that\\nclear thinking is not a skill that is acquired easily and naturally - it must\\nbe consciously learned and developed. The paper describes, using concrete\\nexamples, how the examination and analysis of classical paradoxes can be a fine\\ntool for developing students' clear thinking. It also looks closely at the\\nparadoxes themselves, and at the various solutions that have been proposed for\\nthem. We believe that the extensive literature on paradoxes has not always\\ngiven clear thinking its due emphasis as an analytical tool. We therefore\\nsuggest that other discipkunes could also benefit from drawing upon the\\nstrategies employed by mathematicians to describe and examine the foundations\\nof the problems they encounter.\\n\",\n",
       " '  We present the validation of a recent fractional mathematical model for\\nerythrocyte sedimentation proposed by Sharma et al. \\\\cite{GMR}. The model uses\\na Caputo fractional derivative to build a time fractional diffusion equation\\nsuitable to predict blood sedimentation rates. This validation was carried out\\nby means of erythrocyte sedimentation tests in laboratory. Data on\\nsedimentation rates (percentages) were analyzed and compared with the\\nanalytical solution of the time fractional diffusion equation. The behavior of\\nthe analytical solution related to each blood sample sedimentation data was\\ndescribed and analyzed.\\n',\n",
       " '  A tower is a sequence of simplicial complexes connected by simplicial maps.\\nWe show how to compute a filtration, a sequence of nested simplicial complexes,\\nwith the same persistent barcode as the tower. Our approach is based on the\\nconing strategy by Dey et al. (SoCG 2014). We show that a variant of this\\napproach yields a filtration that is asymptotically only marginally larger than\\nthe tower and can be efficiently computed by a streaming algorithm, both in\\ntheory and in practice. Furthermore, we show that our approach can be combined\\nwith a streaming algorithm to compute the barcode of the tower via matrix\\nreduction. The space complexity of the algorithm does not depend on the length\\nof the tower, but the maximal size of any subcomplex within the tower.\\n',\n",
       " \"  We study nonlinear dynamics of the Earth's tropical climate system. For that,\\nwe apply a recently developed technique for feature extraction and mode\\ndecomposition of spatiotemporal data generated by ergodic dynamical systems.\\nThe method relies on constructing low-dimensional representations (temporal\\npatterns) of signals using eigenfunctions of Koopman operators governing the\\nevolution of observables in ergodic dynamical systems. We apply this technique\\nto a variety of tropical climate datasets and extract a multiscale hierarchy of\\nspatiotemporal patterns on diurnal to interannual timescales. In particular, we\\ndetect without prefiltering the input data modes operating on intraseasonal and\\nshorter timescales that correspond to propagation of organized convection. We\\ndiscuss the salient properties of these propagating features and in particular\\nwe focus on how the activity of certain types of these traveling patterns is\\nrelated to lower-frequency dynamics. As an extension of this work, we discuss\\ntheir potential predictability based on a range of nonparametric techniques and\\npotential advances related to understanding the deterministic and stochastic\\naspects of the variability of these modes.\\n\",\n",
       " '  The general formula for the probability of radiation of a twisted photon by a\\nclassical current is derived. The general theory of generation of twisted\\nphotons by undulators is developed. It is proved that the probability to record\\na twisted photon produced by a classical current is equal to the average number\\nof twisted photons in a given state. The general formula for the projection of\\nthe total angular momentum of twisted photons with given the energy, the\\nlongitudinal projection of momentum, and the helicity is obtained. The symmetry\\nproperty of the average number of twisted photons produced by a charged\\nparticle moving along a planar trajectory is found. The explicit formulas for\\nthe average number of twisted photons generated by undulators both in the\\ndipole and wiggler regimes are obtained. It is established that, for the\\nforward radiation of an ideal right-handed helical undulator, the harmonic\\nnumber $n$ of the twisted photon coincides with its projection of the total\\nangular momentum $m$. As for the ideal left-handed helical undulator, we obtain\\nthat $m=-n$. It is found that the forward radiation of twisted photons by a\\nplanar undulator obeys the selection rule that $n+m$ is an even number. It\\nturns out that the average number of twisted photons produced by the undulator\\nand detected off the undulator axis is a periodic function of $m$ in a certain\\nspectral band of the quantum numbers $m$.\\n',\n",
       " '  We study the Stochastic Gradient Descent (SGD) method in nonconvex\\noptimization problems from the point of view of approximating diffusion\\nprocesses. We prove rigorously that the diffusion process can approximate the\\nSGD algorithm weakly using the weak form of master equation for probability\\nevolution. In the small step size regime and the presence of omnidirectional\\nnoise, our weak approximating diffusion process suggests the following dynamics\\nfor the SGD iteration starting from a local minimizer (resp.~saddle point): it\\nescapes in a number of iterations exponentially (resp.~almost linearly)\\ndependent on the inverse stepsize. The results are obtained using the theory\\nfor random perturbations of dynamical systems (theory of large deviations for\\nlocal minimizers and theory of exiting for unstable stationary points). In\\naddition, we discuss the effects of batch size for the deep neural networks,\\nand we find that small batch size is helpful for SGD algorithms to escape\\nunstable stationary points and sharp minimizers. Our theory indicates that one\\nshould increase the batch size at later stage for the SGD to be trapped in flat\\nminimizers for better generalization.\\n',\n",
       " '  We study the effect of non-magnetic Zn$^{2+}$ (spin-$0$) and magnetic\\nNi$^{2+}$ (spin-$1$) impurities on the ground state and low-lying excitations\\nof the quasi-one-dimensional spin-$1/2$ Heisenberg antiferromagnet\\nSr$_{2}$CuO$_{3}$ using inelastic neutron scattering, specific heat and bulk\\nmagnetization measurements. We show that 1 \\\\% Ni$^{2+}$ doping in Sr$_2$CuO$_3$\\nresults in a sizable spin gap in the spinon excitations, analogous to the case\\nof Ni-doped SrCuO$_2$ previously reported [ref. 1]. However, a similar level of\\nZn$^{2+}$ doping in SrCuO$_2$, investigated here for comparison, did not reveal\\nany signs of a spin gap. Magnetic ordering temperature was found to be\\nsuppressed in the presence of both Zn$^{2+}$ and Ni$^{2+}$ impurities, however,\\nthe rate of suppression due to Ni$^{2+}$ was found to be much more pronounced\\nthan for Zn$^{2+}$. Effect of magnetic field on the ordering temperature is\\ninvestigated. We found that with increasing magnetic field, not only the\\nmagnetic ordering temperature gradually increases but the size of specific heat\\nanomaly associated with the magnetic ordering also progressively enhances,\\nwhich can be qualitatively understood as due to the field induced suppression\\nof quantum fluctuations.\\n',\n",
       " '  We construct the electromagnetically induced transparency (EIT) by\\ndynamically coupling a superradiant state with a subradiant state. The\\nsuperradiant and subradiant states with enhanced and inhibited decay rates act\\nas the excited and metastable states in EIT, respectively. Their energy\\ndifference determined by the distance between the atoms can be measured by the\\nEIT spectra, which renders this method useful in subwavelength metrology. The\\nscheme can also be applied to many atoms in nuclear quantum optics, where the\\ntransparency point due to counter-rotating wave terms can be observed.\\n',\n",
       " '  Efficient and automated classification of phases from minimally processed\\ndata is one goal of machine learning in condensed matter and statistical\\nphysics. Supervised algorithms trained on raw samples of microstates can\\nsuccessfully detect conventional phase transitions via learning a bulk feature\\nsuch as an order parameter. In this paper, we investigate whether neural\\nnetworks can learn to classify phases based on topological defects. We address\\nthis question on the two-dimensional classical XY model which exhibits a\\nKosterlitz-Thouless transition. We find significant feature engineering of the\\nraw spin states is required to convincingly claim that features of the vortex\\nconfigurations are responsible for learning the transition temperature. We\\nfurther show a single-layer network does not correctly classify the phases of\\nthe XY model, while a convolutional network easily performs classification by\\nlearning the global magnetization. Finally, we design a deep network capable of\\nlearning vortices without feature engineering. We demonstrate the detection of\\nvortices does not necessarily result in the best classification accuracy,\\nespecially for lattices of less than approximately 1000 spins. For larger\\nsystems, it remains a difficult task to learn vortices.\\n',\n",
       " \"  We establish quantitative estimates for sampling (dominating) sets in model\\nspaces associated with meromorphic inner functions, i.e. those corresponding to\\nde Branges spaces. Our results encompass the Logvinenko-Sereda-Panejah (LSP)\\nTheorem including Kovrijkine's optimal sampling constants for Paley-Wiener\\nspaces. It also extends Dyakonov's LSP theoremfor model spaces associated with\\nbounded derivative inner functions. Considering meromorphic inner functions\\nallows us tointroduce a new geometric density condition, in terms of which the\\nsampling sets are completely characterized. This, incomparison to Volberg's\\ncharacterization of sampling measures in terms of harmonic measure, enables us\\nto obtain explicitestimates on the sampling constants. The methods combine\\nBaranov-Bernstein inequalities, reverse Carleson measures andRemez inequalities .\\n\",\n",
       " \"  The way we perceive a sound depends on many aspects-- its ecological\\nfrequency, acoustic features, typicality, and most notably, its identified\\nsource. In this paper, we present the HCU400: a dataset of 402 sounds ranging\\nfrom easily identifiable everyday sounds to intentionally obscured artificial\\nones. It aims to lower the barrier for the study of aural phenomenology as the\\nlargest available audio dataset to include an analysis of causal attribution.\\nEach sample has been annotated with crowd-sourced descriptions, as well as\\nfamiliarity, imageability, arousal, and valence ratings. We extend existing\\ncalculations of causal uncertainty, automating and generalizing them with word\\nembeddings. Upon analysis we find that individuals will provide less polarized\\nemotion ratings as a sound's source becomes increasingly ambiguous; individual\\nratings of familiarity and imageability, on the other hand, diverge as\\nuncertainty increases despite a clear negative trend on average.\\n\",\n",
       " '  In voxel-based neuroimage analysis, lesion features have been the main focus\\nin disease prediction due to their interpretability with respect to the related\\ndiseases. However, we observe that there exists another type of features\\nintroduced during the preprocessing steps and we call them \"\\\\textbf{Procedural\\nBias}\". Besides, such bias can be leveraged to improve classification accuracy.\\nNevertheless, most existing models suffer from either under-fit without\\nconsidering procedural bias or poor interpretability without differentiating\\nsuch bias from lesion ones. In this paper, a novel dual-task algorithm namely\\n\\\\emph{GSplit LBI} is proposed to resolve this problem. By introducing an\\naugmented variable enforced to be structural sparsity with a variable splitting\\nterm, the estimators for prediction and selecting lesion features can be\\noptimized separately and mutually monitored by each other following an\\niterative scheme. Empirical experiments have been evaluated on the Alzheimer\\'s\\nDisease Neuroimaging Initiative\\\\thinspace(ADNI) database. The advantage of\\nproposed model is verified by improved stability of selected lesion features\\nand better classification results.\\n',\n",
       " '  Online audio advertising is a particular form of advertising used abundantly\\nin online music streaming services. In these platforms, which tend to host tens\\nof thousands of unique audio advertisements (ads), providing high quality ads\\nensures a better user experience and results in longer user engagement.\\nTherefore, the automatic assessment of these ads is an important step toward\\naudio ads ranking and better audio ads creation. In this paper we propose one\\nway to measure the quality of the audio ads using a proxy metric called Long\\nClick Rate (LCR), which is defined by the amount of time a user engages with\\nthe follow-up display ad (that is shown while the audio ad is playing) divided\\nby the impressions. We later focus on predicting the audio ad quality using\\nonly acoustic features such as harmony, rhythm, and timbre of the audio,\\nextracted from the raw waveform. We discuss how the characteristics of the\\nsound can be connected to concepts such as the clarity of the audio ad message,\\nits trustworthiness, etc. Finally, we propose a new deep learning model for\\naudio ad quality prediction, which outperforms the other discussed models\\ntrained on hand-crafted features. To the best of our knowledge, this is the\\nfirst large-scale audio ad quality prediction study.\\n',\n",
       " '  We investigate scaling properties of human brain functional networks in the\\nresting-state. Analyzing network degree distributions, we statistically test\\nwhether their tails scale as power-law or not. Initial studies, based on\\nleast-squares fitting, were shown to be inadequate for precise estimation of\\npower-law distributions. Subsequently, methods based on maximum-likelihood\\nestimators have been proposed and applied to address this question.\\nNevertheless, no clear consensus has emerged, mainly because results have shown\\nsubstantial variability depending on the data-set used or its resolution. In\\nthis study, we work with high-resolution data (10K nodes) from the Human\\nConnectome Project and take into account network weights. We test for the\\npower-law, exponential, log-normal and generalized Pareto distributions. Our\\nresults show that the statistics generally do not support a power-law, but\\ninstead these degree distributions tend towards the thin-tail limit of the\\ngeneralized Pareto model. This may have implications for the number of hubs in\\nhuman brain functional networks.\\n',\n",
       " '  The problem of class imbalance along with class-overlapping has become a\\nmajor issue in the domain of supervised learning. Most supervised learning\\nalgorithms assume equal cardinality of the classes under consideration while\\noptimizing the cost function and this assumption does not hold true for\\nimbalanced datasets which results in sub-optimal classification. Therefore,\\nvarious approaches, such as undersampling, oversampling, cost-sensitive\\nlearning and ensemble based methods have been proposed for dealing with\\nimbalanced datasets. However, undersampling suffers from information loss,\\noversampling suffers from increased runtime and potential overfitting while\\ncost-sensitive methods suffer due to inadequately defined cost assignment\\nschemes. In this paper, we propose a novel boosting based method called\\nLIUBoost. LIUBoost uses under sampling for balancing the datasets in every\\nboosting iteration like RUSBoost while incorporating a cost term for every\\ninstance based on their hardness into the weight update formula minimizing the\\ninformation loss introduced by undersampling. LIUBoost has been extensively\\nevaluated on 18 imbalanced datasets and the results indicate significant\\nimprovement over existing best performing method RUSBoost.\\n',\n",
       " '  We propose the use of Bayesian networks, which provide both a mean value and\\nan uncertainty estimate as output, to enhance the safety of learned control\\npolicies under circumstances in which a test-time input differs significantly\\nfrom the training set. Our algorithm combines reinforcement learning and\\nend-to-end imitation learning to simultaneously learn a control policy as well\\nas a threshold over the predictive uncertainty of the learned model, with no\\nhand-tuning required. Corrective action, such as a return of control to the\\nmodel predictive controller or human expert, is taken when the uncertainty\\nthreshold is exceeded. We validate our method on fully-observable and\\nvision-based partially-observable systems using cart-pole and autonomous\\ndriving simulations using deep convolutional Bayesian neural networks. We\\ndemonstrate that our method is robust to uncertainty resulting from varying\\nsystem dynamics as well as from partial state observability.\\n',\n",
       " '  This study covers an analytical approach to calculate positively invariant\\nsets of dynamical systems. Using Lyapunov techniques and quantifier elimination\\nmethods, an automatic procedure for determining bounds in the state space as an\\nenclosure of attractors is proposed. The available software tools permit an\\nalgorithmizable process, which normally requires a good insight into the\\nsystems dynamics and experience. As a result we get an estimation of the\\nattractor, whose conservatism only results from the initial choice of the\\nLyapunov candidate function. The proposed approach is illustrated on the\\nwell-known Lorenz system.\\n',\n",
       " '  If the electroweak sector of the standard model is described by classically\\nconformal dynamics, the early Universe evolution can be substantially altered.\\nIt is already known that---contrarily to the standard model case---a first\\norder electroweak phase transition may occur. Here we show that, depending on\\nthe model parameters, a dramatically different scenario may happen: A\\nfirst-order, six massless quark QCD phase transition occurs first, which then\\ntriggers the electroweak symmetry breaking. We derive the necessary conditions\\nfor this dynamics to occur, using the specific example of the classically\\nconformal B-L model. In particular, relatively light weakly coupled particles\\nare predicted, with implications for collider searches. This scenario is also\\npotentially rich in cosmological consequences, such as renewed possibilities\\nfor electroweak baryogenesis, altered dark matter production, and gravitational\\nwave production, as we briefly comment upon.\\n',\n",
       " '  In recent years, coverage-based greybox fuzzing has proven itself to be one\\nof the most effective techniques for finding security bugs in practice.\\nParticularly, American Fuzzy Lop (AFL for short) is deemed to be a great\\nsuccess in fuzzing relatively simple test inputs. Unfortunately, when it meets\\nstructured test inputs such as XML and JavaScript, those grammar-blind trimming\\nand mutation strategies in AFL hinder the effectiveness and efficiency.\\nTo this end, we propose a grammar-aware coverage-based greybox fuzzing\\napproach to fuzz programs that process structured inputs. Given the grammar\\n(which is often publicly available) of test inputs, we introduce a\\ngrammar-aware trimming strategy to trim test inputs at the tree level using the\\nabstract syntax trees (ASTs) of parsed test inputs. Further, we introduce two\\ngrammar-aware mutation strategies (i.e., enhanced dictionary-based mutation and\\ntree-based mutation). Specifically, tree-based mutation works via replacing\\nsubtrees using the ASTs of parsed test inputs. Equipped with grammar-awareness,\\nour approach can carry the fuzzing exploration into width and depth.\\nWe implemented our approach as an extension to AFL, named Superion; and\\nevaluated the effectiveness of Superion on real-life large-scale programs (a\\nXML engine libplist and three JavaScript engines WebKit, Jerryscript and\\nChakraCore). Our results have demonstrated that Superion can improve the code\\ncoverage (i.e., 16.7% and 8.8% in line and function coverage) and bug-finding\\ncapability (i.e., 31 new bugs, among which we discovered 21 new vulnerabilities\\nwith 16 CVEs assigned and 3.2K USD bug bounty rewards received) over AFL and\\njsfunfuzz. We also demonstrated the effectiveness of our grammar-aware trimming\\nand mutation.\\n',\n",
       " \"  The Black-Litterman model combines investors' personal views with historical\\ndata and gives optimal portfolio weights. In this paper we will introduce the\\noriginal Black-Litterman model (section 1), we will modify the model such that\\nit fits in a Bayesian framework by considering the investors' personal views to\\nbe a direct prior on the means of the returns and by adding a typical Inverse\\nWishart prior on the covariance matrix of the returns (section 2). Lastly, we\\nwill use Leonard and Hsu's (1992) idea of adding a prior on the logarithm of\\nthe covariance matrix (section 3). Sensitivity simulations for the level of\\nconfidence that the investor has in their own personal views were performed and\\nperformance of the models was assessed on a test data set consisting of returns\\nover the month of January 2018.\\n\",\n",
       " '  This project serves to analyze the behavior of Ricci Flow in five dimensional\\nmanifolds. Ricci Flow was introduced by Richard Hamilton in 1982 and was an\\nessential tool in proving the Geometrization and Poincare Conjectures. In\\ngeneral, Ricci Flow is a nonlinear PDE whose solutions are rather difficult to\\ncalculate; however, in a homogeneous manifold, the Ricci Flow reduces to an\\nODE. The behavior of Ricci Flow in two, three, and four dimensional homogenous\\nmanifolds has been calculated and is well understood. The work presented here\\nwill describe efforts to better understand the behavior of Ricci Flow in a\\ncertain class of five dimensional homogeneous manifolds.\\n',\n",
       " '  The problem of multi-speaker localization is formulated as a multi-class\\nmulti-label classification problem, which is solved using a convolutional\\nneural network (CNN) based source localization method. Utilizing the common\\nassumption of disjoint speaker activities, we propose a novel method to train\\nthe CNN using synthesized noise signals. The proposed localization method is\\nevaluated for two speakers and compared to a well-known steered response power\\nmethod.\\n',\n",
       " \"  In this paper, there are obtained growth estimates of entire in\\n$\\\\mathbb{C}^n$ function of bounded $\\\\mathbf{L}$-index in joint variables. They\\ndescribe the behaviour of maximum modulus of entire function on a skeleton in a\\npolydisc by behaviour of the function $\\\\mathbf{L}(z)=(l_1(z),\\\\ldots,l_n(z)),$\\nwhere for every $j\\\\in\\\\{1,\\\\ldots, n\\\\}$ \\\\ $l_j:\\\\mathbb{C}^n\\\\to \\\\mathbb{R}_+$ is a\\ncontinuous function. We generalised known results of W. K. Hayman, M. M.\\nSheremeta, A. D. Kuzyk, M. T. Borduyak, T. O. Banakh and V. O. Kushnir for a\\nwider class of functions $\\\\mathbf{L}.$ One of our estimates is sharper even for\\nentire in $\\\\mathbb{C}$ functions of bounded $l$-index than Sheremeta's\\nestimate.\\n\",\n",
       " '  The purpose of this paper is to explore a resolution for the Faint Young Sun\\nParadox that has been mostly rejected by the community, namely the possibility\\nof a somewhat more massive young Sun with a large mass loss rate sustained for\\ntwo to three billion years. This would make the young Sun bright enough to keep\\nboth the terrestrial and Martian oceans from freezing, and thus resolve the\\nparadox. It is found that a large and sustained mass loss is consistent with\\nthe well observed spin-down rate of Sun-like stars, and indeed may be required\\nfor it. It is concluded that a more massive young Sun must be considered a\\nplausible hypothesis.\\n',\n",
       " '  We study the statistics of the kinetic (or equivalently potential) energy for\\n$N$ non-interacting fermions in a $1d$ harmonic trap of frequency $\\\\omega$, at\\nfinite temperature $T$. Remarkably, we find an exact solution for the full\\ndistribution of the kinetic energy, at any temperature $T$ and for any $N$,\\nusing a non-trivial mapping to an integrable Calogero-Moser-Sutherland model.\\nAs a function of temperature $T$, and for large $N$, we identify: (i) a quantum\\nregime, for $T \\\\sim \\\\hbar \\\\omega$, where quantum fluctuations dominate and (ii)\\na thermal regime, for $T \\\\sim N \\\\hbar \\\\omega$, governed by thermal\\nfluctuations. We show how the mean, the variance as well as the large deviation\\nfunction associated with the distribution of the kinetic energy cross over from\\nthe quantum to the thermal regime as temperature increases.\\n',\n",
       " '  With the intention of bringing uniformity to Bengali text entry research,\\nhere we present a new approach for calculating the most popular English text\\nentry evaluation metrics for Bengali. To demonstrate our approach, we conducted\\na user study where we evaluated four popular Bengali text entry techniques.\\n',\n",
       " '  Many problems in machine learning are naturally expressed in the language of\\nundirected graphical models. Here, we propose black-box learning and inference\\nalgorithms for undirected models that optimize a variational approximation to\\nthe log-likelihood of the model. Central to our approach is an upper bound on\\nthe log-partition function parametrized by a function q that we express as a\\nflexible neural network. Our bound makes it possible to track the partition\\nfunction during learning, to speed-up sampling, and to train a broad class of\\nhybrid directed/undirected models via a unified variational inference\\nframework. We empirically demonstrate the effectiveness of our method on\\nseveral popular generative modeling datasets.\\n',\n",
       " '  The stability of charge ordered phases is doping dependent, with different\\nmaterials having particularly stable ordered phases. In the half filled charge\\nordered phases of the cuprates this occurs at one eighth doping, whereas in\\ncharge-stripe ordered La2-xSrxNiO4+delta there is enhanced stability at one\\nthird doping. In this paper we discuss the known details of the charge-stripe\\norder in La2-xSrxNiO4+delta, and how these properties lead to the one third\\ndoping stability.\\n',\n",
       " \"  In this paper we develop a novel framework for numerically solving scalar\\nconservation laws in one space dimension. Utilizing the method of\\ncharacteristics in conjunction with the equal area principle we develop an\\napproach where the weak solution is obtained purely as the solution of a\\nparametric interpolation problem. As this framework hinges on the validity of\\nthe equal area principle, we provide a rigorous discussion of the equal area\\nprinciple and show that, indeed, the equal area principle is equivalent to the\\nRankine-Hugoniot condition, within the specific context studied in this paper.\\nCombining these results with properties of the characteristic equations yields\\nthe desired setting to define the equivalent parametric interpolation problem.\\nWe conclude by applying this framework to Burgers' equation and show how one\\nobtains machine precision in the shock position when the initial condition can\\nbe represented exactly in the chosen space of parametric polynomials.\\n\",\n",
       " '  Learning in models with discrete latent variables is challenging due to high\\nvariance gradient estimators. Generally, approaches have relied on control\\nvariates to reduce the variance of the REINFORCE estimator. Recent work (Jang\\net al. 2016, Maddison et al. 2016) has taken a different approach, introducing\\na continuous relaxation of discrete variables to produce low-variance, but\\nbiased, gradient estimates. In this work, we combine the two approaches through\\na novel control variate that produces low-variance, \\\\emph{unbiased} gradient\\nestimates. Then, we introduce a modification to the continuous relaxation and\\nshow that the tightness of the relaxation can be adapted online, removing it as\\na hyperparameter. We show state-of-the-art variance reduction on several\\nbenchmark generative modeling tasks, generally leading to faster convergence to\\na better final log-likelihood.\\n',\n",
       " '  We propose a new reconstruction operator that aims to recover the missing\\nparts of a function given the observed parts. This new operator belongs to a\\nnew, very large class of functional operators which includes the classical\\nregression operators as a special case. We show the optimality of our\\nreconstruction operator and demonstrate that the usually considered regression\\noperators generally cannot be optimal reconstruction operators. Our estimation\\ntheory allows for autocorrelated functional data and considers the practically\\nrelevant situation in which each of the $n$ functions is observed at $m_i$,\\n$i=1,\\\\dots,n$, discretization points. We derive rates of consistency for our\\nnonparametric estimation procedures using a double asymptotic. For data\\nsituations, as in our real data application where $m_i$ is considerably smaller\\nthan $n$, we show that our functional principal components based estimator can\\nprovide better rates of convergence than conventional nonparametric smoothing\\nmethod.\\n',\n",
       " '  The restricted maximum likelihood method enhances popularity of maximum\\nlikelihood methods for variance component analysis on large scale unbalanced\\ndata. As the high throughput biological data sets and the emerged science on\\nuncertainty quantification, such a method receives increasing attention.\\nEstimating the unknown variance parameters with restricted maximum likelihood\\nmethod usually requires an nonlinear iterative method. Therefore proper\\nformulae for the log-likelihood function and its derivatives play an essential\\nrole in practical algorithm design. It is our aim to provide a mathematical\\nintroduction to this method, and supply a self-contained derivation on some\\navailable formulae used in practical algorithms. Some new proof are supplied.\\n',\n",
       " \"  Network analysis has driven key developments in research on animal behaviour\\nby providing quantitative methods to study the social structures of animal\\ngroups and populations. A recent formalism, known as \\\\emph{multilayer network\\nanalysis}, has advanced the study of multifaceted networked systems in many\\ndisciplines. It offers novel ways to study and quantify animal behaviour as\\nconnected 'layers' of interactions. In this article, we review common questions\\nin animal behaviour that can be studied using a multilayer approach, and we\\nlink these questions to specific analyses. We outline the types of behavioural\\ndata and questions that may be suitable to study using multilayer network\\nanalysis. We detail several multilayer methods, which can provide new insights\\ninto questions about animal sociality at individual, group, population, and\\nevolutionary levels of organisation. We give examples for how to implement\\nmultilayer methods to demonstrate how taking a multilayer approach can alter\\ninferences about social structure and the positions of individuals within such\\na structure. Finally, we discuss caveats to undertaking multilayer network\\nanalysis in the study of animal social networks, and we call attention to\\nmethodological challenges for the application of these approaches. Our aim is\\nto instigate the study of new questions about animal sociality using the new\\ntoolbox of multilayer network analysis.\\n\",\n",
       " '  We address the problem of sparse recovery in an online setting, where random\\nlinear measurements of a sparse signal are revealed sequentially and the\\nobjective is to recover the underlying signal. We propose a reweighted least\\nsquares (RLS) algorithm to solve the problem of online sparse reconstruction,\\nwherein a system of linear equations is solved using conjugate gradient with\\nthe arrival of every new measurement. The proposed online algorithm is useful\\nin a setting where one seeks to design a progressive decoding strategy to\\nreconstruct a sparse signal from linear measurements so that one does not have\\nto wait until all measurements are acquired. Moreover, the proposed algorithm\\nis also useful in applications where it is infeasible to process all the\\nmeasurements using a batch algorithm, owing to computational and storage\\nconstraints. It is not needed a priori to collect a fixed number of\\nmeasurements; rather one can keep collecting measurements until the quality of\\nreconstruction is satisfactory and stop taking further measurements once the\\nreconstruction is sufficiently accurate. We provide a proof-of-concept by\\ncomparing the performance of our algorithm with the RLS-based batch\\nreconstruction strategy, known as iteratively reweighted least squares (IRLS),\\non natural images. Experiments on a recently proposed focal plane array-based\\nimaging setup show up to 1 dB improvement in output peak signal-to-noise ratio\\nas compared with the total variation-based reconstruction.\\n',\n",
       " '  A classical theorem of I. Schur states that the degree of any irreducible\\ncomplex representation of a finite group $G$ divides the order of\\n$G/\\\\mathscr{Z} G$, where $\\\\mathscr{Z} G$ is the center $G$. This note discusses\\nsimilar divisibility results for certain classes of Hopf algebras.\\n',\n",
       " '  We present a general technique for approximating bicriteria minimization\\nproblems with positive-valued, polynomially computable objective functions.\\nGiven $0<\\\\epsilon\\\\leq1$ and a polynomial-time $\\\\alpha$-approximation algorithm\\nfor the corresponding weighted sum problem, we show how to obtain a bicriteria\\n$(\\\\alpha\\\\cdot(1+2\\\\epsilon),\\\\alpha\\\\cdot(1+\\\\frac{2}{\\\\epsilon}))$-approximation\\nalgorithm for the budget-constrained problem whose running time is polynomial\\nin the encoding length of the input and linear in $\\\\frac{1}{\\\\epsilon}$.\\nMoreover, we show that our method can be extended to compute an\\n$(\\\\alpha\\\\cdot(1+2\\\\epsilon),\\\\alpha\\\\cdot(1+\\\\frac{2}{\\\\epsilon}))$-approximate\\nPareto curve under the same assumptions. Our technique applies to many\\nminimization problems to which most previous algorithms for computing\\napproximate Pareto curves cannot be applied because the corresponding gap\\nproblem is $\\\\textsf{NP}$-hard to solve. For maximization problems, however, we\\nshow that approximation results similar to the ones presented here for\\nminimization problems are impossible to obtain in polynomial time unless\\n$\\\\textsf{P}=\\\\textsf{NP}$.\\n',\n",
       " '  The theory of renormalized energy spectrum of localized quasi-particle\\ninteracting with polarization phonons at finite temperature is developed within\\nthe Feynman-Pines diagram technique. The created computer program effectively\\ntakes into account multi-phonon processes, exactly defining all diagrams of\\nmass operator together with their analytical expressions in arbitrary order\\nover the coupling constant. Now it is possible to separate the pole and\\nnon-pole mass operator terms and perform a partial summing of their main terms.\\nThe renormalized spectrum of the system is obtained within the solution of\\ndispersion equation in the vicinity of the main state where the high- and\\nlow-energy complexes of bound states are observed. The properties of the\\nspectrum are analyzed depending on the coupling constant and the temperature.\\n',\n",
       " '  A $\\\\mathit{\\\\text{moving frame}}$ at a rational curve is a basis of vectors\\nmoving along the curve. When the rational curve is given parametrically by a\\nrow vector $\\\\mathbf{a}$ of univariate polynomials, a moving frame with\\nimportant algebraic properties can be defined by the columns of an invertible\\npolynomial matrix $P$, such that $\\\\mathbf{a} P=[\\\\gcd(\\\\mathbf{a}),0\\\\ldots,0]$. A\\n$\\\\mathit{\\\\text{degree-optimal moving frame}}$ has column-wise minimal degree,\\nwhere the degree of a column is defined to be the maximum of the degrees of its\\ncomponents. Algebraic moving frames are closely related to the univariate\\nversions of the celebrated Quillen-Suslin problem, effective Nullstellensatz\\nproblem, and syzygy module problem. However, this paper appears to be the first\\ndevoted to finding an efficient algorithm for constructing a degree-optimal\\nmoving frame, a property desirable in various applications. We compare our\\nalgorithm with other possible approaches, based on already available\\nalgorithms, and show that it is more efficient. We also establish several new\\ntheoretical results concerning the degrees of an optimal moving frame and its\\ncomponents. In addition, we show that any deterministic algorithm for computing\\na degree-optimal algebraic moving frame can be augmented so that it assigns a\\ndegree-optimal moving frame in a $GL_n(\\\\mathbb{K})$-equivariant manner. This\\ncrucial property of classical geometric moving frames, in combination with the\\nalgebraic properties, can be exploited in various problems.\\n',\n",
       " '  We characterize the communication complexity of the following distributed\\nestimation problem. Alice and Bob observe infinitely many iid copies of\\n$\\\\rho$-correlated unit-variance (Gaussian or $\\\\pm1$ binary) random variables,\\nwith unknown $\\\\rho\\\\in[-1,1]$. By interactively exchanging $k$ bits, Bob wants\\nto produce an estimate $\\\\hat\\\\rho$ of $\\\\rho$. We show that the best possible\\nperformance (optimized over interaction protocol $\\\\Pi$ and estimator $\\\\hat\\n\\\\rho$) satisfies $\\\\inf_{\\\\Pi,\\\\hat\\\\rho}\\\\sup_\\\\rho \\\\mathbb{E} [|\\\\rho-\\\\hat\\\\rho|^2] =\\n\\\\Theta(\\\\tfrac{1}{k})$. Furthermore, we show that the best possible unbiased\\nestimator achieves performance of $1+o(1)\\\\over {2k\\\\ln 2}$. Curiously, thus,\\nrestricting communication to $k$ bits results in (order-wise) similar minimax\\nestimation error as restricting to $k$ samples. Our results also imply an\\n$\\\\Omega(n)$ lower bound on the information complexity of the Gap-Hamming\\nproblem, for which we show a direct information-theoretic proof.\\nNotably, the protocol achieving (almost) optimal performance is one-way\\n(non-interactive). For one-way protocols we also prove the\\n$\\\\Omega(\\\\tfrac{1}{k})$ bound even when $\\\\rho$ is restricted to any small open\\nsub-interval of $[-1,1]$ (i.e. a local minimax lower bound). %We do not know if\\nthis local behavior remains true in the interactive setting. Our proof\\ntechniques rely on symmetric strong data-processing inequalities, various\\ntensorization techniques from information-theoretic interactive\\ncommon-randomness extraction, and (for the local lower bound) on the\\nOtto-Villani estimate for the Wasserstein-continuity of trajectories of the\\nOrnstein-Uhlenbeck semigroup.\\n',\n",
       " '  A pupil plane wavefront reconstruction procedure is proposed based on\\nanalysis of a sequence of focal plane images corresponding to a sequence of\\nrandom pupil plane phase probes. The developed method provides the unique\\nnontrivial solution of wavefront retrieval problem and shows global convergence\\nto this solution demonstrated using a Gerchberg-Saxton implementation. The\\nmethod is general and can be used in any optical system that includes\\ndeformable mirrors for active/adaptive wavefront correction. The presented\\nnumerical simulation and lab experimental results show low noise sensitivity,\\nhigh reliability and robustness of the proposed approach for high quality\\noptical wavefront restoration. Laboratory experiments have shown $\\\\lambda$/14\\nrms accuracy in retrieval of a poked DM actuator fiducial pattern with spatial\\nresolution of 20-30$~\\\\mu$m that is comparable with accuracy of direct\\nhigh-resolution interferometric measurements.\\n',\n",
       " '  In the present study we analytically investigate the deformation and bulk\\nrheology of a dilute emulsion of surfactant-laden droplets suspended in a\\nlinear flow. We use an asymptotic approach to predict the effect of surfactant\\ndistribution on the deformation of a single droplet as well as the effective\\nshear and extensional viscosity for the dilute emulsion. The non-uniform\\ndistribution of surfactants due to the bulk flow results in the generation of a\\nMarangoni stress which affects both the deformation as well as the bulk\\nrheology of the suspension. The present analysis is done for the limiting case\\nwhen the surfactant transport is dominated by the surface diffusion relative to\\nsurface convection. As an example, we have used two commonly encountered bulk\\nflows, namely, uniaxial extensional flow and simple shear flow. With the\\nassumption of negligible inertial forces present in either of the phases, we\\nare able to show that both the surfactant concentration on the droplet surface\\nas well as the ratio of viscosity of the droplet phase with respect to the\\nsuspending fluid has a significant effect on the droplet deformation as well as\\nthe bulk rheology. It is seen that increase in the non-uniformity in surfactant\\ndistribution on the droplet surface results in a higher droplet deformation and\\na higher effective viscosity for either of linear flows considered. For the\\ncase of simple shear flow, surfactant distribution is found to have no effect\\non the inclination angle, however, a higher viscosity ratio predicts the\\ndroplet to be more aligned towards the direction of flow.\\n',\n",
       " '  Index-less Indexed Flash Code (ILIFC) is a coding scheme for flash memories,\\nin which one bit of a data sequence is stored in a slice consisting of several\\ncells but the index of the bit is stored implicitly. Although several modified\\nILIFC schemes have been proposed, in this research we consider an ILIFC with\\ninversion cells(I-ILIFC). The I-ILIFC reduces the total number of cell level\\nchanges at each writing request. Computer simulation is used to show that the\\nI-ILIFC improves the average performance of the ILIFC in many cases. This paper\\npresents our derivation of the lower bounds on the number of writing operations\\nby I-ILIFC and shows that the worst-case performance of the I-ILIFC is better\\nthan that of the ILIFC if the code length is sufficiently large. Additionally,\\nwe consider the tight lower bounds thereon. The results show that the threshold\\nof the code length that determines whether the I-ILIFC improves the worst-case\\nperformance of the ILIFC is smaller than that in the first lower bounds.\\n',\n",
       " '  In this paper, we introduce the problem of denoting and deriving the\\ncomplexity of workflows (plans, schedules) in collaborative, planner-assisted\\nsettings where humans and agents are trying to jointly solve a task. The\\ninteractions -- and hence the workflows that connect the human and the agents\\n-- may differ according to the domain and the kind of agents. We adapt insights\\nfrom prior work in human-agent teaming and workflow analysis to suggest metrics\\nfor workflow complexity. The main motivation behind this work is to highlight\\nmetrics for human comprehensibility of plans and schedules. The planning\\ncommunity has seen its fair share of work on the synthesis of plans that take\\ndiversity into account -- what value do such plans hold if their generation is\\nnot guided at least in part by metrics that reflect the ease of engaging with\\nand using those plans?\\n',\n",
       " '  The Cherenkov Telescope Array, CTA, will be the major global observatory for\\nvery high energy gamma-ray astronomy over the next decade and beyond. The\\nscientific potential of CTA is extremely broad: from understanding the role of\\nrelativistic cosmic particles to the search for dark matter. CTA is an explorer\\nof the extreme universe, probing environments from the immediate neighbourhood\\nof black holes to cosmic voids on the largest scales. Covering a huge range in\\nphoton energy from 20 GeV to 300 TeV, CTA will improve on all aspects of\\nperformance with respect to current instruments.\\nThe observatory will operate arrays on sites in both hemispheres to provide\\nfull sky coverage and will hence maximize the potential for the rarest\\nphenomena such as very nearby supernovae, gamma-ray bursts or gravitational\\nwave transients. With 99 telescopes on the southern site and 19 telescopes on\\nthe northern site, flexible operation will be possible, with sub-arrays\\navailable for specific tasks. CTA will have important synergies with many of\\nthe new generation of major astronomical and astroparticle observatories.\\nMulti-wavelength and multi-messenger approaches combining CTA data with those\\nfrom other instruments will lead to a deeper understanding of the broad-band\\nnon-thermal properties of target sources.\\nThe CTA Observatory will be operated as an open, proposal-driven observatory,\\nwith all data available on a public archive after a pre-defined proprietary\\nperiod. Scientists from institutions worldwide have combined together to form\\nthe CTA Consortium. This Consortium has prepared a proposal for a Core\\nProgramme of highly motivated observations. The programme, encompassing\\napproximately 40% of the available observing time over the first ten years of\\nCTA operation, is made up of individual Key Science Projects (KSPs), which are\\npresented in this document.\\n',\n",
       " '  Let M be a closed symplectic manifold of volume V. We say that the symplectic\\npackings of M by ellipsoids are unobstructed if any collection of disjoint\\nsymplectic ellipsoids (possibly of different sizes) of total volume less than V\\nadmits a symplectic embedding to M. We show that the symplectic packings by\\nellipsoids are unobstructed for all even-dimensional tori equipped with Kahler\\nsymplectic forms and all closed hyperkahler manifolds of maximal holonomy, or,\\nmore generally, for closed Campana simple manifolds (that is, Kahler manifolds\\nthat are not unions of their complex subvarieties), as well as for any closed\\nKahler manifold which is a limit of Campana simple manifolds in a smooth\\ndeformation. The proof involves the construction of a Kahler resolution of a\\nKahler orbifold with isolated singularities and relies on the results of\\nDemailly-Paun and Miyaoka on Kahler cohomology classes.\\n',\n",
       " '  For generic systems exhibiting power law behaviors, and hence multiscale\\ndependencies, we propose a new, and yet simple, tool to analyze multifractality\\nand intermittency, after noticing that these concepts are directly related to\\nthe deformation of a probability density function from Gaussian at large scales\\nto non-Gaussian at smaller scales. Our framework is based on information\\ntheory, and uses Shannon entropy and Kullback-Leibler divergence. We propose an\\nextensive application to three-dimensional fully developed turbulence, seen\\nhere as a paradigmatic complex system where intermittency was historically\\ndefined. Moreover, the concepts of scale invariance and multifractality were\\nextensively studied in this field and, most importantly, benchmarked. We\\ncompute our measure on experimental Eulerian velocity measurements, as well as\\non synthetic processes and a phenomenological model of fluid turbulence.Our\\napproach is very general and does not require any underlying model of the\\nsystem, although it can probe the relevance of such a model.\\n',\n",
       " '  Circuit QED techniques have been instrumental to manipulate and probe with\\nexquisite sensitivity the quantum state of superconducting quantum bits coupled\\nto microwave cavities. Recently, it has become possible to fabricate new\\ndevices where the superconducting quantum bits are replaced by hybrid\\nmesoscopic circuits combining nanoconductors and metallic reservoirs. This\\nmesoscopic QED provides a new experimental playground to study the light-matter\\ninteraction in electronic circuits. Here, we present the experimental state of\\nthe art of Mesoscopic QED and its theoretical description. A first class of\\nexperiments focuses on the artificial atom limit, where some quasiparticles are\\ntrapped in nanocircuit bound states. In this limit, the Circuit QED techniques\\ncan be used to manipulate and probe electronic degrees of freedom such as\\nconfined charges, spins, or Andreev pairs. A second class of experiments\\nconsists in using cavity photons to reveal the dynamics of electron tunneling\\nbetween a nanoconductor and fermionic reservoirs. For instance, the Kondo\\neffect, the charge relaxation caused by grounded metallic contacts, and the\\nphoto-emission caused by voltage-biased reservoirs have been studied. The\\ntunnel coupling between nanoconductors and fermionic reservoirs also enable one\\nto obtain split Cooper pairs, or Majorana bound states. Cavity photons\\nrepresent a qualitatively new tool to study these exotic condensed matter\\nstates.\\n',\n",
       " '  In the Standard Model (SM) we calculate the decay rate of the neutron\\nradiative beta decay to order \"O(\\\\alpha^2/\\\\pi^2 ~ 10^{-5})\", where \"\\\\alpha$\"is\\nthe fine--structure constant, and radiative corrections to order \"O(\\\\alpha/\\\\pi\\n~ 10^{-3})\". The obtained results together with the recent analysis of the\\nneutron radiative beta decay to next-to-leading order in the large proton-mass\\nexpansion, performed by Ivanov et al. Phys. Rev. D95, 033007 (2017), describe\\nrecent experimental data by the RDK II Collaboration (Bales et al., Phys. Rev.\\nLett. 116, 242501 (2016)) within 1.5 standard deviations. We argue a\\nsubstantial influence of strong low-energy interactions of hadrons coupled to\\nphotons on the properties of the amplitude of the neutron radiative beta decay\\nunder gauge transformations of real and virtual photons.\\n',\n",
       " '  Many important complex networks, including critical infrastructure and\\nemerging industrial automation systems, are becoming increasingly intricate\\nwebs of interacting feedback control loops. A fundamental concern is to\\nquantify the control properties and performance limitations of the network as a\\nfunction of its dynamical structure and control architecture. We study\\nperformance bounds for networks in terms of optimal feedback control costs. We\\nprovide a set of complementary bounds as a function of the system dynamics and\\nactuator structure. For unstable network dynamics, we characterize a tradeoff\\nbetween feedback control performance and the number of control inputs, in\\nparticular showing that optimal cost can increase exponentially with the size\\nof the network. We also derive a bound on the performance of the worst-case\\nactuator subset for stable networks, providing insight into dynamics properties\\nthat affect the potential efficacy of actuator selection. We illustrate our\\nresults with numerical experiments that analyze performance in regular and\\nrandom networks.\\n',\n",
       " '  Diffusion and flow-driven instability, or transport-driven instability, is\\none of the central mechanisms to generate inhomogeneous gradient of\\nconcentrations in spatially distributed chemical systems. However, verifying\\nthe transport-driven instability of reaction-diffusion-advection systems\\nrequires checking the Jacobian eigenvalues of infinitely many Fourier modes,\\nwhich is computationally intractable. To overcome this limitation, this paper\\nproposes mathematical optimization algorithms that determine the\\nstability/instability of reaction-diffusion-advection systems by finite steps\\nof algebraic calculations. Specifically, the stability/instability analysis of\\nFourier modes is formulated as a sum-of-squares (SOS) optimization program,\\nwhich is a class of convex optimization whose solvers are widely available as\\nsoftware packages. The optimization program is further extended for facile\\ncomputation of the destabilizing spatial modes. This extension allows for\\npredicting and designing the shape of concentration gradient without simulating\\nthe governing equations. The streamlined analysis process of self-organized\\npattern formation is demonstrated with a simple illustrative reaction model\\nwith diffusion and advection.\\n',\n",
       " '  We study collective modes in a classical system of particles with repulsive\\ninverse-power-law (IPL) interactions in the fluid phase, near the fluid-solid\\ncoexistence (IPL melts). The IPL exponent is varied from $n=10$ to $n=100$ to\\nmimic the transition from moderately soft to hard-sphere-like interactions. We\\ncompare the longitudinal dispersion relations obtained using molecular dynamic\\n(MD) simulations with those calculated using the quasi-crystalline\\napproximation (QCA) and find that this simple theoretical approach becomes\\ngrossly inaccurate for $n\\\\gtrsim 20$. Similarly, conventional expressions for\\nhigh-frequency (instantaneous) elastic moduli, predicting their divergence as\\n$n$ increases, are meaningless in this regime. Relations of the longitudinal\\nand transverse elastic velocities of the QCA model to the adiabatic sound\\nvelocity, measured in MD simulations, are discussed for the regime where QCA is\\napplicable. Two potentially useful freezing indicators for classical particle\\nsystems with steep repulsive interactions are discussed.\\n',\n",
       " '  Today when many practitioners run basic NLP on the entire web and\\nlarge-volume traffic, faster methods are paramount to saving time and energy\\ncosts. Recent advances in GPU hardware have led to the emergence of\\nbi-directional LSTMs as a standard method for obtaining per-token vector\\nrepresentations serving as input to labeling tasks such as NER (often followed\\nby prediction in a linear-chain CRF). Though expressive and accurate, these\\nmodels fail to fully exploit GPU parallelism, limiting their computational\\nefficiency. This paper proposes a faster alternative to Bi-LSTMs for NER:\\nIterated Dilated Convolutional Neural Networks (ID-CNNs), which have better\\ncapacity than traditional CNNs for large context and structured prediction.\\nUnlike LSTMs whose sequential processing on sentences of length N requires O(N)\\ntime even in the face of parallelism, ID-CNNs permit fixed-depth convolutions\\nto run in parallel across entire documents. We describe a distinct combination\\nof network structure, parameter sharing and training procedures that enable\\ndramatic 14-20x test-time speedups while retaining accuracy comparable to the\\nBi-LSTM-CRF. Moreover, ID-CNNs trained to aggregate context from the entire\\ndocument are even more accurate while maintaining 8x faster test time speeds.\\n',\n",
       " '  The SPARC TSO weak memory model is defined axiomatically, with a\\nnon-compositional formulation that makes modular reasoning about programs\\ndifficult. Our denotational approach uses pomsets to provide a compositional\\nsemantics capturing exactly the behaviours permitted by SPARC TSO. It uses\\nbuffered states and an inductive definition of execution to assign an\\ninput-output meaning to pomsets. We show that our denotational account is sound\\nand complete relative to the axiomatic account, that is, that it captures\\nexactly the behaviours permitted by the axiomatic account. Our compositional\\napproach facilitates the study of SPARC TSO and supports modular analysis of\\nprogram behaviour.\\n',\n",
       " '  We construct a class of non-commutative, non-cocommutative, semisimple Hopf\\nalgebras of dimension $2n^2$ and present conditions to define an inner faithful\\naction of these Hopf algebras on quantum polynomial algebras, providing, in\\nthis way, more examples of semisimple Hopf actions which do not factor through\\ngroup actions. Also, under certain condition, we classify the inner faithful\\nHopf actions of the Kac-Paljutkin Hopf algebra of dimension $8$, $H_8$, on the\\nquantum plane.\\n',\n",
       " '  Defect-free SrTiO3 (STO) is a band insulator but Angle Resolved Photoemission\\nSpectroscopy (ARPES) experiments have demonstrated the existence of a nanometer\\nthin two-dimensional electron liquid (2DEG) at the (001) oriented surface of\\nthis compound. The bulk is a trivial insulator, but our theoretical study\\nreveals that the parity of electronic wavefunctions in this 2DEG is inverted in\\nthe vicinity of special points in reciprocal space where the low-energy\\ndispersion consists of four gapped Dirac cones with a tilted and anisotropic\\nshape. This gives rise to linearly dispersing topological edge states at the\\none-dimensional boundary. We propose to probe these modes by measuring the\\nJosephson radiation from gapless bound Andreev states in STO based junctions,\\nas it is predicted that they display distinctive signatures of topology.\\n',\n",
       " \"  We seek the conditions for a {\\\\it steady} mean field galactic dynamo. The\\nparameter set is reduced to those appearing in the $\\\\alpha^2$ and\\n$\\\\alpha/\\\\omega$ dynamo, namely velocity amplitudes, and the ratio of sub-scale\\nhelicity to diffusivity. The parameters can be allowed to vary on conical\\nspirals. We analyze the mean field dynamo equations in terms of scale invariant\\nlogarithmic spiral modes and special exact solutions. Compatible scale\\ninvariant gravitational spiral arms are introduced and illustrated in an\\nappendix, but the detailed dynamical interaction with the magnetic field is\\nleft for another work. As a result of planar magnetic spirals `lifting' into\\nthe halo, multiple sign changes in average rotation measures forming a regular\\npattern on each side of the galactic minor axis, are predicted. Such changes\\nhave recently been detected in the CHANG-ES survey.\\n\",\n",
       " '  In this paper, we generalize the well-known index coding problem to exploit\\nthe structure in the source-data to improve system throughput. In many\\napplications, the data to be transmitted may lie (or can be well approximated)\\nin a low-dimensional subspace. We exploit this low-dimensional structure of the\\ndata using an algebraic framework to solve the index coding problem (referred\\nto as subspace-aware index coding) as opposed to the traditional index coding\\nproblem which is subspace-unaware. Also, we propose an efficient algorithm\\nbased on the alternating minimization approach to obtain near optimal index\\ncodes for both subspace-aware and -unaware cases. Our simulations indicate that\\nunder certain conditions, a significant throughput gain (about 90%) can be\\nachieved by subspace-aware index codes over conventional subspace-unaware index\\ncodes.\\n',\n",
       " '  We study the impact of thermal hysteresis at the first-order\\nstructural/ferroelectric phase transitions on the electrocaloric response in\\nbulk BaTiO$_3$ by performing molecular dynamics simulations for a\\nfirst-principles-based effective Hamiltonian. We demonstrate that the\\nelectrocaloric response can conceptually be separated in two contributions: a\\ntransitional part, stemming from the discontinuous jump in entropy at the first\\norder phase transition, and a configurational part, due to the continuous\\nchange of polarization and entropy within each phase. This latter part\\nincreases with the strength of the applied field, but for small fields it is\\nvery small. In contrast, we find a large temperature change of $\\\\sim 1$ K\\nresulting from the transition entropy, which is essentially independent of the\\nfield strength. However, due to the coexistence region close to the first order\\nphase transition, this large electrocaloric response depends on the thermal\\nhistory of the sample and is generally not reversible. We show that this\\nirreversibility can be overcome by using larger fields.\\n',\n",
       " '  The Collatz problem is one of many names (the Collatz Problem, the Syracuse\\nProblem, the Hailstone Problem, the 3x+1 problem). Most commonly, however, the\\nproblem goes by either the 3x+1 problem or the Collatz problem. In addition to\\nhaving many names, the Collatz problem has many variations, such as those in\\nthe form introduced by Jeffrey Lagarias in 1985. This writing discusses several\\nvariations of the Collatz function which involve the Mersenne numbers.\\nFollowing that, we observe the convergent cycles of these functions which we\\ncan then relate back to the original Collatz 3x+1 function. Lastly, we give a\\nproof of the No Divergent Trajectories Theorem and show why the same cannot be\\nshown for similar functions.\\n',\n",
       " '  We consider the cohomological Hall algebra Y of a Lagrangian substack of the\\nmoduli stack of representations of the preprojective algebra of an arbitrary\\nquiver Q, and its actions on the cohomology of quiver varieties. We conjecture\\nthat Y is equal, after a suitable extension of scalars, to the Yangian\\nintroduced by Maulik and Okounkov, and we construct an embedding of Y in the\\nYangian, intertwining the respective actions of both algebras on the cohomology\\nof quiver varieties.\\n',\n",
       " '  The basic idea behind information algebras is that information comes in\\npieces, each referring to a certain question, that these pieces can be combined\\nor aggregated and that the part relating to a given question can be extracted.\\nThis algebraic structure can be given different forms. Questions were\\noriginally represented by subsets of variables. Pieces of information were then\\nrepresented by valuations associated with the domains of variables. This leads\\nto an algebraic structure called valuation algebras. The basic axiomatics of\\nthis algebraic structure was in essence proposed by Shenoy and Shafer. Here a\\nmuch more general view of systems of questions is proposed and pieces of\\ninformation are related to the elements of this system of questions. This leads\\nto a new and extended system of axioms for information algebras. Classical\\nvaluation algebras are essentially a special case of this new system. A full\\ndiscussion of the algebraic theory of this new information algebras is given,\\nincluding local computation, duality between labeled and domain-free versions\\nof the algebras, order of information, finiteness of information and\\napproximation, compact and continuous information algebras. Finally a rather\\ncomplete discussion of uncertain information, based on random maps into\\ninformation algebras is presented. This is shown to represent a generalisation\\nof classical Dempster-Shafer theory.\\n',\n",
       " '  Deep neural networks for machine comprehension typically utilizes only word\\nor character embeddings without explicitly taking advantage of structured\\nlinguistic information such as constituency trees and dependency trees. In this\\npaper, we propose structural embedding of syntactic trees (SEST), an algorithm\\nframework to utilize structured information and encode them into vector\\nrepresentations that can boost the performance of algorithms for the machine\\ncomprehension. We evaluate our approach using a state-of-the-art neural\\nattention model on the SQuAD dataset. Experimental results demonstrate that our\\nmodel can accurately identify the syntactic boundaries of the sentences and\\nextract answers that are syntactically coherent over the baseline methods.\\n',\n",
       " '  A major goal in blind source separation to identify and separate sources is\\nto model their inherent characteristics. While most state-of-the-art approaches\\nare supervised methods trained on large datasets, interest in non-data-driven\\napproaches such as Kernel Additive Modelling (KAM) remains high due to their\\ninterpretability and adaptability. KAM performs the separation of a given\\nsource applying robust statistics on the time-frequency bins selected by a\\nsource-specific kernel function, commonly the K-NN function. This choice\\nassumes that the source of interest repeats in both time and frequency. In\\npractice, this assumption does not always hold. Therefore, we introduce a\\nshift-invariant kernel function capable of identifying similar spectral content\\neven under frequency shifts. This way, we can considerably increase the amount\\nof suitable sound material available to the robust statistics. While this leads\\nto an increase in separation performance, a basic formulation, however, is\\ncomputationally expensive. Therefore, we additionally present acceleration\\ntechniques that lower the overall computational complexity.\\n',\n",
       " \"  The National Football League's (NFL) 2011 collective bargaining agreement\\n(CBA) with its players placed a number of contact and quantity limitations on\\npractices and workouts. Some coaches and others have expressed a concern that\\nthis has led to poor conditioning and a subsequent increase in injuries. We\\nsought to assess whether the 2011 CBA's practice restrictions affected the\\nnumber of overall, conditioning-dependent, and/or non-conditioning-dependent\\ninjuries in the NFL or the number of games missed due to those injuries. The\\nstudy population was player-seasons from 2007-2016. We included regular season,\\nnon-illness, non-head, game-loss injuries. Injuries were identified using a\\ndatabase from Football Outsiders. The primary outcomes were overall,\\nconditioning-dependent and non-conditioning-dependent injury counts by season.\\nWe examined time trends in injury counts before (2007-2010) and after\\n(2011-2016) the CBA using a Poisson interrupted time series model. The number\\nof game-loss regular season, non-head, non-illness injuries grew from 701 in\\n2007 to 804 in 2016 (15% increase). The number of regular season weeks missed\\nexhibited a similar increase. Conditioning-dependent injuries increased from\\n197 in 2007 to 271 in 2011 (38% rise), but were lower and remained relatively\\nunchanged at 220-240 injuries per season thereafter. Non-conditioning injuries\\ndecreased by 37% in the first three years of the new CBA before returning to\\nhistoric levels in 2014-2016. Poisson models for all, conditioning-dependent,\\nand non-conditioning-dependent game-loss injury counts did not show\\nstatistically significant or meaningful detrimental changes associated with the\\nCBA. We did not observe an increase in injuries following the 2011 CBA. Other\\nconcurrent injury-related rule and regulation changes limit specific causal\\ninferences about the practice restrictions, however.\\n\",\n",
       " '  TeV photons from extragalactic sources are absorbed in the intergalactic\\nmedium and initiate electromagnetic cascades. These cascades offer a unique\\ntool to probe the properties of the universe at cosmological scales. We present\\na new Monte Carlo code dedicated to the physics of such cascades. This code has\\nbeen tested against both published results and analytical approximations, and\\nis made publicly available. Using this numerical tool, we investigate the main\\ncascade properties (spectrum, halo extension, time delays), and study in detail\\ntheir dependence on the physical parameters (extra-galactic magnetic field,\\nextra-galactic background light, source redshift, source spectrum and beaming\\nemission). The limitations of analytical solutions are emphasised. In\\nparticular, analytical approximations account only for the first generation of\\nphotons and higher branches of the cascade tree are neglected.\\n',\n",
       " '  Attitudes can have a profound impact on socially relevant behaviours, such as\\nvoting. However, this effect is not uniform across situations or individuals,\\nand it is at present difficult to predict whether attitudes will predict\\nbehaviour in any given circumstance. Using a network model, we demonstrate that\\n(a) more strongly connected attitude networks have a stronger impact on\\nbehaviour, and (b) within any given attitude network, the most central attitude\\nelements have the strongest impact. We test these hypotheses using data on\\nvoting and attitudes toward presidential candidates in the US presidential\\nelections from 1980 to 2012. These analyses confirm that the predictive value\\nof attitude networks depends almost entirely on their level of connectivity,\\nwith more central attitude elements having stronger impact. The impact of\\nattitudes on voting behaviour can thus be reliably determined before elections\\ntake place by using network analyses.\\n',\n",
       " '  In a physical neural system, learning rules must be local both in space and\\ntime. In order for learning to occur, non-local information must be\\ncommunicated to the deep synapses through a communication channel, the deep\\nlearning channel. We identify several possible architectures for this learning\\nchannel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges:\\n1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons;\\n4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of\\nlearning rules. Random backpropagation (RBP) addresses the second and third\\nsymmetry, and some of its variations, such as skipped RBP (SRBP) address the\\nfirst and the fourth symmetry. Here we address the last two desirable\\nsymmetries showing through simulations that they can be achieved and that the\\nlearning channel is particularly robust to symmetry variations. Specifically,\\nrandom backpropagation and its variations can be performed with the same\\nnon-linear neurons used in the main input-output forward channel, and the\\nconnections in the learning channel can be adapted using the same algorithm\\nused in the forward channel, removing the need for any specialized hardware in\\nthe learning channel. Finally, we provide mathematical results in simple cases\\nshowing that the learning equations in the forward and backward channels\\nconverge to fixed points, for almost any initial conditions. In symmetric\\narchitectures, if the weights in both channels are small at initialization,\\nadaptation in both channels leads to weights that are essentially symmetric\\nduring and after learning. Biological connections are discussed.\\n',\n",
       " '  Several representation learning and, more broadly, dimensionality reduction\\ntechniques seek to produce representations of the data that are orthogonal\\n(uncorrelated). Examples include PCA, CCA, Kernel/Deep CCA, the ACE algorithm\\nand correspondence analysis (CA). For a fixed data distribution, all finite\\nvariance representations belong to the same function space regardless of how\\nthey are derived. In this work, we present a theoretical framework for\\nanalyzing this function space, and demonstrate how a basis for this space can\\nbe found using neural networks. We show that this framework (i) underlies\\nrecent multi-view representation learning methods, (ii) enables classical\\nexploratory statistical techniques such as CA to be scaled via neural networks,\\nand (iii) can be used to derive new methods for comparing black-box models. We\\nillustrate these applications empirically through different datasets.\\n',\n",
       " \"  This paper presents an intelligent user interface model dedicated to the\\nexploration of complex databases. This model is implemented on a 3D metaphor :\\na virtual museum. In this metaphor, the database elements are embodied as\\nmuseum objects. The objects are grouped in rooms according to their semantic\\nproperties and relationships and the rooms organization forms the museum. Rooms\\norganization is not predefi-ned but defined incrementally by taking into\\naccount not only the relationships between objects, but also the users centers\\nof interest. The latter are evaluated in real-time through user interactions\\nwithin the virtual museum. This interface allows for a personal reading and\\nfavors the discovery of unsuspec-ted links between data. In this paper, we\\npresent our model's formalization as well as its application to the context of\\ncultural heritage.\\n\",\n",
       " '  In this article, we present the Lie transformation algorithm for autonomous\\nBirkhoff systems. Here, we are referring to Hamiltonian systems that obey a\\nsymplectic structure of the general form. Two examples of normalization in the\\nrestricted three-body problem are given to illustrate the application of the\\nalgorithm in perturbation theory. The efficiency of this algorithm for problems\\nof asymptotic integration in dynamics is discussed for the case where there is\\na need to use non-canonical variables in the phase space.\\n',\n",
       " '  Assessing and managing risks in a changing climate requires projections that\\naccount for decision-relevant uncertainties. These deep uncertainties are often\\napproximated by ensembles of Earth-system model runs that sample only a subset\\nof the known uncertainties. Here we demonstrate and quantify how this approach\\ncan cut off the tails of the distributions of projected climate variables such\\nas sea-level rise. As a result, low-probability high-impact events that may\\ndrive risks can be under-represented. Neglecting the tails of this deep\\nuncertainty may lead to overconfident projections and poor decisions when high\\nreliabilities are important.\\n',\n",
       " '  In this paper we present a geometric control law for position and\\nline-of-sight stabilization of the nonholonomic spherical robot actuated by\\nthree independent actuators. A simple configuration error function with an\\nappropriately defined transport map is proposed to extract feedforward and\\nproportional-derivative control law. Simulations are provided to validate the\\ncontroller performance.\\n',\n",
       " '  We study the finite-size spectrum of the O($N$) symmetric Wilson-Fisher\\nconformal field theory (CFT) on the $d=2$ spatial-dimension torus using the\\nexpansion in $\\\\epsilon=3-d$. This is done by deriving a set of universal\\neffective Hamiltonians describing fluctuations of the zero momentum modes. The\\neffective Hamiltonians take the form of $N$-dimensional quantum anharmonic\\noscillators, which are shown to be strongly coupled at the critical point for\\nsmall $\\\\epsilon$. The low-energy spectrum is solved numerically for $N =\\n1,2,3,4$. Using exact diagonalization (ED), we also numerically study explicit\\nlattice models known to be in the O($2$) and O($3$) universality class,\\nobtaining estimates of the low-lying critical spectrum. The analytic and\\nnumerical results show excellent agreement and the critical low energy torus\\nspectra are qualitatively different among the studied CFTs, identifying them as\\na useful fingerprint for detecting the universality class of a quantum critical\\npoint.\\n',\n",
       " '  Visual Domain Adaptation is a problem of immense importance in computer\\nvision. Previous approaches showcase the inability of even deep neural networks\\nto learn informative representations across domain shift. This problem is more\\nsevere for tasks where acquiring hand labeled data is extremely hard and\\ntedious. In this work, we focus on adapting the representations learned by\\nsegmentation networks across synthetic and real domains. Contrary to previous\\napproaches that use a simple adversarial objective or superpixel information to\\naid the process, we propose an approach based on Generative Adversarial\\nNetworks (GANs) that brings the embeddings closer in the learned feature space.\\nTo showcase the generality and scalability of our approach, we show that we can\\nachieve state of the art results on two challenging scenarios of synthetic to\\nreal domain adaptation. Additional exploratory experiments show that our\\napproach: (1) generalizes to unseen domains and (2) results in improved\\nalignment of source and target distributions.\\n',\n",
       " '  Relative smoothness - a notion introduced by Birnbaum et al. (2011) and\\nrediscovered by Bauschke et al. (2016) and Lu et al. (2016) - generalizes the\\nstandard notion of smoothness typically used in the analysis of gradient type\\nmethods. In this work we are taking ideas from well studied field of stochastic\\nconvex optimization and using them in order to obtain faster algorithms for\\nminimizing relatively smooth functions. We propose and analyze two new\\nalgorithms: Relative Randomized Coordinate Descent (relRCD) and Relative\\nStochastic Gradient Descent (relSGD), both generalizing famous algorithms in\\nthe standard smooth setting. The methods we propose can be in fact seen as a\\nparticular instances of stochastic mirror descent algorithms. One of them,\\nrelRCD corresponds to the first stochastic variant of mirror descent algorithm\\nwith linear convergence rate.\\n',\n",
       " '  Network quantization is an effective solution to compress deep neural\\nnetworks for practical usage. Existing network quantization methods cannot\\nsufficiently exploit the depth information to generate low-bit compressed\\nnetwork. In this paper, we propose two novel network quantization approaches,\\nsingle-level network quantization (SLQ) for high-bit quantization and\\nmulti-level network quantization (MLQ) for extremely low-bit quantization\\n(ternary).We are the first to consider the network quantization from both width\\nand depth level. In the width level, parameters are divided into two parts: one\\nfor quantization and the other for re-training to eliminate the quantization\\nloss. SLQ leverages the distribution of the parameters to improve the width\\nlevel. In the depth level, we introduce incremental layer compensation to\\nquantize layers iteratively which decreases the quantization loss in each\\niteration. The proposed approaches are validated with extensive experiments\\nbased on the state-of-the-art neural networks including AlexNet, VGG-16,\\nGoogleNet and ResNet-18. Both SLQ and MLQ achieve impressive results.\\n',\n",
       " '  We present the photometric results of the eclipsing cataclysmic variable (CV)\\nWZ Sge near the period minimum ($P_{min}$). Eight new mid-eclipse times were\\ndetermined and the orbital ephemeris was updated. Our result shows that the\\norbital period of WZ Sge is decreasing at a rate of\\n$\\\\dot{P}=-2.72(\\\\pm0.23)\\\\times{10^{-13}}\\\\,s s^{-1}$. This secular decrease,\\ncoupled with previous detection of its donor, suggest that WZ Sge is a\\npre-bounce system. Further analysis indicates that the observed period decrease\\nrate is about $1.53$ times higher than pure gravitational radiation (GR)\\ndriving. We constructed the evolutionary track of WZ Sge, which predicts that\\n$P_{min}$ of WZ Sge is $\\\\sim77.98 (\\\\pm0.90)$ min. If the orbital period\\ndecreases at the current rate, WZ Sge will evolve past its $P_{min}$ after\\n$\\\\sim25.3$ Myr. Based on the period evolution equation we find\\n$\\\\dot{M}_{2}\\\\simeq4.04(\\\\pm0.10)\\\\times10^{-11}M_{\\\\odot}yr^{-1}$, which is\\ncompatible with the current concept of CV evolution at ultrashort orbital\\nperiods.\\n',\n",
       " '  A theoretical analysis of the unfolding pathway of simple modular proteins in\\nlength- controlled pulling experiments is put forward. Within this framework,\\nwe predict the first module to unfold in a chain of identical units,\\nemphasizing the ranges of pulling speeds in which we expect our theory to hold.\\nThese theoretical predictions are checked by means of steered molecular\\ndynamics of a simple construct, specifically a chain composed of two\\ncoiled-coils motives, where anisotropic features are revealed. These\\nsimulations also allow us to give an estimate for the range of pulling\\nvelocities in which our theoretical approach is valid.\\n',\n",
       " \"  In the modern era, each Internet user leaves enormous amounts of auxiliary\\ndigital residuals (footprints) by using a variety of on-line services. All this\\ndata is already collected and stored for many years. In recent works, it was\\ndemonstrated that it's possible to apply simple machine learning methods to\\nanalyze collected digital footprints and to create psycho-demographic profiles\\nof individuals. However, while these works clearly demonstrated the\\napplicability of machine learning methods for such an analysis, created simple\\nprediction models still lacks accuracy necessary to be successfully applied for\\npractical needs. We have assumed that using advanced deep machine learning\\nmethods may considerably increase the accuracy of predictions. We started with\\nsimple machine learning methods to estimate basic prediction performance and\\nmoved further by applying advanced methods based on shallow and deep neural\\nnetworks. Then we compared prediction power of studied models and made\\nconclusions about its performance. Finally, we made hypotheses how prediction\\naccuracy can be further improved. As result of this work, we provide full\\nsource code used in the experiments for all interested researchers and\\npractitioners in corresponding GitHub repository. We believe that applying deep\\nmachine learning for psycho-demographic profiling may have an enormous impact\\non the society (for good or worse) and provides means for Artificial\\nIntelligence (AI) systems to better understand humans by creating their\\npsychological profiles. Thus AI agents may achieve the human-like ability to\\nparticipate in conversation (communication) flow by anticipating human\\nopponents' reactions, expectations, and behavior.\\n\",\n",
       " '  To every convex body $K \\\\subseteq \\\\mathbb{R}^d$, one may associate a minimal\\nmatrix convex set $\\\\mathcal{W}^{\\\\textrm{min}}(K)$, and a maximal matrix convex\\nset $\\\\mathcal{W}^{\\\\textrm{max}}(K)$, which have $K$ as their ground level. The\\nmain question treated in this paper is: under what conditions on a given pair\\nof convex bodies $K,L \\\\subseteq \\\\mathbb{R}^d$ does\\n$\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq \\\\mathcal{W}^{\\\\textrm{min}}(L)$ hold?\\nFor a convex body $K$, we aim to find the optimal constant $\\\\theta(K)$ such\\nthat $\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq \\\\theta(K) \\\\cdot\\n\\\\mathcal{W}^{\\\\textrm{min}}(K)$; we achieve this goal for all the $\\\\ell^p$ unit\\nballs, as well as for other sets. For example, if $\\\\overline{\\\\mathbb{B}}_{p,d}$\\nis the closed unit ball in $\\\\mathbb{R}^d$ with the $\\\\ell^p$ norm, then \\\\[\\n\\\\theta(\\\\overline{\\\\mathbb{B}}_{p,d}) = d^{1-|1/p - 1/2|}. \\\\] This constant is\\nsharp, and it is new for all $p \\\\neq 2$. Moreover, for some sets $K$ we find a\\nminimal set $L$ for which $\\\\mathcal{W}^{\\\\textrm{max}}(K) \\\\subseteq\\n\\\\mathcal{W}^{\\\\textrm{min}}(L)$. In particular, we obtain that a convex body $K$\\nsatisfies $\\\\mathcal{W}^{\\\\textrm{max}}(K) = \\\\mathcal{W}^{\\\\textrm{min}}(K)$ if\\nand only if $K$ is a simplex.\\nThese problems relate to dilation theory, convex geometry, operator systems,\\nand completely positive maps. We discuss and exploit these connections as well.\\nFor example, our results show that every $d$-tuple of self-adjoint operators of\\nnorm less than or equal to $1$, can be dilated to a commuting family of\\nself-adjoints, each of norm at most $\\\\sqrt{d}$. We also introduce new explicit\\nconstructions of these (and other) dilations.\\n',\n",
       " '  Grasp detection is an essential skill for widespread use of robots. Recent\\nworks demonstrate the advanced performance of Convolutional Neural Network\\n(CNN) on robotic grasp detection. However, a significant shortcoming of\\nexisting grasp detection algorithms is that they all ignore the affiliation\\nbetween grasps and targets. In this paper, we propose a robotic grasp detection\\nalgorithm based on Region of Interest (RoI) to simultaneously detect targets\\nand their grasps in object overlapping scenes. Our proposed algorithm uses\\nRegions of Interest (RoIs) to detect grasps while doing classification and\\nlocation regression of targets. To train the network, we contribute a much\\nbigger multi-object grasp dataset than Cornell Grasp Dataset, which is based on\\nVisual Manipulation Relationship Dataset. Experimental results demonstrate that\\nour algorithm achieves 24.9% miss rate at 1FPPI and 68.2% mAP with grasp on our\\ndataset. Robotic experiments demonstrate that our proposed algorithm can help\\nrobots grasp specified target in multi-object scenes at 84% success rate.\\n',\n",
       " \"  Ceramic is a material frequently used in industry because of its favorable\\nproperties. Common approaches in shape optimization for ceramic structures aim\\nto minimize the tensile stress acting on the component, as it is the main\\ndriver for failure. In contrast to this, we follow a more natural approach by\\nminimizing the component's probability of failure under a given tensile load.\\nSince the fundamental work of Weibull, the probabilistic description of the\\nstrength of ceramics is standard and has been widely applied. Here, for the\\nfirst time, the resulting failure probabilities are used as objective functions\\nin PDE constrained shape optimization.\\nTo minimize the probability of failure, we choose a gradient based method\\ncombined with a first discretize then optimize approach. For discretization\\nfinite elements are used. Using the Lagrangian formalism, the shape gradient\\nvia the adjoint equation is calculated at low computational cost. The\\nimplementation is verified by comparison of it with a finite difference method\\napplied to a minimal 2d example. Furthermore, we construct shape flows towards\\nan optimal / improved shape in the case of a simple beam and a bended joint.\\n\",\n",
       " '  We consider online linear optimization over symmetric positive semi-definite\\nmatrices, which has various applications including the online collaborative\\nfiltering. The problem is formulated as a repeated game between the algorithm\\nand the adversary, where in each round t the algorithm and the adversary choose\\nmatrices X_t and L_t, respectively, and then the algorithm suffers a loss given\\nby the Frobenius inner product of X_t and L_t. The goal of the algorithm is to\\nminimize the cumulative loss. We can employ a standard framework called Follow\\nthe Regularized Leader (FTRL) for designing algorithms, where we need to choose\\nan appropriate regularization function to obtain a good performance guarantee.\\nWe show that the log-determinant regularization works better than other popular\\nregularization functions in the case where the loss matrices L_t are all\\nsparse. Using this property, we show that our algorithm achieves an optimal\\nperformance guarantee for the online collaborative filtering. The technical\\ncontribution of the paper is to develop a new technique of deriving performance\\nbounds by exploiting the property of strong convexity of the log-determinant\\nwith respect to the loss matrices, while in the previous analysis the strong\\nconvexity is defined with respect to a norm. Intuitively, skipping the norm\\nanalysis results in the improved bound. Moreover, we apply our method to online\\nlinear optimization over vectors and show that the FTRL with the Burg entropy\\nregularizer, which is the analogue of the log-determinant regularizer in the\\nvector case, works well.\\n',\n",
       " '  Several auroral events that occurred in the past have not been catalogued as\\nsuch due to fact that they were described in the historical sources with\\ndifferent terminology. Hayakawa et al. (2016) have reviewed historical oriental\\nchronicles and have proposed the terms \"unusual rainbow\" and \"white rainbow\" as\\ncandidates to auroras. In this work, we present three events that took place in\\nthe 18th century in two different settings (the Iberian Peninsula and Brazil)\\nthat were originally described with similar definition/wording used by the\\noriental chronicles, despite the inherent differences in terms associated to\\noriental and Latin languages. We show that these terms are indeed applicable to\\nthe three case studies from Europe and South America. Thus, the auroral\\ncatalogues available can be extended for occidental sources with this new\\nterminology.\\n',\n",
       " '  Convnets have enabled significant progress in pedestrian detection recently,\\nbut there are still open questions regarding suitable architectures and\\ntraining data. We revisit CNN design and point out key adaptations, enabling\\nplain FasterRCNN to obtain state-of-the-art results on the Caltech dataset.\\nTo achieve further improvement from more and better data, we introduce\\nCityPersons, a new set of person annotations on top of the Cityscapes dataset.\\nThe diversity of CityPersons allows us for the first time to train one single\\nCNN model that generalizes well over multiple benchmarks. Moreover, with\\nadditional training with CityPersons, we obtain top results using FasterRCNN on\\nCaltech, improving especially for more difficult cases (heavy occlusion and\\nsmall scale) and providing higher localization quality.\\n',\n",
       " '  We consider matrix completion for recommender systems from the point of view\\nof link prediction on graphs. Interaction data such as movie ratings can be\\nrepresented by a bipartite user-item graph with labeled edges denoting observed\\nratings. Building on recent progress in deep learning on graph-structured data,\\nwe propose a graph auto-encoder framework based on differentiable message\\npassing on the bipartite interaction graph. Our model shows competitive\\nperformance on standard collaborative filtering benchmarks. In settings where\\ncomplimentary feature information or structured data such as a social network\\nis available, our framework outperforms recent state-of-the-art methods.\\n',\n",
       " \"  Clustering consists of grouping together samples giving their similar\\nproperties. The problem of modeling simultaneously groups of samples and\\nfeatures is known as Co-Clustering. This paper introduces ROCCO - a Robust\\nContinuous Co-Clustering algorithm. ROCCO is a scalable, hyperparameter-free,\\neasy and ready to use algorithm to address Co-Clustering problems in practice\\nover massive cross-domain datasets. It operates by learning a graph-based\\ntwo-sided representation of the input matrix. The underlying proposed\\noptimization problem is non-convex, which assures a flexible pool of solutions.\\nMoreover, we prove that it can be solved with a near linear time complexity on\\nthe input size. An exhaustive large-scale experimental testbed conducted with\\nboth synthetic and real-world datasets demonstrates ROCCO's properties in\\npractice: (i) State-of-the-art performance in cross-domain real-world problems\\nincluding Biomedicine and Text Mining; (ii) very low sensitivity to\\nhyperparameter settings; (iii) robustness to noise and (iv) a linear empirical\\nscalability in practice. These results highlight ROCCO as a powerful\\ngeneral-purpose co-clustering algorithm for cross-domain practitioners,\\nregardless of their technical background.\\n\",\n",
       " '  He atom scattering has been shown to be a sensitive probe of electron-phonon\\ninteraction properties at surfaces. Here it is shown that measurements of the\\nthermal attenuation of the specular He atom diffraction peak (the Debye-Waller\\neffect) can determine the electron-phonon coupling constant $\\\\lambda$ for\\nultrathin films of metal overlayers on various close-packed metal substrates.\\nValues of $\\\\lambda$ obtained for single and multiple monolayers of alkali\\nmetals, and for Pb layers on Cu(111), extrapolated to large thicknesses, agree\\nfavorably with known bulk values. This demonstrates that He atom scattering can\\nmeasure the electron-phonon coupling strength as a function of film thickness\\non a layer-by-layer basis.\\n',\n",
       " '  We prove the classification of homomorphisms from the algebra of symmetric\\nfunctions to $\\\\mathbb{R}$ with non-negative values on Macdonald symmetric\\nfunctions $P_{\\\\lambda}$, that was conjectured by S.V. Kerov in 1992.\\n',\n",
       " '  We give a characterization of $n$-cluster tilting subcategories of\\nrepresentation-directed algebras based on the $n$-Auslander-Reiten\\ntranslations. As an application we classify acyclic Nakayama algebras with\\nhomogeneous relations which admit an $n$-cluster tilting subcategory. Finally,\\nwe classify Nakayama algebras of global dimension $d<\\\\infty$ which admit a\\n$d$-cluster tilting subcategory.\\n',\n",
       " '  This paper is concerned with developing a novel distributed Kalman filtering\\nalgorithm over wireless sensor networks based on randomized consensus strategy.\\nCompared with the centralized algorithm, distributed filtering techniques\\nrequire less computation per sensor and lead to more robust estimation since\\nthey simply use the information from the neighboring nodes in the network.\\nHowever, poor local sensor estimation caused by limited observability and\\nnetwork topology changes which interfere the global consensus are challenging\\nissues. Motivated by this observation, we propose a novel randomized\\ngossip-based distributed Kalman filtering algorithm. Information exchange and\\ncomputation in the proposed algorithm can be carried out in an arbitrarily\\nconnected network of nodes. In addition, the computational burden can be\\ndistributed for a sensor which communicates with a stochastically selected\\nneighbor at each clock step under schemes of gossip algorithm. In this case,\\nthe error covariance matrix changes stochastically at every clock step, thus\\nthe convergence is considered in a probabilistic sense. We provide the mean\\nsquare convergence analysis of the proposed algorithm. Under a sufficient\\ncondition, we show that the proposed algorithm is quite appealing as it\\nachieves better mean square error performance theoretically than the\\nnoncooperative decentralized Kalman filtering algorithm. Besides, considering\\nthe limited computation, communication, and energy resources in the wireless\\nsensor networks, we propose an optimization problem which minimizes the average\\nexpected state estimation error based on the proposed algorithm. To solve the\\nproposed problem efficiently, we transform it into a convex optimization\\nproblem. And a sub-optimal solution is attained. Examples and simulations are\\nprovided to illustrate the theoretical results.\\n',\n",
       " '  This work, which extends Squire et al. [ApJL, 830 L25 (2016)], explores the\\neffect of self-generated pressure anisotropy on linearly polarized\\nshear-Alfvén fluctuations in low-collisionality plasmas. Such anisotropies\\nlead to stringent limits on the amplitude of magnetic perturbations in\\nhigh-beta plasmas, above which a fluctuation can destabilize itself through the\\nparallel firehose instability. This causes the wave frequency to approach zero,\\n\"interrupting\" the wave and stopping its oscillation. These effects are\\nexplored in detail in the collisionless and weakly collisional \"Braginskii\"\\nregime, for both standing and traveling waves. The focus is on simplified\\nmodels in one dimension, on scales much larger than the ion gyroradius. The\\neffect has interesting implications for the physics of magnetized turbulence in\\nthe high-beta conditions that are prevalent in many astrophysical plasmas.\\n',\n",
       " \"  We show that the automorphism group of Philip Hall's universal locally finite\\ngroup has ample generics,that is, it admits comeager diagonal conjugacy classes\\nin all dimensions.Consequently, it has the small index property, is not the\\nunion of a countable chain of non-open subgroups, and has the automatic\\ncontinuity property. Also, we discuss some algebraic and topological properties\\nof the automorphism group of Hall universal group. For example, we show that\\nevery generic automorphism of Hall universal group is conjugate to all of its\\npowers, and hence has roots of all orders.\\n\",\n",
       " '  Security enhancement is important in terms of both classical and quantum\\ninformation. The recent development of a quantum storage device is noteworthy,\\nand a coherence time of one second or longer has been demonstrated. On the\\nother hand, although the encryption of a quantum bit or quantum memory has been\\nproposed theoretically, no experiment has yet been carried out. Here we report\\nthe demonstration of a quantum memory with an encryption function that is\\nrealized by scrambling and retrieving the recorded quantum phase. We developed\\ntwo independent Ramsey interferometers on an atomic ensemble trapped below a\\npersistent supercurrent atom chip. By operating the two interferometers with\\nrandom phases, the quantum phase recorded by a pulse of the first\\ninterferometer was modulated by the second interferometer pulse. The scrambled\\nquantum phase was restored by employing another pulse of the second\\ninterferometer with a specific time delay. This technique paves way for\\nimproving the security of quantum information technology.\\n',\n",
       " '  The object of the present paper is to introduce and investigate two new\\ngeneral subclasses ${{S}^{*}}C(\\\\alpha ,\\\\beta ;\\\\gamma )$ and $T{{S}^{*}}C(\\\\alpha\\n,\\\\beta ;\\\\gamma )~~(\\\\alpha, \\\\beta \\\\in [0,1),~\\\\gamma \\\\in [0,1])$ of the analytic\\nfunctions. Here, we give sufficient conditions as well as necessary and\\nsufficient conditions for the functions belonging to the classes.\\n',\n",
       " '  The current models of image representation based on Convolutional Neural\\nNetworks (CNN) have shown tremendous performance in image retrieval. Such\\nmodels are inspired by the information flow along the visual pathway in the\\nhuman visual cortex. We propose that in the field of particular object\\nretrieval, the process of extracting CNN representations from query images with\\na given region of interest (ROI) can also be modelled by taking inspiration\\nfrom human vision. Particularly, we show that by making the CNN pay attention\\non the ROI while extracting query image representation leads to significant\\nimprovement over the baseline methods on challenging Oxford5k and Paris6k\\ndatasets. Furthermore, we propose an extension to a recently introduced\\nencoding method for CNN representations, regional maximum activations of\\nconvolutions (R-MAC). The proposed extension weights the regional\\nrepresentations using a novel saliency measure prior to aggregation. This leads\\nto further improvement in retrieval accuracy.\\n',\n",
       " '  Current astrophysical models of the interstellar medium assume that small\\nscale variation and noise can be modelled as Gaussian random fields or simple\\ntransformations thereof, such as lognormal. We use topological methods to\\ninvestigate this assumption for three regions of the southern sky. We consider\\nGaussian random fields on two-dimensional lattices and investigate the expected\\ndistribution of topological structures quantified through Betti numbers. We\\ndemonstrate that there are circumstances where differences in topology can\\nidentify differences in distributions when conventional marginal or correlation\\nanalyses may not. We propose a non-parametric method for comparing two fields\\nbased on the counts of topological features and the geometry of the associated\\npersistence diagrams. When we apply the methods to the astrophysical data, we\\nfind strong evidence against a Gaussian random field model for each of the\\nthree regions of the interstellar medium that we consider. Further, we show\\nthat there are topological differences at a local scale between these different\\nregions.\\n',\n",
       " '  We present a study of the kinematics of the extraplanar ionized gas around\\nseveral dozen galaxies observed by the Mapping of Nearby Galaxies at the Apache\\nPoint Observatory (MaNGA) survey. We considered a sample of 67 edge-on galaxies\\nout of more than 1400 extragalactic targets observed by MaNGA, in which we\\nfound 25 galaxies (or 37%) with regular lagging of the rotation curve at large\\ndistances from the galactic midplane. We model the observed $H\\\\alpha$ emission\\nvelocity fields in the galaxies, taking projection effects and a simple model\\nfor the dust extinction into the account. We show that the vertical lag of the\\nrotation curve is necessary in the modeling, and estimate the lag amplitude in\\nthe galaxies. We find no correlation between the lag and the star formation\\nrate in the galaxies. At the same time, we report a correlation between the lag\\nand the galactic stellar mass, central stellar velocity dispersion, and axial\\nratio of the light distribution. These correlations suggest a possible higher\\nratio of infalling-to-local gas in early-type disk galaxies or a connection\\nbetween lags and the possible presence of hot gaseous halos, which may be more\\nprevalent in more massive galaxies. These results again demonstrate that\\nobservations of extraplanar gas can serve as a potential probe for accretion of\\ngas.\\n',\n",
       " '  In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of\\nn regions (neighborhoods) and we seek a shortest tour that visits each region.\\nAs a generalization of the classical Euclidean TSP, TSPN is also NP-hard. In\\nthis paper, we present new approximation results for the TSPN, including (1) a\\nconstant-factor approximation algorithm for the case of arbitrary connected\\nneighborhoods having comparable diameters; and (2) a PTAS for the important\\nspecial case of disjoint unit disk neighborhoods (or nearly disjoint,\\nnearly-unit disks). Our methods also yield improved approximation ratios for\\nvarious special classes of neighborhoods, which have previously been studied.\\nFurther, we give a linear-time O(1)-approximation algorithm for the case of\\nneighborhoods that are (infinite) straight lines.\\n',\n",
       " '  This paper implements Simultaneous Localization and Mapping (SLAM) technique\\nto construct a map of a given environment. A Real Time Appearance Based Mapping\\n(RTAB-Map) approach was taken for accomplishing this task. Initially, a 2d\\noccupancy grid and 3d octomap was created from a provided simulated\\nenvironment. Next, a personal simulated environment was created for mapping as\\nwell. In this appearance based method, a process called Loop Closure is used to\\ndetermine whether a robot has seen a location before or not. In this paper, it\\nis seen that RTAB-Map is optimized for large scale and long term SLAM by using\\nmultiple strategies to allow for loop closure to be done in real time and the\\nresults depict that it can be an excellent solution for SLAM to develop robots\\nthat can map an environment in both 2d and 3d.\\n',\n",
       " '  The widespread availability of electronic health records (EHRs) promises to\\nusher in the era of personalized medicine. However, the problem of extracting\\nuseful clinical representations from longitudinal EHR data remains challenging.\\nIn this paper, we explore deep neural network models with learned medical\\nfeature embedding to deal with the problems of high dimensionality and\\ntemporality. Specifically, we use a multi-layer convolutional neural network\\n(CNN) to parameterize the model and is thus able to capture complex non-linear\\nlongitudinal evolution of EHRs. Our model can effectively capture local/short\\ntemporal dependency in EHRs, which is beneficial for risk prediction. To\\naccount for high dimensionality, we use the embedding medical features in the\\nCNN model which hold the natural medical concepts. Our initial experiments\\nproduce promising results and demonstrate the effectiveness of both the medical\\nfeature embedding and the proposed convolutional neural network in risk\\nprediction on cohorts of congestive heart failure and diabetes patients\\ncompared with several strong baselines.\\n',\n",
       " '  Automatic assembly has broad applications in industries. Traditional assembly\\ntasks utilize predefined trajectories or tuned force control parameters, which\\nmake the automatic assembly time-consuming, difficult to generalize, and not\\nrobust to uncertainties. In this paper, we propose a learning framework for\\nhigh precision industrial assembly. The framework combines both the supervised\\nlearning and the reinforcement learning. The supervised learning utilizes\\ntrajectory optimization to provide the initial guidance to the policy, while\\nthe reinforcement learning utilizes actor-critic algorithm to establish the\\nevaluation system when the supervisor is not accurate. The proposed learning\\nframework is more efficient compared with the reinforcement learning and\\nachieves better stability performance than the supervised learning. The\\neffectiveness of the method is verified by both the simulation and experiment.\\nExperimental videos are available at~\\\\cite{website}.\\n',\n",
       " '  Business process models describe the way of working in an organization.\\nTypically, business process models distinguish between the normal flow of work\\nand exceptions to that normal flow. However, they often present an idealized\\nview. This means that unexpected exceptions - exceptions that are not modelled\\nin the business process model - can also occur in practice. This has an effect\\non the efficiency of the organization, because information systems are not\\ndeveloped to handle unexpected exceptions. This paper studies the relation\\nbetween the occurrence of exceptions and operational performance. It does this\\nby analyzing the execution logs of business processes from five organizations,\\nclassifying execution paths as normal or exceptional. Subsequently, it analyzes\\nthe differences between normal and exceptional paths. The results show that\\nexceptions are related to worse operational performance in terms of a longer\\nthroughput time and that unexpected exceptions relate to a stronger increase in\\nthroughput time than expected exceptions.\\n',\n",
       " '  We build simple computational models of belief dynamics within the framework\\nof discrete-spin statistical physics models, and explore how suitable they are\\nfor understanding and predicting real-world belief change on both the\\nindividual and group levels. We find that accurate modeling of real-world\\npatterns requires attending to social interaction rules that people use,\\nnetwork structures in which they are embedded, distributions of initial beliefs\\nand intrinsic preferences, and the relative importance of social information\\nand intrinsic preferences. We demonstrate that these model parameters can be\\nconstrained by empirical measurement, and the resulting models can be used to\\ninvestigate the mechanisms underlying belief dynamics in actual societies. We\\nuse data from two longitudinal studies of belief change, one on 80~individuals\\nliving in an MIT dorm during the 2008 presidential election season, and another\\non 94~participants recruited from Mechanical Turk during the 2016 presidential\\nelection primary season. We find that simple statistical physics-based models\\ncontain predictive value for real-world belief dynamics and enable empirical\\ntests of different assumptions about the underlying network structure and the\\nsocial interaction rules.\\n',\n",
       " '  Dropout is a simple yet effective algorithm for regularizing neural networks\\nby randomly dropping out units through Bernoulli multiplicative noise, and for\\nsome restricted problem classes, such as linear or logistic regression, several\\ntheoretical studies have demonstrated the equivalence between dropout and a\\nfully deterministic optimization problem with data-dependent Tikhonov\\nregularization. This work presents a theoretical analysis of dropout for matrix\\nfactorization, where Bernoulli random variables are used to drop a factor,\\nthereby attempting to control the size of the factorization. While recent work\\nhas demonstrated the empirical effectiveness of dropout for matrix\\nfactorization, a theoretical understanding of the regularization properties of\\ndropout in this context remains elusive. This work demonstrates the equivalence\\nbetween dropout and a fully deterministic model for matrix factorization in\\nwhich the factors are regularized by the sum of the product of the norms of the\\ncolumns. While the resulting regularizer is closely related to a variational\\nform of the nuclear norm, suggesting that dropout may limit the size of the\\nfactorization, we show that it is possible to trivially lower the objective\\nvalue by doubling the size of the factorization. We show that this problem is\\ncaused by the use of a fixed dropout rate, which motivates the use of a rate\\nthat increases with the size of the factorization. Synthetic experiments\\nvalidate our theoretical findings.\\n',\n",
       " '  Research on vehicular networking (V2X) security has produced a range of\\nsecurity mechanisms and protocols tailored for this domain, addressing both\\nsecurity and privacy. Typically, the security analysis of these proposals has\\nlargely been informal. However, formal analysis can be used to expose flaws and\\nultimately provide a higher level of assurance in the protocols.\\nThis paper focusses on the formal analysis of a particular element of\\nsecurity mechanisms for V2X found in many proposals: the revocation of\\nmalicious or misbehaving vehicles from the V2X system by invalidating their\\ncredentials. This revocation needs to be performed in an unlinkable way for\\nvehicle privacy even in the context of vehicles regularly changing their\\npseudonyms. The REWIRE scheme by Forster et al. and its subschemes BASIC and\\nRTOKEN aim to solve this challenge by means of cryptographic solutions and\\ntrusted hardware.\\nFormal analysis using the TAMARIN prover identifies two flaws with some of\\nthe functional correctness and authentication properties in these schemes. We\\nthen propose Obscure Token (OTOKEN), an extension of REWIRE to enable\\nrevocation in a privacy preserving manner. Our approach addresses the\\nfunctional and authentication properties by introducing an additional key-pair,\\nwhich offers a stronger and verifiable guarantee of successful revocation of\\nvehicles without resolving the long-term identity. Moreover OTOKEN is the first\\nV2X revocation protocol to be co-designed with a formal model.\\n',\n",
       " '  Group factor analysis (GFA) methods have been widely used to infer the common\\nstructure and the group-specific signals from multiple related datasets in\\nvarious fields including systems biology and neuroimaging. To date, most\\navailable GFA models require Gibbs sampling or slice sampling to perform\\ninference, which prevents the practical application of GFA to large-scale data.\\nIn this paper we present an efficient collapsed variational inference (CVI)\\nalgorithm for the nonparametric Bayesian group factor analysis (NGFA) model\\nbuilt upon an hierarchical beta Bernoulli process. Our CVI algorithm proceeds\\nby marginalizing out the group-specific beta process parameters, and then\\napproximating the true posterior in the collapsed space using mean field\\nmethods. Experimental results on both synthetic and real-world data demonstrate\\nthe effectiveness of our CVI algorithm for the NGFA compared with\\nstate-of-the-art GFA methods.\\n',\n",
       " '  Single-cell RNA sequencing (scRNA-seq) is a fast growing approach to measure\\nthe genome-wide transcriptome of many individual cells in parallel, but results\\nin noisy data with many dropout events. Existing methods to learn molecular\\nsignatures from bulk transcriptomic data may therefore not be adapted to\\nscRNA-seq data, in order to automatically classify individual cells into\\npredefined classes. We propose a new method called DropLasso to learn a\\nmolecular signature from scRNA-seq data. DropLasso extends the dropout\\nregularisation technique, popular in neural network training, to esti- mate\\nsparse linear models. It is well adapted to data corrupted by dropout noise,\\nsuch as scRNA-seq data, and we clarify how it relates to elastic net\\nregularisation. We provide promising results on simulated and real scRNA-seq\\ndata, suggesting that DropLasso may be better adapted than standard regularisa-\\ntions to infer molecular signatures from scRNA-seq data.\\n',\n",
       " '  Using supporting backchannel (BC) cues can make human-computer interaction\\nmore social. BCs provide a feedback from the listener to the speaker indicating\\nto the speaker that he is still listened to. BCs can be expressed in different\\nways, depending on the modality of the interaction, for example as gestures or\\nacoustic cues. In this work, we only considered acoustic cues. We are proposing\\nan approach towards detecting BC opportunities based on acoustic input features\\nlike power and pitch. While other works in the field rely on the use of a\\nhand-written rule set or specialized features, we made use of artificial neural\\nnetworks. They are capable of deriving higher order features from input\\nfeatures themselves. In our setup, we first used a fully connected feed-forward\\nnetwork to establish an updated baseline in comparison to our previously\\nproposed setup. We also extended this setup by the use of Long Short-Term\\nMemory (LSTM) networks which have shown to outperform feed-forward based setups\\non various tasks. Our best system achieved an F1-Score of 0.37 using power and\\npitch features. Adding linguistic information using word2vec, the score\\nincreased to 0.39.\\n',\n",
       " '  We consider the $(n,k,d,\\\\ell)$ secure exact-repair regenerating code problem,\\nwhich generalizes the $(n,k,d)$ exact-repair regenerating code problem with the\\nadditional constraint that the stored file needs to be kept\\ninformation-theoretically secure against an eavesdropper, who can access the\\ndata transmitted to regenerate a total of $\\\\ell$ different failed nodes. For\\nall known results on this problem, the achievable tradeoff regions between the\\nnormalized storage capacity and repair bandwidth have a single corner point,\\nachieved by a scheme proposed by Shah, Rashmi and Kumar (the SRK point). Since\\nthe achievable tradeoff regions of the exact-repair regenerating code problem\\nwithout any secrecy constraints are known to have multiple corner points in\\ngeneral, these existing results suggest a phase-change-like behavior, i.e.,\\nenforcing a secrecy constraint ($\\\\ell\\\\geq 1$) immediately reduces the tradeoff\\nregion to one with a single corner point. In this work, we first show that when\\nthe secrecy parameter $\\\\ell$ is sufficiently large, the SRK point is indeed the\\nonly corner point of the tradeoff region. However, when $\\\\ell$ is small, we\\nshow that the tradeoff region can in fact have multiple corner points. In\\nparticular, we establish a precise characterization of the tradeoff region for\\nthe $(7,6,6,1)$ problem, which has exactly two corner points. Thus, a smooth\\ntransition, instead of a phase-change-type of transition, should be expected as\\nthe secrecy constraint is gradually strengthened.\\n',\n",
       " \"  Link prediction is a key problem for network-structured data. Link prediction\\nheuristics use some score functions, such as common neighbors and Katz index,\\nto measure the likelihood of links. They have obtained wide practical uses due\\nto their simplicity, interpretability, and for some of them, scalability.\\nHowever, every heuristic has a strong assumption on when two nodes are likely\\nto link, which limits their effectiveness on networks where these assumptions\\nfail. In this regard, a more reasonable way should be learning a suitable\\nheuristic from a given network instead of using predefined ones. By extracting\\na local subgraph around each target link, we aim to learn a function mapping\\nthe subgraph patterns to link existence, thus automatically learning a\\n`heuristic' that suits the current network. In this paper, we study this\\nheuristic learning paradigm for link prediction. First, we develop a novel\\n$\\\\gamma$-decaying heuristic theory. The theory unifies a wide range of\\nheuristics in a single framework, and proves that all these heuristics can be\\nwell approximated from local subgraphs. Our results show that local subgraphs\\nreserve rich information related to link existence. Second, based on the\\n$\\\\gamma$-decaying theory, we propose a new algorithm to learn heuristics from\\nlocal subgraphs using a graph neural network (GNN). Its experimental results\\nshow unprecedented performance, working consistently well on a wide range of\\nproblems.\\n\",\n",
       " '  Shifted combinatorial optimization is a new nonlinear optimization framework,\\nwhich is a broad extension of standard combinatorial optimization, involving\\nthe choice of several feasible solutions at a time. It captures well studied\\nand diverse problems ranging from congestive to partitioning problems. In\\nparticular, every standard combinatorial optimization problem has its shifted\\ncounterpart, which is typically much harder. Here we initiate a study of\\napproximation algorithms for this broad optimization framework.\\n',\n",
       " '  We define the notion $\\\\phi(x,y)$ has $NIP$ in $A$, where $A$ is a subset of a\\nmodel, and give some equivalences by translating results from [1]. Using\\nadditional material from [11] we discuss the number of coheirs when $A$ is not\\nnecessarily countable. We also revisit the notion \"$\\\\phi(x,y)$ has $NOP$ in a\\nmodel $M$\" from [8].\\n',\n",
       " '  We study in this paper a class of constrained linear-quadratic (LQ) optimal\\ncontrol problem formulations for the scalar-state stochastic system with\\nmultiplicative noise, which has various applications, especially in the\\nfinancial risk management. The linear constraint on both the control and state\\nvariables considered in our model destroys the elegant structure of the\\nconventional LQ formulation and has blocked the derivation of an explicit\\ncontrol policy so far in the literature. We successfully derive in this paper\\nthe analytical control policy for such a class of problems by utilizing the\\nstate separation property induced from its structure. We reveal that the\\noptimal control policy is a piece-wise affine function of the state and can be\\ncomputed off-line efficiently by solving two coupled Riccati equations. Under\\nsome mild conditions, we also obtain the stationary control policy for infinite\\ntime horizon. We demonstrate the implementation of our method via some\\nillustrative examples and show how to calibrate our model to solve dynamic\\nconstrained portfolio optimization problems.\\n',\n",
       " '  We study a class of stably projectionless simple C*-algebras which may be\\nviewed as having generalized tracial rank one in analogy with the unital case.\\nSome structural question concerning these simple C*-algebras are studied. The\\npaper also serves as a technical support for the classification of separable\\nstably projectionless simple amenable Jiang-Su stable C*-algebras.\\n',\n",
       " '  In this paper, we study a model of opinion dynamics in a social network in\\nthe presence increasing interpersonal influence, i.e., increasing peer\\npressure. Each agent in the social network has a distinct social stress\\nfunction given by a weighted sum of internal and external behavioral pressures.\\nWe assume a weighted average update rule and prove conditions under which a\\nconnected group of agents converge to a fixed opinion distribution, and under\\nwhich conditions the group reaches consensus. We show that the update rule is a\\ngradient descent and explain its transient and asymptotic convergence\\nproperties. Through simulation, we study the rate of convergence on a\\nscale-free network and then validate the assumption of increasing peer pressure\\nin a simple empirical model.\\n',\n",
       " '  We construct the error distributions for the galactic rotation speed\\n($\\\\Theta_0$) using 137 data points from measurements compiled in De Grijs et\\nal. (arXiv:1709.02501), with all observations normalized to the galactocentric\\ndistance of 8.3 kpc. We then checked (using the same procedures as in works by\\nRatra et al) if the errors constructed using the weighted mean and the median\\nas the estimate, obey Gaussian statistics. We find using both these estimates\\nthat they have much wider tails than a Gaussian distribution. We also tried to\\nfit the data to three other distributions: Cauchy, double-exponential, and\\nStudents-t. The best fit is obtained using the Students-$t$ distribution for\\n$n=2$ using the median value as the central estimate, corresponding to a\\n$p$-value of 0.1. We also calculate the median value of $\\\\Theta_0$ using all\\nthe data as well as using the median of each set of measurements based on the\\ntracer population used. Because of the non-gaussianity of the residuals, we\\npoint out that the subgroup median value, given by $\\\\Theta_{med}=219.65$ km/sec\\nshould be used as the central estimate for $\\\\Theta_0$.\\n',\n",
       " '  We use deep HI observations obtained as part of the extended GALEX Arecibo\\nSDSS survey (xGASS) to study the cold gas properties of central galaxies across\\nenvironments. We find that, below stellar masses of 10^10.2 Msun, central\\ngalaxies in groups have an average atomic hydrogen gas fraction ~0.3dex higher\\nthan those in isolation at the same stellar mass. At these stellar masses,\\ngroup central galaxies are usually found in small groups of N=2 members. The\\nhigher HI content in these low mass group central galaxies is mirrored by their\\nhigher average star formation activity and molecular hydrogen content. At\\nlarger stellar masses, this difference disappears and central galaxies in\\ngroups have similar (or even smaller) gas reservoirs and star formation\\nactivity compared to those in isolation. We discuss possible scenarios able to\\nexplain our findings and suggest that the higher gas content in low mass group\\ncentral galaxies is likely due to contributions from the cosmic web or HI-rich\\nminor mergers, which also fuel their enhanced star formation activity.\\n',\n",
       " '  In this paper, we study almost regular Landsberg general\\n$(\\\\alpha,\\\\beta)$-metrics in Finsler geometry. The corresponding equivalent\\nequations are given. By solving the equations, we give the classification of\\nLandsberg general $(\\\\alpha,\\\\beta)$-metrics under the conditon that $\\\\beta$ is\\nclosed and conformal to $\\\\alpha$. Under this condition, we prove that regular\\nLandsberg general $(\\\\alpha,\\\\beta)$-metrics must be Berwaldian when the\\ndimension is greater than two. For the almost regular case, the classification\\nalso is given and some new non-Berwaldian Landsberg metrics are found.\\n',\n",
       " '  In this note, the attitude and inertial sensors drift biases estimation for\\nStrapdown inertial navigation system is investigated. A semi-analytic method is\\nproposed, which contains two interlaced solution procedures. Specifically, the\\nattitude encoding the body frame changes and gyroscopes drift biases are\\nestimated through attitude estimation while the attitude encoding the constant\\nvalue at the very start and accelerometers drift biases are determined through\\nonline optimization.\\n',\n",
       " '  Regulators require financial institutions to estimate counterparty default\\nrisks from liquid CDS quotes for the valuation and risk management of OTC\\nderivatives. However, the vast majority of counterparties do not have liquid\\nCDS quotes and need proxy CDS rates. Existing methods cannot account for\\ncounterparty-specific default risks; we propose to construct proxy CDS rates by\\nassociating to illiquid counterparty liquid CDS Proxy based on Machine Learning\\nTechniques. After testing 156 classifiers from 8 most popular classifier\\nfamilies, we found that some classifiers achieve highly satisfactory accuracy\\nrates. Furthermore, we have rank-ordered the performances and investigated\\nperformance variations amongst and within the 8 classifier families. This paper\\nis, to the best of our knowledge, the first systematic study of CDS Proxy\\nconstruction by Machine Learning techniques, and the first systematic\\nclassifier comparison study based entirely on financial market data. Its\\nfindings both confirm and contrast existing classifier performance literature.\\nGiven the typically highly correlated nature of financial data, we investigated\\nthe impact of correlation on classifier performance. The techniques used in\\nthis paper should be of interest for financial institutions seeking a CDS Proxy\\nmethod, and can serve for proxy construction for other financial variables.\\nSome directions for future research are indicated.\\n',\n",
       " '  We present results on simplifying an acting group preserving properties of\\nactions: transitivity, being a coset space and preserving a fixed\\nequiuniformity in case of a $G$-Tychonoff space.\\n',\n",
       " '  The nearest neighbor method together with the dynamic time warping (DTW)\\ndistance is one of the most popular approaches in time series classification.\\nThis method suffers from high storage and computation requirements for large\\ntraining sets. As a solution to both drawbacks, this article extends learning\\nvector quantization (LVQ) from Euclidean spaces to DTW spaces. The proposed LVQ\\nscheme uses asymmetric weighted averaging as update rule. Empirical results\\nexhibited superior performance of asymmetric generalized LVQ (GLVQ) over other\\nstate-of-the-art prototype generation methods for nearest neighbor\\nclassification.\\n',\n",
       " '  Two-dimensional transition metal dichalcogenides (TMDCs), as promising\\nalternative plasmonics supporting materials to graphene, exhibit potential\\napplications in sensing. Here, we propose an ultrasensitive, accurate\\nlong-range surface plasmon resonance (LRSPR) imaging biosensor with\\ntwo-dimensional TMDC layers, which shows higher detection accuracy than that of\\nconventional SPR biosensor. It is found that the imaging sensitivity of the\\nproposed LRSPR biosensor can be enhanced by the integration of TMDC layers,\\nwhich is different from the previous graphene-based LRSPR or SPR imaging\\nsensor, whose imaging sensitivity usually decreases with the number of graphene\\nlayers. The sensitivity enhancement or degradation effect for the proposed\\nchalcogenide-cytop-gold-TMDCs based biosensor depends on the thickness of gold\\nthin film and cytop layer. Imaging sensitivity of more than 4000\\n$\\\\text{RIU}^{-1}$ can be obtained with a high detection accuracy of more than\\n120 $\\\\text{deg}^{-1}$. We expect that the proposed TMDCs mediated LRSPR imaging\\nsensor could provide potential applications in chemical sensing and biosensing\\nfor a highly sensitive and accurate simultaneous detection of multiple\\nbiomolecular interactions.\\n',\n",
       " \"  We present tilting rates for galaxies comparable to the Milky Way (MW) in a\\n$\\\\Lambda$ cold dark matter cosmological hydrodynamical simulation, and compare\\nthese with the predicted tilting rate detection limit of the {\\\\it Gaia}\\nsatellite $0.28\\\\degrees$Gyr$^{-1}$. We first identify galaxies with mass\\ncomparable to the MW ($9 \\\\times 10^{11} \\\\le M_{200} \\\\le 1.2 \\\\times 10^{12}\\n\\\\Msun $) and consider the tilting rates between $z=0.3$ and $0$. This sample\\nyields a tilting rate of $7.6\\\\degrees \\\\pm 4.5\\\\degrees$Gyr$^{-1}$. We constrain\\nour sample further to exclude any galaxies that have high stellar accretion\\nduring the same time. We still find significant tilting, with an average rate\\nof $6.3\\\\degrees$Gyr$^{-1}$. Both subsamples tilt with rates significantly above\\n{\\\\it Gaia}'s predicted detection limit. We show that our sample of galaxies\\ncovers a wide range of environments, including some similar to the MW's. We\\nfind galaxies in denser regions tilt with higher rates then galaxies in less\\ndense regions. We also find correlations between the angular misalignment of\\nthe hot gas corona, and the tilting rate. {\\\\it Gaia} is likely to be able to\\ndirectly measure tilting in the MW. Such a detection will provide an important\\nconstraint on the environment of the MW, including the rate of gas cooling onto\\nthe disc, the shape and orientation of its dark matter halo, and the mass of\\nthe Large Magellanic Cloud. Conversely, failure to detect tilting may suggest\\nthe MW is in a very quiet configuration.\\n\",\n",
       " '  We review two important non-perturbative approaches for extracting the\\nphysics of low-dimensional strongly correlated quantum systems. Firstly, we\\nstart by providing a comprehensive review of non-Abelian bosonization. This\\nincludes an introduction to the basic elements of conformal field theory as\\napplied to systems with a current algebra, and we orient the reader by\\npresenting a number of applications of non-Abelian bosonization to models with\\nlarge symmetries. We then tie this technique into recent advances in the\\nability of cold atomic systems to realize complex symmetries. Secondly, we\\ndiscuss truncated spectrum methods for the numerical study of systems in one\\nand two dimensions. For one-dimensional systems we provide the reader with\\nconsiderable insight into the methodology by reviewing canonical applications\\nof the technique to the Ising model (and its variants) and the sine-Gordon\\nmodel. Following this we review recent work on the development of\\nrenormalization groups, both numerical and analytical, that alleviate the\\neffects of truncating the spectrum. Using these technologies, we consider a\\nnumber of applications to one-dimensional systems: properties of carbon\\nnanotubes, quenches in the Lieb-Liniger model, 1+1D quantum chromodynamics, as\\nwell as Landau-Ginzburg theories. In the final part we move our attention to\\nconsider truncated spectrum methods applied to two-dimensional systems. This\\ninvolves combining truncated spectrum methods with matrix product state\\nalgorithms. We describe applications of this method to two-dimensional systems\\nof free fermions and the quantum Ising model, including their non-equilibrium\\ndynamics.\\n',\n",
       " \"  In this paper an extension of the spectral Lanczos' tau method to systems of\\nnonlinear integro-differential equations is proposed. This extension includes\\n(i) linearization coefficients of orthogonal polynomials products issued from\\nnonlinear terms and (ii) recursive relations to implement matrix inversion\\nwhenever a polynomial change of basis is required and (iii) orthogonal\\npolynomial evaluations directly on the orthogonal basis. All these improvements\\nensure numerical stability and accuracy in the approximate solution. Exposed in\\ndetail, this novel approach is able to significantly outperform numerical\\napproximations with other methods as well as different tau implementations.\\nNumerical results on a set of problems illustrate the impact of the\\nmathematical techniques introduced.\\n\",\n",
       " '  The ferroelectric to paraelectric phase transition of multiferroic\\nCaMnTi$_2$O$_6$ has been investigated at high pressures and ambient temperature\\nby second harmonic generation (SHG), Raman spectroscopy, and powder and\\nsingle-crystal x-ray diffraction. We have found that CaMnTi$_2$O$_6$ undergoes\\na pressure-induced structural phase transition ($P4_2mc \\\\rightarrow P4_2/nmc$)\\nat $\\\\sim$7 GPa to the same paraelectric structure found at ambient pressure and\\n$T_c$ = 630 K. The continuous linear decrease of the SHG intensity that\\ndisappears at 7 GPa and the existence of a Raman active mode at 244 cm$^{-1}$\\nthat first softens up to 7 GPa and then hardens with pressure, are used to\\ndiscuss the nature of the phase transition of CaMnTi$_2$O$_6$ for which a\\nd$T_c$/d$P = -48$ K/GPa has been found. Neither a volume contraction nor a\\nchange of the normalized pressure on the eulerian strain are observed across\\nthe phase transition with all the unit-cell volume data following a second\\norder Birch-Murnaghan equation of state with a bulk modulus of $B_0$ =\\n182.95(2) GPa.\\n',\n",
       " \"  We introduce a family of factorisable ribbon quasi-Hopf algebras $Q(N)$ for\\n$N$ a positive integer: as an algebra, $Q(N)$ is the semidirect product of\\n$\\\\mathbb{C}\\\\mathbb{Z}_2$ with the direct sum of a Grassmann and a Clifford\\nalgebra in $2N$ generators. We show that $Rep Q(N)$ is ribbon equivalent to the\\nsymplectic fermion category $SF(N)$ that was computed by the third author from\\nconformal blocks of the corresponding logarithmic conformal field theory. The\\nlatter category in turn is conjecturally ribbon equivalent to representations\\nof $V_{ev}$, the even part of the symplectic fermion vertex operator super\\nalgebra.\\nUsing the formalism developed in our previous paper we compute the projective\\n$SL(2,\\\\mathbb{Z})$-action on the centre of $Q(N)$ as obtained from\\nLyubashenko's general theory of mapping class group actions for factorisable\\nfinite ribbon categories. This allows us to test a conjectural non-semisimple\\nversion of the modular Verlinde formula: we verify that the\\n$SL(2,\\\\mathbb{Z})$-action computed from $Q(N)$ agrees projectively with that on\\npseudo trace functions of $V_{ev}$.\\n\",\n",
       " '  This article introduces a tensor network subspace algorithm for the\\nidentification of specific polynomial state space models. The polynomial\\nnonlinearity in the state space model is completely written in terms of a\\ntensor network, thus avoiding the curse of dimensionality. We also prove how\\nthe block Hankel data matrices in the subspace method can be exactly\\nrepresented by low rank tensor networks, reducing the computational and storage\\ncomplexity significantly. The performance and accuracy of our subspace\\nidentification algorithm are illustrated by numerical experiments, showing that\\nour tensor network implementation is around 20 times faster than the standard\\nmatrix implementation before the latter fails due to insufficient memory, is\\nrobust with respect to noise and can model real-world systems.\\n',\n",
       " '  Optical distortions can significantly deteriorate the measurement accuracy in\\nimaging systems. Such distortions can occur at fluctuating phase boundaries as\\nwell as multiple-phase flows and result from the accompanied refractive index\\nchanges. Due to multiple reflexes arising from a fluid flow setup, the usage of\\na wave front sensor (WFS) can be hindered. In this work we outline a wave front\\nsensor-less approach which includes iterative aberration correction with a fast\\ndeformable mirror (DM). A combination of sharpness metric (SM) image evaluation\\nand iterative optimization is demonstrated. The SM was measured for each image\\nwhile adjusting seven Zernike modes (after Noll index enumeration) in their\\namplitude. The SM is used as an indicator for wave front aberrations without\\nusing a wave front sensor to correct wave front distortions that are generated\\nby the DM. The proposed method allows for the reduction of systematic\\nmeasurement uncertainties in fluid flow measurement techniques as particle\\nimage velocimetry (PIV). Five different sharpness metrics are demonstrated for\\nreliable sharpness maximization with a deformable mirror of 69 elements. A\\nsystematic linear search (LS) algorithm was applied in order to find the\\noptimal mirror shape. The reduction of measurement uncertainty for PIV\\nmeasurements is shown. The iterative approach offers a way to reduce static or\\nslowly changing wave front distortions in a fluid flow setup where a WFS is not\\napplicable.\\n',\n",
       " '  The subject of this work is the shock development problem in fluid mechanics.\\nA shock originates from an acoustically spacelike surface in spacetime at which\\nthe 1st derivatives of the physical variables blow up. The solution requires\\nthe construction of a hypersurface in spacetime which is acoustically timelike\\nas viewed from its future, acoustically spacelike as viewed from its past, the\\nshock hypersurface, across which the physical variables suffer discontinuities\\nobeying jump conditions in accordance with the integral form of the particle\\nand energy-momentum conservation laws. Mathematically, this is a free boundary\\nproblem, with nonlinear conditions at the free boundary, for a 1st order\\nquasilinear hyperbolic system of p.d.e., with characteristic initial data which\\nare singular at the past boundary of the initial characteristic hypersurface,\\nthat boundary being the surface of origin. This work solves, in any number of\\nspatial dimensions, a restricted form of the problem which retains the\\nessential difficulties due to the singular nature of the surface of origin. The\\nsolution is accomplished through the introduction of new geometric and analytic\\nmethods.\\n',\n",
       " '  We work with attracting subshifts generated by substitutions which are also\\nirreducible parageometric automorphisms of free groups. For such a dynamical\\nsystem, we construct a tree substitution to approximate the repelling real tree\\nof the automorphism. We produce images of this tree inside the Rauzy fractal\\nwhen the substitution is irreducible Pisot. We describe the contour of this\\ntree and compute an interval exchange transformation of the circle covering the\\noriginal substitution.\\n',\n",
       " '  Accurate molecular data for the low-lying states of SiO are computed and used\\nto calculate rate constants for radiative association of Si and O. Einstein\\nA-coefficients are also calculated for transitions between all of the bound and\\nquasi-bound levels for each molecular state. The radiative widths are used\\ntogether with elastic tunneling widths to define effective radiative\\nassociation rate constants which include both direct and indirect (inverse\\npredissociation) formation processes. The indirect process is evaluated for two\\nkinetic models which represent limiting cases for astrophysical environments.\\nThe first case scenario assumes an equilibrium distribution of quasi-bound\\nstates and would be applicable whenever collisional and/or radiative excitation\\nmechanisms are able to maintain the population. The second case scenario\\nassumes that no excitation mechanisms are available which corresponds to the\\nlimit of zero radiation temperature and zero atomic density. Rate constants for\\nSiO formation in realistic astrophysical environments would presumably lie\\nbetween these two limiting cases.\\n',\n",
       " \"  We present CROSSGRAD, a method to use multi-domain training data to learn a\\nclassifier that generalizes to new domains. CROSSGRAD does not need an\\nadaptation phase via labeled or unlabeled data, or domain features in the new\\ndomain. Most existing domain adaptation methods attempt to erase domain signals\\nusing techniques like domain adversarial training. In contrast, CROSSGRAD is\\nfree to use domain signals for predicting labels, if it can prevent overfitting\\non training domains. We conceptualize the task in a Bayesian setting, in which\\na sampling step is implemented as data augmentation, based on domain-guided\\nperturbations of input instances. CROSSGRAD parallelly trains a label and a\\ndomain classifier on examples perturbed by loss gradients of each other's\\nobjectives. This enables us to directly perturb inputs, without separating and\\nre-mixing domain signals while making various distributional assumptions.\\nEmpirical evaluation on three different applications where this setting is\\nnatural establishes that (1) domain-guided perturbation provides consistently\\nbetter generalization to unseen domains, compared to generic instance\\nperturbation methods, and that (2) data augmentation is a more stable and\\naccurate method than domain adversarial training.\\n\",\n",
       " '  Fundamental experimental measurements of quantities such as ignition delay\\ntimes, laminar flame speeds, and species profiles (among others) serve\\nimportant roles in understanding fuel chemistry and validating chemical kinetic\\nmodels. However, despite both the importance and abundance of such information\\nin the literature, the community lacks a widely adopted standard format for\\nthis data. This impedes both sharing and wide use by the community. Here we\\nintroduce a new chemical kinetics experimental data format, ChemKED, and the\\nrelated Python-based package for validating and working with ChemKED-formatted\\nfiles called PyKED. We also review past and related efforts, and motivate the\\nneed for a new solution. ChemKED currently supports the representation of\\nautoignition delay time measurements from shock tubes and rapid compression\\nmachines. ChemKED-formatted files contain all of the information needed to\\nsimulate experimental data points, including the uncertainty of the data.\\nChemKED is based on the YAML data serialization language, and is intended as a\\nhuman- and machine-readable standard for easy creation and automated use.\\nDevelopment of ChemKED and PyKED occurs openly on GitHub under the BSD 3-clause\\nlicense, and contributions from the community are welcome. Plans for future\\ndevelopment include support for experimental data from laminar flame, jet\\nstirred reactor, and speciation measurements.\\n',\n",
       " '  The postulate of independence of cause and mechanism (ICM) has recently led\\nto several new causal discovery algorithms. The interpretation of independence\\nand the way it is utilized, however, varies across these methods. Our aim in\\nthis paper is to propose a group theoretic framework for ICM to unify and\\ngeneralize these approaches. In our setting, the cause-mechanism relationship\\nis assessed by comparing it against a null hypothesis through the application\\nof random generic group transformations. We show that the group theoretic view\\nprovides a very general tool to study the structure of data generating\\nmechanisms with direct applications to machine learning.\\n',\n",
       " '  The current exoplanet database includes 5454 confirmed planets and candidate\\nplanets observed with the KEPLER mission. We find 932 planet pairs from which\\nwe extract distance and orbital period ratios. While earlier studies used the\\nTitius-Bode law or a generalized version with logarithmic spacing, which both\\nlack a physical model, we employ here the theory of harmonic orbit resonances,\\nwhich contains quantized ratios instead, to explain the observed planet\\ndistance ratios and to predict undetected exoplanets. We find that the most\\nprevailing harmonic ratios are (2:1), (3:2), and (5:3), in 73\\\\% of the cases,\\nwhile alternative harmonic ratios of (5:4), (4:3), (5:2), (3:1) occur in 27\\\\%\\nof the other cases. Our orbital predictions includes 171 exoplanets, 2 Jupiter\\nmoons, one Saturn moon, 3 Uranus moons, and 4 Neptune moons. The accuracy of\\nthe predicted planet distances amounts to a few percent, which fits the data\\nsignificantly better than the Titius-Bode law or a logarithmic spacing. This\\ninformation may be useful for targeted exoplanet searches with Kepler data and\\nto estimate the number of live-carrying planets in habitable zones.\\n',\n",
       " '  Although the word-popularity based negative sampler has shown superb\\nperformance in the skip-gram model, the theoretical motivation behind\\noversampling popular (non-observed) words as negative samples is still not well\\nunderstood. In this paper, we start from an investigation of the gradient\\nvanishing issue in the skipgram model without a proper negative sampler. By\\nperforming an insightful analysis from the stochastic gradient descent (SGD)\\nlearning perspective, we demonstrate that, both theoretically and intuitively,\\nnegative samples with larger inner product scores are more informative than\\nthose with lower scores for the SGD learner in terms of both convergence rate\\nand accuracy. Understanding this, we propose an alternative sampling algorithm\\nthat dynamically selects informative negative samples during each SGD update.\\nMore importantly, the proposed sampler accounts for multi-dimensional\\nself-embedded features during the sampling process, which essentially makes it\\nmore effective than the original popularity-based (one-dimensional) sampler.\\nEmpirical experiments further verify our observations, and show that our\\nfine-grained samplers gain significant improvement over the existing ones\\nwithout increasing computational complexity.\\n',\n",
       " '  Despite rapid advances in machine learning tools, the majority of neural\\ndecoding approaches still use traditional methods. Improving the performance of\\nneural decoding algorithms allows us to better understand the information\\ncontained in a neural population, and can help advance engineering applications\\nsuch as brain machine interfaces. Here, we apply modern machine learning\\ntechniques, including neural networks and gradient boosting, to decode from\\nspiking activity in 1) motor cortex, 2) somatosensory cortex, and 3)\\nhippocampus. We compare the predictive ability of these modern methods with\\ntraditional decoding methods such as Wiener and Kalman filters. Modern methods,\\nin particular neural networks and ensembles, significantly outperformed the\\ntraditional approaches. For instance, for all of the three brain areas, an LSTM\\ndecoder explained over 40% of the unexplained variance from a Wiener filter.\\nThese results suggest that modern machine learning techniques should become the\\nstandard methodology for neural decoding. We provide a tutorial and code to\\nfacilitate wider implementation of these methods.\\n',\n",
       " '  As network deployments become denser, interference arises as a dominant\\nperformance degradation factor. To confront with this trend, Long Term\\nEvolution (LTE) incorporated features aiming at enabling cooperation among\\ndifferent base stations, a technique termed as Coordinated Multi Point (CoMP).\\nRecent field trial results and theoretical studies of the performance of CoMP\\nschemes revealed, however, that their gains are not as high as initially\\nexpected, despite their large coordination overhead. In this paper, we review\\nrecent advanced Coordinated Beamforming (CB) schemes, a special family of CoMP\\nthat reduces the coordination overhead through a joint choice of transmit and\\nreceive linear filters. We focus on assessing their resilience to uncoordinated\\ninterference and Channel State Information (CSI) imperfections, which both\\nseverely limit the performance gains of all CoMP schemes. We present a simple\\nyet encompassing system model that aims at incorporating different parameters\\nof interest in the relative interference power and CSI errors, and then utilize\\nit for the performance evaluation of the state-of-the-art in CB schemes. It is\\nshown that blindly applying CB in all system scenarios can indeed be\\ncounter-productive.\\n',\n",
       " '  Let $\\\\C$ be a triangulated category with a cluster tilting subcategory $\\\\T$.\\nWe introduce the notion of $\\\\T[1]$-cluster tilting subcategories (also called\\nghost cluster tilting subcategories) of $\\\\C$, which are a generalization of\\ncluster tilting subcategories. We first develop a basic theory on ghost cluster\\ntilting subcategories. Secondly, we study links between ghost cluster tilting\\ntheory and $\\\\tau$-tilting theory: Inspired by the work of Iyama, J{\\\\o}rgensen\\nand Yang \\\\cite{ijy}, we introduce the notion of $\\\\tau$-tilting subcategories\\nand tilting subcategories of $\\\\mod\\\\T$. We show that there exists a bijection\\nbetween weak $\\\\T[1]$-cluster tilting subcategories of $\\\\C$ and support\\n$\\\\tau$-tilting subcategories of $\\\\mod\\\\T$. Moreover, we figure out the\\nsubcategories of $\\\\mod\\\\T$ which correspond to cluster tilting subcategories of\\n$\\\\C$. This generalizes and improves several results by Adachi-Iyama-Reiten\\n\\\\cite{AIR}, Beligiannis \\\\cite{Be2}, and Yang-Zhu \\\\cite{YZ}. Finally, we prove\\nthat the definition of ghost cluster tilting objects is equivalent to the\\ndefinition of relative cluster tilting objects introduced by the first and the\\nthird author in \\\\cite{YZ}.\\n',\n",
       " '  We revisit the classic online bin packing problem. In this problem, items of\\npositive sizes no larger than 1 are presented one by one to be packed into\\nsubsets called \"bins\" of total sizes no larger than 1, such that every item is\\nassigned to a bin before the next item is presented. We use online partitioning\\nof items into classes based on sizes, as in previous work, but we also apply a\\nnew method where items of one class can be packed into more than two types of\\nbins, where a bin type is defined according to the number of such items grouped\\ntogether. Additionally, we allow the smallest class of items to be packed in\\nmultiple kinds of bins, and not only into their own bins. We combine this with\\nthe approach of packing of sufficiently big items according to their exact\\nsizes. Finally, we simplify the analysis of such algorithms, allowing the\\nanalysis to be based on the most standard weight functions. This simplified\\nanalysis allows us to study the algorithm which we defined based on all these\\nideas. This leads us to the design and analysis of the first algorithm of\\nasymptotic competitive ratio strictly below 1.58, specifically, we break this\\nbarrier and provide an algorithm AH (Advanced Harmonic) whose asymptotic\\ncompetitive ratio does not exceed 1.5783.\\n',\n",
       " '  Effective utilization of photovoltaic (PV) plants requires weather\\nvariability robust global solar radiation (GSR) forecasting models. Random\\nweather turbulence phenomena coupled with assumptions of clear sky model as\\nsuggested by Hottel pose significant challenges to parametric & non-parametric\\nmodels in GSR conversion rate estimation. Also, a decent GSR estimate requires\\ncostly high-tech radiometer and expert dependent instrument handling and\\nmeasurements, which are subjective. As such, a computer aided monitoring (CAM)\\nsystem to evaluate PV plant operation feasibility by employing smart grid past\\ndata analytics and deep learning is developed. Our algorithm, SolarisNet is a\\n6-layer deep neural network trained on data collected at two weather stations\\nlocated near Kalyani metrological site, West Bengal, India. The daily GSR\\nprediction performance using SolarisNet outperforms the existing state of art\\nand its efficacy in inferring past GSR data insights to comprehend daily and\\nseasonal GSR variability along with its competence for short term forecasting\\nis discussed.\\n',\n",
       " '  Human motion modelling is a classical problem at the intersection of graphics\\nand computer vision, with applications spanning human-computer interaction,\\nmotion synthesis, and motion prediction for virtual and augmented reality.\\nFollowing the success of deep learning methods in several computer vision\\ntasks, recent work has focused on using deep recurrent neural networks (RNNs)\\nto model human motion, with the goal of learning time-dependent representations\\nthat perform tasks such as short-term motion prediction and long-term human\\nmotion synthesis. We examine recent work, with a focus on the evaluation\\nmethodologies commonly used in the literature, and show that, surprisingly,\\nstate-of-the-art performance can be achieved by a simple baseline that does not\\nattempt to model motion at all. We investigate this result, and analyze recent\\nRNN methods by looking at the architectures, loss functions, and training\\nprocedures used in state-of-the-art approaches. We propose three changes to the\\nstandard RNN models typically used for human motion, which result in a simple\\nand scalable RNN architecture that obtains state-of-the-art performance on\\nhuman motion prediction.\\n',\n",
       " \"  We propose a new simple convergence acceleration method for wide range class\\nof convergent alternating series. It has some common features with Smith's and\\nFord's modification of Levin's and Weniger's sequence transformations, but its\\ncomputational and memory cost is lower. We compare all three methods and give\\nsome common theoretical results. Numerical examples confirm a similar\\nperformance of all of them.\\n\",\n",
       " '  There has been considerable interest in making Bayesian inference more\\nscalable. In big data settings, most literature focuses on reducing the\\ncomputing time per iteration, with less focused on reducing the number of\\niterations needed in Markov chain Monte Carlo (MCMC). This article focuses on\\ndata augmentation MCMC (DA-MCMC), a widely used technique. DA-MCMC samples tend\\nto become highly autocorrelated in large data samples, due to a miscalibration\\nproblem in which conditional posterior distributions given augmented data are\\ntoo concentrated. This makes it necessary to collect very long MCMC paths to\\nobtain acceptably low MC error. To combat this inefficiency, we propose a\\nfamily of calibrated data augmentation algorithms, which appropriately adjust\\nthe variance of conditional posterior distributions. A Metropolis-Hastings step\\nis used to eliminate bias in the stationary distribution of the resulting\\nsampler. Compared to existing alternatives, this approach can dramatically\\nreduce MC error by reducing autocorrelation and increasing the effective number\\nof DA-MCMC samples per computing time. The approach is simple and applicable to\\na broad variety of existing data augmentation algorithms, and we focus on three\\npopular models: probit, logistic and Poisson log-linear. Dramatic gains in\\ncomputational efficiency are shown in applications.\\n',\n",
       " '  We present stacked average far-infrared spectra of a sample of 197 dusty,\\nstar-forming galaxies (DSFGs) at $0.005 < z < 4$ using close to 90% of the\\nSPIRE Fourier Transform Spectrometer (FTS) extragalactic data archive from the\\nHerschel Space Observatory based on 3.5 years of science operations. These\\nspectra explore an observed-frame $\\\\rm 447\\\\,GHz-1568\\\\,GHz$ ($\\\\rm 191\\\\,\\\\mu\\nm-671\\\\,\\\\mu m$) frequency (wavelength) range allowing us to observe the main\\natomic and molecular lines emitted by gas in the interstellar medium. The\\nsample is sub-divided into five redshift bins at $0.005 < z < 0.05$, $0.05 < z\\n< 0.2$, $0.2 < z < 0.5$, $0.8 < z <2$, and $2 < z < 4$. To study the dependence\\nof observed spectral lines on total infrared luminosity, the sources in a\\nsubset of the redshift bins are stacked in luminosity bins. These stacked\\nspectra are used to determine the average properties of the interstellar medium\\nand dense molecular gas properties of DSFGs, in particular, the fine-structure\\nline ([CII] 158 $\\\\mu$m and [OI] 63 $\\\\mu$m) luminosity ratios, and the line to\\nfar-IR luminosity ratios are used to model the gas density and radiation field\\nstrength in the photodissociation regions (PDRs). For the low-redshift sample,\\nwe additionally present the average spectral line energy distributions (SLED)\\nof CO and $\\\\rm{H_2O}$ rotational transitions and also consider PDR conditions\\nbased on a combination of [CI] 370 $\\\\mu$m and 609 $\\\\mu$m and $\\\\rm CO (7-6)$\\nlines. For the high-z ($0.8 < z < 4$) sample PDR models suggest a molecular gas\\ndistribution in the presence of a radiation field that is at least a factor of\\n10$^3$ larger than the Milky-Way and with a neutral gas density of roughly\\n10$^3$ to 10$^5$ cm$^{-3}$. The corresponding PDR models for the low-z sample\\nsuggest a UV radiation field and gas density comparable to those at high-z.\\n',\n",
       " '  We report the first results from a search for transiting warm Jupiter\\nexoplanets - gas giant planets receiving stellar irradiation below about $10^8$\\nerg s$^{-1}$ cm$^{-2}$, equivalent to orbital periods beyond about 10 days\\naround Sun-like stars. We have discovered two transiting warm Jupiter\\nexoplanets initially identified as transiting candidates in ${\\\\it K2}$\\nphotometry. K2-114b has a mass of $1.85^{+0.23}_{-0.22}\\\\ M_J$, a radius of\\n$0.942^{+0.032}_{-0.020}\\\\ R_J$, and an orbital period of 11.4 days. K2-115b has\\na mass of $0.84^{+0.18}_{-0.20}\\\\ M_J$, a radius of $1.115^{+0.057}_{-0.061}\\\\\\nR_J$, and an orbital period of 20.3 days. Both planets are among the longest\\nperiod transiting gas giant planets with a measured mass, and they are orbiting\\nrelatively old host stars. Both planets are not inflated as their radii are\\nconsistent with theoretical expectations. Their position in the planet radius -\\nstellar irradiation diagram is consistent with the scenario where the radius -\\nirradiation correlation levels off below about 10$^8$ erg s$^{-1}$ cm$^{-2}$,\\nsuggesting that for warm Jupiters the stellar irradiation does not play a\\nsignificant role in determining the planet radius. We also report our\\nidentification of another ${\\\\it K2}$ transiting warm Jupiter candidate, EPIC\\n212504617, as a false positive.\\n',\n",
       " \"  Efficient coupling between integrated optical waveguides and optical fibers\\nis essential to the success of integrated photonics. While many solutions\\nexist, perfectly vertical grating couplers which scatter light out of a\\nwaveguide in the direction normal to the waveguide's top surface are an ideal\\ncandidate due to their potential to reduce packaging complexity. Designing such\\ncouplers with high efficiency, however, has proven difficult. In this paper, we\\nuse electromagnetic inverse design techniques to optimize a high efficiency\\ntwo-layer perfectly vertical silicon grating coupler. Our base design achieves\\na chip-to-fiber coupling efficiency of over 99% (-0.04 dB) at 1550 nm. Using\\nthis base design, we apply subsequent constrained optimizations to achieve\\nvertical couplers with over 96% efficiency which are fabricable using a 65 nm\\nprocess.\\n\",\n",
       " '  In this paper we address the problem of developing on-line visual tracking\\nalgorithms. We present a specialized communication protocol that serves as a\\nbridge between a tracker implementation and utilizing application. It decouples\\ndevelopment of algorithms and application, encouraging re-usability. The\\nprimary use case is algorithm evaluation where the protocol facilitates more\\ncomplex evaluation scenarios that are used nowadays thus pushing forward the\\nfield of visual tracking. We present a reference implementation of the protocol\\nthat makes it easy to use in several popular programming languages and discuss\\nwhere the protocol is already used and some usage scenarios that we envision\\nfor the future.\\n',\n",
       " \"  Peakons are special weak solutions of a class of nonlinear partial\\ndifferential equations modelling non-linear phenomena such as the breakdown of\\nregularity and the onset of shocks. We show that the natural concept of weak\\nsolutions in the case of the modified Camassa-Holm equation studied in this\\npaper is dictated by the distributional compatibility of its Lax pair and, as a\\nresult, it differs from the one proposed and used in the literature based on\\nthe concept of weak solutions used for equations of the Burgers type.\\nSubsequently, we give a complete construction of peakon solutions satisfying\\nthe modified Camassa-Holm equation in the sense of distributions; our approach\\nis based on solving certain inverse boundary value problem the solution of\\nwhich hinges on a combination of classical techniques of analysis involving\\nStieltjes' continued fractions and multi-point Padé approximations. We\\npropose sufficient conditions needed to ensure the global existence of peakon\\nsolutions and analyze the large time asymptotic behaviour whose special\\nfeatures include a formation of pairs of peakons which share asymptotic speeds,\\nas well as Toda-like sorting property.\\n\",\n",
       " '  Radiomics aims to extract and analyze large numbers of quantitative features\\nfrom medical images and is highly promising in staging, diagnosing, and\\npredicting outcomes of cancer treatments. Nevertheless, several challenges need\\nto be addressed to construct an optimal radiomics predictive model. First, the\\npredictive performance of the model may be reduced when features extracted from\\nan individual imaging modality are blindly combined into a single predictive\\nmodel. Second, because many different types of classifiers are available to\\nconstruct a predictive model, selecting an optimal classifier for a particular\\napplication is still challenging. In this work, we developed multi-modality and\\nmulti-classifier radiomics predictive models that address the aforementioned\\nissues in currently available models. Specifically, a new reliable classifier\\nfusion strategy was proposed to optimally combine output from different\\nmodalities and classifiers. In this strategy, modality-specific classifiers\\nwere first trained, and an analytic evidential reasoning (ER) rule was\\ndeveloped to fuse the output score from each modality to construct an optimal\\npredictive model. One public data set and two clinical case studies were\\nperformed to validate model performance. The experimental results indicated\\nthat the proposed ER rule based radiomics models outperformed the traditional\\nmodels that rely on a single classifier or simply use combined features from\\ndifferent modalities.\\n',\n",
       " '  In our recent works, we developed a probabilistic framework for structural\\nanalysis in undirected networks and directed networks. The key idea of that\\nframework is to sample a network by a symmetric and asymmetric bivariate\\ndistribution and then use that bivariate distribution to formerly defining\\nvarious notions, including centrality, relative centrality, community, and\\nmodularity. The main objective of this paper is to extend the probabilistic\\ndefinition to attributed networks, where sampling bivariate distributions by\\nexponentially twisted sampling. Our main finding is that we find a way to deal\\nwith the sampling of the attributed network including signed network. By using\\nthe sampling method, we define the various centralities in attributed networks.\\nThe influence centralities and trust centralities correctly show that how to\\nidentify centralities in signed network. The advertisement-specific influence\\ncentralities also perfectly define centralities when the attributed networks\\nthat have node attribute. Experimental results on real-world dataset\\ndemonstrate the different centralities with changing the temperature. Further\\nexperiments are conducted to gain a deeper understanding of the importance of\\nthe temperature.\\n',\n",
       " '  State-of-the-art password guessing tools, such as HashCat and John the\\nRipper, enable users to check billions of passwords per second against password\\nhashes. In addition to performing straightforward dictionary attacks, these\\ntools can expand password dictionaries using password generation rules, such as\\nconcatenation of words (e.g., \"password123456\") and leet speak (e.g.,\\n\"password\" becomes \"p4s5w0rd\"). Although these rules work well in practice,\\nexpanding them to model further passwords is a laborious task that requires\\nspecialized expertise. To address this issue, in this paper we introduce\\nPassGAN, a novel approach that replaces human-generated password rules with\\ntheory-grounded machine learning algorithms. Instead of relying on manual\\npassword analysis, PassGAN uses a Generative Adversarial Network (GAN) to\\nautonomously learn the distribution of real passwords from actual password\\nleaks, and to generate high-quality password guesses. Our experiments show that\\nthis approach is very promising. When we evaluated PassGAN on two large\\npassword datasets, we were able to surpass rule-based and state-of-the-art\\nmachine learning password guessing tools. However, in contrast with the other\\ntools, PassGAN achieved this result without any a-priori knowledge on passwords\\nor common password structures. Additionally, when we combined the output of\\nPassGAN with the output of HashCat, we were able to match 51%-73% more\\npasswords than with HashCat alone. This is remarkable, because it shows that\\nPassGAN can autonomously extract a considerable number of password properties\\nthat current state-of-the art rules do not encode.\\n',\n",
       " '  A method is proposed for solving equality constrained nonlinear optimization\\nproblems involving twice continuously differentiable functions. The method\\nemploys a trust funnel approach consisting of two phases: a first phase to\\nlocate an $\\\\epsilon$-feasible point and a second phase to seek optimality while\\nmaintaining at least $\\\\epsilon$-feasibility. A two-phase approach of this kind\\nbased on a cubic regularization methodology was recently proposed along with a\\nsupporting worst-case iteration complexity analysis. Unfortunately, however, in\\nthat approach, the objective function is completely ignored in the first phase\\nwhen $\\\\epsilon$-feasibility is sought. The main contribution of the method\\nproposed in this paper is that the same worst-case iteration complexity is\\nachieved, but with a first phase that also accounts for improvements in the\\nobjective function. As such, the method typically requires fewer iterations in\\nthe second phase, as the results of numerical experiments demonstrate.\\n',\n",
       " '  Recently, the soft attention mechanism, which was originally proposed in\\nlanguage processing, has been applied in computer vision tasks like image\\ncaptioning. This paper presents improvements to the soft attention model by\\ncombining a convolutional LSTM with a hierarchical system architecture to\\nrecognize action categories in videos. We call this model the Convolutional\\nHierarchical Attention Model (CHAM). The model applies a convolutional\\noperation inside the LSTM cell and an attention map generation process to\\nrecognize actions. The hierarchical architecture of this model is able to\\nexplicitly reason on multi-granularities of action categories. The proposed\\narchitecture achieved improved results on three publicly available datasets:\\nthe UCF sports dataset, the Olympic sports dataset and the HMDB51 dataset.\\n',\n",
       " '  We show that the monodromy for a genus one, fibered knot can have at most two\\nmonodromy equivalence classes of once-unclean arcs. We use this to classify all\\nmonodromies of genus one, fibered knots that possess once-unclean arcs, all\\nmanifolds containing genus one fibered knots with generalized crossing changes\\nresulting in another genus one fibered knot, and all generalized crossing\\nchanges between two genus one, fibered knots.\\n',\n",
       " '  We introduce a trimmed version of the Hill estimator for the index of a\\nheavy-tailed distribution, which is robust to perturbations in the extreme\\norder statistics. In the ideal Pareto setting, the estimator is essentially\\nfinite-sample efficient among all unbiased estimators with a given strict upper\\nbreak-down point. For general heavy-tailed models, we establish the asymptotic\\nnormality of the estimator under second order conditions and discuss its\\nminimax optimal rate in the Hall class. We introduce the so-called trimmed Hill\\nplot, which can be used to select the number of top order statistics to trim.\\nWe also develop an automatic, data-driven procedure for the choice of trimming.\\nThis results in a new type of robust estimator that can {\\\\em adapt} to the\\nunknown level of contamination in the extremes. As a by-product we also obtain\\na methodology for identifying extreme outliers in heavy tailed data. The\\ncompetitive performance of the trimmed Hill and adaptive trimmed Hill\\nestimators is illustrated with simulations.\\n',\n",
       " '  Direct imaging of exoplanet systems requires the use of coronagraphs to reach\\nhigh contrast levels (10^-8 to 10^-11) at small angular separations (0.1\").\\nHowever, the performance of these devices is drastically limited by aberrations\\n(in phase or in amplitude, introduced either by atmosphere or by the optics).\\nCoronagraphs must therefore be combined with extreme adaptive optic systems,\\ncomposed of a focal plane wavefront sensor and of a high order deformable\\nmirror. These adaptive optic systems must reach a residual error in the\\ncorrected wavefront of less than 0.1 nm (RMS) with a rate of 1 kHz. In\\naddition, the surface defects of the deformable mirror, inherent from the\\nfabrication process, must be limited in order to avoid the introduction of\\namplitude aberrations. An experimental high contrast bench has been developed\\nat the Paris Observatory (LESIA). This bench includes a Boston Micromachine\\ndeformable mirror composed of 1024 actuators. For a precise analysis of its\\nsurface and performance, we characterized this mirror on the interferometric\\nbench developed since 2004 at the Marseille Observatory (LAM). In this paper,\\nwe present this interferometric bench as well as the results of the analysis.\\nThis will include a precise surface characterization and a description of the\\nbehavior of the actuators, on a 10 by 10 actuator range (behavior of a single\\nactuator, study of the cross-talk between neighbor actuators, influence of a\\nstuck actuator) and on full mirror scale (general surface shape).\\n',\n",
       " '  In this paper, we use a new partial order, called the f-majorization order.\\nThe new order includes as special cases the majorization , the reciprocal\\nmajorization and the p-larger orders. We provide a comprehensive account of the\\nmathematical properties of the f-majorization order and give applications of\\nthis order in the context of stochastic comparison for extreme order statistics\\nof independent samples following the Frechet distribution and scale model. We\\ndiscuss stochastic comparisons of series systems with independent heterogeneous\\nexponentiated scale components in terms of the usual stochastic order and the\\nhazard rate order. We also derive new result on the usual stochastic order for\\nthe largest order statistics of samples having exponentiated scale marginals\\nand Archimedean copula structure.\\n',\n",
       " \"  The task of determining a speaker's native language based only on his\\nspeeches in a second language is known as Native Language Identification or\\nNLI. Due to its increasing applications in various domains of speech signal\\nprocessing, this has emerged as an important research area in recent times. In\\nthis paper we have proposed an i-vector based approach to develop an automatic\\nNLI system using MFCC and GFCC features. For evaluation of our approach, we\\nhave tested our framework on the 2016 ComParE Native language sub-challenge\\ndataset which has English language speakers from 11 different native language\\nbackgrounds. Our proposed method outperforms the baseline system with an\\nimprovement in accuracy by 21.95% for the MFCC feature based i-vector framework\\nand 22.81% for the GFCC feature based i-vector framework.\\n\",\n",
       " '  In a recent paper, T. Austin has proved an analogous theorem for the\\ncontinuous torus of the original Junta theorem proved by Friedgut in the case\\nof the Boolean cube. Analogous statements have been established recently in\\ndiscrete cases such as the discrete Tori by Ellis et.al., and in the case of\\nslices of the Boolean cube by Wimmer and Filmus. In the continuous case,\\nthrough the notion of geometric influences, a statement has also been\\nestablished by Keller, Mossel and Sen for Boltzmann probability measures. In\\nthis article, we broaden the scope of the arguments of T. Austin to get an\\nunified proof of these results, removing the restriction to Boolean functions.\\nIndeed, the proof of T. Austin relies on semigroup arguments and can be\\nperformed in a general framework that covers both Cayley or Schreier graphs or\\nproduct of log-concave probability measures.\\n',\n",
       " '  Low-quality results have been a long-standing problem on microtask\\ncrowdsourcing platforms, driving away requesters and justifying low wages for\\nworkers. To date, workers have been blamed for low-quality results: they are\\nsaid to make as little effort as possible, do not pay attention to detail, and\\nlack expertise. In this paper, we hypothesize that requesters may also be\\nresponsible for low-quality work: they launch unclear task designs that confuse\\neven earnest workers, under-specify edge cases, and neglect to include\\nexamples. We introduce prototype tasks, a crowdsourcing strategy requiring all\\nnew task designs to launch a small number of sample tasks. Workers attempt\\nthese tasks and leave feedback, enabling the re- quester to iterate on the\\ndesign before publishing it. We report a field experiment in which tasks that\\nunderwent prototype task iteration produced higher-quality work results than\\nthe original task designs. With this research, we suggest that a simple and\\nrapid iteration cycle can improve crowd work, and we provide empirical evidence\\nthat requester \"quality\" directly impacts result quality.\\n',\n",
       " '  In an effort to overcome the data deluge in computational biology and\\nbioinformatics and to facilitate bioinformatics research in the era of big\\ndata, we identify some of the most influential algorithms that have been widely\\nused in the bioinformatics community. These top data mining and machine\\nlearning algorithms cover classification, clustering, regression, graphical\\nmodel-based learning, and dimensionality reduction. The goal of this study is\\nto guide the focus of scalable computing experts in the endeavor of applying\\nnew storage and scalable computation designs to bioinformatics algorithms that\\nmerit their attention most, following the engineering maxim of \"optimize the\\ncommon case\".\\n',\n",
       " '  We show that the symplectic contraction map of Hilgert-Manon-Martens -- a\\nsymplectic version of Popov\\'s horospherical contraction -- is simply the\\nquotient of a Hamiltonian manifold $M$ by a \"stratified null foliation\" that is\\ndetermined by the group action and moment map. We also show that the quotient\\ndifferential structure on the symplectic contraction of $M$ supports a Poisson\\nbracket. We end by proving a very general description of the topology of fibers\\nof Gelfand-Zeitlin systems on multiplicity free Hamiltonian $U(n)$ and $SO(n)$\\nmanifolds.\\n',\n",
       " '  We report on two ultrastable lasers each stabilized to independent silicon\\nFabry-Pérot cavities operated at 124 K. The fractional frequency instability\\nof each laser is completely determined by the fundamental thermal Brownian\\nnoise of the mirror coatings with a flicker noise floor of $4 \\\\times 10^{-17}$\\nfor integration times between 0.8 s and a few tens of seconds. We rigorously\\ntreat the notorious divergencies encountered with the associated flicker\\nfrequency noise and derive methods to relate this noise to observable and\\npractically relevant linewidths and coherence times. The individual laser\\nlinewidth obtained from the phase noise spectrum or the direct beat note\\nbetween the two lasers can be as small as 5 mHz at 194 THz. From the measured\\nphase evolution between the two laser fields we derive usable phase coherence\\ntimes for different applications of 11 s and 60 s.\\n',\n",
       " \"  We survey some recent topics on singularities, with a focus on their\\nconnection to the minimal model program. This includes the construction and\\nproperties of dual complexes, the proof of the ACC conjecture for log canonical\\nthresholds and the recent progress on the `local stability theory' of an\\narbitrary Kawamata log terminal singularity.\\n\",\n",
       " '  Dynamic economic dispatch (DED) problem considering prohibited operating\\nzones (POZ), ramp rate constraints, transmission losses and spinning reserve\\nconstraints is a complicated non-linear problem which is difficult to solve\\nefficiently. In this paper, a mixed integer linear programming (MILP) method is\\nproposed to solve such a DED problem. Firstly, a novel MILP formulation for DED\\nproblem without considering the transmission losses, denoted by MILP-1, is\\npresented by using perspective cut reformulation technique. When the\\ntransmission losses are considered, the quadratic terms in the transmission\\nlosses are replaced by their first order Taylor expansions, and then an MILP\\nformulation for DED considering the transmission losses, denoted by MILP-2, is\\nobtained. Based on MILP-1 and MILP-2, an MILP-iteration algorithm (MILP-IA) is\\nproposed to solve the complicated DED problem. The effectiveness of the MILP-1\\nand MILP-IA are assessed by several cases and the simulation results show that\\nboth of them can solve to competitive solutions in a short time.\\n',\n",
       " '  In the first part of the thesis, we study a classical invariant of projective\\nvarieties, the secant defectivity. The second part is devoted to modern\\nalgebraic geometry, we study the birational geometry of blow-ups of\\nGrassmannians at points.\\n',\n",
       " '  We have obtained the Vlasov equation and Boltzmann kinetic equation using\\nPoisson bracket (classical Hamilton equation) and Rindler Hamiltonian. Further,\\nwe treat the whole Universe as a statistical system with galaxies as the point\\nparticle constituents in large scale structure. Since the collisions of\\ngalaxies are very rare phenomena, we assume that the gas with the constituents\\nas point galaxies satisfy Vlasov equation. Considering the astrophysical\\ncatastrophic event, e.g., the creation of gravity waves by the collisions of\\nblack holes, and further assuming that when such a wave passes through the gas\\ncauses a kind of polarization of mass distribution. This polarization of mass\\ndistribution will further gives rise to gravitational permittivity or\\ndielectric constant. We have shown that the low frequency gravity waves will be\\nabsorbed, whereas the high frequency part will pass through the gas of point\\ngalaxies. It is further noticed that the region in space with extremely high\\ngravitational field is transparent to gravity waves. In the other part of this\\nwork, using the Boltzmann equation and replacing the collision term by the\\nrelaxation time approximation and further assuming a small deviation from the\\nequilibrium configuration of the stellar / galactic plasma in Rindler space, we\\nhave obtained the kinetic coefficients. For the first time we have derived an\\nexpression for the coefficient of gravitational flow. It has further been shown\\nthat in presence of strong gravitational field all the kinetic coefficients\\nbecome vanishingly small.\\n',\n",
       " \"  This paper describes the design and implementation of a ground-related\\nodometry sensor suitable for micro aerial vehicles. The sensor is based on a\\nground-facing camera and a single-board Linux-based embedded computer with a\\nmultimedia System on a Chip (SoC). The SoC features a hardware video encoder\\nwhich is used to estimate the optical flow online. The optical flow is then\\nused in combination with a distance sensor to estimate the vehicle's velocity.\\nThe proposed sensor is compared to a similar existing solution and evaluated in\\nboth indoor and outdoor environments.\\n\",\n",
       " '  We prove polarization theorems for arbitrary classical-quantum (cq) channels.\\nThe input alphabet is endowed with an arbitrary Abelian group operation and an\\nAr{\\\\i}kan-style transformation is applied using this operation. It is shown\\nthat as the number of polarization steps becomes large, the synthetic\\ncq-channels polarize to deterministic homomorphism channels which project their\\ninput to a quotient group of the input alphabet. This result is used to\\nconstruct polar codes for arbitrary cq-channels and arbitrary classical-quantum\\nmultiple access channels (cq-MAC). The encoder can be implemented in $O(N\\\\log\\nN)$ operations, where $N$ is the blocklength of the code. A quantum successive\\ncancellation decoder for the constructed codes is proposed. It is shown that\\nthe probability of error of this decoder decays faster than $2^{-N^{\\\\beta}}$\\nfor any $\\\\beta<\\\\frac{1}{2}$.\\n',\n",
       " '  We study singular integral operators induced by $3$-dimensional\\nCalderón-Zygmund kernels in the Heisenberg group. We show that if such an\\noperator is $L^{2}$ bounded on vertical planes, with uniform constants, then it\\nis also $L^{2}$ bounded on all intrinsic graphs of compactly supported\\n$C^{1,\\\\alpha}$ functions over vertical planes.\\nIn particular, the result applies to the operator $\\\\mathcal{R}$ induced by\\nthe kernel $$\\\\mathcal{K}(z) = \\\\nabla_{\\\\mathbb{H}} \\\\| z \\\\|^{-2}, \\\\quad z \\\\in\\n\\\\mathbb{H} \\\\setminus \\\\{0\\\\},$$ the horizontal gradient of the fundamental\\nsolution of the sub-Laplacian. The $L^{2}$ boundedness of $\\\\mathcal{R}$ is\\nconnected with the question of removability for Lipschitz harmonic functions.\\nAs a corollary of our result, we infer that the intrinsic graphs mentioned\\nabove are non-removable. Apart from subsets of vertical planes, these are the\\nfirst known examples of non-removable sets with positive and locally finite\\n$3$-dimensional measure.\\n',\n",
       " \"  Upon a matrix representation of a binary bipartite network, via the\\npermutation invariance, a coupling geometry is computed to approximate the\\nminimum energy macrostate of a network's system. Such a macrostate is supposed\\nto constitute the intrinsic structures of the system, so that the coupling\\ngeometry should be taken as information contents, or even the nonparametric\\nminimum sufficient statistics of the network data. Then pertinent null and\\nalternative hypotheses, such as nestedness, are to be formulated according to\\nthe macrostate. That is, any efficient testing statistic needs to be a function\\nof this coupling geometry. These conceptual architectures and mechanisms are by\\nand large still missing in community ecology literature, and rendered\\nmisconceptions prevalent in this research area. Here the algorithmically\\ncomputed coupling geometry is shown consisting of deterministic multiscale\\nblock patterns, which are framed by two marginal ultrametric trees on row and\\ncolumn axes, and stochastic uniform randomness within each block found on the\\nfinest scale. Functionally a series of increasingly larger ensembles of matrix\\nmimicries is derived by conforming to the multiscale block configurations. Here\\nmatrix mimicking is meant to be subject to constraints of row and column sums\\nsequences. Based on such a series of ensembles, a profile of distributions\\nbecomes a natural device for checking the validity of testing statistics or\\nstructural indexes. An energy based index is used for testing whether network\\ndata indeed contains structural geometry. A new version block-based nestedness\\nindex is also proposed. Its validity is checked and compared with the existing\\nones. A computing paradigm, called Data Mechanics, and its application on one\\nreal data network are illustrated throughout the developments and discussions\\nin this paper.\\n\",\n",
       " '  Compared to rigid actuators, Series Elastic Actuators (SEAs) offer a\\npotential reduction of motor energy consumption and peak power, though these\\nbenefits are highly dependent on the design of the torque-elongation profile of\\nthe elastic element. In the case of linear springs, natural dynamics is a\\ntraditional method for this design, but it has two major limitations: arbitrary\\nload trajectories are difficult or impossible to analyze and it does not\\nconsider actuator constraints. Parametric optimization is also a popular design\\nmethod that addresses these limitations, but solutions are only optimal within\\nthe space of the parameters. To overcome these limitations, we propose a\\nnon-parametric convex optimization program for the design of the nonlinear\\nelastic element that minimizes energy consumption and peak power for an\\narbitrary periodic reference trajectory. To obtain convexity, we introduce a\\nconvex approximation to the expression of peak power; energy consumption is\\nshown to be convex without approximation. The combination of peak power and\\nenergy consumption in the cost function leads to a multiobjective convex\\noptimization framework that comprises the main contribution of this paper. As a\\ncase study, we recover the elongation-torque profile of a cubic spring, given\\nits natural oscillation as the reference load. We then design nonlinear SEAs\\nfor an ankle prosthesis that minimize energy consumption and peak power for\\ndifferent trajectories and extend the range of achievable tasks when subject to\\nactuator constraints.\\n',\n",
       " '  As AI systems become more ubiquitous, securing them becomes an emerging\\nchallenge. Over the years, with the surge in online social media use and the\\ndata available for analysis, AI systems have been built to extract, represent\\nand use this information. The credibility of this information extracted from\\nopen sources, however, can often be questionable. Malicious or incorrect\\ninformation can cause a loss of money, reputation, and resources; and in\\ncertain situations, pose a threat to human life. In this paper, we use an\\nensembled semi-supervised approach to determine the credibility of Reddit posts\\nby estimating their reputation score to ensure the validity of information\\ningested by AI systems. We demonstrate our approach in the cybersecurity\\ndomain, where security analysts utilize these systems to determine possible\\nthreats by analyzing the data scattered on social media websites, forums,\\nblogs, etc.\\n',\n",
       " '  This paper deals with the problem of detecting fallen people lying on the\\nfloor by means of a mobile robot equipped with a 3D depth sensor. In the\\nproposed algorithm, inspired by semantic segmentation techniques, the 3D scene\\nis over-segmented into small patches. Fallen people are then detected by means\\nof two SVM classifiers: the first one labels each patch, while the second one\\ncaptures the spatial relations between them. This novel approach showed to be\\nrobust and fast. Indeed, thanks to the use of small patches, fallen people in\\nreal cluttered scenes with objects side by side are correctly detected.\\nMoreover, the algorithm can be executed on a mobile robot fitted with a\\nstandard laptop making it possible to exploit the 2D environmental map built by\\nthe robot and the multiple points of view obtained during the robot navigation.\\nAdditionally, this algorithm is robust to illumination changes since it does\\nnot rely on RGB data but on depth data. All the methods have been thoroughly\\nvalidated on the IASLAB-RGBD Fallen Person Dataset, which is published online\\nas a further contribution. It consists of several static and dynamic sequences\\nwith 15 different people and 2 different environments.\\n',\n",
       " '  We present a general methodology to evaluate matrix elements of the effective\\ncore potentials (ECPs) within one-electron basis set of Slater-type orbitals\\n(STOs). The scheme is based on translation of individual STO distributions in\\nthe framework of Barnett-Coulson method. We discuss different types of\\nintegrals which naturally appear and reduce them to few basic quantities which\\ncan be calculated recursively or purely numerically. Additionally, we consider\\nevaluation of the STOs matrix elements involving the core polarisation\\npotentials (CPP) and effective spin-orbit potentials. Construction of the STOs\\nbasis sets designed specifically for use with ECPs is discussed and differences\\nin comparison with all-electron basis sets are briefly summarised. We verify\\nthe validity of the present approach by calculating excitation energies, static\\ndipole polarisabilities and valence orbital energies for the alkaline earth\\nmetals (Ca, Sr, Ba). Finally, we evaluate interaction energies, permanent\\ndipole moments and ionisation energies for barium and strontium hydrides, and\\ncompare them with the best available experimental and theoretical data.\\n',\n",
       " '  We present a study by computer simulations of a class of complex-valued\\nsolutions of the three-dimensional Navier-Stokes equations in the whole space,\\nwhich, according to Li and Sinai, present a blow-up (singularity) at a finite\\ntime. The computer results allow a detailed study of the blow-up mechanism, and\\nshow interesting features of the behavior of the solutions near the blow-up\\ntime, such as the concentration of energy and enstrophy in a small region\\naround a few points of physical space, while outside this region the \"fluid\"\\nremains \"quiet\".\\n',\n",
       " \"  Background Computer-based geometrical meshes of bones are important for\\napplications in computational biomechanics as well as clinical software. There\\nis however a lack of freely available detailed bone meshes, especially related\\nto the human female morphology.\\nMethods & Results We provide high resolution bone meshes of the lower body,\\nderived from CT images of a 59 year old female cadaver that were sourced from\\nthe Visible Human Data Set, Visible Human Project (NIH, USA). Important bone\\nlandmarks and joint rotation axes are identified from the extracted meshes. A\\nscript-based framework is developed to provide a graphical user interface that\\ncan visualize, resample and modify the meshes to fit different subject scales.\\nConclusion This open-data resource fills a gap in available data and is\\nprovided for free usage in research and other applications. The associated\\nscripts allows users to easily transform the meshes to different laboratory and\\nsoftware setups. This resource may be accessed through the following web link:\\nthis https URL\\nThis document is the author's version of this article.\\n\",\n",
       " '  Equilibrium theormodynamics is characterized by two fundamental ideas:\\nthermalisation--that systems approach a late time thermal state; and phase\\nstructure--that thermal states exhibit singular changes as various parameters\\ncharacterizing the system are changed. We summarise recent progress that has\\nestablished generalizations of these ideas to periodically driven, or Floquet,\\nclosed quantum systems. This has resulted in the discovery of entirely new\\nphases which exist only out of equilibrium, such as the $\\\\pi$-spin glass or\\nFloquet time crystal.\\n',\n",
       " '  This paper presents a deep learning method for faster magnetic resonance\\nimaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and\\nprovides a rationale for why the proposed approach works well. Uniform\\nsubsampling is used in the time-consuming phase-encoding direction to capture\\nhigh-resolution image information, while permitting the image-folding problem\\ndictated by the Poisson summation formula. To deal with the localization\\nuncertainty due to image folding, very few low-frequency k-space data are\\nadded. Training the deep learning net involves input and output images that are\\npairs of Fourier transforms of the subsampled and fully sampled k-space data.\\nNumerous experiments show the remarkable performance of the proposed method;\\nonly 29% of k-space data can generate images of high quality as effectively as\\nstandard MRI reconstruction with fully sampled data.\\n',\n",
       " '  We introduce a dynamic artificial neural network-based (ANN) adaptive\\ninference process, which learns temporal predictive models of dynamical\\nsystems. We term the process REPRISE, a REtrospective and PRospective Inference\\nSchEme. REPRISE infers the unobservable contextual state that best explains its\\nrecently encountered sensorimotor experiences as well as accompanying,\\ncontext-dependent temporal predictive models retrospectively. Meanwhile, it\\nexecutes prospective inference, optimizing upcoming motor activities in a\\ngoal-directed manner. In a first implementation, a recurrent neural network\\n(RNN) is trained to learn a temporal forward model, which predicts the\\nsensorimotor contingencies of different simulated dynamic vehicles. The RNN is\\naugmented with contextual neurons, which enable the compact encoding of\\ndistinct, but related sensorimotor dynamics. We show that REPRISE is able to\\nconcurrently learn to separate and approximate the encountered sensorimotor\\ndynamics. Moreover, we show that REPRISE can exploit the learned model to\\ninduce goal-directed, model-predictive control, that is, approximate active\\ninference: Given a goal state, the system imagines a motor command sequence\\noptimizing it with the prospective objective to minimize the distance to a\\ngiven goal. Meanwhile, the system evaluates the encountered sensorimotor\\ncontingencies retrospectively, adapting its neural hidden states for\\nmaintaining model coherence. The RNN activities thus continuously imagine the\\nupcoming future and reflect on the recent past, optimizing both, hidden state\\nand motor activities. In conclusion, the combination of temporal predictive\\nstructures with modulatory, generative encodings offers a way to develop\\ncompact event codes, which selectively activate particular types of\\nsensorimotor event-specific dynamics.\\n',\n",
       " '  The International Cosmic Day (ICD) is an astroparticle physics outreach event\\nfor high-school students and brings together students and different physics\\noutreach projects from all over the world. Groups of scientists, teachers, and\\nstudents meet for one day to learn about cosmic rays and perform an experiment\\nwith atmospheric muons. All participating groups investigate an identical\\nquestion. The students are enabled to work together like in an international\\ncollaboration, discussing their results in joint video conferences. Analyzing\\ndata, comparing and discussing with other \"young scientists\" gives the students\\na glimpse of how professional scientific research works. Scientists join the\\nvideo conferences and give lectures to provide an insight in current\\nastroparticle physics research. Several participating research experiments\\nanalyze big science data tailored to the questions addressed by the students\\nand present their results on equal terms with the students. To create a lasting\\nevent, proceedings with measurement results of all participating groups are\\npublished. Every participant receives a personal e-mail with his certificate\\nand the proceedings booklet. Organized by DESY in cooperation with Netzwerk\\nTeilchenwelt, IPPOG, QuarkNet, Fermilab, and national partners like INFN, the\\nICD is a growing event with more and more popularity. We present the\\norganization of the event and the experience from five years of ICD.\\n',\n",
       " '  The splitting number of a plane irreducible curve for a Galois cover is\\neffective to distinguish the embedded topologies of plane curves. In this\\npaper, we define a connected number of any plane curve for a Galois cover whose\\nbranch divisor has no common components with the plane curve, which is similar\\nto the splitting number. We classify the embedded topology of Artal\\narrangements of degree $b\\\\geq 4$ by the connected number, where an Artal\\narrangement of degree $b$ is a plane curve consisting of one smooth curve of\\ndgree $b$ and three total inflectional tangents.\\n',\n",
       " '  Many computer vision problems are formulated as the optimization of a cost\\nfunction. This approach faces two main challenges: (i) designing a cost\\nfunction with a local optimum at an acceptable solution, and (ii) developing an\\nefficient numerical method to search for one (or multiple) of these local\\noptima. While designing such functions is feasible in the noiseless case, the\\nstability and location of local optima are mostly unknown under noise,\\nocclusion, or missing data. In practice, this can result in undesirable local\\noptima or not having a local optimum in the expected place. On the other hand,\\nnumerical optimization algorithms in high-dimensional spaces are typically\\nlocal and often rely on expensive first or second order information to guide\\nthe search. To overcome these limitations, this paper proposes Discriminative\\nOptimization (DO), a method that learns search directions from data without the\\nneed of a cost function. Specifically, DO explicitly learns a sequence of\\nupdates in the search space that leads to stationary points that correspond to\\ndesired solutions. We provide a formal analysis of DO and illustrate its\\nbenefits in the problem of 3D point cloud registration, camera pose estimation,\\nand image denoising. We show that DO performed comparably or outperformed\\nstate-of-the-art algorithms in terms of accuracy, robustness to perturbations,\\nand computational efficiency.\\n',\n",
       " '  Over the past few years, a number of successful humanoid platforms have been\\ndeveloped, including the Nao and the DARwIn-OP, both of which are used by many\\nresearch groups for the investigation of bipedal walking, full-body motions,\\nand human-robot interaction. The NimbRo-OP is an open humanoid platform under\\ndevelopment by team NimbRo of the University of Bonn. Significantly larger than\\nthe two aforementioned humanoids, this platform has the potential to interact\\nwith a more human-scale environment. This paper describes a software framework\\nfor the NimbRo-OP that is based on the Robot Operating System (ROS) middleware.\\nThe software provides functionality for hardware abstraction, visual\\nperception, and behavior generation, and has been used to implement basic\\nsoccer skills. These were demonstrated at RoboCup 2013, as part of the winning\\nteam of the Humanoid League competition.\\n',\n",
       " '  Despite the remarkable progress in face recognition related technologies,\\nreliably recognizing faces across ages still remains a big challenge. The\\nappearance of a human face changes substantially over time, resulting in\\nsignificant intra-class variations. As opposed to current techniques for\\nage-invariant face recognition, which either directly extract age-invariant\\nfeatures for recognition, or first synthesize a face that matches target age\\nbefore feature extraction, we argue that it is more desirable to perform both\\ntasks jointly so that they can leverage each other. To this end, we propose a\\ndeep Age-Invariant Model (AIM) for face recognition in the wild with three\\ndistinct novelties. First, AIM presents a novel unified deep architecture\\njointly performing cross-age face synthesis and recognition in a mutual\\nboosting way. Second, AIM achieves continuous face rejuvenation/aging with\\nremarkable photorealistic and identity-preserving properties, avoiding the\\nrequirement of paired data and the true age of testing samples. Third, we\\ndevelop effective and novel training strategies for end-to-end learning the\\nwhole deep architecture, which generates powerful age-invariant face\\nrepresentations explicitly disentangled from the age variation. Moreover, we\\npropose a new large-scale Cross-Age Face Recognition (CAFR) benchmark dataset\\nto facilitate existing efforts and push the frontiers of age-invariant face\\nrecognition research. Extensive experiments on both our CAFR and several other\\ncross-age datasets (MORPH, CACD and FG-NET) demonstrate the superiority of the\\nproposed AIM model over the state-of-the-arts. Benchmarking our model on one of\\nthe most popular unconstrained face recognition datasets IJB-C additionally\\nverifies the promising generalizability of AIM in recognizing faces in the\\nwild.\\n',\n",
       " '  In this paper, we give a procedure of how to discretize the recursion\\noperators by considering unified bilinear forms of integrable hierarchies. As\\ntwo illustrative examples, the unified bilinear forms of the AKNS hierarchy and\\nthe KdV hierarchy are presented from their recursion operators. Via the\\ncompatibility between soliton equations and their auto-Bäcklund\\ntransformations, the bilinear integrable hierarchies are discretized and the\\ndiscrete recursion operators are obtained. The discrete recursion operators\\nconverge to the original continuous forms after a standard limit.\\n',\n",
       " '  We identify two issues with the family of algorithms based on the Adversarial\\nImitation Learning framework. The first problem is implicit bias present in the\\nreward functions used in these algorithms. While these biases might work well\\nfor some environments, they can also lead to sub-optimal behavior in others.\\nSecondly, even though these algorithms can learn from few expert\\ndemonstrations, they require a prohibitively large number of interactions with\\nthe environment in order to imitate the expert for many real-world\\napplications. In order to address these issues, we propose a new algorithm\\ncalled Discriminator-Actor-Critic that uses off-policy Reinforcement Learning\\nto reduce policy-environment interaction sample complexity by an average factor\\nof 10. Furthermore, since our reward function is designed to be unbiased, we\\ncan apply our algorithm to many problems without making any task-specific\\nadjustments.\\n',\n",
       " '  Even though end-to-end supervised learning has shown promising results for\\nsensorimotor control of self-driving cars, its performance is greatly affected\\nby the weather conditions under which it was trained, showing poor\\ngeneralization to unseen conditions. In this paper, we show how knowledge can\\nbe transferred using semantic maps to new weather conditions without the need\\nto obtain new ground truth data. To this end, we propose to divide the task of\\nvehicle control into two independent modules: a control module which is only\\ntrained on one weather condition for which labeled steering data is available,\\nand a perception module which is used as an interface between new weather\\nconditions and the fixed control module. To generate the semantic data needed\\nto train the perception module, we propose to use a generative adversarial\\nnetwork (GAN)-based model to retrieve the semantic information for the new\\nconditions in an unsupervised manner. We introduce a master-servant\\narchitecture, where the master model (semantic labels available) trains the\\nservant model (semantic labels not available). We show that our proposed method\\ntrained with ground truth data for a single weather condition is capable of\\nachieving similar results on the task of steering angle prediction as an\\nend-to-end model trained with ground truth data of 15 different weather\\nconditions.\\n',\n",
       " '  We propose a new mechanism for integration of OWL ontologies using semantic\\nimport relations. In contrast to the standard OWL importing, we do not require\\nall axioms of the imported ontologies to be taken into account for reasoning\\ntasks, but only their logical implications over a chosen signature. This\\nproperty comes natural in many ontology integration scenarios, especially when\\nthe number of ontologies is large. In this paper, we study the complexity of\\nreasoning over ontologies with semantic import relations and establish a range\\nof tight complexity bounds for various fragments of OWL.\\n',\n",
       " '  We propose modeling an angle-of-arrival (AOA) positioning measurement as a\\nvon Mises-Fisher (VMF) distributed unit vector instead of the conventional\\nnormally distributed azimuth and elevation measurements. Describing the\\n2-dimensional AOA measurement with three numbers removes discontinuities and\\nreduces nonlinearity at the poles of the azimuth-elevation coordinate system.\\nOur computer simulations show that the proposed VMF measurement noise model\\nbased filters outperform the normal distribution based algorithms in accuracy\\nin a scenario where close-to-pole measurements occur frequently.\\n',\n",
       " '  Millennials are arriving to university sometimes uncomfortable with the\\nmethods of some courses. Ideas that worked with previous generations of\\nstudents begin to fail when digital natives receive paper and pencil as tools.\\nCourses must update from old paper-based methods to hands-on and computerized\\nversions. The present work discusses about this update and comments on one\\nimplementation in the course Computer Organization of the Computer Science\\ncurriculum at Universidad de Buenos Aires. It also includes some metrics that\\nshow the effectiveness of the changes in attracting and engaging the digital\\ngeneration.\\n',\n",
       " '  Generalised contact structures are studied from the point of view of reduced\\ngeneralised complex structures, naturally incorporating non-coorientable\\nstructures as non-trivial fibering. The infinitesimal symmetries are described\\nin detail, with a geometric description given in terms of gerbes. As an\\napplication of the reduction procedure, generalised coKähler structures are\\ndefined in a way which extends the Kähler/coKähler correspondence.\\n',\n",
       " '  We introduce an axiomatic approach to group recommendations, in line of\\nprevious work on the axiomatic treatment of trust-based recommendation systems,\\nranking systems, and other foundational work on the axiomatic approach to\\ninternet mechanisms in social choice settings. In group recommendations we wish\\nto recommend to a group of agents, consisting of both opinionated and undecided\\nmembers, a joint choice that would be acceptable to them. Such a system has\\nmany applications, such as choosing a movie or a restaurant to go to with a\\ngroup of friends, recommending games for online game players, & other communal\\nactivities.\\nOur method utilizes a given social graph to extract information on the\\nundecided, relying on the agents influencing them. We first show that a set of\\nfairly natural desired requirements (a.k.a axioms) leads to an impossibility,\\nrendering mutual satisfaction of them unreachable. However, we also show a\\nmodified set of axioms that fully axiomatize a group variant of the random-walk\\nrecommendation system, expanding a previous result from the individual\\nrecommendation case.\\n',\n",
       " \"  In the context of data-mining competitions (e.g., Kaggle, KDDCup, ILSVRC\\nChallenge), we show how access to an oracle that reports a contestant's\\nlog-loss score on the test set can be exploited to deduce the ground-truth of\\nsome of the test examples. By applying this technique iteratively to batches of\\n$m$ examples (for small $m$), all of the test labels can eventually be\\ninferred. In this paper, (1) We demonstrate this attack on the first stage of a\\nrecent Kaggle competition (Intel & MobileODT Cancer Screening) and use it to\\nachieve a log-loss of $0.00000$ (and thus attain a rank of #4 out of 848\\ncontestants), without ever training a classifier to solve the actual task. (2)\\nWe prove an upper bound on the batch size $m$ as a function of the\\nfloating-point resolution of the probability estimates that the contestant\\nsubmits for the labels. (3) We derive, and demonstrate in simulation, a more\\nflexible attack that can be used even when the oracle reports the accuracy on\\nan unknown (but fixed) subset of the test set's labels. These results underline\\nthe importance of evaluating contestants based only on test data that the\\noracle does not examine.\\n\",\n",
       " '  In this paper we study the logical foundations of automated inductive theorem\\nproving. To that aim we first develop a theoretical model that is centered\\naround the difficulty of finding induction axioms which are sufficient for\\nproving a goal.\\nBased on this model, we then analyze the following aspects: the choice of a\\nproof shape, the choice of an induction rule and the language of the induction\\nformula. In particular, using model-theoretic techniques, we clarify the\\nrelationship between notions of inductiveness that have been considered in the\\nliterature on automated inductive theorem proving. This is a corrected version\\nof the paper arXiv:1704.01930v5 published originally on Nov.~16, 2017.\\n',\n",
       " '  The problem of cache enabled private information retrieval (PIR) is\\nconsidered in which a user wishes to privately retrieve one out of $K$\\nmessages, each of size $L$ bits from $N$ distributed databases. The user has a\\nlocal cache of storage $SL$ bits which can be used to store any function of the\\n$K$ messages. The main contribution of this work is the exact characterization\\nof the capacity of cache aided PIR as a function of the storage parameter $S$.\\nIn particular, for a given cache storage parameter $S$, the\\ninformation-theoretically optimal download cost $D^{*}(S)/L$ (or the inverse of\\ncapacity) is shown to be equal to $(1- \\\\frac{S}{K})\\\\left(1+ \\\\frac{1}{N}+ \\\\ldots\\n+ \\\\frac{1}{N^{K-1}}\\\\right)$. Special cases of this result correspond to the\\nsettings when $S=0$, for which the optimal download cost was shown by Sun and\\nJafar to be $\\\\left(1+ \\\\frac{1}{N}+ \\\\ldots + \\\\frac{1}{N^{K-1}}\\\\right)$, and the\\ncase when $S=K$, i.e., cache size is large enough to store all messages\\nlocally, for which the optimal download cost is $0$. The intermediate points\\n$S\\\\in (0, K)$ can be readily achieved through a simple memory-sharing based PIR\\nscheme. The key technical contribution of this work is the converse, i.e., a\\nlower bound on the download cost as a function of storage $S$ which shows that\\nmemory sharing is information-theoretically optimal.\\n',\n",
       " '  Frequency tunability of 3D microwave cavities opens up numerous possibilities\\nfor their use in hybrid quantum systems and related technologies. For many\\napplications it is desirable to tune the resonance at cryogenic temperatures\\nwithout mechanical actuation. We show that a superconducting 3D microwave\\ncavity can be tuned at the percent level by taking advantage of the dielectric\\nproperties of superfluid $^4$He at milliKelvin temperatures, without affecting\\nits intrinsic quality factor -- reaching $3\\\\times10^5$ in the present\\nexperiment.\\n',\n",
       " \"  Dynamic portfolio optimization is the process of sequentially allocating\\nwealth to a collection of assets in some consecutive trading periods, based on\\ninvestors' return-risk profile. Automating this process with machine learning\\nremains a challenging problem. Here, we design a deep reinforcement learning\\n(RL) architecture with an autonomous trading agent such that, investment\\ndecisions and actions are made periodically, based on a global objective, with\\nautonomy. In particular, without relying on a purely model-free RL agent, we\\ntrain our trading agent using a novel RL architecture consisting of an infused\\nprediction module (IPM), a generative adversarial data augmentation module\\n(DAM) and a behavior cloning module (BCM). Our model-based approach works with\\nboth on-policy or off-policy RL algorithms. We further design the back-testing\\nand execution engine which interact with the RL agent in real time. Using\\nhistorical {\\\\em real} financial market data, we simulate trading with practical\\nconstraints, and demonstrate that our proposed model is robust, profitable and\\nrisk-sensitive, as compared to baseline trading strategies and model-free RL\\nagents from prior work.\\n\",\n",
       " '  The AFiD code, an open source solver for the incompressible Navier-Stokes\\nequations ({\\\\color{blue}\\\\burl{this http URL}}), has been ported to GPU\\nclusters to tackle large-scale wall-bounded turbulent flow simulations. The GPU\\nporting has been carried out in CUDA Fortran with the extensive use of kernel\\nloop directives (CUF kernels) in order to have a source code as close as\\npossible to the original CPU version; just a few routines have been manually\\nrewritten. A new transpose scheme, which is not limited to the GPU version only\\nand can be generally applied to any CFD code that uses pencil distributed\\nparallelization, has been devised to improve the scaling of the Poisson solver,\\nthe main bottleneck of incompressible solvers. The GPU version can reduce the\\nwall clock time by an order of magnitude compared to the CPU version for large\\nmeshes. Due to the increased performance and efficient use of memory, the GPU\\nversion of AFiD can perform simulations in parameter ranges that are\\nunprecedented in thermally-driven wall-bounded turbulence. To verify the\\naccuracy of the code, turbulent Rayleigh-Bénard convection and plane Couette\\nflow are simulated and the results are in good agreement with the experimental\\nand computational data that published in previous literatures.\\n',\n",
       " '  The statistics of the deformation and breakup of neutrally buoyant\\nsub-Kolmogorov ellipsoidal drops is investigated via Lagrangian simulations of\\nhomogeneous isotropic turbulence. The mean lifetime of a drop is also studied\\nas a function of the initial drop size and the capillary number. A vector model\\nof drop previously introduced by Olbricht, Rallison and Leal [J. Non-Newtonian\\nFluid Mech. $\\\\mathbf{10}$, 291 (1982)] is used to predict the behaviour of the\\nabove quantities analytically.\\n',\n",
       " '  We implemented several multilabel classification algorithms in the machine\\nlearning package mlr. The implemented methods are binary relevance, classifier\\nchains, nested stacking, dependent binary relevance and stacking, which can be\\nused with any base learner that is accessible in mlr. Moreover, there is access\\nto the multilabel classification versions of randomForestSRC and rFerns. All\\nthese methods can be easily compared by different implemented multilabel\\nperformance measures and resampling methods in the standardized mlr framework.\\nIn a benchmark experiment with several multilabel datasets, the performance of\\nthe different methods is evaluated.\\n',\n",
       " '  The evaluation of vector wave fields can be accurately performed by means of\\ndiffraction integrals, differential equations and also series expansions. In\\nthis paper, a Bessel series expansion which basis relies on the exact solution\\nof the Helmholtz equation in cylindrical coordinates is theoretically developed\\nfor the straightforward yet accurate description of low-numerical-aperture\\nfocal waves. The validity of this approach is confirmed by explicit application\\nto Gaussian beams and apertured focused fields in the paraxial regime. Finally\\nwe discuss how our procedure can be favorably implemented in scattering\\nproblems.\\n',\n",
       " \"  We investigate the validity of two common assumptions in the modelling of\\nsuperconducting circuits: first, that the superconducting qubits are pointlike,\\nand second, that the UV behaviour of the transmission line is not relevant to\\nthe qubit dynamics. We show that in the experimentally accessible ultra-strong\\ncoupling regime and for short (but attainable) times, the use of an inaccurate\\ncutoff model (such as sharp, or none at all) could introduce very significant\\ninaccuracies in the model's predictions.\\n\",\n",
       " '  We construct an infinite family of odd-symplectic forms (also known as\\nHamiltonian structures) on the 3-sphere that do not admit a symplectic\\ncobordism to the standard contact structure on the 3-sphere. This answers in\\nthe negative a question raised by Joel Fish motivated by the search for minimal\\ncharacteristic flows.\\n',\n",
       " \"  In \\\\cite{ChCa}, Califano and Chiuderi conjectured that the energy of\\nincompressible Magnetic hydrodynamical system is dissipated at a rate that is\\nindependent of the ohmic resistivity. The goal of this paper is to\\nmathematically justify this conjecture in three space dimension provided that\\nthe initial magnetic field and velocity is a small perturbation of the\\nequilibrium state $(e_3,0).$ In particular, we prove that for such data, 3-D\\nincompressible MHD system without magnetic diffusion has a unique global\\nsolution. Furthermore, the velocity field and the difference between the\\nmagnetic field and $e_3$ decay to zero in both $L^\\\\infty$ and $L^2$ norms with\\nexplicit rates. We point out that the decay rate in the $L^2$ norm is optimal\\nin sense that this rate coincides with that of the linear system. The main idea\\nof the proof is to exploit H$\\\\ddot{o}$rmander's version of Nash-Moser iteration\\nscheme, which is very much motivated by the seminar papers \\\\cite{Kl80, Kl82,\\nKl84} by Klainerman on the long time behavior to the evolution equations.\\n\",\n",
       " \"  Designing an efficient routing strategy is of great importance to alleviate\\ntraffic congestion in multilayer networks. In this work, we design an effective\\nrouting strategy for multilayer networks by comprehensively considering the\\nroles of nodes' local structures in micro-level, as well as the macro-level\\ndifferences in transmission speeds between different layers. Both numerical and\\nanalytical results indicate that our proposed routing strategy can reasonably\\nredistribute the traffic load of the low speed layer to the high speed layer,\\nand thus the traffic capacity of multilayer networks are significantly enhanced\\ncompared with the monolayer low speed networks. There is an optimal combination\\nof macro- and micro-level control parameters at which can remarkably alleviate\\nthe congestion and thus maximize the traffic capacity for a given multilayer\\nnetwork. Moreover, we find that increasing the size and the average degree of\\nthe high speed layer can enhance the traffic capacity of multilayer networks\\nmore effectively. We finally verify that real-world network topology does not\\ninvalidate the results. The theoretical predictions agree well with the\\nnumerical simulations.\\n\",\n",
       " '  A variety of copper tellurium oxide minerals are known, and many of them\\nexhibit either unusual forms of magnetism, or potentially novel spin liquid\\nbehavior. Here, I review a number of the more interesting materials with a\\nfocus on their crystalline symmetry and, if known, the nature of their\\nmagnetism. Many of these exist (so far) in mineral form only, and most have yet\\nto have their magnetic properties studied. This means a largely unexplored\\nspace of materials awaits our exploration.\\n',\n",
       " '  The determinant method in the conformal bootstrap is applied for the critical\\nphenomena of a single polymer in arbitrary $D$ dimensions. The scale dimensions\\n(critical exponents) of the polymer ($2< D \\\\le 4$) and the branched polymer ($3\\n< D \\\\le 8$) are obtained from the small determinants. It is known that the\\ndimensional reduction of the branched polymer in $D$ dimensions to Yang-Lee\\nedge singularity in $D$-$2$ dimensions holds exactly. We examine this\\nequivalence by the small determinant method.\\n',\n",
       " '  The Generalized Burnside Theorem, due to Laudal, generalizes the classical\\nBurnside Theorem and is obtained using noncommutative deformations of the\\nfamily of simple right $A$-modules when $A$ is a finite dimensional associative\\nalgebra over an algebraically closed field. In this paper, we prove a form of\\nthe Generalized Burnside Theorem that is more general, where we do not assume\\nthat $k$ is algebraically closed. The main purpose of the paper is to clarify\\nand generalize the proof. As an application of the theorem, we introduce a\\nstandard form for finite dimensional algebras.\\n',\n",
       " '  Short- to mid-term magnetic phenomena on the stellar surface of M-type stars\\ncannot only resemble the effects of planets in radial velocity data, but also\\nmay hide them. We analyze 145 spectroscopic HARPS-N observations of GJ 3942\\ntaken over the past five years and additional photometry to disentangle stellar\\nactivity effects from genuine Doppler signals as a result of the orbital motion\\nof the star around the common barycenter with its planet. To achieve this, we\\nuse the common methods of pre-whitening, and treat the correlated red noise by\\na first-order moving average term and by Gaussian-process regression following\\nan MCMC analysis. We identify the rotational period of the star at 16.3 days\\nand discover a new super-Earth, GJ 3942 b, with an orbital period of 6.9 days\\nand a minimum mass of 7.1 Me. An additional signal in the periodogram of the\\nresiduals is present but we cannot claim it to be related to a second planet\\nwith sufficient significance at this point. If confirmed, such planet candidate\\nwould have a minimum mass of 6.3 Me and a period of 10.4 days, which might\\nindicate a 3:2 mean-motion resonance with the inner planet.\\n',\n",
       " '  We consider the polyhedral properties of two spanning tree problems with\\nadditional constraints. In the first problem, it is required to find a tree\\nwith a minimum sum of edge weights among all spanning trees with the number of\\nleaves less or equal a given value. In the second problem, an additional\\nconstraint is the assumption that the degree of all vertices of the spanning\\ntree does not exceed a given value. The decision versions of both problems are\\nNP-complete.\\nWe consider the polytopes of these problems and their 1-skeletons. We prove\\nthat in both cases it is a NP-complete problem to determine whether the\\nvertices of 1-skeleton are adjacent. Although it is possible to obtain a\\nsuperpolynomial lower bounds on the clique numbers of these graphs. These\\nvalues characterize the time complexity in a broad class of algorithms based on\\nlinear comparisons. The results indicate a fundamental difference in\\ncombinatorial and geometric properties between the considered problems and the\\nclassical minimum spanning tree problem.\\n',\n",
       " '  With the need for flexible and on-demand decision support, Dynamic Data\\nWarehouses (DDW) provide benefits over traditional data warehouses due to their\\ndynamic characteristics in structuring and access mechanism. A DDW is a data\\nframework that accommodates data source changes easily to allow seamless\\nquerying to users. Materialized Views (MV) are proven to be an effective\\nmethodology to enhance the process of retrieving data from a DDW as results are\\npre-computed and stored in it. However, due to the static nature of\\nmaterialized views, the level of dynamicity that can be provided at the MV\\naccess layer is restricted. As a result, the collection of materialized views\\nis not compatible with ever-changing reporting requirements. It is important\\nthat the MV collection is consistent with current and upcoming queries. The\\nsolution to the above problem must consider the following aspects: (a) MV must\\nbe matched against an OLAP query in order to recognize whether the MV can\\nanswer the query, (b) enable scalability in the MV collection, an intuitive\\nmechanism to prune it and retrieve closely matching MVs must be incorporated,\\n(c) MV collection must be able to evolve in correspondence to the regularly\\nchanging user query patterns. Therefore, the primary objective of this paper is\\nto explore these aspects and provide a well-rounded solution for the MV access\\nlayer to remove the mismatch between the MV collection and reporting\\nrequirements. Our contribution to solve the problem includes a Query Matching\\nTechnique, a Domain Matching Technique and Maintenance of the MV collection. We\\ndeveloped an experimental platform using real data-sets to evaluate the\\neffectiveness in terms of performance and precision of the proposed techniques.\\n',\n",
       " \"  An information owner, possessing diverse data sources, might want to offer\\ninformation services based on these sources to cooperation partners and to this\\nend interact with these partners by receiving and sending messages, which the\\nowner on his part generates by program execution. Independently from data\\nrepresentation or its physical storage, information release to a partner might\\nbe restricted by the owner's confidentiality policy on an integrated, unified\\nview of the sources. Such a policy should even be enforced if the partner as an\\nintelligent and only semi-honest attacker attempts to infer hidden information\\nfrom message data, also employing background knowledge. For this problem of\\ninference control, we present a framework for a unified, holistic control of\\ninformation flow induced by program-based processing of the data sources to\\nmessages sent to a cooperation partner. Our framework expands on and combines\\nestablished concepts for confidentiality enforcement and its verification and\\nis instantiated in a Java environment. More specifically, as a hybrid control\\nwe combine gradual release of information via declassification, enforced by\\nstatic program analysis using a security type system, with a dynamic monitoring\\napproach. The dynamic monitoring employs flow tracking for generalizing values\\nto be declassified under confidentiality policy compliance.\\n\",\n",
       " '  We study the average stack cost of Buechi pushdown automata (Buechi PDA). We\\nassociate a non-negative price with each stack symbol and define the cost of a\\nstack as the sum of costs of all its elements. We introduce and study the\\naverage stack cost problem (ASC), which asks whether there exists an accepting\\nrun of a given Buechi PDA such that the long-run average of stack costs is\\nbelow some given threshold. The ASC problem generalizes mean-payoff objective\\nand can be used to express quantitative properties of pushdown systems. In\\nparticular, we can compute the average response time using the ASC problem. We\\nshow that the ASC problem can be solved in polynomial time.\\n',\n",
       " '  Let $\\\\mathfrak{a}$ be an ideal of a commutative noetherian (not necessarily\\nlocal) ring $R$. In the case $\\\\cd(\\\\mathfrak{a},R)\\\\leq 1$, we show that the\\nsubcategory of $\\\\mathfrak{a}$-cofinite $R$-modules is abelian. Using this and\\nthe technique of way-out functors, we show that if $\\\\cd(\\\\mathfrak{a},R)\\\\leq 1$,\\nor $\\\\dim(R/\\\\mathfrak{a}) \\\\leq 1$, or $\\\\dim(R) \\\\leq 2$, then the local\\ncohomology module $H^{i}_{\\\\mathfrak{a}}(X)$ is $\\\\mathfrak{a}$-cofinite for\\nevery $R$-complex $X$ with finitely generated homology modules and every $i \\\\in\\n\\\\mathbb{Z}$. We further answer Question 1.3 in the three aforementioned cases,\\nand reveal a correlation between Questions 1.1, 1.2, and 1.3.\\n',\n",
       " '  We describe an ongoing project in learning to perform primitive actions from\\ndemonstrations using an interactive interface. In our previous work, we have\\nused demonstrations captured from humans performing actions as training samples\\nfor a neural network-based trajectory model of actions to be performed by a\\ncomputational agent in novel setups. We found that our original framework had\\nsome limitations that we hope to overcome by incorporating communication\\nbetween the human and the computational agent, using the interaction between\\nthem to fine-tune the model learned by the machine. We propose a framework that\\nuses multimodal human-computer interaction to teach action concepts to\\nmachines, making use of both live demonstration and communication through\\nnatural language, as two distinct teaching modalities, while requiring few\\ntraining samples.\\n',\n",
       " '  Symmetry is closely intertwined with the function, genetics, and chemical\\nproperties of multiprotein complexes. Here, we explore the relation between\\nstructural symmetry and the ability of membrane proteins to sense and induce\\nmembrane curvature, which is a key factor for modulating the shape and\\norganization of cell membranes. Using coarse-grained simulations and elasticity\\ntheory, we show that the potential for direction-dependent membrane curvature\\nsensing is limited to asymmetric proteins, dimers, and tetramers, and argue\\nthat one should expect this anisotropy to be strongest for dimers. Odd and\\nhigher-order symmetries strongly suppress directional curvature sensing. This\\nclassification gives a new perspective on the structure-function relation for\\nmembrane proteins, and simplifies the task of translating between molecular\\nsensing mechanisms and their large-scale cellular consequences.\\n',\n",
       " '  We would like to learn a representation of the data which decomposes an\\nobservation into factors of variation which we can independently control.\\nSpecifically, we want to use minimal supervision to learn a latent\\nrepresentation that reflects the semantics behind a specific grouping of the\\ndata, where within a group the samples share a common factor of variation. For\\nexample, consider a collection of face images grouped by identity. We wish to\\nanchor the semantics of the grouping into a relevant and disentangled\\nrepresentation that we can easily exploit. However, existing deep probabilistic\\nmodels often assume that the observations are independent and identically\\ndistributed. We present the Multi-Level Variational Autoencoder (ML-VAE), a new\\ndeep probabilistic model for learning a disentangled representation of a set of\\ngrouped observations. The ML-VAE separates the latent representation into\\nsemantically meaningful parts by working both at the group level and the\\nobservation level, while retaining efficient test-time inference. Quantitative\\nand qualitative evaluations show that the ML-VAE model (i) learns a\\nsemantically meaningful disentanglement of grouped data, (ii) enables\\nmanipulation of the latent representation, and (iii) generalises to unseen\\ngroups.\\n',\n",
       " '  We show that there are an irrational rotation $Tx=x+\\\\alpha$ on the circle\\n$\\\\mathbb{T}$ and a continuous $\\\\varphi\\\\colon\\\\mathbb{T}\\\\to\\\\mathbb{R}$ such that\\nfor each (continuous) uniquely ergodic flow\\n$\\\\mathcal{S}=(S_t)_{t\\\\in\\\\mathbb{R}}$ acting on a compact metric space $Y$, the\\nautomorphism $T_{\\\\varphi,\\\\mathcal{S}}$ acting on $(X\\\\times Y,\\\\mu\\\\otimes\\\\nu)$ by\\nthe formula $T_{\\\\varphi,\\\\mathcal{S}}(x,y)=(Tx,S_{\\\\varphi(x)}(y))$, where $\\\\mu$\\nstands for Lebesgue measure on $\\\\mathbb{T}$ and $\\\\nu$ denotes the unique\\n$\\\\mathcal{S}$-invariant measure, has the property of asymptotically orthogonal\\npowers. This gives a class of relatively weakly mixing extensions of irrational\\nrotations for which Sarnak\\'s conjecture on Möbius disjointness holds for all\\nuniquely ergodic models of $T_{\\\\varphi,\\\\mathcal{S}}$. Moreover, we obtain a\\nclass of \"random\" ergodic sequences $(c_n)\\\\subset\\\\mathbb{Z}$ such that if\\n$\\\\boldsymbol{\\\\mu}$ denotes the Möbius function, then $$\\n\\\\lim_{N\\\\to\\\\infty}\\\\frac1N\\\\sum_{n\\\\leq N}g(S_{c_n}y)\\\\boldsymbol{\\\\mu}(n)=0 $$ for\\nall (continuous) uniquely ergodic flows $\\\\mathcal{S}$, all $g\\\\in C(Y)$ and\\n$y\\\\in Y$.\\n',\n",
       " '  With the advent of the Internet, large amount of digital text is generated\\neveryday in the form of news articles, research publications, blogs, question\\nanswering forums and social media. It is important to develop techniques for\\nextracting information automatically from these documents, as lot of important\\ninformation is hidden within them. This extracted information can be used to\\nimprove access and management of knowledge hidden in large text corpora.\\nSeveral applications such as Question Answering, Information Retrieval would\\nbenefit from this information. Entities like persons and organizations, form\\nthe most basic unit of the information. Occurrences of entities in a sentence\\nare often linked through well-defined relations; e.g., occurrences of person\\nand organization in a sentence may be linked through relations such as employed\\nat. The task of Relation Extraction (RE) is to identify such relations\\nautomatically. In this paper, we survey several important supervised,\\nsemi-supervised and unsupervised RE techniques. We also cover the paradigms of\\nOpen Information Extraction (OIE) and Distant Supervision. Finally, we describe\\nsome of the recent trends in the RE techniques and possible future research\\ndirections. This survey would be useful for three kinds of readers - i)\\nNewcomers in the field who want to quickly learn about RE; ii) Researchers who\\nwant to know how the various RE techniques evolved over time and what are\\npossible future research directions and iii) Practitioners who just need to\\nknow which RE technique works best in various settings.\\n',\n",
       " '  In this paper, by using a characterization of functions having fractional\\nderivative, we propose a rigorous fractional Lyapunov function candidate method\\nto analyze stability of fractional-order nonlinear systems. First, we prove an\\ninequality concerning the fractional derivatives of convex Lyapunov functions\\nwithout the assumption on the existence of derivative of pseudo-states. Second,\\nwe establish fractional Lyapunov functions to fractional-order systems without\\nthe assumption on the global existence of solutions. Our theorems fill the gaps\\nand strengthen results in some existing papers.\\n',\n",
       " '  By using first-principles electronic structure calculations, we predict that\\nthe extreme magnetoresistance (XMR) material LaSb takes a topological phase\\ntransition without breaking any symmetry under a hydrostatic pressure applied\\nbetween 3 and 4 GPa, meanwhile the electron-hole compensation remains in its\\nelectronic band structure. Thus LaSb provides an ideal platform for studying\\nthe individual role of topological property playing in the XMR phenomenon, in\\naddition to the electron-hole compensation. This has general implication to the\\nrelationship of XMR effect and topological property in topological materials.\\n',\n",
       " '  In recent times, many of the breakthroughs in various vision-related tasks\\nhave revolved around improving learning of deep models; these methods have\\nranged from network architectural improvements such as Residual Networks, to\\nvarious forms of regularisation such as Batch Normalisation. In essence, many\\nof these techniques revolve around better conditioning, allowing for deeper and\\ndeeper models to be successfully learned. In this paper, we look towards better\\nconditioning Generative Adversarial Networks (GANs) in an unsupervised learning\\nsetting. Our method embeds the powerful discriminating capabilities of a\\ndecision forest into the discriminator of a GAN. This results in a better\\nconditioned model which learns in an extremely stable way. We demonstrate\\nempirical results which show both clear qualitative and quantitative evidence\\nof the effectiveness of our approach, gaining significant performance\\nimprovements over several popular GAN-based approaches on the Oxford Flowers\\nand Aligned Celebrity Faces datasets.\\n',\n",
       " '  We consider goodness-of-fit tests with i.i.d. samples generated from a\\ncategorical distribution $(p_1,...,p_k)$. For a given $(q_1,...,q_k)$, we test\\nthe null hypothesis whether $p_j=q_{\\\\pi(j)}$ for some label permutation $\\\\pi$.\\nThe uncertainty of label permutation implies that the null hypothesis is\\ncomposite instead of being singular. In this paper, we construct a testing\\nprocedure using statistics that are defined as indefinite integrals of some\\nsymmetric polynomials. This method is aimed directly at the invariance of the\\nproblem, and avoids the need of matching the unknown labels. The asymptotic\\ndistribution of the testing statistic is shown to be chi-squared, and its power\\nis proved to be nearly optimal under a local alternative hypothesis. Various\\ndegenerate structures of the null hypothesis are carefully analyzed in the\\npaper. A two-sample version of the test is also studied.\\n',\n",
       " '  Optimization problems pervade essentially every scientific discipline and\\nindustry. Many such problems require finding a solution that maximizes the\\nnumber of constraints satisfied. Often, these problems are particularly\\ndifficult to solve because they belong to the NP-hard class, namely algorithms\\nthat always find a solution in polynomial time are not known. Over the past\\ndecades, research has focused on developing heuristic approaches that attempt\\nto find an approximation to the solution. However, despite numerous research\\nefforts, in many cases even approximations to the optimal solution are hard to\\nfind, as the computational time for further refining a candidate solution grows\\nexponentially with input size. Here, we show a non-combinatorial approach to\\nhard optimization problems that achieves an exponential speed-up and finds\\nbetter approximations than the current state-of-the-art. First, we map the\\noptimization problem into a boolean circuit made of specially designed,\\nself-organizing logic gates, which can be built with (non-quantum) electronic\\ncomponents; the equilibrium points of the circuit represent the approximation\\nto the problem at hand. Then, we solve its associated non-linear ordinary\\ndifferential equations numerically, towards the equilibrium points. We\\ndemonstrate this exponential gain by comparing a sequential MatLab\\nimplementation of our solver with the winners of the 2016 Max-SAT competition\\non a variety of hard optimization instances. We show empirical evidence that\\nour solver scales linearly with the size of the problem, both in time and\\nmemory, and argue that this property derives from the collective behavior of\\nthe simulated physical circuit. Our approach can be applied to other types of\\noptimization problems and the results presented here have far-reaching\\nconsequences in many fields.\\n',\n",
       " '  Most of the traditional convolutional neural networks (CNNs) implements\\nbottom-up approach (feed-forward) for image classifications. However, many\\nscientific studies demonstrate that visual perception in primates rely on both\\nbottom-up and top-down connections. Therefore, in this work, we propose a CNN\\nnetwork with feedback structure for Solar power plant detection on\\nmiddle-resolution satellite images. To express the strength of the top-down\\nconnections, we introduce feedback CNN network (FB-Net) to a baseline CNN model\\nused for solar power plant classification on multi-spectral satellite data.\\nMoreover, we introduce a method to improve class activation mapping (CAM) to\\nour FB-Net, which takes advantage of multi-channel pulse coupled neural network\\n(m-PCNN) for weakly-supervised localization of the solar power plants from the\\nfeatures of proposed FB-Net. For the proposed FB-Net CAM with m-PCNN,\\nexperimental results demonstrated promising results on both solar-power plant\\nimage classification and detection task.\\n',\n",
       " '  Explicit signaling between threads is a perennial cause of bugs in concurrent\\nprograms. While there are several run-time techniques to automatically notify\\nthreads upon the availability of some shared resource, such techniques are not\\nwidely-adopted due to their run-time overhead. This paper proposes a new\\nsolution based on static analysis for automatically generating a performant\\nexplicit-signal program from its corresponding implicit-signal implementation.\\nThe key idea is to generate verification conditions that allow us to minimize\\nthe number of required signals and unnecessary context switches, while\\nguaranteeing semantic equivalence between the source and target programs. We\\nhave implemented our method in a tool called Expresso and evaluate it on\\nchallenging benchmarks from prior papers and open-source software.\\nExpresso-generated code significantly outperforms past automatic signaling\\nmechanisms (avg. 1.56x speedup) and closely matches the performance of\\nhand-optimized explicit-signal code.\\n',\n",
       " '  In this paper we express the linearized dynamics of interacting interfacial\\nwaves in stratified shear flows in the compact form of action-angle Hamilton\\nequations. The pseudo-energy serves as the Hamiltonian of the system, the\\naction coordinates are the contribution of the interfacial waves to the\\nwave-action, and the angles are their phases. The term \"generalized\\naction-angle\" aims to emphasize that the action of each wave is generally time\\ndependent and this allows instability. An attempt is made to relate this\\nformalism to the action at a distance resonance instability mechanism between\\ncounter-propagating vorticity waves via the global conservations of\\npseudo-energy and pseudo-momentum.\\n',\n",
       " '  We use polarization-resolved electronic Raman spectroscopy to study charge\\ndynamics in non-magnetic FeSe$_{1-x}$S$_x$ superconductor. We observe two\\nfeatures of the $XY$ quadrupole symmetry: a low-energy quasi-elastic peak (QEP)\\nand an electronic continuum. The QEP exhibits critical enhancement upon cooling\\ntowards the structural transition at $T_S(x)$. Below $T_S(x)$, the QEP\\ndiminishes gradually, and a gap with temperature evolution reminiscent of a\\nmean-field order parameter opens in the continuum. The intensity of the QEP\\ndevelops with increasing sulfur doping $x$ and maximizes at $x\\\\approx$ 0.15,\\nwhile the gap magnitude decreases with the suppression of $T_S(x)$. We\\ninterpret the development of the gap in the quadrupole scattering channel as\\nthe formation of a stripe quadrupole order: a wave of quadrupole moment without\\ncharge or spin modulation.\\n',\n",
       " '  We give a non-technical introduction to convergence-divergence models, a new\\nmodeling approach for phylogenetic data that allows for the usual divergence of\\nspecies post speciation but also allows for species to converge, i.e. become\\nmore similar over time. By examining the $3$-taxon case in some detail we\\nillustrate that phylogeneticists have been \"spoiled\" in the sense of not having\\nto think about the structural parameters in their models by virtue of the\\nstrong assumption that evolution is treelike. We show that there are not always\\ngood statistical reasons to prefer the usual class of treelike models over more\\ngeneral convergence-divergence models. Specifically we show many $3$-taxon\\ndatasets can be equally well explained by supposing violation of the molecular\\nclock due to change in the rate of evolution along different edges, or by\\nkeeping the assumption of a constant rate of evolution but instead assuming\\nthat evolution is not a purely divergent process. Given the abundance of\\nevidence that evolution is not strictly treelike, our discussion is an\\nillustration that as phylogeneticists we often need to think clearly about the\\nstructural form of the models we use.\\n',\n",
       " '  Asymptotics of quantum $6j$ symbols corresponding to a hyperbolic tetrahedra\\nis investigated and the first two leading terms are determined for the case\\nthat the tetrahedron has a ideal or ultra-ideal vertex. These terms are given\\nby the volume and the determinant of the Gram matrix of the tetrahedron. A\\nrelation to the volume conjecture of the Turaev-Viro invariant is also\\ndiscussed.\\n',\n",
       " '  Parameters in deep neural networks which are trained on large-scale databases\\ncan generalize across multiple domains, which is referred as \"transferability\".\\nUnfortunately, the transferability is usually defined as discrete states and it\\ndiffers with domains and network architectures. Existing works usually\\nheuristically apply parameter-sharing or fine-tuning, and there is no\\nprincipled approach to learn a parameter transfer strategy. To address the gap,\\na parameter transfer unit (PTU) is proposed in this paper. The PTU learns a\\nfine-grained nonlinear combination of activations from both the source and the\\ntarget domain networks, and subsumes hand-crafted discrete transfer states. In\\nthe PTU, the transferability is controlled by two gates which are artificial\\nneurons and can be learned from data. The PTU is a general and flexible module\\nwhich can be used in both CNNs and RNNs. Experiments are conducted with various\\nnetwork architectures and multiple transfer domain pairs. Results demonstrate\\nthe effectiveness of the PTU as it outperforms heuristic parameter-sharing and\\nfine-tuning in most settings.\\n',\n",
       " '  Network Function Virtualization (NFV) has the potential to significantly\\nreduce the capital and operating expenses, shorten product release cycle, and\\nimprove service agility. In this paper, we focus on minimizing the total number\\nof Virtual Network Function (VNF) instances to provide a specific service\\n(possibly at different locations) to all the flows in a network. Certain\\nnetwork security and analytics applications may allow fractional processing of\\na flow at different nodes (corresponding to datacenters), giving an opportunity\\nfor greater optimization of resources. Through a reduction from the set cover\\nproblem, we show that this problem is NP-hard and cannot even be approximated\\nwithin a factor of (1 - o(1)) ln(m) (where m is the number of flows) unless\\nP=NP. Then, we design two simple greedy algorithms and prove that they achieve\\nan approximation ratio of (1 - o(1)) ln(m) + 2, which is asymptotically\\noptimal. For special cases where each node hosts multiple VNF instances (which\\nis typically true in practice), we also show that our greedy algorithms have a\\nconstant approximation ratio. Further, for tree topologies we develop an\\noptimal greedy algorithm by exploiting the inherent topological structure.\\nFinally, we conduct extensive numerical experiments to evaluate the performance\\nof our proposed algorithms in various scenarios.\\n',\n",
       " '  We prove a version of the classical Mittag-Leffler Theorem for regular\\nfunctions over quaternions. Our result relies upon an appropriate notion of\\nprincipal part, that is inspired by the recent definition of spherical\\nanalyticity.\\n',\n",
       " '  A number of micro-scale biological flows are characterized by spatio-temporal\\nchaos. These include dense suspensions of swimming bacteria, microtubule\\nbundles driven by motor proteins, and dividing and migrating confluent layers\\nof cells. A characteristic common to all of these systems is that they are\\nladen with active matter, which transforms free energy in the fluid into\\nkinetic energy. Because of collective effects, the active matter induces\\nmulti-scale flow motions that bear strong visual resemblance to turbulence. In\\nthis study, multi-scale statistical tools are employed to analyze direct\\nnumerical simulations (DNS) of periodic two- (2D) and three-dimensional (3D)\\nactive flows and compare them to classic turbulent flows. Statistical\\ndescriptions of the flows and their variations with activity levels are\\nprovided in physical and spectral spaces. A scale-dependent intermittency\\nanalysis is performed using wavelets. The results demonstrate fundamental\\ndifferences between active and high-Reynolds number turbulence; for instance,\\nthe intermittency is smaller and less energetic in active flows, and the work\\nof the active stress is spectrally exerted near the integral scales and\\ndissipated mostly locally by viscosity, with convection playing a minor role in\\nmomentum transport across scales.\\n',\n",
       " '  We give a negative answer to the Newman--Shapiro problem on weighted\\napproximation for entire functions formulated in 1966 and motivated by the\\ntheory of operators on the Fock space. There exists a function in the Fock\\nspace such that its exponential multiples do not approximate some entire\\nmultiples in the space. Furthermore, we establish several positive results\\nunder different restrictions on the function in question.\\n',\n",
       " '  This work is dedicated to eliminating the overhead of guaranteeing the\\nstorage order in modern IO stack. The existing block device adopts\\nprohibitively expensive resort in ensuring the storage order among write\\nrequests: interleaving successive write requests with transfer and flush.\\nExploiting the cache barrier command for the Flash storage, we overhaul the IO\\nscheduler, the dispatch module and the filesystem so that these layers are\\norchestrated to preserve the ordering condition imposed by the application can\\nbe delivered to the storage. Key ingredients of Barrier Enabled IO stack are\\nEpoch based IO scheduling, Order Preserving Dispatch, and Dual Mode Journaling.\\nBarrier enabled IO stack successfully eliminates the root cause of excessive\\noverhead in enforcing the storage order. Dual Mode Journaling in BarrierFS\\ndedicates the separate threads to effectively decouple the control plane and\\ndata plane of the journal commit. We implement Barrier Enabled IO Stack in\\nserver as well as in mobile platform. SQLite performance increases by 270% and\\n75%, in server and in smartphone, respectively. Relaxing the durability of a\\ntransaction, SQLite performance and MySQL performance increases as much as by\\n73X and by 43X, respectively, in server storage.\\n',\n",
       " '  Malicious crowdsourcing forums are gaining traction as sources of spreading\\nmisinformation online, but are limited by the costs of hiring and managing\\nhuman workers. In this paper, we identify a new class of attacks that leverage\\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\\nthe generation of fake online reviews for products and services. Not only are\\nthese attacks cheap and therefore more scalable, but they can control rate of\\ncontent output to eliminate the signature burstiness that makes crowdsourced\\ncampaigns easy to detect.\\nUsing Yelp reviews as an example platform, we show how a two phased review\\ngeneration and customization attack can produce reviews that are\\nindistinguishable by state-of-the-art statistical detectors. We conduct a\\nsurvey-based user study to show these reviews not only evade human detection,\\nbut also score high on \"usefulness\" metrics by users. Finally, we develop novel\\nautomated defenses against these attacks, by leveraging the lossy\\ntransformation introduced by the RNN training and generation cycle. We consider\\ncountermeasures against our mechanisms, show that they produce unattractive\\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\\nsimple constraints imposed by online service providers.\\n',\n",
       " \"  This note presents several results in graph theory inspired by the author's\\nwork in the proof theory of linear logic; these results are purely\\ncombinatorial and do not involve logic.\\nWe show that trails avoiding forbidden transitions and rainbow paths for\\ncomplete multipartite color classes can be found in linear time, whereas\\nfinding rainbow paths is NP-complete for any other restriction on color\\nclasses. For the tractable cases, we also state new structural properties\\nequivalent to Kotzig's theorem on bridges in unique perfect matchings.\\nWe also exhibit a connection between blossoms and bridge deletion orders in\\nunique perfect matchings.\\n\",\n",
       " '  We introduce a novel approach for dealing with eigenvalue problems of\\nSturm-Liouville operators generated by the differential expression\\n\\\\begin{equation*} Ly=\\\\frac{1}{r}\\\\left( -(p\\\\left[ y^{\\\\prime }+sy\\\\right]\\n)^{\\\\prime }+sp\\\\left[ y^{\\\\prime }+sy\\\\right] +qy\\\\right) \\\\end{equation*} which is\\nbased on norm resolvent convergence of classical Sturm-Liouville operators.\\nThis enables us to describe the continuous dependence of the $n$-th eigenvalue\\non the space of self-adjoint boundary conditions and the coefficients of the\\ndifferential equation after giving the inequalities among the eigenvalues.\\nMoreover, oscillation properties of the eigenfunctions are also characterized.\\nIn particular, our main results can be applied to solve a class of\\nSturm-Liouville problems with transmission conditions.\\n',\n",
       " '  Koopman operator is a composition operator defined for a dynamical system\\ndescribed by nonlinear differential or difference equation. Although the\\noriginal system is nonlinear and evolves on a finite-dimensional state space,\\nthe Koopman operator itself is linear but infinite-dimensional (evolves on a\\nfunction space). This linear operator captures the full information of the\\ndynamics described by the original nonlinear system. In particular, spectral\\nproperties of the Koopman operator play a crucial role in analyzing the\\noriginal system. In the first part of this paper, we review the so-called\\nKoopman operator theory for nonlinear dynamical systems, with emphasis on modal\\ndecomposition and computation that are direct to wide applications. Then, in\\nthe second part, we present a series of applications of the Koopman operator\\ntheory to power systems technology. The applications are established as\\ndata-centric methods, namely, how to use massive quantities of data obtained\\nnumerically and experimentally, through spectral analysis of the Koopman\\noperator: coherency identification of swings in coupled synchronous generators,\\nprecursor diagnostic of instabilities in the coupled swing dynamics, and\\nstability assessment of power systems without any use of mathematical models.\\nFuture problems of this research direction are identified in the last\\nconcluding part of this paper.\\n',\n",
       " '  Scientometric techniques have been remarkably successful at mapping science\\nbut they face important difficulties when mapping research for societal\\nproblems possibly because they they are derived only from scientific documents\\nand thus do not rely on non-academic expert knowledge. Here we aim to explore\\nhow ontologies can be used in science mapping, thus enriching current\\nalgorithmic techniques with systematic domain expert knowledge. This study\\nintroduces the methodology behind the construction of an ontology and tests\\npotential uses in science mapping. We use obesity as a topic of case study.\\n',\n",
       " '  Time-varying coverage, namely sweep coverage is a recent development in the\\narea of wireless sensor networks, where a small number of mobile sensors sweep\\nor monitor comparatively large number of locations periodically. In this\\narticle we study barrier sweep coverage with mobile sensors where the barrier\\nis considered as a finite length continuous curve on a plane. The coverage at\\nevery point on the curve is time-variant. We propose an optimal solution for\\nsweep coverage of a finite length continuous curve. Usually energy source of a\\nmobile sensor is battery with limited power, so energy restricted sweep\\ncoverage is a challenging problem for long running applications. We propose an\\nenergy restricted sweep coverage problem where every mobile sensors must visit\\nan energy source frequently to recharge or replace its battery. We propose a\\n$\\\\frac{13}{3}$-approximation algorithm for this problem. The proposed algorithm\\nfor multiple curves achieves the best possible approximation factor 2 for a\\nspecial case. We propose a 5-approximation algorithm for the general problem.\\nAs an application of the barrier sweep coverage problem for a set of line\\nsegments, we formulate a data gathering problem. In this problem a set of\\nmobile sensors is arbitrarily monitoring the line segments one for each. A set\\nof data mules periodically collects the monitoring data from the set of mobile\\nsensors. We prove that finding the minimum number of data mules to collect data\\nperiodically from every mobile sensor is NP-hard and propose a 3-approximation\\nalgorithm to solve it.\\n',\n",
       " '  In the setting of a Lie group of polynomial volume growth, we derive\\ninequalities of Caffarelli-Kohn-Nirenberg type, where the weights involved are\\npowers of the Carnot-Caratheodory distance associated with a fixed system of\\nvector fields which satisfy the Hörmander condition.\\nThe use of weak $L^p$ spaces is crucial in our proofs and we formulate these\\ninequalities within the framework of $L^{p,q}$ Lorentz spaces (a scale of\\n(quasi)-Banach spaces which extend the more classical $L^p$ Lebesgue spaces)\\nthereby obtaining a refinement of, for instance, Sobolev and Hardy-Sobolev\\ninequalities.\\n',\n",
       " \"  We consider 3+1 rotationally symmetric Lorentzian Einstein spacetime\\nmanifolds with $\\\\Lambda >0$ and reduce the equations to 2+1 Einstein equations\\ncoupled to `shifted' wave maps. Subsequently, we prove various (explicit)\\npositive mass-energy theorems. No smallness is assumed.\\n\",\n",
       " '  The increased availability of the multi-view data (data on the same samples\\nfrom multiple sources) has led to strong interest in models based on low-rank\\nmatrix factorizations. These models represent each data view via shared and\\nindividual components, and have been successfully applied for exploratory\\ndimension reduction, association analysis between the views, and further\\nlearning tasks such as consensus clustering. Despite these advances, there\\nremain significant challenges in modeling partially-shared components, and\\nidentifying the number of components of each type\\n(shared/partially-shared/individual). In this work, we formulate a novel linked\\ncomponent model that directly incorporates partially-shared structures. We call\\nthis model SLIDE for Structural Learning and Integrative DEcomposition of\\nmulti-view data. We prove the existence of SLIDE decomposition and explicitly\\ncharacterize the identifiability conditions. The proposed model fitting and\\nselection techniques allow for joint identification of the number of components\\nof each type, in contrast to existing sequential approaches. In our empirical\\nstudies, SLIDE demonstrates excellent performance in both signal estimation and\\ncomponent selection. We further illustrate the methodology on the breast cancer\\ndata from The Cancer Genome Atlas repository.\\n',\n",
       " \"  We model a nonlinear price curve quoted in a market as the utility\\nindifference curve of a representative liquidity supplier. As the utility\\nfunction we adopt a g-expectation. In contrast to the standard framework of\\nfinancial engineering, a trader is no more price taker as any trade has a\\npermanent market impact via an effect to the supplier's inventory. The P&L of a\\ntrading strategy is written as a nonlinear stochastic integral. Under this\\nmarket impact model, we introduce a completeness condition under which any\\nderivative can be perfectly replicated by a dynamic trading strategy. In the\\nspecial case of a Markovian setting the corresponding pricing and hedging can\\nbe done by solving a semi-linear PDE.\\n\",\n",
       " '  When balancing, a humanoid robot can be easily subjected to unexpected\\ndisturbances like external pushes. In these circumstances, reactive movements\\nas steps become a necessary requirement in order to avoid potentially harmful\\nfalling states. In this paper we conceive a Model Predictive Controller which\\ndetermines a desired set of contact wrenches by predicting the future evolution\\nof the robot, while taking into account constraints switching in case of steps.\\nThe control inputs computed by this strategy, namely the desired contact\\nwrenches, are directly obtained on the robot through a modification of the\\nmomentum-based whole-body torque controller currently implemented on iCub. The\\nproposed approach is validated through simulations in a stepping scenario,\\nrevealing high robustness and reliability when executing a recovery strategy.\\n',\n",
       " '  Computational propaganda deploys social or political bots to try to shape,\\nsteer and manipulate online public discussions and influence decisions.\\nCollective behaviour of populations of social bots has not been yet widely\\nstudied, though understanding of collective patterns arising from interactions\\nbetween bots would aid social bot detection. Here we show that there are\\nsignificant differences in collective behaviour between population of bots and\\npopulation of humans as detected from their Twitter activity. Using a large\\ndataset of tweets we have collected during the UK EU referendum campaign, we\\nseparated users into population of bots and population of humans based on the\\nlength of sequences of their high-frequency tweeting activity. We show that\\nwhile pairwise correlations between users are weak they co-exist with\\ncollective correlated states, however the statistics of correlations and\\nco-spiking probability differ in both populations. Our results demonstrate that\\npopulations of social bots and human users in social media exhibit collective\\nproperties similar to the ones found in social and biological systems placed\\nnear a critical point.\\n',\n",
       " '  In many distributed learning problems, the heterogeneous loading of computing\\nmachines may harm the overall performance of synchronous strategies. In this\\npaper, we propose an effective asynchronous distributed framework for the\\nminimization of a sum of smooth functions, where each machine performs\\niterations in parallel on its local function and updates a shared parameter\\nasynchronously. In this way, all machines can continuously work even though\\nthey do not have the latest version of the shared parameter. We prove the\\nconvergence of the consistency of this general distributed asynchronous method\\nfor gradient iterations then show its efficiency on the matrix factorization\\nproblem for recommender systems and on binary classification.\\n',\n",
       " '  The MAP-Elites algorithm produces a set of high-performing solutions that\\nvary according to features defined by the user. This technique has the\\npotential to be a powerful tool for design space exploration, but is limited by\\nthe need for numerous evaluations. The Surrogate-Assisted Illumination\\nalgorithm (SAIL), introduced here, integrates approximative models and\\nintelligent sampling of the objective function to minimize the number of\\nevaluations required by MAP-Elites.\\nThe ability of SAIL to efficiently produce both accurate models and diverse\\nhigh performing solutions is illustrated on a 2D airfoil design problem. The\\nsearch space is divided into bins, each holding a design with a different\\ncombination of features. In each bin SAIL produces a better performing solution\\nthan MAP-Elites, and requires several orders of magnitude fewer evaluations.\\nThe CMA-ES algorithm was used to produce an optimal design in each bin: with\\nthe same number of evaluations required by CMA-ES to find a near-optimal\\nsolution in a single bin, SAIL finds solutions of similar quality in every bin.\\n',\n",
       " '  We consider the problem of determining the asymptotic order of the Gelfand\\nnumbers of mixed-(quasi-)norm embeddings $\\\\ell^b_p(\\\\ell^d_q) \\\\hookrightarrow\\n\\\\ell^b_r(\\\\ell^d_u)$ given that $p \\\\leq r$ and $q \\\\leq u$, with emphasis on\\ncases with $p\\\\leq 1$ and/or $q\\\\leq 1$. These cases turn out to be related to\\nstructured sparsity. We obtain sharp bounds in a number of interesting\\nparameter constellations. Our new matching bounds for the Gelfand numbers of\\nthe embeddings of $\\\\ell_1^b(\\\\ell_2^d)$ and $\\\\ell_2^b(\\\\ell_1^d)$ into\\n$\\\\ell_2^b(\\\\ell_2^d)$ imply optimality assertions for the recovery of\\nblock-sparse and sparse-in-levels vectors, respectively. In addition, we apply\\nthe sharp estimates for $\\\\ell^b_p(\\\\ell^d_q)$-spaces to obtain new two-sided\\nestimates for the Gelfand numbers of multivariate Besov space embeddings in\\nregimes of small mixed smoothness. It turns out that in some particular cases\\nthese estimates show the same asymptotic behaviour as in the univariate\\nsituation. In the remaining cases they differ at most by a $\\\\log\\\\log$ factor\\nfrom the univariate bound.\\n',\n",
       " '  In this paper, we present a novel nonparametric motion flow model that\\neffectively describes a motion trajectory of a human and its application to\\nhuman robot cooperation. To this end, motion flow similarity measure which\\nconsiders both spatial and temporal properties of a trajectory is proposed by\\nutilizing the mean and variance functions of a Gaussian process. We also\\npresent a human robot cooperation method using the proposed motion flow model.\\nGiven a set of interacting trajectories of two workers, the underlying reward\\nfunction of cooperating behaviors is optimized by using the learned motion\\ndescription as an input to the reward function where a stochastic trajectory\\noptimization method is used to control a robot. The presented human robot\\ncooperation method is compared with the state-of-the-art algorithm, which\\nutilizes a mixture of interaction primitives (MIP), in terms of the RMS error\\nbetween generated and target trajectories. While the proposed method shows\\ncomparable performance with the MIP when the full observation of human\\ndemonstrations is given, it shows superior performance with respect to given\\npartial trajectory information.\\n',\n",
       " \"  Deep Learning is a consolidated, state-of-the-art Machine Learning tool to\\nfit a function when provided with large data sets of examples. However, in\\nregression tasks, the straightforward application of Deep Learning models\\nprovides a point estimate of the target. In addition, the model does not take\\ninto account the uncertainty of a prediction. This represents a great\\nlimitation for tasks where communicating an erroneous prediction carries a\\nrisk. In this paper we tackle a real-world problem of forecasting impending\\nfinancial expenses and incomings of customers, while displaying predictable\\nmonetary amounts on a mobile app. In this context, we investigate if we would\\nobtain an advantage by applying Deep Learning models with a Heteroscedastic\\nmodel of the variance of a network's output. Experimentally, we achieve a\\nhigher accuracy than non-trivial baselines. More importantly, we introduce a\\nmechanism to discard low-confidence predictions, which means that they will not\\nbe visible to users. This should help enhance the user experience of our\\nproduct.\\n\",\n",
       " '  Cable-in-Conduit Conductors (CICCs) are used in the fabrication of\\nsuperconducting fusion grade magnets. It acts as a narrow cryostat to provide\\ncryo-stability with direct contact of coolant fluid to conductor. The\\nsuperconducting magnets are cooled using forced flow (FF), supercritical helium\\nor two phase (TP) cooling through void space in the CICC. Thermo-hydraulics\\nusing supercritical helium single phase flow is well-known and established.\\nResearch topic of behavior of forced flow, two phase (TP) helium cooling in\\nCICC involves perceived risks of the CICC running into flow chocking and\\npossible thermo-acoustic oscillations leading to flow instabilities. This\\nresearch work involves study of forced flow two phase helium cooling in CICC\\nwound superconducting magnets. The TP flow provides cryo-stability by the\\nlatent heat of helium not by enthalpy as in case of CICC being cooled with\\nsupercritical helium. Study reveals some attractive regimes in the case of TP\\ncooling, at a given mass flow rate of single phase helium at the inlet and a\\nheat flux acting on the CICC. Analysis carried out predicts significant gains\\nwith TP cooling on a prototype CICC, which is circular in cross section and\\nappropriate for fusion devices for high magnetic field applications. These\\ngeneral formalisms may be extended to specific magnets wound with CICC. This\\npaper describes analysis of TP cooling of a CICC.\\n',\n",
       " '  Scenarios of execution are commonly used to specify partial behaviour and\\ninteractions between different objects and components in a system. To avoid\\noverall inconsistency in specifications, various automated methods have emerged\\nin the literature to compose (behavioural) models. In recent work, we have\\nshown how the theorem prover Isabelle can be combined with the constraint\\nsolver Z3 to efficiently detect inconsistencies in two or more behavioural\\nmodels and, in their absence, generate the composition. Here, we extend our\\napproach further and show how to generate the correct composition (as a set of\\nvalid traces) of dephased models. This work has been inspired by a problem from\\na medical domain where different care pathways (for chronic conditions) may be\\napplied to the same patient with different starting points.\\n',\n",
       " '  In this paper, we describe how the hypergeometric test can be used to\\ndetermine whether a given theme of interest occurs in a storyset at a frequency\\nmore than would be expected by chance. By a storyset we mean simply a list of\\nstories defined according to a common attribute (e.g., author, movement,\\nperiod). The test works roughly as follows: Given a background storyset and a\\nsub-storyset of interest, the test determines whether a given theme is\\nover-represented in the sub-storyset, based on comparing the proportions of\\nstories in the sub-storyset and background storyset featuring the theme. A\\nstoryset is said to be \"enriched\" for a theme with respect to a particular\\nbackground storyset, when the theme is identified as being significantly\\nover-represented by the test. Furthermore, we introduce here a toy dataset\\nconsisting of 280 manually themed Star Trek television franchise episodes. As a\\nproof of concept, we use the hypergeometric test to analyze the Star Trek\\nstories for enriched themes. The hypergeometric testing approach to theme\\nenrichment analysis is implemented for the Star Trek thematic dataset in the R\\npackage stoRy. A related R Shiny web application can be found at\\nthis https URL.\\n',\n",
       " '  We develop a simple routine unifying the analysis of several important\\nrecently-developed stochastic optimization methods including SAGA, Finito, and\\nstochastic dual coordinate ascent (SDCA). First, we show an intrinsic\\nconnection between stochastic optimization methods and dynamic jump systems,\\nand propose a general jump system model for stochastic optimization methods.\\nOur proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then\\nwe combine jump system theory with several simple quadratic inequalities to\\nderive sufficient conditions for convergence rate certifications of the\\nproposed jump system model under various assumptions (with or without\\nindividual convexity, etc). The derived conditions are linear matrix\\ninequalities (LMIs) whose sizes roughly scale with the size of the training\\nset. We make use of the symmetry in the stochastic optimization methods and\\nreduce these LMIs to some equivalent small LMIs whose sizes are at most 3 by 3.\\nWe solve these small LMIs to provide analytical proofs of new convergence rates\\nfor SAGA, Finito and SDCA (with or without individual convexity). We also\\nexplain why our proposed LMI fails in analyzing SAG. We reveal a key difference\\nbetween SAG and other methods, and briefly discuss how to extend our LMI\\nanalysis for SAG. An advantage of our approach is that the proposed analysis\\ncan be automated for a large class of stochastic methods under various\\nassumptions (with or without individual convexity, etc).\\n',\n",
       " '  Network structure can have significant effects on the propagation of\\ndiseases, memes, and information on social networks. Such effects depend on the\\nspecific type of dynamical process that affects the nodes and edges of a\\nnetwork, and it is important to develop tractable models of spreading processes\\non networks to explore how network structure affects dynamics. In this paper,\\nwe incorporate the idea of \\\\emph{synergy} into a two-state (\"active\" or\\n\"passive\") threshold model of social influence on networks. Our model\\'s update\\nrule is deterministic, and the influence of each meme-carrying (i.e., active)\\nneighbor can --- depending on a parameter --- either be enhanced or inhibited\\nby an amount that depends on the number of active neighbors of a node. Such a\\nsynergistic system models social behavior in which the willingness to adopt\\neither accelerates or saturates depending on the number of neighbors who have\\nadopted that behavior. We illustrate that the synergy parameter in our model\\nhas a crucial effect on system dynamics, as it determines whether degree-$k$\\nnodes are possible or impossible to activate. We simulate synergistic meme\\nspreading on both random-graph models and networks constructed from empirical\\ndata. Using a local-tree approximation, we examine the spreading of synergistic\\nmemes and find good agreement on all but one of the networks on which we\\nsimulate spreading. We find for any network and for a broad family of\\nsynergistic models that one can predict which synergy-parameter values allow\\ndegree-$k$ nodes to be activated.\\n',\n",
       " '  Detection of atrial fibrillation (AF), a type of cardiac arrhythmia, is\\ndifficult since many cases of AF are usually clinically silent and undiagnosed.\\nIn particular paroxysmal AF is a form of AF that occurs occasionally, and has a\\nhigher probability of being undetected. In this work, we present an attention\\nbased deep learning framework for detection of paroxysmal AF episodes from a\\nsequence of windows. Time-frequency representation of 30 seconds recording\\nwindows, over a 10 minute data segment, are fed sequentially into a deep\\nconvolutional neural network for image-based feature extraction, which are then\\npresented to a bidirectional recurrent neural network with an attention layer\\nfor AF detection. To demonstrate the effectiveness of the proposed framework\\nfor transient AF detection, we use a database of 24 hour Holter\\nElectrocardiogram (ECG) recordings acquired from 2850 patients at the\\nUniversity of Virginia heart station. The algorithm achieves an AUC of 0.94 on\\nthe testing set, which exceeds the performance of baseline models. We also\\ndemonstrate the cross-domain generalizablity of the approach by adapting the\\nlearned model parameters from one recording modality (ECG) to another\\n(photoplethysmogram) with improved AF detection performance. The proposed high\\naccuracy, low false alarm algorithm for detecting paroxysmal AF has potential\\napplications in long-term monitoring using wearable sensors.\\n',\n",
       " '  Confinement at the helical edge of a topological insulator is possible in the\\npresence of proximity-induced magnetic (F) or superconducting (S) order. The\\ninterplay of both phenomena leads to the formation of localized Majorana bound\\nstates (MBS) or likewise (under certain resonance conditions) the formation of\\nordinary Andreev bound states (ABS). We investigate the properties of bound\\nstates in junctions composed of alternating regions of F or S barriers.\\nInterestingly, the direction of magnetization in F regions and the relative\\nsuperconducting phase between S regions can be exploited to hybridize MBS or\\nABS at will. We show that the local properties of MBS translate into a\\nparticular nonlocal superconducting pairing amplitude. Remarkably, the symmetry\\nof the pairing amplitude contains information about the nature of the bound\\nstate that it stems from. Hence, this symmetry can in principle be used to\\ndistinguish MBS from ABS, owing to the strong connection between local density\\nof states and nonlocal pairing in our setup.\\n',\n",
       " '  Statistical agencies utilize models to synthesize respondent-level data for\\nrelease to the general public as an alternative to the actual data records. A\\nBayesian model synthesizer encodes privacy protection by employing a\\nhierarchical prior construction that induces smoothing of the real data\\ndistribution. Synthetic respondent-level data records are often preferred to\\nsummary data tables due to the many possible uses by researchers and data\\nanalysts. Agencies balance a trade-off between utility of the synthetic data\\nversus disclosure risks and hold a specific target threshold for disclosure\\nrisk before releasing synthetic datasets. We introduce a pseudo posterior\\nlikelihood that exponentiates each contribution by an observation\\nrecord-indexed weight in (0, 1), defined to be inversely proportional to the\\ndisclosure risk for that record in the synthetic data. Our use of a vector of\\nweights allows more precise downweighting of high risk records in a fashion\\nthat better preserves utility as compared with using a scalar weight. We\\nillustrate our method with a simulation study and an application to the\\nConsumer Expenditure Survey of the U.S. Bureau of Labor Statistics. We\\ndemonstrate how the frequentist consistency and uncertainty quantification are\\naffected by the inverse risk-weighting.\\n',\n",
       " '  We perform the calculation of the dc resistivity as a function of temperature\\nof the \"strange-metal\" state that emerges in the vicinity of a\\nspin-density-wave phase transition in the presence of weak disorder. This\\nscenario is relevant to the phenomenology of many important correlated\\nmaterials, such as, e.g., the pnictides, the heavy-fermion compounds and the\\ncuprates. To accomplish this task, we implement the memory-matrix approach that\\nallows the calculation of the transport coefficients of the model beyond the\\nquasiparticle paradigm. Our computation is also inspired by the $\\\\epsilon=3-d$\\nexpansion in a hot-spot model embedded in $d$-space dimensions recently put\\nforth by Sur and Lee [Phys. Rev. B 91, 125136 (2015)], in which they find a new\\nlow-energy non-Fermi liquid fixed point that is perturbatively accessible near\\nthree dimensions. As a consequence, we are able to establish here the\\ntemperature and doping dependence of the electrical resistivity at intermediate\\ntemperatures of a two-dimensional disordered antiferromagnetic metallic model\\nwith a composite operator that couples the order-parameter fluctuations to the\\nentire Fermi surface. We argue that our present theory provides a good basis in\\norder to unify the experimental transport data, e.g., in the cuprates and the\\npnictide superconductors, within a wide range of doping regimes.\\n',\n",
       " '  We introduce a method to evaluate the relative populations of different\\nconformers of molecular species in solution, aiming at quantum mechanical\\naccuracy, while keeping the computational cost at a nearly molecular-mechanics\\nlevel. This goal is achieved by combining long classical molecular-dynamics\\nsimulations to sample the free-energy landscape of the system, advanced\\nclustering techniques to identify the most relevant conformers, and\\nthermodynamic perturbation theory to correct the resulting populations, using\\nquantum-mechanical energies from density-functional theory. A quantitative\\ncriterion for assessing the accuracy thus achieved is proposed. The resulting\\nmethodology is demonstrated in the specific case of cyanin\\n(cyanidin-3-glucoside) in water solution.\\n',\n",
       " '  RNNs and their variants have been widely adopted for image captioning. In\\nRNNs, the production of a caption is driven by a sequence of latent states.\\nExisting captioning models usually represent latent states as vectors, taking\\nthis practice for granted. We rethink this choice and study an alternative\\nformulation, namely using two-dimensional maps to encode latent states. This is\\nmotivated by the curiosity about a question: how the spatial structures in the\\nlatent states affect the resultant captions? Our study on MSCOCO and Flickr30k\\nleads to two significant observations. First, the formulation with 2D states is\\ngenerally more effective in captioning, consistently achieving higher\\nperformance with comparable parameter sizes. Second, 2D states preserve spatial\\nlocality. Taking advantage of this, we visually reveal the internal dynamics in\\nthe process of caption generation, as well as the connections between input\\nvisual domain and output linguistic domain.\\n',\n",
       " '  While several approaches to face emotion recognition task are proposed in\\nliterature, none of them reports on power consumption nor inference time\\nrequired to run the system in an embedded environment. Without adequate\\nknowledge about these factors it is not clear whether we are actually able to\\nprovide accurate face emotion recognition in the embedded environment or not,\\nand if not, how far we are from making it feasible and what are the biggest\\nbottlenecks we face.\\nThe main goal of this paper is to answer these questions and to convey the\\nmessage that instead of reporting only detection accuracy also power\\nconsumption and inference time should be reported as real usability of the\\nproposed systems and their adoption in human computer interaction strongly\\ndepends on it. In this paper, we identify the state-of-the art face emotion\\nrecognition methods that are potentially suitable for embedded environment and\\nthe most frequently used datasets for this task. Our study shows that most of\\nthe performed experiments use datasets with posed expressions or in a\\nparticular experimental setup with special conditions for image collection.\\nSince our goal is to evaluate the performance of the identified promising\\nmethods in the realistic scenario, we collect a new dataset with\\nnon-exaggerated emotions and we use it, in addition to the publicly available\\ndatasets, for the evaluation of detection accuracy, power consumption and\\ninference time on three frequently used embedded devices with different\\ncomputational capabilities. Our results show that gray images are still more\\nsuitable for embedded environment than color ones and that for most of the\\nanalyzed systems either inference time or energy consumption or both are\\nlimiting factor for their adoption in real-life embedded applications.\\n']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7c9b90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for i in topic_sen:\n",
    "    for j in i:\n",
    "        if j in counts:\n",
    "            counts[j] +=1\n",
    "        else:\n",
    "            counts[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "183b7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for i in topic_sen:\n",
    "    art=[]\n",
    "    for j in i:\n",
    "        if(counts[j]>1):\n",
    "            art.append(j)\n",
    "    new_data.append(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9a758c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38703"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in new_data:\n",
    "    c = c + len(i)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "546c6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {}\n",
    "w = []\n",
    "for i in new_data:\n",
    "    for word in i:\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for i in syn.lemmas():\n",
    "                synonyms.append(i.name())\n",
    "        if(len(set(synonyms))==0):\n",
    "            replace[word] = word\n",
    "            w.append(word)\n",
    "        else:\n",
    "            for i in synonyms:\n",
    "                if i not in w:\n",
    "                    replace[i] = word\n",
    "                    w.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a4946bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_topic_sen = []\n",
    "for i in new_data:\n",
    "    a = []\n",
    "    for j in i:\n",
    "        if(j in replace):\n",
    "            a.append(replace[j])\n",
    "        else:\n",
    "            a.append(j)\n",
    "    final_topic_sen.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d1083fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38703"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in final_topic_sen:\n",
    "    c = c + len(i)\n",
    "    \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4364e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f3a29368",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.80, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "efa42418",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in final_topic_sen:\n",
    "    s = \"\"\n",
    "    for j in i:\n",
    "        s = s+\" \"+j\n",
    "    documents.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4edf0f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0981d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9e510153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/intesurahmed/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3394"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cdb4e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9d5cc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in final_topic_sen:\n",
    "    s = []\n",
    "    for j in i:\n",
    "        if j in valid:\n",
    "            s.append(j)\n",
    "    if(len(s)>0):\n",
    "        final.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "59186d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "248b9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = []\n",
    "for i in final:\n",
    "    s = \"\"\n",
    "    for j in i:\n",
    "        s = s+j+\" \"\n",
    "    dt.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a13fe51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1,1), stop_words = 'english')\n",
    "\n",
    "X = cv.fit_transform(dt)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ab4a6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cv.get_feature_names()\n",
    "df = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b811a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8a837155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/f1d7t8ds66q5225tvtl8vhd00000gn/T/ipykernel_820/1718618950.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  matrix = df.where(np.triu(np.ones(df.shape)).astype(np.bool))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_2</th>\n",
       "      <th>_6</th>\n",
       "      <th>_odot</th>\n",
       "      <th>_x</th>\n",
       "      <th>a3c</th>\n",
       "      <th>ab</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yielding</th>\n",
       "      <th>young</th>\n",
       "      <th>yz</th>\n",
       "      <th>z3</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_odot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3c</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeta</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3377 rows × 3377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _2   _6  _odot   _x  a3c   ab  abc  ability  absence  absolute  ...  \\\n",
       "_2      0.0  0.0    0.0  1.0  0.0  0.0  0.0      0.0      0.0       0.0  ...   \n",
       "_6      NaN  0.0    0.0  0.0  0.0  0.0  0.0      0.0      1.0       0.0  ...   \n",
       "_odot   NaN  NaN    0.0  0.0  0.0  0.0  0.0      0.0      0.0       0.0  ...   \n",
       "_x      NaN  NaN    NaN  0.0  0.0  0.0  0.0      0.0      0.0       0.0  ...   \n",
       "a3c     NaN  NaN    NaN  NaN  0.0  0.0  0.0      1.0      0.0       0.0  ...   \n",
       "...     ...  ...    ...  ...  ...  ...  ...      ...      ...       ...  ...   \n",
       "z3      NaN  NaN    NaN  NaN  NaN  NaN  NaN      NaN      NaN       NaN  ...   \n",
       "zero    NaN  NaN    NaN  NaN  NaN  NaN  NaN      NaN      NaN       NaN  ...   \n",
       "zeta    NaN  NaN    NaN  NaN  NaN  NaN  NaN      NaN      NaN       NaN  ...   \n",
       "zigzag  NaN  NaN    NaN  NaN  NaN  NaN  NaN      NaN      NaN       NaN  ...   \n",
       "zone    NaN  NaN    NaN  NaN  NaN  NaN  NaN      NaN      NaN       NaN  ...   \n",
       "\n",
       "        yield  yielded  yielding  young   yz   z3  zero  zeta  zigzag  zone  \n",
       "_2        0.0      0.0       0.0    0.0  0.0  0.0   0.0   0.0     0.0     0  \n",
       "_6        0.0      0.0       0.0    0.0  0.0  0.0   0.0   0.0     0.0     0  \n",
       "_odot     0.0      0.0       0.0    1.0  0.0  0.0   0.0   0.0     0.0     0  \n",
       "_x        0.0      0.0       0.0    0.0  0.0  0.0   0.0   0.0     0.0     0  \n",
       "a3c       0.0      0.0       0.0    0.0  0.0  0.0   0.0   0.0     0.0     0  \n",
       "...       ...      ...       ...    ...  ...  ...   ...   ...     ...   ...  \n",
       "z3        NaN      NaN       NaN    NaN  NaN  0.0   0.0   0.0     0.0     0  \n",
       "zero      NaN      NaN       NaN    NaN  NaN  NaN   0.0   0.0     0.0     0  \n",
       "zeta      NaN      NaN       NaN    NaN  NaN  NaN   NaN   0.0     0.0     0  \n",
       "zigzag    NaN      NaN       NaN    NaN  NaN  NaN   NaN   NaN     0.0     0  \n",
       "zone      NaN      NaN       NaN    NaN  NaN  NaN   NaN   NaN     NaN     0  \n",
       "\n",
       "[3377 rows x 3377 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = df.where(np.triu(np.ones(df.shape)).astype(np.bool))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "722e9748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_2</td>\n",
       "      <td>_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2</td>\n",
       "      <td>_6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_2</td>\n",
       "      <td>_odot</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_2</td>\n",
       "      <td>_x</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_2</td>\n",
       "      <td>a3c</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703748</th>\n",
       "      <td>zeta</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703749</th>\n",
       "      <td>zeta</td>\n",
       "      <td>zone</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703750</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>zigzag</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703751</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>zone</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703752</th>\n",
       "      <td>zone</td>\n",
       "      <td>zone</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5703753 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Row  Column  Value\n",
       "0            _2      _2    0.0\n",
       "1            _2      _6    0.0\n",
       "2            _2   _odot    0.0\n",
       "3            _2      _x    1.0\n",
       "4            _2     a3c    0.0\n",
       "...         ...     ...    ...\n",
       "5703748    zeta  zigzag    0.0\n",
       "5703749    zeta    zone    0.0\n",
       "5703750  zigzag  zigzag    0.0\n",
       "5703751  zigzag    zone    0.0\n",
       "5703752    zone    zone    0.0\n",
       "\n",
       "[5703753 rows x 3 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix.stack().reset_index()\n",
    "matrix.columns = ['Row','Column','Value']\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ca4daba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_2</td>\n",
       "      <td>_x</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>_2</td>\n",
       "      <td>accretion</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>_2</td>\n",
       "      <td>achieve</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>_2</td>\n",
       "      <td>action</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>_2</td>\n",
       "      <td>advice</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703586</th>\n",
       "      <td>x1</td>\n",
       "      <td>xrays</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703634</th>\n",
       "      <td>xray</td>\n",
       "      <td>xrays</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703688</th>\n",
       "      <td>year</td>\n",
       "      <td>yield</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703689</th>\n",
       "      <td>year</td>\n",
       "      <td>yielded</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703691</th>\n",
       "      <td>year</td>\n",
       "      <td>young</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Row     Column  Value\n",
       "3          _2         _x    1.0\n",
       "26         _2  accretion    1.0\n",
       "30         _2    achieve    1.0\n",
       "39         _2     action    1.0\n",
       "76         _2     advice    1.0\n",
       "...       ...        ...    ...\n",
       "5703586    x1      xrays    1.0\n",
       "5703634  xray      xrays    1.0\n",
       "5703688  year      yield    2.0\n",
       "5703689  year    yielded    1.0\n",
       "5703691  year      young    1.0\n",
       "\n",
       "[476751 rows x 3 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge = matrix[matrix[\"Value\"] != 0]\n",
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "59521981",
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = edge.Row.values\n",
    "node2 = edge.Column.values\n",
    "value = edge.Value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c3e32076",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 1/value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7587220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# from networkx.algorithms.community import k_clique_communities\n",
    "# from networkx.algorithms import community\n",
    "import community.community_louvain as community_louvain\n",
    "import networkx.algorithms.community as nx_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7949475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "91367245",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(node1)):\n",
    "    G.add_edge(node1[i], node2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c775c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3a6e492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall community -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "89a295d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-louvain in /Users/intesurahmed/opt/anaconda3/lib/python3.9/site-packages (0.16)\r\n",
      "Requirement already satisfied: networkx in /Users/intesurahmed/opt/anaconda3/lib/python3.9/site-packages (from python-louvain) (2.8.8)\r\n",
      "Requirement already satisfied: numpy in /Users/intesurahmed/opt/anaconda3/lib/python3.9/site-packages (from python-louvain) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3857f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d5f7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = max(list(partition.values()))\n",
    "total_com = m+1\n",
    "total_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4efd984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------->\n",
      "Total Words:  1205\n",
      "Words:  ['achieve', 'action', 'agrees', 'area', 'based', 'camera', 'control', 'data', 'evaluate', 'guidance', 'insight', 'introduce', 'paper', 'protocol', 'provides', 'proving', 'reduce', 'representation', 'rule', 'sensing', 'technique', 'use', 'versus', 'work', 'generation', 'understood', 'account', 'compared', 'majority', 'undergoing', 'address', 'analysis', 'analyzed', 'approach', 'attributed', 'box', 'challenging', 'driving', 'experiment', 'feature', 'finding', 'introducing', 'performance', 'validated', 'a3c', 'ability', 'advantage', 'agent', 'applicability', 'aspect', 'atari', 'attention', 'called', 'card', 'challenge', 'cnn', 'code', 'deal', 'engaged', 'game', 'handcrafted', 'highlight', 'human', 'incorporate', 'job', 'learn', 'learning', 'learns', 'led', 'method', 'network', 'online', 'operation', 'option', 'propose', 'qlearning', 'reaching', 'relationship', 'reward', 'skill', 'suite', 'tackle', 'train', 'trained', 'computation', 'improving', 'information', 'process', 'algorithm', 'bayesian', 'content', 'focus', 'forward', 'generate', 'image', 'input', 'model', 'produce', 'security', 'signal', 'trust', 'way', 'abstraction', 'accelerate', 'accuracy', 'achieved', 'achieves', 'acquiring', 'acquisition', 'activity', 'adaptive', 'adding', 'addition', 'adopted', 'ai', 'aid', 'aimed', 'aligned', 'allocation', 'analyze', 'analyzing', 'application', 'applying', 'architecture', 'assessment', 'attempted', 'attribute', 'autoencoders', 'availability', 'avoided', 'background', 'baseline', 'batch', 'behave', 'believe', 'benchmark', 'benefit', 'big', 'biology', 'biomarkers', 'body', 'boosting', 'brain', 'built', 'cancer', 'capability', 'capturing', 'catch', 'chance', 'citizen', 'classification', 'cluttered', 'coherence', 'collect', 'collected', 'collection', 'combine', 'communication', 'community', 'complement', 'computational', 'concern', 'conduct', 'conducted', 'confirms', 'connectivity', 'consideration', 'contained', 'context', 'convnet', 'correctness', 'cortex', 'cost', 'course', 'cpu', 'crash', 'create', 'creating', 'cycle', 'database', 'dataset', 'datasets', 'decision', 'decoder', 'decoding', 'denoising', 'design', 'designed', 'designing', 'detect', 'developing', 'dialogue', 'difficulty', 'dimensionality', 'disease', 'diverse', 'document', 'dollar', 'effectiveness', 'efficiency', 'effort', 'elaborating', 'engineering', 'enhance', 'enhancing', 'ensure', 'entity', 'era', 'estimation', 'evaluated', 'evaluating', 'evaluation', 'exchanged', 'execution', 'exercise', 'existing', 'experience', 'expert', 'expertise', 'exploration', 'explore', 'expressed', 'extracting', 'extraction', 'face', 'facilitate', 'facilitates', 'factorization', 'fail', 'finetuning', 'focused', 'footprint', 'formulated', 'generates', 'github', 'gpu', 'gpus', 'gram', 'grasping', 'growing', 'guideline', 'handle', 'hardware', 'heavy', 'highresolution', 'hinders', 'hippocampus', 'hope', 'hyperparameters', 'illness', 'illumination', 'implementation', 'implemented', 'implementing', 'improved', 'inability', 'incident', 'indicated', 'indicator', 'individual', 'inference', 'inspired', 'instruction', 'integrate', 'integrates', 'intelligence', 'intelligent', 'interface', 'internet', 'investigation', 'iot', 'issue', 'kalman', 'kernel', 'knowing', 'knowledge', 'lab', 'lack', 'language', 'layout', 'lda', 'learned', 'learner', 'leverage', 'leveraging', 'likelihood', 'living', 'loss', 'lstm', 'machine', 'maintaining', 'making', 'manipulation', 'manner', 'marker', 'mean', 'mediated', 'memory', 'methodology', 'million', 'missing', 'ml', 'modern', 'modify', 'modularity', 'motor', 'multiple', 'music', 'need', 'networking', 'neural', 'night', 'novel', 'obesity', 'objective', 'operating', 'opinion', 'opponent', 'organization', 'organized', 'outbreak', 'outperformed', 'output', 'participant', 'participate', 'partition', 'pass', 'patient', 'perception', 'perform', 'performing', 'performs', 'perspective', 'piece', 'pilot', 'pixel', 'planning', 'policy', 'posed', 'practice', 'practitioner', 'prediction', 'presenting', 'prevailing', 'privacy', 'programming', 'proposed', 'prototype', 'providing', 'proxy', 'purpose', 'quality', 'question', 'rain', 'reader', 'reasoning', 'recognition', 'recommendation', 'redundancy', 'redundant', 'relevance', 'relying', 'repair', 'repository', 'requires', 'requiring', 'research', 'researcher', 'resource', 'retraining', 'reviewing', 'risk', 'robot', 'robust', 'run', 'safety', 'scene', 'selection', 'semantics', 'sensor', 'service', 'setting', 'shared', 'sharing', 'showed', 'society', 'software', 'specification', 'spiking', 'spot', 'stacking', 'started', 'strategy', 'street', 'structured', 'student', 'success', 'suitability', 'super', 'supervised', 'supervision', 'support', 'tailor', 'target', 'tasked', 'technology', 'tend', 'testing', 'thing', 'thousand', 'threat', 'today', 'tool', 'track', 'training', 'trait', 'understand', 'universe', 'university', 'url', 'usage', 'user', 'utility', 'utilization', 'utilize', 'validate', 'validating', 'validation', 'variance', 'varied', 'vehicle', 'verified', 'video', 'vision', 'walking', 'weight', 'weighting', 'wiener', 'accurate', 'behaviour', 'care', 'emerged', 'node', 'prover', 'solver', 'life', 'goal', 'offer', 'share', 'tested', 'hand', 'competition', 'describes', 'functionality', 'league', 'nao', 'platform', 'soccer', 'synthesize', 'team', 'adoption', 'caffe', 'convert', 'crowdsourced', 'deep', 'file', 'format', 'grammar', 'importance', 'post', 'processing', 'produced', 'reality', 'realtime', 'reproducibility', 'table', 'ui', 'violation', 'visualization', 'accelerated', 'attempt', 'bias', 'capture', 'carried', 'customer', 'decomposing', 'detects', 'feedback', 'imbalanced', 'lowrank', 'misclassification', 'optimized', 'outperforms', 'personalized', 'preference', 'update', 'identifying', 'timefrequency', 'efficient', 'opportunity', 'accessed', 'assist', 'communicated', 'ct', 'currency', 'http', 'improvement', 'industry', 'infrastructure', 'landmark', 'management', 'people', 'proposing', 'server', 'suffers', 'vulnerability', 'web', 'mismatch', 'reporting', 'retrieve', 'retrieving', 'scalability', 'structuring', 'promising', 'adapt', 'advance', 'causal', 'collaborative', 'convenience', 'criterion', 'defines', 'denoting', 'detailed', 'dropout', 'ease', 'enables', 'encoded', 'end', 'engaging', 'enriched', 'express', 'grating', 'grouped', 'guided', 'inferring', 'integrating', 'internetofthings', 'item', 'label', 'latent', 'li', 'meaning', 'mobility', 'motivation', 'movement', 'multicriteria', 'named', 'navigation', 'neuron', 'occurring', 'overfitting', 'pairwise', 'partitioning', 'popularity', 'predicate', 'proposes', 'ranking', 'reading', 'reflect', 'release', 'revisit', 'sentiment', 'supposed', 'text', 'theme', 'thought', 'toy', 'trying', 'variety', 'word', 'workflow', 'achieving', 'activation', 'analyst', 'annotate', 'annotation', 'app', 'art', 'attack', 'attacker', 'augmentation', 'balancing', 'blog', 'bootstrapping', 'breast', 'bridge', 'bridging', 'brings', 'capable', 'cd', 'classifier', 'communicating', 'connectome', 'corpus', 'credibility', 'cue', 'cyber', 'dealing', 'default', 'defense', 'desired', 'detecting', 'devise', 'drive', 'ehrs', 'embeddings', 'emerging', 'employed', 'estimating', 'expanding', 'expense', 'explanation', 'explores', 'extracted', 'faced', 'feasibility', 'feedforward', 'fitted', 'forum', 'future', 'gene', 'gesture', 'giving', 'grid', 'handling', 'health', 'heuristic', 'highquality', 'hour', 'ignore', 'imbalance', 'imported', 'imposes', 'increased', 'insert', 'integration', 'intel', 'javascript', 'leastsquares', 'long', 'managing', 'market', 'mining', 'modality', 'modelled', 'money', 'news', 'occupancy', 'offline', 'ontology', 'oversampling', 'past', 'pearson', 'playing', 'precise', 'predefined', 'predicting', 'push', 'python', 'realworld', 'record', 'recurrent', 'represents', 'ridge', 'scanner', 'second', 'seeking', 'selecting', 'selects', 'sentence', 'sequencing', 'sought', 'sound', 'speaker', 'specialized', 'specificity', 'string', 'supporting', 'surgery', 'transformed', 'tso', 'undirected', 'variability', 'whilst', 'horizon', 'centrality', 'acquired', 'adaptation', 'adapting', 'addressed', 'administration', 'adversarial', 'agency', 'alarm', 'alternative', 'analytics', 'attribution', 'auc', 'automating', 'bandwidth', 'beijing', 'belief', 'bottleneck', 'burden', 'cfd', 'characterizes', 'cifar10', 'city', 'cnns', 'collaboration', 'company', 'conditioning', 'consumption', 'contend', 'convey', 'convolutional', 'correspond', 'cosmology', 'cranknicolson', 'crf', 'decade', 'demonstrates', 'deploying', 'diagnosis', 'dilated', 'directive', 'discriminating', 'drawback', 'drawing', 'drug', 'elbo', 'emotion', 'encoding', 'encryption', 'endtoend', 'establishing', 'evolved', 'exceeds', 'excellent', 'explored', 'exploring', 'extent', 'fairness', 'feeling', 'figure', 'fortran', 'gaining', 'gating', 'highaccuracy', 'house', 'hyperparameter', 'identifies', 'inspiration', 'introduces', 'investment', 'investor', 'iterative', 'january', 'keywords', 'labeling', 'labelled', 'lasso', 'lesion', 'lstms', 'maximizing', 'merit', 'message', 'minute', 'monitoring', 'ner', 'neuroimaging', 'observed', 'occlusion', 'october', 'odometry', 'opensource', 'optimize', 'optimizer', 'optimum', 'overcome', 'pain', 'parallelization', 'pencil', 'person', 'player', 'preprocessing', 'preserved', 'printer', 'printing', 'processor', 'ratedistortion', 'reallife', 'reconstructed', 'reconstructing', 'registration', 'regulation', 'relevant', 'removing', 'retaining', 'retrieval', 'rnn', 'rnns', 'road', 'roi', 'routine', 'rv', 'sacrificing', 'saliency', 'saving', 'segment', 'session', 'smartphones', 'spectator', 'speedup', 'squared', 'stereo', 'stop', 'stream', 'supply', 'tracking', 'tradeoff', 'traffic', 'truth', 'updated', 'usability', 'useful', 'utilizing', 'variational', 'vortex', 'winner', 'writing', 'yielding', 'automatic', 'ecommerce', 'establishes', 'exposure', 'generalize', 'marketing', 'prevent', 'regressors', 'separating', 'speech', 'spend', 'advertising', 'alexnet', 'apps', 'build', 'caption', 'check', 'compensation', 'compress', 'compressed', 'confidentiality', 'discriminator', 'diverge', 'eliminated', 'encoder', 'encourages', 'executed', 'expand', 'extrapolation', 'feel', 'fiber', 'gan', 'gans', 'india', 'kspace', 'mlq', 'mri', 'multilevel', 'normalization', 'promoting', 'publishing', 'recovering', 'reinforce', 'replicated', 'representing', 'requested', 'resnet18', 'running', 'scientist', 'subjective', 'trusted', 'verification', 'alice', 'annotated', 'backpropagation', 'bidirectional', 'billion', 'captioning', 'concatenation', 'demanding', 'dnns', 'encode', 'failed', 'generative', 'hash', 'hierarchical', 'hmdb51', 'incorporation', 'investigating', 'lesson', 'multitask', 'obtains', 'opposed', 'organism', 'participating', 'played', 'prostate', 'referred', 'replaces', 'sent', 'succeeded', 'suggestion', 'toolbox', 'trick', 'wish', 'affiliation', 'answering', 'aperture', 'benchmarking', 'bootstrap', 'computes', 'contribute', 'decentralized', 'derives', 'discipline', 'disentangled', 'downloaded', 'english', 'exploratory', 'gate', 'german', 'imitation', 'matlab', 'mnist', 'multiprocessing', 'offpolicy', 'overlapping', 'paired', 'read', 'recognizing', 'rgbd', 'shortcoming', 'spread', 'spreading', 'stateoftheart', 'supercomputer', 'superiority', 'thanks', 'transforming', 'car', 'decouples', 'locality', 'sensorimotor', 'steering', 'weather', 'astronomy', 'biased', 'breakthrough', 'capitalize', 'collecting', 'demand', 'examination', 'expands', 'look', 'mathematics', 'month', 'networked', 'offering', 'paradox', 'pave', 'unsupervised', 'wired', 'contrary', 'generality', 'discourse', 'education', 'international', 'newcomer', 'school', 'slowing', 'unconstrained', 'weibull', 'asset', 'assignment', 'assistance', 'autonomy', 'collective', 'complicated', 'demonstrating', 'demonstration', 'differs', 'distinguishes', 'engine', 'getting', 'handtuning', 'ipm', 'kmeans', 'lowered', 'mitigating', 'portfolio', 'provider', 'resulted', 'sending', 'shortterm', 'syntax', 'teaching', 'trading', 'cam', 'plant', 'principled', 'ancient', 'assessed', 'characterise', 'contingency', 'county', 'death', 'decode', 'ecosystem', 'efficacy', 'evaluates', 'executes', 'exhibited', 'explains', 'friend', 'hidden', 'incentive', 'infers', 'intervention', 'movie', 'optimizing', 'recommend', 'recommending', 'registered', 'restaurant', 'rhythm', 'social', 'steered', 'token', 'trader', 'tweet', 'twitter', 'pool', 'receives', 'synchronization', 'ad', 'audio', 'clarity', 'click', 'distinguishing', 'ensures', 'owner', 'privacypreserving', 'streaming', 'trustworthiness', 'violating', 'waveform', 'gaze', 'trimming', 'turned', 'visibility', 'yielded', 'crowd', 'labor', 'recruited', 'undertaking', 'loglikelihood', 'noisy', 'regularisation', 'employing', 'encodes', 'imagenet', 'percentage', 'program', 'relating', 'android', 'api', 'balance', 'changed', 'computer', 'desire', 'developer', 'discovering', 'documentation', 'emulation', 'google', 'influenced', 'inventory', 'library', 'list', 'official', 'recommender', 'simplifying', 'worker', 'addressing', 'adjustment', 'alter', 'boost', 'bounding', 'comprised', 'consumer', 'creates', 'dnn', 'envisioned', 'equipped', 'forest', 'grouping', 'implicit', 'make', 'nowadays', 'phrase', 'resolving', 'tailored', 'targeting', 'mexico', 'citation', 'business', 'aim', 'contributes', 'disaster', 'exemplified', 'marketer', 'omitting', 'publication', 'exception', 'layered', 'multilayer', 'sdn', 'swarm', 'bug', 'comprehension', 'collapse', 'dilemma', 'preventing', 'reflects', 'autoencoder', 'different', 'minority', 'disclosure', 'injury', 'quantification', 'remained', 'season', 'crowdsourcing', 'animal', 'exceeding', 'party', 'heterogeneity', 'imputing', 'axb', 'blood', 'destabilize', 'generalises', 'hashing', 'reachability', 'svm', 'combat', 'documented', 'floor', 'gnu', 'grounded', 'justify', 'mc', 'multiplication', 'multiview', 'optimisation', 'prevents', 'pricing', 'rgb', 'slam', 'summarization', 'korean', 'victim', 'atlas', 'deemed', 'minimising', 'ambiguity', 'cited', 'bank', 'compliance', 'credit', 'government', 'java', 'mechanical', 'offered', 'partner', 'prevention', 'turk', 'native', 'ledger', 'inaccuracy', 'chip', 'misinformation', 'trade']\n",
      "\n",
      "\n",
      "\n",
      "1 ------->\n",
      "Total Words:  611\n",
      "Words:  ['accretion', 'candidate', 'clustering', 'contribution', 'cooling', 'correlation', 'dependence', 'depth', 'detected', 'discovered', 'distribution', 'dust', 'event', 'exoplanets', 'explain', 'fading', 'favor', 'follows', 'host', 'including', 'japan', 'jupiter', 'lead', 'measurement', 'motion', 'nucleus', 'num', 'object', 'observation', 'observatory', 'occultation', 'planet', 'present', 'prime', 'profile', 'rate', 'region', 'resolution', 'rm', 's2', 'seen', 'separation', 'set', 'simultaneous', 'star', 'telescope', 'textit', 'time', 'transiting', 'uncertainty', 'wavelength', 'agreement', 'disappears', 'peak', 'pressure', '_odot', 'according', 'age', 'alpha', 'arm', 'association', 'assuming', 'classified', 'cloud', 'cluster', 'confirmed', 'consisting', 'counterpart', 'cross', 'density', 'embedded', 'emission', 'emphasizes', 'episode', 'estimate', 'evolution', 'fainter', 'filament', 'flux', 'follow', 'formation', 'ghz', 'giant', 'hi', 'identified', 'illustrating', 'inactive', 'lasting', 'lens', 'lifetime', 'link', 'luminosity', 'm33', 'mass', 'mathrm', 'molecular', 'planck', 'population', 'redshift', 'reference', 'resolve', 'resultant', 's_', 'selected', 'shed', 'site', 'sky', 'spiral', 'stage', 'suggesting', 'survey', 'undetected', 'uv', 'year', 'young', 'ch', 'continuum', 'interpret', 'magnitude', 'mechanism', 'nh', 'sn', 'component', 'conclusion', 'environment', 'gained', 'key', 'play', 'reproduce', 'underlying', 'measure', 'orientation', 'sensitivity', 'solid', 'analyse', 'constrain', 'controlled', 'curve', 'dark', 'depend', 'fusion', 'generating', 'hst', 'kev', 'mock', 'particle', 'position', 'prescription', 'psf', 'ring', 'simulation', 'targeted', 'affect', 'allowing', 'attenuation', 'average', 'bin', 'characteristic', 'chemical', 'cold', 'combining', 'connect', 'constrained', 'core', 'cosmic', 'detection', 'deviation', 'discovery', 'discus', 'dominated', 'doppler', 'dozen', 'duration', 'enabling', 'evidence', 'expectation', 'extending', 'fitting', 'galaxy', 'gravity', 'grow', 'growth', 'history', 'hold', 'hr', 'identify', 'impact', 'incidence', 'indication', 'inferred', 'institution', 'instrument', 'laboratory', 'light', 'limited', 'line', 'localization', 'location', 'meteorite', 'mixing', 'modeled', 'observables', 'observe', 'organic', 'package', 'parametrization', 'parametrizations', 'picture', 'plan', 'prior', 'probe', 'provided', 'recognized', 'report', 'represent', 'required', 'rest', 'resulting', 'sample', 'scale', 'search', 'searching', 'simulated', 'spanned', 'specie', 'spectroscopic', 'spectrum', 'speed', 'start', 'stored', 'subtraction', 'suggest', 'taken', 'treated', 'truncated', 'understanding', 'velocity', 'automated', 'combined', 'coverage', 'pathway', 'presented', 'z3', 'absolute', 'allowed', 'analysed', 'appear', 'appearing', 'approx', 'carlo', 'cdm', 'color', 'competing', 'converted', 'differentiating', 'em', 'fast', 'fit', 'fourier', 'fraction', 'fragment', 'fragmentation', 'galactic', 'indicates', 'lambda', 'massive', 'mev', 'monte', 'neutrino', 'overestimation', 'overview', 'period', 'phi_', 'photometric', 'r_', 'ratio', 'sigma_8', 'spectrometer', 'tension', 'water', 'absorbed', 'branch', 'centered', 'creation', 'damped', 'delay', 'emitter', 'enhanced', 'explorer', 'faint', 'gas', 'hole', 'iv', 'kpc', 'looking', 'ly', 'lyman', 'medium', 'mounted', 'neglected', 'plasma', 'projected', 'published', 'radiation', 'spectrograph', 'surrounding', 'tev', 'width', 'absorbing', 'affected', 'albedo', 'board', 'comet', 'extinction', 'grain', 'mission', 'mu', 'preparation', 'rosetta', 'slope', 'standard', 'assembly', 'orbital', 'precision', 'abundance', 'al', 'anchored', 'annihilation', 'autoignition', 'battery', 'chemistry', 'compression', 'day', 'dense', 'disk', 'escape', 'evolving', 'examining', 'formed', 'fuel', 'harvested', 'ignition', 'imply', 'intended', 'jet', 'keeping', 'kepler', 'kinetics', 'license', 'midplane', 'migrate', 'occurs', 'operates', 'primitive', 'prone', 'released', 'resonant', 'serve', 'shorter', 'speciation', 'tube', 'turbulence', 'undergo', 'working', 'world', 'andor', 'cherenkov', 'diagnostics', 'millimeter', 'mesh', 'morphology', 'possibility', 'proposal', 'reliability', 'remote', 'rotation', 'evolve', 'matched', 'remove', 'binary', 'blue', 'bubble', 'catalogue', 'collapsing', 'comparing', 'condensed', 'crust', 'date', 'decaying', 'dispersion', 'dominating', 'dwarf', 'exceed', 'explosion', 'followed', 'friction', 'injecting', 'local', 'locate', 'member', 'mimicking', 'moving', 'orbit', 'outer', 'processed', 'refining', 'reservoir', 'scalar', 'shell', 'subsamples', 'supernova', 'timing', 'took', 'turbulent', 'yield', 'actor', 'apache', 'bt', 'carry', 'climate', 'confounding', 'forming', 'hide', 'included', 'ionized', 'lag', 'markov', 'powerlaw', 'prevalent', 'quantify', 'repeating', 'revealing', 'science', 'shifted', 'accounting', 'collider', 'contamination', 'covering', 'large', 'nuclear', 'parent', 'radio', 'xray', 'choosing', 'corona', 'exclude', 'gyr', 'inappropriate', 'le', 'm_', 'msun', 'mw', 'pm', 'predicted', 'satellite', 'tilting', 'timescale', 'timescales', 'ec', 'added', 'agree', 'alignment', 'basin', 'century', 'governing', 'landscape', 'logarithmic', 'marginalizing', 'millisecond', 'moon', 'neptune', 'november', 'pdf', 'percent', 'principal', 'quasar', 'recording', 'regarded', 'saturn', 'spectral', 'thermal', 'transient', 'covariates', 'einstein', 'mitigated', 'plot', 'silicon', 'budget', 'chamber', 'claim', 'cooled', 'dissipation', 'enclosure', 'firstorder', 'maintained', 'minimum', 'photometry', 'pid', 'pv', 'significance', 'swing', 'arrangement', 'cm', 'coherent', 'distinct', 'flight', 'furthermore', 'hill', 'loading', 'moonlet', 'moonlets', 'radius', 'reviewed', 'seed', 'subregion', 'sun', 'superposition', 'ultraviolet', 'avoids', 'diffuse', 'gathering', 'spatial', 'adopt', 'decreasing', 'arrival', 'astrophysics', 'digital', 'summer', 'crowding', 'mdp', 'solar', 'believed', 'correlate', 'leave', 'propagating', 'retains', 'sd', 'extreme', 'pointing', 'relativity', 'status', 'asteroid', 'relied', 'affecting', 'extrapolated', 'amended', 'calibrated', 'calibration', 'herschel', 'observing', 'recorded', 'bright', 'brighter', 'depletion', 'gev', 'prepared', 'varies', 'brazil', 'crime', 'viewing', 'contributed', 'interferometer', 'merging', 'texture', 'infrared', 'homogenization', 'streamwise', 'good', 'goodnessoffit', 'm_odot', 'synergy', 'consortium', 'instrumentation', 'catalog', 'inclination', 'sloan', 'week', 'onset', 'punishment', 'heated', 'oxygen', 'optimised', 'yz', 'compiled', 'terminology', 'cooperating', 'hubble', 'lensing', 'operate', 'river', 'dynamo', 'lifting', 'dusty', 'launched', 'polarisation', 'stacked', 'x1', 'xrays', 'odot', 'primary', 'receiving', 'astroparticle', 'ray', 'burst', 'hemisphere', 'balloon', 'originates', 'deposition', 'operated', 'sim', 'wind']\n",
      "\n",
      "\n",
      "\n",
      "2 ------->\n",
      "Total Words:  43\n",
      "Words:  ['barrier', 'transportation', 'adopts', 'cache', 'exploiting', 'filesystem', 'layer', 'module', 'preserving', 'stack', 'strength', 'thread', 'cause', 'dedicated', 'ensuring', 'implement', 'enabled', 'storage', 'delivered', 'preserve', 'request', 'level', 'smartphone', 'write', 'journal', 'overhead', 'enforcing', 'resort', 'command', 'flash', 'mysql', 'io', 'scheduler', 'scheduling', 'root', 'dispatch', 'eliminating', 'epoch', 'guaranteeing', 'imposed', 'ingredient', 'relaxing', 'transaction']\n",
      "\n",
      "\n",
      "\n",
      "3 ------->\n",
      "Total Words:  645\n",
      "Words:  ['_2', '_x', 'anomaly', 'applied', 'ba', 'behavior', 'calculate', 'calculation', 'center', 'charge', 'circuit', 'comparison', 'concentration', 'consequence', 'correction', 'curvature', 'degree', 'developed', 'diamond', 'diffraction', 'doping', 'edge', 'effect', 'energy', 'enhances', 'ev', 'excitation', 'expansion', 'factor', 'fc', 'fe', 'fermion', 'field', 'fluctuation', 'gap', 'group', 'heat', 'heisenberg', 'hotspot', 'impurity', 'increase', 'increasing', 'induced', 'investigated', 'ion', 'kondo', 'lattice', 'macroscopic', 'magnetism', 'magnetization', 'marked', 'material', 'measured', 'microscopic', 'moment', 'neutron', 'ni', 'nitrogenvacancy', 'nv', 'order', 'ordering', 'pb', 'phase', 'physic', 'presence', 'promise', 'pulsed', 'quantum', 'replaced', 'reported', 'resonance', 'scattering', 'screening', 'si', 'sigma', 'sign', 'spin', 'sr', 'state', 'structure', 'study', 'substitution', 'superconducting', 'superconductors', 'suppressed', 'suppression', 't_c', 'temperature', 'theory', 'transfer', 'transition', 'tuning', 'van', 'volume', '_6', 'arises', 'change', 'contraction', 'decrease', 'exhibit', 'gpa', 'intensity', 'mode', 'modulus', 'pairing', 'performed', 'powder', 'raman', 'relaxation', 'rightarrow', 'sc', 'shift', 'spectroscopy', 'strain', 'susceptibility', 'ac', 'bar', 'bond', 'carrier', 'collision', 'condensate', 'configuration', 'cooper', 'correlated', 'decoupling', 'development', 'develops', 'diagram', 'dirac', 'discover', 'discussed', 'driven', 'dynamic', 'electron', 'enhancement', 'established', 'eu', 'finite', 'floquet', 'frame', 'implication', 'includes', 'induces', 'insulating', 'insulator', 'matter', 'meson', 'modulation', 'occurrence', 'open', 'pair', 'polarization', 'prefer', 'qcd', 'quark', 'realizing', 'reduced', 'remains', 'reversal', 'rotating', 'schwinger', 'semiconductor', 'similarity', 'superconductor', 'symmetry', 't_', 't_mathrm', 'threshold', 'transforms', 'vacuum', 'wave', 'wrt', 'xy', 'ab', 'amplitude', 'andreev', 'beta', 'bonding', 'changing', 'composed', 'consists', 'constant', 'coupled', 'der', 'dimer', 'dipole', 'direction', 'disorder', 'fingerprint', 'indicating', 'initio', 'interaction', 'interplay', 'investigate', 'junction', 'localized', 'majorana', 'nature', 'owing', 'phenomenon', 'potential', 'principle', 'property', 'setup', 'signature', 'translate', 'waals', 'basis', 'description', 'anisotropy', 'apparatus', 'argue', 'arising', 'array', 'ass', 'atom', 'avenue', 'branching', 'c24h12', 'carbon', 'cell', 'characterized', 'complex', 'compound', 'connected', 'contrast', 'contributing', 'conversion', 'coronene', 'correspondence', 'created', 'defect', 'demonstrated', 'device', 'distortion', 'driver', 'ed', 'elasticity', 'examine', 'exchange', 'expect', 'explained', 'firm', 'higherorder', 'hydrocarbon', 'imaging', 'include', 'induce', 'influence', 'instability', 'introduction', 'knot', 'laser', 'ligand', 'membrane', 'mixture', 'molecule', 'neighbor', 'oriented', 'propagation', 'protein', 'pyrene', 'reason', 'renormalization', 'response', 'selectivity', 'shape', 'simplifies', 'spectrometry', 'starting', 'studied', 'substrate', 'subsystem', 'suggested', 'suppress', 'surface', 'tendency', 'tissue', 'translating', 'transmit', 'tuned', 'vapor', 'vicinity', 'avoid', 'composition', 'interference', 'viscosity', 'wall', 'angle', 'caused', 'chaos', 'described', 'extended', 'ionization', 'modulated', 'section', 'trajectory', 'frequency', 'pas', 'photon', 'rise', 'contact', 'dc', 'depending', 'depends', 'diffusion', 'maintenance', 'occupation', 'phys', 'predict', 'reach', 'rev', 'signed', 'universality', 'absorption', 'appearance', 'appears', 'ce', 'doped', 'emerges', 'fall', 'fermi', 'filling', 'hybridization', 'hyperthermia', 'mn', 'nanoparticles', 'photoemission', 'resistance', 'reveals', 'superconductivity', 'terminating', 'valence', 'vanishes', 'chain', 'dm', 'fluid', 'force', 'generated', 'interacting', 'interacts', 'melting', 'precursor', 'sector', 'momentum', 'suggests', 'confirm', 'accelerator', 'air', 'amplifier', 'asymmetry', 'detector', 'determination', 'downstream', 'facility', 'fused', 'germany', 'hydrogen', 'liquid', 'national', 'paving', 'planned', 'pulse', 'thz', 'aided', 'bone', 'topology', 'flexibility', 'accompanied', 'applicable', 'coming', 'hindered', 'maximization', 'mirror', 'outline', 'sm', 'cavity', 'differ', 'echo', 'emergence', 'ladder', 'metaphor', 'paradigm', 'regime', 'remaining', 'revealed', 'room', 'schrödinger', 'stress', 'truncation', 'bc', 'bcs', 'circumstance', 'coexisting', 'comprising', 'disordered', 'engineered', 'focusing', 'happen', 'packet', 'phonons', 'quasiparticle', 'realization', 'renormalized', 'resting', 'skyrmion', 'soliton', 'stepping', 'switching', 'tempering', 'termination', 'torque', 'treatment', 'triple', 'couple', 'electroweak', 'hadron', 'production', 'boseeinstein', 'colliding', 'drop', 'consistent', 'actuator', 'axis', 'bath', 'breathing', 'conducting', 'convection', 'crystal', 'deploy', 'devised', 'dichalcogenides', 'dominates', 'draw', 'enable', 'exoplanet', 'graphene', 'inspection', 'measuring', 'metal', 'modifying', 'monitored', 'parity', 'plasmon', 'predicts', 'pupil', 'quadrature', 'ranging', 'rms', 'se', 'soc', 'spacing', 'tau', 'wavefront', 'window', 'zone', 'decay', 'encountered', 'lie', 'radiative', 'suffices', 'tunneling', 'byproduct', 'cern', 'compact', 'emulsion', 'excited', 'fine', 'gauge', 'mr', 'nm', 'oscillation', 'periodic', 'planar', 'progression', 'proton', 'waveguide', 'behaves', 'conduction', 'ge', 'grade', 'gyroscope', 'hint', 'microscopy', 'overlayer', 'persistence', 'polycrystalline', 'polymer', 'prevalence', 'semiconducting', 'synthesized', 'tapered', 'tracing', 'crossing', 'sic', 'utilising', 'constrains', 'inclusion', 'triggered', 'act', 'acting', 'conductivity', 'conductor', 'confined', 'diagonalization', 'fabrication', 'fractionalization', 'helium', 'honeycomb', 'kitaev', 'magnet', 'optic', 'perceived', 'render', 'summation', 'transparency', 'bring', 'hall', 'nu', 'vacancy', 'foliation', 'mentioned', 'realized', 'suspected', 'bundle', 'degenerate', 'dns', 'hampered', 'intermittency', 'isotropic', 'migrating', 'mouse', 'resemblance', 'signaling', 'suspension', 'wavelet', 'disrupt', 'fluorescent', 'corrected', 'hopping', 'range', 'break', 'display', 'mimic', 'weakly', 'dilute', 'calculating', 'charged', 'exclusion', 'experimental', 'higgs', 'magnetoresistance', 'md', 'muon', 'qubits', 'quoted', 'simulating', 'split', 'trapped', 'wavefunctions', 'election', 'polarized', 'tunability', 'binding', 'conserved', 'horn', 'receptor', 'perturbative', 'entanglement', 'inner', 'luttinger', 'advantageous', 'chirality', 'transverse', 'droplet', 'marangoni', 'microwave', 'superfluid', 'emerge', 'voting', 'coincidence', 'monolayer', 'photoelectron', 'tmds', 'stemming', 'coating', 'pocket', 'roughness', 'switch', 'weyl', 'ca', 'crystallization', 'doubling', 'eigenvalue', 'grosspitaevskii', 'independence', 'neck', 'obstacle', 'spinning', 'suited', 'helicity', 'hit', 'cuprates', 'curved', 'dune', 'lee', 'manipulate', 'manybody', 'metallic', 'phenomenology', 'proximity', 'realspace', 'sitter', 'stock', 'su', 'wigner', 'longrange', 'obeys', 'oh', 'chern', 'gapped', 'protected', 'attitude', 'centroid', 'possessing', 'twisted', 'classifying', 'singleparticle', 'josephson', 'sto', 'landau', 'semimetals', 'staggered', 'freezing', 'bessel', 'warping', 'zigzag', 'injection', 'quasi', 'arriving', 'elucidated', 'mit', 'thickness', 'semimetal', 'wire']\n",
      "\n",
      "\n",
      "\n",
      "4 ------->\n",
      "Total Words:  41\n",
      "Words:  ['scenario', 'expected', 'channel', 'trend', 'base', 'assessing', 'coordination', 'deployment', 'filter', 'incorporating', 'matching', 'power', 'trial', 'wider', 'receiver', 'reduces', 'multi', 'rf', 'accommodates', 'gain', 'incorporated', 'station', 'handled', 'termed', 'worstcase', 'denser', 'aiming', 'degradation', 'high', 'raised', 'quantization', 'coding', 'beamforming', 'having', 'mmwave', 'quantifies', 'serf', 'cooperation', 'receive', 'csi', 'resilience']\n",
      "\n",
      "\n",
      "\n",
      "5 ------->\n",
      "Total Words:  832\n",
      "Words:  ['advice', 'algebra', 'allow', 'allows', 'associated', 'augmented', 'ball', 'bit', 'block', 'case', 'category', 'class', 'closed', 'computed', 'computing', 'condition', 'decided', 'defined', 'determining', 'dimensional', 'family', 'following', 'formalism', 'formula', 'function', 'generalization', 'generalized', 'generator', 'given', 'heart', 'homology', 'integer', 'involving', 'like', 'limit', 'literature', 'mathbb', 'number', 'obtained', 'operator', 'problem', 'product', 'prove', 'series', 'sf', 'simplified', 'size', 'sl', 'source', 'studying', 'sum', 'term', 'theorem', 'trace', 'unit', 'vector', 'verify', 'version', 'vertex', 'widetilde', 'absence', 'equation', 'existence', 'count', 'estimated', 'exists', 'parameter', 'point', 'regulating', 'stability', 'assumed', 'combination', 'considered', 'develop', 'hypothesis', 'leading', 'simple', 'space', 'sparse', 'step', 'variation', 'alternating', 'belongs', 'connection', 'contains', 'determine', 'exploited', 'reducing', 'regression', 'relative', 'abc', 'approximate', 'assumption', 'complexity', 'dot', 'elimination', 'example', 'gröbner', 'matrix', 'modelling', 'multivariate', 'noise', 'p_1', 'polynomial', 'regularity', 'relies', 'resolved', 'scheme', 'situation', 'solving', 'statistic', 'transform', 'approximation', 'ascent', 'assume', 'automaton', 'bound', 'captured', 'characterization', 'characterizing', 'clique', 'compare', 'concept', 'concerning', 'considering', 'considers', 'consistency', 'constraint', 'construction', 'convergence', 'corresponds', 'corroborate', 'corrupted', 'decide', 'defining', 'definition', 'derivative', 'difference', 'dimension', 'dirichlet', 'discrepancy', 'discussion', 'divergence', 'ensemble', 'explicit', 'expression', 'extends', 'extension', 'fact', 'failure', 'flow', 'form', 'gaussian', 'generalizes', 'geometry', 'gibbs', 'gradient', 'guarantee', 'idea', 'ii', 'iii', 'illustrated', 'index', 'infection', 'interpolating', 'introduced', 'inverse', 'involves', 'ising', 'iteration', 'kind', 'know', 'known', 'leaf', 'linking', 'logic', 'manifold', 'match', 'math', 'maximum', 'mechanic', 'min', 'minimize', 'nonlinear', 'notion', 'obstruction', 'ot', 'path', 'posse', 'predictor', 'probability', 'procedure', 'random', 'randomized', 'rank', 'recovered', 'relation', 'replacing', 'requirement', 'right', 'robustness', 'sampler', 'sampling', 'sense', 'sequence', 'shown', 'shrinkage', 'smoothing', 'smoothness', 'solution', 'solve', 'subject', 'subspace', 'supported', 'taking', 'transformation', 'tree', 'twostage', 'type', 'value', 'variable', 'viewed', 'wasserstein', 'approximated', 'argument', 'boundary', 'bounded', 'deriving', 'describing', 'distance', 'drift', 'gamma', 'generalizing', 'height', 'inconsistency', 'infty', 'interfering', 'laplace', 'monotone', 'monotonicity', 'motivated', 'novelty', 'priori', 'reflected', 'vanishing', 'asymptotics', 'bivariate', 'cap', 'coefficient', 'compatibility', 'concerned', 'converge', 'convex', 'derived', 'descent', 'determinant', 'drawn', 'geometric', 'hankel', 'implying', 'instance', 'invariant', 'l2', 'law', 'max', 'normalized', 'pareto', 'penalty', 'singularity', 'slice', 'sparsity', 'square', 'boltzmann', 'bracket', 'cascade', 'constituent', 'equilibrium', 'hamilton', 'hamiltonian', 'map', 'permittivity', 'poisson', 'satisfy', 'analogue', 'linear', 'related', 'building', 'chosen', 'constructed', 'discretization', 'establish', 'inequality', 'lmi', 'lyapunov', 'ro', 'synthesis', 'transitivity', 'winning', 'attained', 'clock', 'graph', 'illustration', 'quantity', 'reynolds', 'think', 'transferring', 'virtue', 'featuring', 'interpretation', 'load', 'multiphase', 'transformer', 'admm', 'aforementioned', 'averaging', 'consensus', 'distributed', 'error', 'frac', 'preconditioning', 'projection', 'restriction', 'scaled', 'subset', 'acceleration', 'additive', 'assumes', 'choice', 'convergent', 'ford', 'formulation', 'interpretability', 'kam', 'article', 'ax', 'intersection', 'pi', 'answer', 'conservatism', 'exploitation', 'infinity', 'restricted', 'optimization', 'adleman', 'assigned', 'atomic', 'attracting', 'avoiding', 'bayes', 'bipartite', 'checked', 'checking', 'choose', 'classify', 'column', 'conservation', 'converges', 'decomposition', 'determines', 'dropping', 'et', 'examined', 'exist', 'filtering', 'formalization', 'fourthorder', 'framed', 'grows', 'harmonic', 'hierarchy', 'highorder', 'iid', 'implies', 'initialization', 'interesting', 'invariance', 'koopman', 'ldots', 'logarithm', 'losing', 'minimization', 'net', 'nonconvex', 'np', 'optimality', 'packing', 'permutation', 'planted', 'proof', 'proportion', 'randomness', 'rearrangement', 'recover', 'regard', 'rendered', 'represented', 'respect', 'routing', 'row', 'scaling', 'scope', 'separated', 'simplify', 'solves', 'splitting', 'throughput', 'timevarying', 'uniform', 'walk', 'adversary', 'axiom', 'constructing', 'copula', 'cut', 'darboux', 'discrete', 'disturbance', 'embedding', 'entry', 'equality', 'estimator', 'ideal', 'interact', 'kortewegde', 'left', 'lorentz', 'observability', 'observable', 'obtain', 'oracle', 'oscillator', 'recovery', 'regularization', 'rna', 'sgd', 'simplicity', 'specified', 'statement', 'subgraphs', 'supervisor', 'symbol', 'tail', 'transmission', 'unifies', 'valuation', 'visiting', 'vries', 'accumulating', 'divide', 'f_1', 'improves', 'obtaining', 'proved', 'syzygy', 'analogy', 'capacity', 'cauchy', 'centralized', 'coincide', 'completion', 'containing', 'coordinate', 'corner', 'directed', 'discontinuity', 'discretizations', 'discretized', 'discretizing', 'elevation', 'euler', 'fails', 'frobenius', 'general', 'helmholtz', 'inducing', 'integral', 'integrands', 'inversion', 'involve', 'involved', 'lagrangian', 'length', 'limiting', 'linearization', 'log', 'log2', 'lowcomplexity', 'maximize', 'minimizing', 'misspecification', 'mixed', 'motivates', 'neumann', 'nonlinearity', 'norm', 'orthogonality', 'page', 'parameterized', 'pca', 'perturbation', 'poly', 'preconditioner', 'quantile', 'reconstruction', 'recovers', 'sci', 'sequential', 'smooth', 'sqrt', 'stopping', 'suffer', 'tensor', 'transmitted', 'union', 'vanilla', 'written', 'perturbed', 'robin', 'asked', 'associate', 'briefly', 'cdot', 'commuting', 'cone', 'coupler', 'digit', 'divergent', 'duality', 'genome', 'genuine', 'guaranteed', 'interpolation', 'lu', 'mcmc', 'meet', 'minimax', 'motif', 'nonzero', 'outlier', 'partitioned', 'piecewise', 'reconstruct', 'satisfies', 'selfadjoint', 'simplex', 'subseteq', 'surrogate', 'tao', 'theta', 'adapted', 'admits', 'applies', 'calculus', 'chi', 'converse', 'covered', 'cutoff', 'delta', 'denote', 'diameter', 'ell', 'equivalent', 'identity', 'k1', 'kept', 'mbox', 'nabla', 'omegasubset', 'phrasing', 'positivity', 'qquad', 'r_0', 'reverse', 'solvability', 'spanning', 'sphere', 'adjacent', 'asks', 'boolean', 'cancellation', 'convexity', 'covariance', 'deduce', 'epsilon', 'exchanging', 'fisher', 'functional', 'leader', 'maximizes', 'minimizes', 'nphard', 'omega', 'regularized', 'regularizer', 'replace', 'round', 'satisfied', 'semigroup', 'simulate', 'straightforward', 'translation', 'visit', 'wireless', 'x_t', 'analog', 'emphasis', 'foundation', 'reweighted', 'seek', 'weighted', 'going', 'chooses', 'automorphism', 'circle', 'denotes', 'discretize', 'joint', 'lebesgue', 'lim_', 'pde', 'cantor', 'cohomology', 'comprises', 'disjoint', 'divisor', 'emphasize', 'exhibiting', 'gp', 'graded', 'holonomy', 'linearized', 'multiplicity', 'multiplier', 'nashmoser', 'pure', 'standing', 'subgroup', 'vorticity', 'coin', 'devoted', 'eigenfunctions', 'n2', 'note', 'sampled', 'satisfaction', 'traveling', 'cover', 'jump', 'optimal', 'parametric', 'riccati', 'sea', 'stabilization', 'normality', 'clarify', 'emph', 'siam', 'summary', 'unperturbed', 'folding', 'alexander', 'algebraic', 'approximating', 'assertion', 'constellation', 'continuity', 'cube', 'leq', 'mathbf', 'minimizers', 'n1', 'nls', 'perfect', 'rogue', 'visited', 'bellman', 'central', 'certificate', 'combinatorics', 'departure', 'eigenvectors', 'f_', 'freedom', 'hilbert', 'hyperplanes', 'ij', 'integrability', 'lecture', 'lipschitz', 'montecarlo', 'simplification', 'stabilize', 'subproblems', 'tomography', 'undersampling', 'unknown', 'formalized', 'adjacency', 'connecting', 'stirling', 'triangle', 'npcomplete', 'polytopes', 'correct', 'admissibility', 'admit', 'autocorrelation', 'componentwise', 'subcategories', 'deformation', 'ellipsoid', 'galerkin', 'governed', 'torus', 'universal', 'evolves', 'saga', 'inefficiency', 'kl', 'kullbackleibler', 'seminar', 'affine', 'derivation', 'drinfeld', 'gl', 'kdv', 'lax', 'putting', 'arbitrary', 'cup', 'bernoulli', 'span', 'congestion', 'glass', 'hamiltonians', 'k2', 'l_1', 'l_n', 'polytope', 'x_n', 'bijection', 'cite', 'ghost', 'nested', 'occurred', 'rainbow', 'simpler', 'stochastic', 'zero', 'coincides', 'finiteness', 'functors', 'generalisation', 'homomorphism', 'integrated', 'jacobi', 'mathfrak', 'recurrence', 'referring', 'retracts', 'worked', 'xxz', 'c_2', 'l_p', 'noetherian', 'riemann', 'appendix', 'arrives', 'attempting', 'better', 'bimodal', 'book', 'coloring', 'distinguish', 'encompasses', 'linearity', 'nlog', 'parametrized', 'puzzle', 'rotated', 'stated', 'substitute', 'thompson', 'tiling', 'waypoints', 'burger', 'hinge', 'dim', 'f2', 'i1', 'indexed', 'kähler', 'la', 'lambda2', 'laplacebeltrami', 'phi', 'setminus', 'skeleton', 'stationary', 'tuples', 'anderson', 'digraph', 'eigenstates', 'identifiability', 'spacetime', 'valued', 'zeta', 'reformulated', 'alphabet', 'isomorphism', 'stein', 'ramanujan', 'coexistence', 'counting', 'indifference', 'peakon', 'container', 'linfty', 'appl', 'neighborhood', 'rational', 'recursion', 'conjectured', 'euclidean', 'half', 'magnetic', 'substituting', 'cayley', 'clause', 'ricci', 'hardy', 'unique']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "community_word = []\n",
    "for i in range(0, total_com):\n",
    "    a=[]\n",
    "    for j in partition:\n",
    "        if partition[j] == i:\n",
    "            a.append(j)\n",
    "            \n",
    "            \n",
    "    print(i,\"------->\")\n",
    "    print(\"Total Words: \", len(a))\n",
    "    print(\"Words: \", a)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    community_word.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "19b57429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------------>\n",
      "{'model': 0.10532511311634746, 'paper': 0.10196576825174695, 'approach': 0.10092456818815873, 'data': 0.10008122663118807, 'proposed': 0.09796911972083842, 'method': 0.09667825767662173, 'work': 0.09665158917146084, 'based': 0.09561996602195139, 'network': 0.09356312328331788, 'learning': 0.09288463557433223, 'performance': 0.09202976081897457, 'provides': 0.09163945533520197, 'analysis': 0.0897516508253345, 'information': 0.08853455848085122, 'algorithm': 0.0878466841940894, 'job': 0.0848450227804734, 'application': 0.08371089742597773, 'use': 0.0831204245432088, 'experiment': 0.08269171718037364, 'feature': 0.08092084131909891, 'training': 0.07953181726439464, 'propose': 0.07871743798293594, 'way': 0.07810016690144876, 'technique': 0.07789011238012905, 'process': 0.07714830566866454, 'existing': 0.0766670658933, 'datasets': 0.07658127799100903, 'machine': 0.07480637377223996, 'input': 0.07390381705931678, 'accuracy': 0.07223809361639963, 'prediction': 0.07222312434853352, 'research': 0.07221588180254536, 'practice': 0.07196865618638443, 'compared': 0.07156649343586538, 'issue': 0.07024408378713813, 'need': 0.0698036633825922, 'dataset': 0.06967631104698663, 'introduce': 0.06933440986835744, 'challenge': 0.0692292250044787, 'image': 0.06901537775823553, 'design': 0.06835642794249061, 'knowledge': 0.06755439135504882, 'control': 0.06715199443170035, 'improving': 0.06710444053973723, 'strategy': 0.06570623453599196, 'address': 0.06552445227946628, 'challenging': 0.06528157898944534, 'tool': 0.06479796383218396, 'cost': 0.06464887430417605, 'question': 0.06440848708726542, 'architecture': 0.06422247727433873, 'facilitates': 0.06362933916179636, 'proving': 0.06302533783323402, 'representation': 0.06287885003563647, 'setting': 0.06281515694821273, 'user': 0.06272149686450515, 'evaluation': 0.062453768434870126, 'focus': 0.061432647062914764, 'classification': 0.06118912949318828, 'addition': 0.060567152455891254, 'perform': 0.06022753099148592, 'ability': 0.059955074807835025, 'community': 0.05856754474374475, 'produce': 0.05849423829167948, 'account': 0.05819139341004856, 'estimation': 0.05799816094580774, 'train': 0.057815095345027115, 'finding': 0.05779827160220809, 'output': 0.057593100780854715, 'called': 0.057485695334723474, 'improvement': 0.05700983632422869, 'goal': 0.05671961507004905, 'learn': 0.05663057528840466, 'code': 0.05617509247211932, 'evaluate': 0.055586641132515324, 'programming': 0.05530776227283068, 'trained': 0.055193909986531536, 'target': 0.054900643116926405, 'requires': 0.05446991489063195, 'language': 0.054352849694338, 'context': 0.05391707482996653, 'knowing': 0.05384419012486286, 'achieves': 0.05370271902741579, 'end': 0.05362247608520385, 'efficiency': 0.053600065026889264, 'implementation': 0.05327825501270875, 'offer': 0.05286000091548374, 'memory': 0.05253273457044062, 'processing': 0.05246871781031501, 'lack': 0.05235212670843646, 'baseline': 0.05228026406332608, 'platform': 0.052250065001647715, 'communication': 0.05203364039416126, 'attention': 0.05198911605613599, 'outperforms': 0.051929705417484276, 'universe': 0.05183038109757164, 'mean': 0.0517010185985012, 'inference': 0.05153454928429876, 'generation': 0.0514288006385282, 'benchmark': 0.05110281928530904, 'area': 0.05097159457629191, 'designed': 0.05086215410709005, 'resource': 0.05018541543901211, 'benefit': 0.05008794528267729, 'sensor': 0.050054036541213695, 'weight': 0.050045621038461725, 'decision': 0.049927578326220544, 'achieve': 0.049696018046178424, 'reduce': 0.049404268006232044, 'quality': 0.04918497972448979, 'capture': 0.049145601983505705, 'making': 0.04896845433012003, 'achieved': 0.04886902584518837, 'support': 0.04873488161507782, 'software': 0.04846251115601547, 'computation': 0.04840372673914673, 'run': 0.04832835948808001, 'risk': 0.04831163144983089, 'effectiveness': 0.04794113747451803, 'security': 0.047887129752744464, 'evaluated': 0.047883505500942274, 'generate': 0.04787927869813148, 'signal': 0.047780099669143726, 'operation': 0.04774351781162435, 'enables': 0.04766935114337977, 'human': 0.047527904046458375, 'node': 0.04752466609162657, 'developing': 0.047422056660307146, 'selection': 0.04735078856502588, 'loss': 0.046865827258180746, 'handle': 0.04608510088936314, 'built': 0.04607064415162311, 'effort': 0.04573817896872336, 'relationship': 0.045634837539905784, 'aspect': 0.04537412603592363, 'technology': 0.04532680761853222, 'face': 0.04521055251566021, 'action': 0.045174043421372406, 'researcher': 0.04498781405115683, 'people': 0.04483320634554873, 'execution': 0.04473286778333482, 'rule': 0.04465228584409556, 'experience': 0.04448310659287338, 'recognition': 0.04433719592464086, 'online': 0.04402052671911252, 'combine': 0.043890581061097604, 'neural': 0.04359491646348925, 'vision': 0.04331065346829832, 'improved': 0.04319523849659423, 'missing': 0.04273864331017357, 'structured': 0.04271849301025372, 'novel': 0.04266254031976193, 'implemented': 0.04262570179865345, 'content': 0.042222597445725485, 'engaged': 0.04215354084587364, 'reward': 0.04210282926325262, 'attack': 0.04182235797059123, 'analyze': 0.04160261331252508, 'performing': 0.04144463355876386, 'policy': 0.04096999985240947, 'capability': 0.040694332571830936, 'service': 0.04057632664177425, 'activity': 0.04046013620680387, 'classifier': 0.040425290852946404, 'shared': 0.04039849368952749, 'insight': 0.03985853444837001, 'leverage': 0.03978873247558855, 'label': 0.03967747582913493, 'applying': 0.03934591938272669, 'camera': 0.03922055458474395, 'methodology': 0.03920902998797701, 'extraction': 0.03884773447229141, 'word': 0.038815627636148625, 'advantage': 0.038717351566846, 'hand': 0.03860475033063227, 'importance': 0.03845825685149262, 'learns': 0.03842862167088839, 'agent': 0.03837741782811724, 'partition': 0.03835486616082912, 'future': 0.03803989203237109, 'providing': 0.03801941075606024, 'collected': 0.037798152973514805, 'proposes': 0.03778666408861499, 'vehicle': 0.03773417787153333, 'predicting': 0.03767563689811516, 'performs': 0.03755727027310382, 'art': 0.0374543330829634, 'game': 0.03744798348548563, 'conducted': 0.037418598855568024, 'attempt': 0.03741607609827197, 'database': 0.03737583682235864, 'interface': 0.0370556661247213, 'collection': 0.037040559517354625, 'expert': 0.03692821179660206, 'testing': 0.03691143261955137, 'recurrent': 0.0369048700409022, 'supervised': 0.03657051551441241, 'perspective': 0.03649848113847756, 'background': 0.03648194791026686, 'explore': 0.03646889276919891, 'document': 0.03633423260473501, 'analyzing': 0.03622761082981525, 'monitoring': 0.0361868242071796, 'body': 0.0360668482972452, 'scalability': 0.03602727779423691, 'promising': 0.035936717191011325, 'deep': 0.03584517223206935, 'employed': 0.03562416487977653, 'manner': 0.0355737586897076, 'requiring': 0.03557143641738187, 'led': 0.035423335536039595, 'focused': 0.03535994145049627, 'acquired': 0.035301683551601515, 'increased': 0.03525711511234457, 'labelled': 0.035116776962495856, 'success': 0.03492431953867177, 'adopted': 0.03489396856904154, 'formulated': 0.03477337817485352, 'multiple': 0.03449613734897596, 'protocol': 0.03448916291024934, 'management': 0.034486122273053504, 'deal': 0.0344651851692213, 'demonstrates': 0.034462833493905706, 'hardware': 0.034081563007248725, 'inspired': 0.033982281401226964, 'cnn': 0.033852353851214795, 'assessment': 0.033820539220764854, 'achieving': 0.033656717840398684, 'investigation': 0.033644543902044945, 'trust': 0.03361966502608489, 'operating': 0.033522264159636474, 'sharing': 0.033492804808928404, 'individual': 0.033491432914130335, 'robot': 0.03324184484033813, 'entity': 0.03323884486004992, 'internet': 0.0332144277559182, 'advance': 0.03304247337176011, 'build': 0.033029806030745984, 'detecting': 0.03301713155994691, 'generates': 0.03257630803448699, 'conduct': 0.03255718845537966, 'ensure': 0.03254225917529339, 'text': 0.032510343467485915, 'detect': 0.03250483888554693, 'produced': 0.03249296882735329, 'tested': 0.0323750648320511, 'carried': 0.032355401985727006, 'prototype': 0.03232945225413119, 'speedup': 0.0322994304094756, 'organization': 0.03226892013843134, 'engineering': 0.03222503921094149, 'decade': 0.03217167292110187, 'scene': 0.03214467866267364, 'integration': 0.03207430047179763, 'opportunity': 0.032073265688409715, 'variance': 0.03200223798436971, 'bias': 0.03191095542132241, 'indicator': 0.031849916452642804, 'mining': 0.031834437274470447, 'difficulty': 0.031768872112529496, 'emerged': 0.03166493333746319, 'identifying': 0.03151828984565931, 'overcome': 0.03141664202547349, 'enhance': 0.03138793269015206, 'behaviour': 0.031376500116845465, 'majority': 0.03133184134237413, 'person': 0.031167804778918003, 'video': 0.031148932441177075, 'feasibility': 0.031143804462063537, 'growing': 0.031086144646687935, 'dealing': 0.031066497153363726, 'modality': 0.030971937254739398, 'tackle': 0.030954169375836123, 'embeddings': 0.03095052594412651, 'validation': 0.03088529691857967, 'validate': 0.030840609189404698, 'accurate': 0.030805505842320734, 'rnn': 0.030719016265235963, 'efficient': 0.03060336106201232, 'iot': 0.030454849389149254, 'release': 0.03036978789096691, 'lstm': 0.030363347016815912, 'variability': 0.030352163274991406, 'robust': 0.030308594581456783, 'brain': 0.030304678735009142, 'url': 0.030246163426261994, 'create': 0.03020413464809005, 'desired': 0.03013460174344002, 'convolutional': 0.030133090438738054, 'student': 0.030101994096676014, 'estimating': 0.029947910959189045, 'optimized': 0.029820986169385857, 'privacy': 0.0297347954834983, 'augmentation': 0.029624750649463766, 'hour': 0.029570755684423064, 'introducing': 0.029492328887120174, 'message': 0.029491026903448073, 'connectivity': 0.02944050859755096, 'introduces': 0.029329807008246403, 'era': 0.029086785855366434, 'facilitate': 0.028988246858437577, 'availability': 0.028881303311651344, 'neuron': 0.028858449563042655, 'adaptation': 0.028721252450132875, 'activation': 0.02871773155089189, 'patient': 0.02869616269381939, 'intelligence': 0.028659060615554142, 'second': 0.02840764333297371, 'creating': 0.028370118792557592, 'kernel': 0.028358456634534474, 'running': 0.02818957962205229, 'industry': 0.028181509887918937, 'annotation': 0.028145446266271083, 'track': 0.02808692614677328, 'bayesian': 0.027995994945671853, 'realworld': 0.027993987036180248, 'market': 0.02791438854566059, 'usage': 0.02790982380537627, 'cycle': 0.027805493895276104, 'outperformed': 0.027754024662868273, 'cnns': 0.02759113904518835, 'dimensionality': 0.027474149895579985, 'sentence': 0.02744107672355863, 'rnns': 0.027413554960019335, 'practitioner': 0.027325312585777483, 'share': 0.027276609670604732, 'supporting': 0.02720489278150321, 'extracting': 0.027117625301312943, 'showed': 0.02711079650416806, 'concern': 0.027082626223720856, 'http': 0.027075982466890393, 'vortex': 0.027056231351325035, 'update': 0.027039196015175675, 'utilize': 0.027036558744281448, 'manipulation': 0.02699558449097819, 'adversarial': 0.026957879776467186, 'feedback': 0.02690752569041903, 'expanding': 0.02686095828491129, 'understand': 0.026743559142431702, 'relevance': 0.026697525411501614, 'sensing': 0.026629722542514004, 'semantics': 0.026595193045018593, 'pass': 0.026511057069173782, 'generative': 0.02648325309368525, 'driving': 0.026462180507397445, 'cancer': 0.02643308014179677, 'adoption': 0.026403702735495523, 'leveraging': 0.026260019465240963, 'emerging': 0.026256113370212338, 'describes': 0.02624297055477373, 'aid': 0.026039706852874857, 'recommendation': 0.02595264636430063, 'health': 0.02590717047335478, 'corpus': 0.025689436282072733, 'participant': 0.02555288826039462, 'society': 0.02553701360656089, 'highlight': 0.025481881751525718, 'lab': 0.0254666893501546, 'gan': 0.025456833401151752, 'utility': 0.025445727677730928, 'maintaining': 0.025264818973689977, 'handling': 0.02516699552621671, 'allocation': 0.025059414640637854, 'post': 0.02498535771267176, 'supervision': 0.0249780876058577, 'attribute': 0.02494050938989766, 'bottleneck': 0.02488943850399716, 'skill': 0.024854912613217407, 'believe': 0.024831708760570448, 'collaborative': 0.024805523376251824, 'designing': 0.024728393045958207, 'company': 0.024676660312841558, 'truth': 0.024665121084407278, 'analyzed': 0.024640428018692387, 'analytics': 0.024616623375079336, 'customer': 0.0245864905790545, 'scientist': 0.02457654017256766, 'tend': 0.02456719842123403, 'thing': 0.024550094870142473, 'github': 0.024543043423932348, 'retrieval': 0.024488953197899083, 'biology': 0.024462314735664924, 'removing': 0.024449922660789516, 'piece': 0.02439288619144589, 'today': 0.02439233392351623, 'popularity': 0.02438019483571063, 'latent': 0.02417736601395241, 'started': 0.024083363347109796, 'equipped': 0.02406197511323375, 'record': 0.02399319639620723, 'acquisition': 0.02395974982066632, 'perception': 0.02393371662455611, 'reasoning': 0.02388278252863756, 'team': 0.023863891464470908, 'competition': 0.02382500050998721, 'gpu': 0.02360197043476413, 'identifies': 0.023560573285422035, 'preference': 0.023556098716822852, 'employing': 0.023497391506780575, 'relying': 0.023438859787808283, 'gans': 0.02338187147308187, 'fail': 0.023369920435295427, 'contained': 0.023333850594229967, 'course': 0.023327122037272788, 'brings': 0.02326486623283007, 'api': 0.023243317344734598, 'collect': 0.023152506180693828, 'playing': 0.023137792351127257, 'life': 0.023137509233449056, 'pixel': 0.02310701746475468, 'guidance': 0.023091292643346906, 'million': 0.023062133287801566, 'safety': 0.023020702501201227, 'adding': 0.022985507006023684, 'long': 0.022963734299490935, 'factorization': 0.022790857167133492, 'utilizing': 0.022778704433838483, 'causal': 0.022765145016845064, 'encoding': 0.022684723927929043, 'optimize': 0.022682515128167522, 'criterion': 0.022502735556941746, 'coherence': 0.022413713441097504, 'verified': 0.02240048368497323, 'consideration': 0.022379233349607133, 'generalize': 0.022333737919879325, 'worker': 0.022293479111519715, 'varied': 0.022248209011211505, 'discovering': 0.022230138553676587, 'explains': 0.02221264986091548, 'validated': 0.021972596212084274, 'alternative': 0.021969033063203847, 'implementing': 0.021930999965813006, 'representing': 0.021872524472794024, 'resulted': 0.021856155892498664, 'file': 0.02179288496906008, 'faced': 0.02178715298912607, 'cortex': 0.02178703069926917, 'boosting': 0.02176514274193143, 'spread': 0.02171358497041941, 'posed': 0.02168079615037528, 'adapt': 0.02165136628212383, 'tradeoff': 0.02162636925753333, 'hope': 0.02151546388599281, 'detects': 0.021426407923733907, 'purpose': 0.02137561845436137, 'objective': 0.021339994256427693, 'batch': 0.021316205563977203, 'extracted': 0.0212811563844077, 'compressed': 0.021267442471062648, 'tailored': 0.021197002822638988, 'expressed': 0.02112240971420307, 'relevant': 0.021110033208607992, 'breakthrough': 0.02107406631211352, 'consumption': 0.021054257660246205, 'labeling': 0.021014897241263385, 'grid': 0.020961361967236084, 'retrieve': 0.02089810247417355, 'expand': 0.02084333621513458, 'evaluating': 0.02072465956516146, 'networking': 0.020720372190937884, 'planning': 0.020597455313515353, 'web': 0.020544507318437155, 'detailed': 0.020543195393509506, 'disease': 0.020475169895514983, 'overfitting': 0.020436630817364996, 'collaboration': 0.020361132762413803, 'demonstration': 0.020341428136172165, 'specification': 0.020243914302674467, 'publication': 0.02013691537259074, 'session': 0.02006983131718277, 'hyperparameter': 0.02003663735855747, 'computational': 0.02001864724106065, 'redundancy': 0.019995309062746713, 'box': 0.01996970386694252, 'news': 0.019945225471783738, 'theme': 0.01990106142289113, 'proxy': 0.019764931762163172, 'occurring': 0.019751477580836597, 'visualization': 0.019705415749118077, 'marketing': 0.01966256428356758, 'suffers': 0.019614717596801907, 'variety': 0.01956512117339502, 'eliminated': 0.01954651807739724, 'annotated': 0.01950603305810271, 'usability': 0.01938915910684506, 'organized': 0.01937805298251739, 'named': 0.019371144883812683, 'cue': 0.0193541264337971, 'complement': 0.019340197646718234, 'university': 0.01932233975242652, 'mri': 0.01929832809883896, 'chance': 0.019296733879270233, 'speech': 0.019289875119057952, 'speaker': 0.019255680134743162, 'discipline': 0.019234731757096217, 'prevent': 0.01920867000509746, 'movement': 0.019163685861205572, 'attributed': 0.01914630007747241, 'superiority': 0.0191351889712567, 'exploration': 0.019110743914032252, 'giving': 0.01910284166842939, 'weighting': 0.019091874390454015, 'balancing': 0.019065481956429035, 'lowrank': 0.018991238178183753, 'integrate': 0.018988430336140623, 'car': 0.01897081284651878, 'personalized': 0.018959334272173122, 'balance': 0.01887015689750321, 'item': 0.01883762008997316, 'segment': 0.018768157749750297, 'check': 0.018760820961020646, 'modelled': 0.018700233438280086, 'tracking': 0.018643675538016883, 'encoded': 0.018627182928277745, 'ranking': 0.01862585132862659, 'portfolio': 0.018619954167885807, 'utilization': 0.018596927440008428, 'proposing': 0.01854220776608791, 'assistance': 0.01852477242025254, 'shortcoming': 0.018508263609533036, 'dnns': 0.018505178026082467, 'adapting': 0.018486063618902634, 'explanation': 0.01837286956002615, 'opponent': 0.0183255827041474, 'likelihood': 0.01831345765812092, 'stream': 0.01828711838738031, 'big': 0.018280288494250854, 'trusted': 0.01827999031830612, 'stop': 0.018274107062058575, 'apps': 0.01827084709541701, 'reflect': 0.01818653760948052, 'aligned': 0.018077489758661955, 'gaining': 0.018055827315617466, 'solver': 0.01802702805340546, 'meaning': 0.01802059464664759, 'care': 0.01801633648300453, 'exceeds': 0.018009736267229137, 'engine': 0.0179967905311687, 'discriminator': 0.01799036784079221, 'reporting': 0.017977125378534034, 'validating': 0.017873974756778065, 'mitigating': 0.017868082498636167, 'centrality': 0.017849490123521165, 'imbalanced': 0.017818834707688615, 'highresolution': 0.017812515048379274, 'applicability': 0.017806699797363473, 'heuristic': 0.017757978206322057, 'expertise': 0.017733888249844284, 'bandwidth': 0.01773099036986011, 'observed': 0.01772643423998159, 'investigating': 0.01771272450191512, 'exposure': 0.017680276030085873, 'forum': 0.01765946863799035, 'capturing': 0.01759443665345906, 'exploring': 0.017566991147356513, 'encode': 0.01736011972982877, 'pilot': 0.017315896086022877, 'separating': 0.017303620509829545, 'library': 0.017302765289897718, 'defense': 0.01726800723439562, 'efficacy': 0.017213451640453202, 'hidden': 0.0171814158621708, 'verification': 0.017151436403703892, 'drive': 0.017147355886636007, 'supposed': 0.017143390884919, 'enhancing': 0.017135831525989333, 'indicated': 0.017074450783114477, 'suite': 0.017036679333368932, 'reality': 0.01696348363296766, 'demand': 0.016928140244513168, 'landmark': 0.0169259302156888, 'endtoend': 0.016867663694515256, 'denoising': 0.016828508356055347, 'vulnerability': 0.016812876882282092, 'footprint': 0.016801003439269234, 'automating': 0.016800896539299903, 'evolved': 0.016746729836788734, 'trick': 0.01671785702466703, 'look': 0.01665300315207676, 'conditioning': 0.016644204624761023, 'convert': 0.016632327307259272, 'predefined': 0.016578181518368536, 'motor': 0.016555956837798712, 'avoided': 0.01654138745266133, 'repair': 0.016532556872621153, 'highquality': 0.016492900477691187, 'paired': 0.01647706570003871, 'partitioning': 0.01643320078025048, 'autoencoders': 0.016431667589021117, 'forward': 0.016395697604835932, 'express': 0.01638617542102, 'hyperparameters': 0.016306788198068835, 'receives': 0.016260188181174685, 'benchmarking': 0.01625291455901156, 'opposed': 0.016238559578767003, 'addressed': 0.016236051498786683, 'guideline': 0.01613898075547913, 'bug': 0.016121132225633213, 'behave': 0.016087243549509446, 'decoder': 0.016086297031181866, 'exploratory': 0.01606268429159834, 'expense': 0.01605560761750684, 'intelligent': 0.01604316296891111, 'cpu': 0.016001141005767983, 'lasso': 0.015999909050237557, 'dilated': 0.015991101678004462, 'partner': 0.01594347654866354, 'dropout': 0.01590940007231901, 'push': 0.015860994160801743, 'spreading': 0.015858507538043513, 'disaster': 0.01584833959891143, 'street': 0.015835816695190665, 'supply': 0.015832527836468695, 'hinders': 0.01582292383282413, 'traffic': 0.015813583922581954, 'layout': 0.015802754159398812, 'burden': 0.015766646593892257, 'consumer': 0.01572467638210473, 'recovering': 0.01571890682320843, 'infrastructure': 0.015687562558880562, 'opensource': 0.015685327984085642, 'versus': 0.015676583433014743, 'toy': 0.015636155080183217, 'sentiment': 0.01561893880502385, 'decomposing': 0.0156104112114368, 'token': 0.01559130807764685, 'specificity': 0.015590932555709225, 'reconstructing': 0.015583212647704065, 'reaching': 0.015581334432429846, 'instruction': 0.01557030267870476, 'boost': 0.015568153143936113, 'optimizing': 0.015561340950906088, 'table': 0.015551878609190436, 'shortterm': 0.015542997264635481, 'grasping': 0.015539921729952739, 'aimed': 0.015534195488887684, 'violation': 0.015527641837841895, 'forest': 0.015492831001485284, 'atari': 0.015464322895449075, 'encoder': 0.015446631409579942, 'occlusion': 0.015384273305876987, 'mnist': 0.015356744890579054, 'autoencoder': 0.01532780647165242, 'assessed': 0.01531041308763144, 'feeling': 0.015290082628510766, 'downloaded': 0.015284567686428871, 'cifar10': 0.015277267885521759, 'hash': 0.015262658766199729, 'living': 0.015262243560093395, 'establishes': 0.01521820309061969, 'social': 0.015188379014078776, 'opinion': 0.015172898577192019, 'multilayer': 0.015172057950738834, 'dollar': 0.015154264248543546, 'diagnosis': 0.015135722582128855, 'imbalance': 0.015114979408545772, 'overlapping': 0.015094395430869907, 'exemplified': 0.014999904157413962, 'assist': 0.014983086808368594, 'format': 0.014936819374457625, 'attacker': 0.014896085089991273, 'ad': 0.01489554085362755, 'owner': 0.014859478318423006, 'player': 0.014849861305803659, 'catch': 0.014831446450397646, 'connectome': 0.014823799595754006, 'maximizing': 0.01481519574681495, 'realtime': 0.01478501739580159, 'explores': 0.014683855809486127, 'python': 0.014668319674291679, 'writing': 0.014654730040140394, 'deploying': 0.014630087301198826, 'offline': 0.014627676991504605, 'figure': 0.01459208614352858, 'gate': 0.0145827643385179, 'transforming': 0.01457745055010387, 'incorporate': 0.014565720776523057, 'generality': 0.01456247716186723, 'locality': 0.014554292122980856, 'discriminating': 0.014542470076490574, 'crowd': 0.014521256318743576, 'fitted': 0.01451360569552168, 'horizon': 0.014506447505654253, 'preserved': 0.014461567975022063, 'pairwise': 0.014434678616798863, 'structuring': 0.014398008832205192, 'finetuning': 0.014396420055739545, 'bridge': 0.014392866913492132, 'selects': 0.01438456098013575, 'thousand': 0.014373906891048439, 'percentage': 0.014369848383436525, 'trading': 0.014353856319421546, 'sound': 0.014345062010992683, 'reallife': 0.014317560100449387, 'investment': 0.01430805281545263, 'selecting': 0.014304338897289584, 'read': 0.014301351598460424, 'svm': 0.014292468109068904, 'learned': 0.014281129212706195, 'saving': 0.014244790012657868, 'explored': 0.014233807614310149, 'imposes': 0.01422118401504923, 'modern': 0.014209328428144256, 'ai': 0.014062225995999645, 'evaluates': 0.01405493084376155, 'correspond': 0.014054189847627583, 'google': 0.014035716473668306, 'offering': 0.014008427544248447, 'intervention': 0.013972126772080136, 'yielding': 0.013942970155917245, 'abstraction': 0.013941272310683428, 'repository': 0.013925737043213853, 'privacypreserving': 0.013921318099949339, 'demonstrating': 0.013876808502657038, 'publishing': 0.013865211582144687, 'advertising': 0.013848584758409652, 'astronomy': 0.013839888341931682, 'incorporation': 0.013838670005073772, 'drug': 0.013837330844326846, 'ui': 0.013811002405627376, 'trait': 0.0137677045429962, 'expands': 0.013760789197191479, 'attribution': 0.013743610637446918, 'distinguishing': 0.013710874633056435, 'principled': 0.013708483845184716, 'revisit': 0.013706401081726044, 'assignment': 0.013700545072598432, 'month': 0.013687572982004606, 'thanks': 0.013662742995688124, 'obesity': 0.013655123659305952, 'unsupervised': 0.013645525852326633, 'encryption': 0.01363359130530886, 'learner': 0.013629694006630695, 'replaces': 0.013606313399934386, 'marketer': 0.013594852742249914, 'gating': 0.013588250915424057, 'extent': 0.013585861302020259, 'scanner': 0.013568787326942411, 'seeking': 0.013563584735180824, 'optimum': 0.013501271393129184, 'referred': 0.013437395553870192, 'feedforward': 0.013423069596425646, 'convnet': 0.013415430413142197, 'synthesize': 0.013400987735898182, 'integrates': 0.013395594689467551, 'envisioned': 0.013392341968830915, 'rv': 0.013358993655503103, 'grouped': 0.013343702031797432, 'app': 0.013338808827097077, 'devise': 0.013331333774823971, 'recognizing': 0.013310183564073623, 'answering': 0.0133054542311296, 'mathematics': 0.013300687653363815, 'modularity': 0.01328391300066138, 'automatic': 0.013270763427715089, 'registration': 0.013242038469518358, 'communicating': 0.013237059715001338, 'kalman': 0.013207539682340702, 'multitask': 0.013207533288910453, 'annotate': 0.01317186052587736, 'lstms': 0.013167615178401792, 'differs': 0.01315756649175114, 'demanding': 0.01314341588600177, 'decentralized': 0.013102031461680935, 'drawing': 0.013098447777080816, 'drawback': 0.013097283871854081, 'agency': 0.013078860117755175, 'english': 0.013064201710595554, 'city': 0.013040368343609688, 'ehrs': 0.01303516228407945, 'retaining': 0.013023743653850967, 'attempted': 0.013021730607697667, 'ecommerce': 0.013014923094393317, 'obtains': 0.012940944220625614, 'comprised': 0.01293820527612072, 'recommender': 0.012902945434795868, 'sent': 0.012900742162027648, 'computes': 0.012870075136830004, 'threat': 0.012861964804618332, 'crowdsourced': 0.012856842279141108, 'sensorimotor': 0.01285280889119369, 'grammar': 0.012820295091803621, 'yielded': 0.012815548891014389, 'fiber': 0.01281203576341773, 'specialized': 0.012808198963463474, 'diverse': 0.0127721550679713, 'misclassification': 0.012738873575956109, 'qlearning': 0.012729263689757405, 'capitalize': 0.012725865766491089, 'crowdsourcing': 0.012719258338945, 'undergoing': 0.012710876554142046, 'analyst': 0.012708137414629535, 'stacking': 0.012706548103344784, 'contributes': 0.012703359745144324, 'summarization': 0.012681325049336447, 'decoding': 0.012666444045598713, 'default': 0.012656720785099433, 'crf': 0.012642660244398248, 'ner': 0.012642660244398248, 'disentangled': 0.012603802130189825, 'dnn': 0.012603648868311494, 'violating': 0.012594773875844963, 'internetofthings': 0.012567200069080497, 'accelerated': 0.012565136265495267, 'collecting': 0.012538275059783058, 'spend': 0.012530623975643924, 'investor': 0.012461124445927571, 'audio': 0.012431266999539661, 'affiliation': 0.012403752499713537, 'iterative': 0.01238675878409865, 'list': 0.012371753014256248, 'retrieving': 0.012362097149889627, 'roi': 0.012330181507873997, 'marker': 0.01232022282536396, 'neuroimaging': 0.012284683928819597, 'currency': 0.012283227210836906, 'auc': 0.012260962192329614, 'reflects': 0.012245407195752355, 'examination': 0.012230480510215093, 'pave': 0.012228889749682302, 'whilst': 0.012227191510003883, 'regulation': 0.012197767413290015, 'labor': 0.012185998567039924, 'rgb': 0.012178726549264968, 'supercomputer': 0.012178444912844389, 'clarity': 0.01217335001832215, 'aim': 0.01216726486881568, 'twitter': 0.012163754660617677, 'modify': 0.012150459070291705, 'citation': 0.012143701591251593, 'weather': 0.012141591297559075, 'soccer': 0.012098462359006237, 'addressing': 0.0120866367691943, 'spot': 0.01208440601297771, 'reconstructed': 0.012078068162878808, 'bridging': 0.012070744925540111, 'feel': 0.01206130743571943, 'gpus': 0.012060993013634948, 'executed': 0.012044205866780112, 'suggestion': 0.012021934526698695, 'animal': 0.01197777714176118, 'succeeded': 0.011969442523144523, 'minute': 0.011962530433406584, 'program': 0.011961758051577114, 'prover': 0.011954302891369204, 'newcomer': 0.011946774022830698, 'timefrequency': 0.01190099124553983, 'tweet': 0.011892896486444949, 'noisy': 0.01187338716166938, 'imagenet': 0.01185986087534015, 'accessed': 0.011819042344531695, 'preventing': 0.011818090450613253, 'reproducibility': 0.011807321607747072, 'turned': 0.011802787985998472, 'mismatch': 0.011776708614346989, 'unconstrained': 0.011758944157032531, 'ignore': 0.011737411931758417, 'spiking': 0.011729027645136381, 'fairness': 0.011701388072813275, 'mobility': 0.011672043475006593, 'android': 0.011659510829966057, 'sacrificing': 0.011658613171079576, 'synchronization': 0.011649160855126788, 'squared': 0.011637436707901096, 'motivation': 0.011631989220346965, 'documentation': 0.011610838723752844, 'correctness': 0.011603772233987694, 'handcrafted': 0.011568491603693882, 'inspiration': 0.01155220745468465, 'hierarchical': 0.011546958321526942, 'printer': 0.011538603129073231, 'printing': 0.011538603129073231, 'caffe': 0.011531158053315232, 'distinguishes': 0.011530335324729555, 'victim': 0.01151565391620013, 'crash': 0.011507573624885584, 'updated': 0.01149211415404851, 'ipm': 0.011479075959077436, 'computer': 0.011458893289196147, 'leastsquares': 0.011429024867105389, 'routine': 0.011414495272000195, 'adaptive': 0.011413211149932547, 'infers': 0.011408763174987515, 'blog': 0.011407485579549516, 'offered': 0.011404026835752014, 'participate': 0.011401074430996853, 'recruited': 0.011391789438628813, 'enriched': 0.011390949653074479, 'developer': 0.011381475256851677, 'cosmology': 0.011380763971251767, 'provider': 0.011369156537768021, 'mc': 0.011362105126891784, 'represents': 0.011357490738101538, 'sending': 0.011331272469178923, 'decouples': 0.011317182134569108, 'lowered': 0.011287057289075714, 'variational': 0.011283929223193798, 'encodes': 0.011252443830555195, 'saliency': 0.011246842230782324, 'understood': 0.01124570611242491, 'merit': 0.011205855866456541, 'inferring': 0.011192829976441117, 'reachability': 0.011188723167790154, 'caption': 0.011182584297915788, 'predicate': 0.01115252540986071, 'asset': 0.011149850144008414, 'confidentiality': 0.011136714368198762, 'preprocessing': 0.011103178223918327, 'ecosystem': 0.011090366248481275, 'option': 0.01108494101963182, 'java': 0.0110675691790997, 'alice': 0.011062518562796062, 'streaming': 0.011039810669307105, 'presenting': 0.01103701482625733, 'convey': 0.011028183773660096, 'steering': 0.011012171388555135, 'concatenation': 0.010991500831538836, 'incident': 0.010989026454996251, 'trustworthiness': 0.01096253759720279, 'stateoftheart': 0.010951783014824327, 'misinformation': 0.010945904906370369, 'citizen': 0.010941127486312853, 'keywords': 0.010940509657390492, 'denoting': 0.01092876437117124, 'relating': 0.01089319600984562, 'optimizer': 0.010893177790394983, 'education': 0.01087646533018051, 'nao': 0.0108428853090119, 'cam': 0.010838117354933133, 'plant': 0.010838117354933133, 'precise': 0.010822867235017302, 'multiplication': 0.010818760696050792, 'emotion': 0.010807900440043086, 'click': 0.01080217514749046, 'hippocampus': 0.010792449244860097, 'establishing': 0.010784867713941453, 'elaborating': 0.010765322859867574, 'exercise': 0.010754756249330246, 'li': 0.01073462102826073, 'imputing': 0.010692946829177409, 'administration': 0.010691455257820956, 'exceeding': 0.010670281822655142, 'belief': 0.010664237759306546, 'executes': 0.010660063687555999, 'justify': 0.010653906235368027, 'bounding': 0.010648180884517919, 'imitation': 0.010640341794474735, 'requested': 0.010623799072833687, 'atlas': 0.01061533275601401, 'javascript': 0.010613361838301921, 'discourse': 0.010610334821153037, 'parallelization': 0.010598719199842049, 'compress': 0.010590309293577576, 'creates': 0.010586102222227608, 'wish': 0.0105856606311028, 'offpolicy': 0.010574453894047339, 'complicated': 0.010563845911951628, 'retraining': 0.01054611057925716, 'prostate': 0.010507782720630573, 'targeting': 0.010506536171251421, 'heterogeneity': 0.010494583373369282, 'excellent': 0.010455109958202582, 'breast': 0.010404678034941712, 'a3c': 0.010393902500414682, 'make': 0.010390069156909178, 'house': 0.010382914048317671, 'acquiring': 0.010380998554232218, 'past': 0.010373547845105718, 'getting': 0.010372145671021387, 'exchanged': 0.010357617050369349, 'integrating': 0.010313444924776476, 'participating': 0.01030094544444206, 'syntax': 0.01029814407919388, 'billion': 0.010293837493785905, 'beijing': 0.010281828482599412, 'tasked': 0.010271238060986499, 'surgery': 0.010259523825771175, 'lesion': 0.010248563605735252, 'alarm': 0.010235312341644928, 'multiview': 0.010207466026661912, 'communicated': 0.0101900419337872, 'smartphones': 0.010169821321809755, 'toolbox': 0.010168975368799635, 'sought': 0.010162271783936033, 'redundant': 0.010154037806388145, 'oversampling': 0.010148962162711873, 'music': 0.010132651840085053, 'transformed': 0.01012974071231212, 'inability': 0.01011694183532135, 'illumination': 0.010091003111998276, 'insert': 0.010072949881640186, 'october': 0.010064079407100942, 'compensation': 0.010058390771451126, 'autonomy': 0.010051852281522004, 'guided': 0.01002779525287105, 'alexnet': 0.010027714582834996, 'resnet18': 0.010027714582834996, 'workflow': 0.010016349554245808, 'collapse': 0.010011575145959836, 'grouping': 0.009992681992113657, 'gaze': 0.009991879641472367, 'compliance': 0.009987706812236466, 'undertaking': 0.009981546636033815, 'minority': 0.00996946395070666, 'handtuning': 0.009959520745723632, 'replicated': 0.009948673548110198, 'desire': 0.009937850110439435, 'navigation': 0.00993278347099373, 'agrees': 0.00992783241015167, 'undirected': 0.009926500508544213, 'networked': 0.009914976457542671, 'rhythm': 0.009851379212453019, 'lda': 0.009845512787501183, 'extrapolation': 0.009844254895883971, 'different': 0.009832321028622188, 'grounded': 0.009829521845023469, 'ridge': 0.009828635692552046, 'bidirectional': 0.00971781777063925, 'credibility': 0.009707750210230974, 'reader': 0.009692071687354142, 'kmeans': 0.00968716157486851, 'contribute': 0.009664102556845681, 'server': 0.009659049464633099, 'encourages': 0.009655412615791347, 'loglikelihood': 0.009639901190048109, 'disclosure': 0.009629568188560847, 'combat': 0.009608534412836179, 'optimisation': 0.009588557600625118, 'regularisation': 0.009583641309867262, 'ct': 0.009582552708875446, 'ensures': 0.009575398225121077, 'multicriteria': 0.009574336884228745, 'wired': 0.009529970984809706, 'biomarkers': 0.009510343648059907, 'night': 0.009473452785178865, 'contend': 0.009470004410808778, 'biased': 0.009467775870802476, 'multiprocessing': 0.009440474924405966, 'deemed': 0.009410710014925796, 'korean': 0.009405140601294304, 'incentive': 0.009393891243287872, 'government': 0.009368825423448773, 'ease': 0.009364870505760143, 'kspace': 0.00933914153353468, 'capable': 0.009273676007331066, 'useful': 0.009271687593240355, 'implicit': 0.00926527572862107, 'contrary': 0.009249052110494971, 'season': 0.009237251584817025, 'omitting': 0.009219470761590017, 'simplifying': 0.009206439756352148, 'characterizes': 0.009185511006887161, 'bootstrapping': 0.009156289713224767, 'played': 0.009140923366355087, 'visibility': 0.00914075143294983, 'directive': 0.009138459853200375, 'movie': 0.009125734523553428, 'recommending': 0.009109439537678135, 'gene': 0.009098638937191709, 'comprehension': 0.009096987740502488, 'characterise': 0.009088815876664087, 'cyber': 0.009058790653873201, 'india': 0.009044071929246174, 'subjective': 0.009044071929246174, 'ambiguity': 0.009041182695999428, 'ratedistortion': 0.009007633890911478, 'stereo': 0.008940189961635226, 'wiener': 0.008927947508816175, 'official': 0.008914739222299494, 'pool': 0.008871678533455928, 'suitability': 0.008784712785802704, 'confirms': 0.008766649638954132, 'bootstrap': 0.008723847543082015, 'dialogue': 0.008720518953362287, 'injury': 0.00870984529912225, 'derives': 0.008667956397913994, 'matlab': 0.00866101717032466, 'mediated': 0.008653080785151139, 'pain': 0.008624678573877408, 'sdn': 0.008616340780499223, 'recommend': 0.008569424173267599, 'accelerate': 0.008560913152329947, 'processor': 0.008541451370406013, 'alter': 0.008517859554693107, 'death': 0.008497304458900283, 'trimming': 0.008495662692875276, 'hmdb51': 0.008494195001693308, 'road': 0.008465001892565069, 'nowadays': 0.008464270819134789, 'rgbd': 0.008462346327089547, 'regressors': 0.008457718519428281, 'restaurant': 0.008422087664068519, 'pearson': 0.008420285263139093, 'school': 0.008410629500286112, 'gesture': 0.008392613477405667, 'occupancy': 0.00839078837520152, 'super': 0.008372519151667, 'reinforce': 0.008371647799423414, 'exception': 0.00836117910255699, 'aperture': 0.008328816175114447, 'tailor': 0.008325669011323117, 'dilemma': 0.008325597382630865, 'business': 0.008308153271844997, 'card': 0.008298865058744904, 'string': 0.008257433721524923, 'resolving': 0.00821824900783902, 'collective': 0.008216766068635912, 'mlq': 0.008214790589369237, 'waveform': 0.008206481691366401, 'ledger': 0.008199322325196337, 'thought': 0.008188009717093514, 'county': 0.008162849922297223, 'phrase': 0.008155095993115636, 'swarm': 0.008147570217195926, 'native': 0.00814674888857121, 'inventory': 0.008125276596791972, 'german': 0.00812464591718579, 'normalization': 0.008122642258003071, 'highaccuracy': 0.008111945056881766, 'axb': 0.00811104484946916, 'hashing': 0.00811104484946916, 'ml': 0.008073607572897117, 'promoting': 0.008061928751292635, 'prevailing': 0.008035235976132751, 'odometry': 0.008030027317139218, 'walking': 0.00802913211655221, 'minimising': 0.008019745770451446, 'prevents': 0.00794660462564145, 'cfd': 0.007935302419976201, 'remained': 0.007930606731230572, 'backpropagation': 0.00793005333054623, 'cluttered': 0.007921276400107096, 'captioning': 0.007903398116883913, 'engaging': 0.00785333157316889, 'weibull': 0.007791051204390007, 'floor': 0.0077848999790697815, 'tso': 0.007778137581255657, 'intel': 0.007764976937613265, 'sequencing': 0.007703668905024022, 'friend': 0.0076792982576637005, 'international': 0.007674328494532743, 'convenience': 0.007672916838162629, 'reviewing': 0.0076633102931680215, 'quantification': 0.007642682716664767, 'changed': 0.007622841543125168, 'winner': 0.007612346701884132, 'diverge': 0.007556557571911287, 'functionality': 0.0075554942899980415, 'trying': 0.007490202671945853, 'contingency': 0.007416622260883092, 'documented': 0.007415975485002831, 'managing': 0.007395808542139292, 'trade': 0.007385835294389866, 'cranknicolson': 0.007347042792446668, 'elbo': 0.007295690572062909, 'defines': 0.007270650220215632, 'exhibited': 0.00722075900469342, 'influenced': 0.007187582818790981, 'grating': 0.0071000351325580064, 'pencil': 0.007076527402345959, 'reading': 0.007068653741527025, 'mechanical': 0.007067793394473728, 'turk': 0.007067793394473728, 'fortran': 0.007060709693232928, 'destabilize': 0.007028543142657233, 'january': 0.007005980635161444, 'blood': 0.006989356593392349, 'adjustment': 0.0069874655253034275, 'prevention': 0.006886394853072746, 'cd': 0.0068724548598924325, 'rain': 0.006869030827928812, 'multilevel': 0.006840933564513271, 'lesson': 0.006800377207691306, 'registered': 0.00675492950697094, 'gnu': 0.006586740711557622, 'decode': 0.006582877061019719, 'inaccuracy': 0.006581849265391217, 'money': 0.006566924622287818, 'gram': 0.0063560122488177705, 'chip': 0.006295821121805634, 'organism': 0.0062747720786892535, 'emulation': 0.006263307450868024, 'layered': 0.006218410861070864, 'slam': 0.006212691729931211, 'ancient': 0.006194663640841378, 'teaching': 0.006102026637538389, 'failed': 0.006100163086534408, 'heavy': 0.006099398487570969, 'slowing': 0.006024952519533198, 'pricing': 0.005952305417368569, 'steered': 0.0059282243960927855, 'league': 0.005924416828722294, 'generalises': 0.005733645004308302, 'outbreak': 0.005687433598838976, 'trader': 0.005582605137695481, 'mexico': 0.0053473491972496, 'bank': 0.004593762973205066, 'credit': 0.004593762973205066, 'illness': 0.0045252355271708355, 'paradox': 0.004495216676728701, 'spectator': 0.0044859205723097395, 'ontology': 0.004396109837617982, 'party': 0.00434520807398178, 'cited': 0.0037512931878736565, 'imported': 0.0033620244339382715}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ------------>\n",
      "{'set': 0.1261188714351734, 'rate': 0.12135560319508157, 'time': 0.12115616676351322, 'observation': 0.11601550611210798, 'present': 0.11373045113258956, 'simulation': 0.11141117000655815, 'distribution': 0.11042239555965667, 'discovered': 0.10517700165067108, 'mass': 0.10346054538727115, 'evolution': 0.09902443748526074, 'num': 0.09892135953998174, 'reference': 0.09852126513844482, 'star': 0.09850601065173431, 'density': 0.09653947645060265, 'mechanism': 0.09618940804961995, 'environment': 0.09464342883409899, 'scale': 0.09378514941107702, 'estimate': 0.09373937329216445, 'measurement': 0.09136725979315315, 'region': 0.0874440297026847, 'survey': 0.08734039450073476, 'galaxy': 0.08723975813662393, 'measure': 0.08682127725499553, 'including': 0.0865862108657769, 'lead': 0.08556067631086912, 'emission': 0.08532203974012713, 'year': 0.08439663162926474, 'component': 0.08427721417586606, 'sample': 0.08404924709701342, 'formation': 0.08338682585312754, 'identify': 0.08287069719228986, 'gas': 0.08171794550561434, 'discus': 0.08140957138608737, 'contribution': 0.08130517056327727, 'detection': 0.08036232062082517, 'period': 0.07981697477821198, 'resulting': 0.07904749832646021, 'magnitude': 0.0790148573004374, 'provided': 0.07754726859761886, 'required': 0.07746598229272929, 'object': 0.0772625991871848, 'presented': 0.0770167313816994, 'cluster': 0.07637643666496176, 'search': 0.0755512007992048, 'telescope': 0.07506340397102874, 'luminosity': 0.07380052615557754, 'spectrum': 0.07281344093672251, 'population': 0.07189021611288593, 'line': 0.07133576709438297, 'report': 0.07069761847852872, 'yield': 0.07026178204083143, 'suggest': 0.07001341622139978, 'particle': 0.06989850783707217, 'velocity': 0.06986059869661455, 'medium': 0.06871705955949967, 'understanding': 0.06823499553448034, 'galactic': 0.06730478111501229, 'dust': 0.06653592488348785, 'impact': 0.06649005391510004, 'identified': 0.06616435405743469, 'according': 0.06612543367903811, 'event': 0.0660587917693825, 'separation': 0.06572980026562432, 'characteristic': 0.06560604562330434, 'fraction': 0.0655743474951492, 'candidate': 0.06546022461311557, 'agreement': 0.06478826465942622, 'ratio': 0.06471489641651526, 'hole': 0.0645001108540948, 'standard': 0.06407074796736408, 'combining': 0.06396245945086647, 'instrument': 0.06388796290022464, 'al': 0.0633744709220132, 'correlation': 0.06295185850008304, 'redshift': 0.06246640666057023, 'dependence': 0.061931740222223274, 'position': 0.061810615549917715, 'disk': 0.06103846217528401, 'evidence': 0.06041704843900335, 'speed': 0.06029831049346805, 'cross': 0.060260658425524895, 'flux': 0.06020368453628482, 'mission': 0.06012778803730006, 'resolution': 0.060019755156227726, 'predicted': 0.05953278519461678, 'uncertainty': 0.05944805473392222, 'sensitivity': 0.059367646542296364, 'detected': 0.05901793858393192, 'motion': 0.05886142312964197, 'precision': 0.05819503604582736, 'play': 0.05722496471866431, 'location': 0.05713495780108138, 'ring': 0.056112104383277746, 'science': 0.05610707260440905, 'enhanced': 0.05577071596886619, 'world': 0.05575841845224431, 'site': 0.0556662748090477, 'curve': 0.05517907018392932, 'constrain': 0.054989168751666935, 'growth': 0.054434512092337656, 'gained': 0.05441621569128349, 'limited': 0.054228107648035796, 'underlying': 0.053950492214861735, 'explain': 0.05379817105546529, 'radiation': 0.053318983213833, 'follows': 0.053010202512546255, 'generating': 0.052526979109162576, 'cloud': 0.052414926556474686, 'embedded': 0.052382097014919214, 'link': 0.05202593221215294, 'pressure': 0.05149613615469829, 'taken': 0.05139719368577161, 'fast': 0.051257132184024584, 'observatory': 0.05107980881738966, 'possibility': 0.050340586625725756, 'probe': 0.05013186299063187, 'alpha': 0.05010727929762914, 'assuming': 0.050028396909426134, 'comparing': 0.049978714102777426, 'dark': 0.04979932179588156, 'combined': 0.049498808559342175, 'simulated': 0.04927102878620686, 'peak': 0.04898510804223219, 'hold': 0.04875001169308419, 'discovery': 0.04864479738109142, 'fit': 0.048611154381716745, 'spectrometer': 0.04820406539759612, 'spectroscopic': 0.04807880997262728, 'occurs': 0.047715302385611544, 'host': 0.04741460865996679, 'dense': 0.047387711259433675, 'day': 0.047179185063727584, 'carlo': 0.047119353360344764, 'monte': 0.047119353360344764, 'selected': 0.046808944739901784, 'fitting': 0.0466557681395807, 'light': 0.04655722549198629, 'average': 0.04644010042767941, 'enabling': 0.04621982064490487, 'consisting': 0.045783332722317605, 'sky': 0.04530811122343681, 'laboratory': 0.04503832111968116, 'color': 0.044840229621707035, 'radius': 0.04429035079527814, 'surrounding': 0.0442540782006251, 'allowing': 0.04400732331149658, 'deviation': 0.04389484165924503, 'conclusion': 0.043532834137143456, 'member': 0.04352877347401733, 'mixing': 0.043344110085897274, 'suggesting': 0.04332623858025431, 'dwarf': 0.043205952635768055, 'transient': 0.043034583798070826, 'profile': 0.04283771785730775, 'duration': 0.042574141873299644, 'association': 0.04232579685266352, 'start': 0.04231370191026021, 'seen': 0.042312334631375445, 'history': 0.04202532143513328, 'orbit': 0.04195227867934476, 'dominated': 0.04184192138836654, 'rm': 0.04178770126726048, 'grain': 0.04157697479806953, 'width': 0.041475864546133674, 'episode': 0.041279703277854775, 'counterpart': 0.041181465783881654, 'radio': 0.04099617117739899, 'remove': 0.04098915888318618, 'represent': 0.040922583561239484, 'fourier': 0.04087122612404774, 'constrained': 0.04072846421995118, 'explorer': 0.04068494617460401, 'carry': 0.040673292683054106, 'planet': 0.04067087985239344, 'm_': 0.040604976787490275, 'uv': 0.04002028554922077, 'automated': 0.03995889277997319, 'nucleus': 0.03950204805906562, 'expectation': 0.03907167445099625, 'package': 0.039055516255959655, 'abundance': 0.038878536406967236, 'dispersion': 0.038765238754514326, 'resolve': 0.03873248551874415, 'refining': 0.03864810913784293, 'mesh': 0.03812372664478437, 'moving': 0.038106265895267895, 'markov': 0.0380945966861815, 'published': 0.03801116946910641, 'rotation': 0.03790117188059711, 'depth': 0.037694306391766234, 'appear': 0.03753990638659673, 'imply': 0.03739473534648393, 'plasma': 0.03716928955421712, 'giant': 0.036899647288845136, 'quantify': 0.03668797026273728, 'covering': 0.036627466386824716, 'stage': 0.03656634860637095, 'cooling': 0.03626104559731511, 'accretion': 0.036161432154703424, 'turbulent': 0.03614821838950965, 'key': 0.03613420779950582, 'localization': 0.03610853226065922, 'core': 0.035878434822154776, 'avoids': 0.03534326046834262, 'wavelength': 0.03524002688043551, 'thermal': 0.03515793278076275, 'depend': 0.034750567121837724, 'searching': 0.034600735223591035, 'faint': 0.03446398890776607, 'orientation': 0.03436218708532252, 'reservoir': 0.03432160422758692, 'coverage': 0.034211816644308425, 'turbulence': 0.03420393575333386, 'age': 0.03410896751820842, 'affect': 0.033951600017006554, 'mu': 0.03389365893993321, 'grow': 0.033841606262954876, 'followed': 0.0336901635207681, 'timescales': 0.03354911552592242, 'shed': 0.0335398286536368, 'gravity': 0.033496170936018206, 'timing': 0.03349379280792261, 'specie': 0.03329783337179279, 'observe': 0.03328298444457268, 'chemical': 0.03314053277892903, 'water': 0.03313546889247152, 'working': 0.032979114273143637, 'allowed': 0.03284303296449473, 'nuclear': 0.032827972613078724, 'burst': 0.03277153135299313, 'reproduce': 0.03276093833716595, 'inferred': 0.03267554937646384, 'le': 0.03230716606041152, 'fusion': 0.03223412764501828, 'minimum': 0.03221706372777938, 'arm': 0.03220216559569841, 'hemisphere': 0.0321637368208166, 'plan': 0.03212991289233993, 'indicates': 0.032066664725488525, 'affected': 0.03183123132159558, 'emphasizes': 0.03177018024858676, 'delay': 0.0317255416914489, 'formed': 0.031669793240544086, 'fainter': 0.031113355765868028, 'satellite': 0.031051847936991093, 'binary': 0.030736771143647573, 'absolute': 0.03072960366290897, 'forming': 0.03070782255501628, 'targeted': 0.03065348381857974, 'lifetime': 0.03054042155279239, 'controlled': 0.030516277987657957, '_odot': 0.03031546968801625, 'subsamples': 0.030286192840867622, 'continuum': 0.03025656646781863, 'xray': 0.030222543510909843, 'explosion': 0.030202098235058587, 'gev': 0.030160367064649397, 'prior': 0.030108633205845052, 'cold': 0.02992893304466544, 'date': 0.02981667056239075, 'serve': 0.0295880267423053, 'flight': 0.029268676613356172, 'diagnostics': 0.029237546335154463, 'kev': 0.029178224588237645, 'modeled': 0.02913497633099265, 'proposal': 0.02904448223889397, 'spectrograph': 0.02900603133093378, 'evolving': 0.02877134116066594, 'morphology': 0.02874006226036658, 'projected': 0.028586080566552752, 'compression': 0.028347610515125646, 'hi': 0.028268275428248165, 'observing': 0.02818986500550704, 'shorter': 0.028085888873460106, 'locate': 0.028069634443641075, 'damped': 0.027950527920680136, 'creation': 0.027947982189781187, 'outer': 0.027798837760727023, 'attenuation': 0.0277147184600218, 'absorbed': 0.027660104481824464, 'approx': 0.02759220362676851, 'filament': 0.027585857248816854, 'confirmed': 0.02742922313531875, 'resultant': 0.027384751538002253, 'spiral': 0.027272706957904066, 'reliability': 0.02719734044494008, 'condensed': 0.02710140794731564, 'gyr': 0.02705631267495082, 'parent': 0.02704468075318621, 'mock': 0.02704247512415632, 'exceed': 0.026981180066176936, 'corona': 0.026960501198229497, 'supernova': 0.02689116451354354, 'fuel': 0.02670698527330722, 'solid': 0.026632646815584422, 'quasar': 0.026523489487703965, 'powerlaw': 0.026498418992330325, 'released': 0.02628126266180436, 'follow': 0.026077851101694537, 'institution': 0.025885296539384428, 'digital': 0.025819388610731093, 'ly': 0.025802986227272007, 'mimicking': 0.025716946717828346, 'crust': 0.02567734464118325, 'loading': 0.025623627972094557, 'matched': 0.02552166776433735, 'ionized': 0.02548859682355792, 'midplane': 0.025471652589006046, 'm33': 0.02539955547947793, 'inactive': 0.025392496710135062, 'neglected': 0.025358780640916352, 'illustrating': 0.02520375103016369, 'bubble': 0.025151459292512474, 'took': 0.02508735634928395, 'shell': 0.024951479046981837, 'herschel': 0.024898754526642666, 'cosmic': 0.024843525330497742, 'injecting': 0.02482446000862418, 'r_': 0.024791736454154802, 'cm': 0.02478688856137013, 'friction': 0.02469189041948965, 'decaying': 0.02439764970660078, 'converted': 0.024395732390608407, 'recorded': 0.024392264271278243, 'em': 0.02411082420381829, 'prone': 0.02406782197982534, 'extreme': 0.02405857980489851, 'dissipation': 0.0239140100233375, 'lyman': 0.023617109957756816, 'governing': 0.023557520782670933, 'young': 0.02350938389727955, 'sd': 0.023489858705539903, 'alignment': 0.02346380574404723, 'dozen': 0.023447281404319398, 'arrival': 0.023317228421561493, 'iv': 0.023286828026473545, 'cooled': 0.023284089544726938, 'bin': 0.023212052223966294, 'ghz': 0.023208387677773664, 'catalog': 0.023163173054904142, 'parametrization': 0.023145870951948467, 'andor': 0.023137645876523238, 'treated': 0.023137326162370943, 'neutrino': 0.023121511963882766, 'classified': 0.023086833698241473, 'textit': 0.0230351178641599, 'lasting': 0.022991300406279978, 'repeating': 0.0229627707165384, 'undetected': 0.022936012323148524, 'scalar': 0.02292280731670868, 'truncated': 0.02286335302778014, 'competing': 0.022794817433864377, 'molecular': 0.022776029551186835, 'extending': 0.02276102805649923, 'looking': 0.02275200801572672, 'japan': 0.02273848989922301, 'dominating': 0.02272750618493169, 'mathrm': 0.022692958273258138, 'significance': 0.02267172290674131, 'local': 0.022597097061126573, 'astrophysics': 0.022523992579614738, 'sloan': 0.022453216553930972, 'good': 0.022347158219081887, 'brighter': 0.02233047665550351, 'sun': 0.02225275289115823, 'doppler': 0.022203015711402416, 'm_odot': 0.02216040440113393, 'msun': 0.022145353085567032, 'tev': 0.022133906000500747, 'xrays': 0.02212916267021764, 'slope': 0.022027887779946888, 'observables': 0.021861383956669315, 'millimeter': 0.021798713627375673, 'chemistry': 0.021794108040913897, 'calibration': 0.02178181157290474, 'collapsing': 0.021774316357401922, 'agree': 0.021749559376649973, 'cherenkov': 0.021695560956452264, 'accounting': 0.02165249950177107, 'catalogue': 0.021579138755669, 'mounted': 0.021557179835895716, 'kpc': 0.02155713564824605, 'evolve': 0.02152464721735755, 'decreasing': 0.0215172830779708, 'indication': 0.021347539594224255, 'regarded': 0.02105662570750808, 'tilting': 0.021029132354069963, 'mw': 0.02100865409361992, 'extinction': 0.021002061471934452, 'disappears': 0.0209647696333706, 'onset': 0.020913452783618596, 'centered': 0.020882836491648696, 'recognized': 0.020879285534212474, 'photometric': 0.02074112412326071, 'moon': 0.020662165161900743, 'mitigated': 0.02055745776826091, 'contamination': 0.02035830610983922, 'operates': 0.020287227077623326, 'picture': 0.020245226306777497, 'speciation': 0.020155308887267392, 'dusty': 0.020097277743829873, 'albedo': 0.020073784850178435, 'recording': 0.0200696093627234, 'exoplanets': 0.020053777401351894, 'jupiter': 0.020053777401351894, 'lens': 0.02003936879212484, 'spanned': 0.01994477077603346, 'comet': 0.01994222649920562, 'operated': 0.01987748164151096, 'pm': 0.019819076363656124, 'millisecond': 0.01981684921288118, 'climate': 0.01980040148209786, 'prepared': 0.01971189540114548, 'infrared': 0.01964740990247418, 'firstorder': 0.019643662796740482, 'stored': 0.01963504816989993, 'blue': 0.01961548845929885, 'migrate': 0.0195118550758806, 'resonant': 0.019412706926341533, 'kepler': 0.019388376354623277, 'occultation': 0.01924742666461599, 'lag': 0.019122955299577197, 'leave': 0.019121279315426443, 'parametrizations': 0.019054846084554208, 'astroparticle': 0.0189397141288219, 'actor': 0.018876741802064778, 'einstein': 0.018842623254896933, 'asteroid': 0.018841175429782947, 'subtraction': 0.01882086061862457, 'undergo': 0.018818021756052277, 'prevalent': 0.018787568763855955, 'status': 0.01875130199016724, 'balloon': 0.01872876718482805, 'processed': 0.018665887196601266, 'odot': 0.018655508664408287, 'operate': 0.018633060814031308, 'annihilation': 0.018567875371629856, 'autoignition': 0.018564868236699162, 'ignition': 0.018564868236699162, 'contributed': 0.01856252496910176, 'timescale': 0.01852928845415979, 'analysed': 0.01840055513296967, 'maintained': 0.01828076150097342, 'saturn': 0.018154376623735046, 'adopt': 0.01813904745216744, 'claim': 0.01811214714589107, 'synergy': 0.018052579760869818, 'added': 0.018040235262692928, 'varies': 0.017949282649735117, 'emitter': 0.017854788073210386, 'stacked': 0.017847372128053214, 'overview': 0.017816196368996118, 'appearing': 0.017768484649408604, 'exclude': 0.017704391871944954, 'spatial': 0.017703586022592536, 'believed': 0.01759753482355984, 'collider': 0.01759017554117793, 'consortium': 0.017543200447781727, 'rosetta': 0.017530251424457615, 'tension': 0.01752674006486224, 'planck': 0.01750615083333524, 'primitive': 0.017359968761768867, 'week': 0.01717487604380194, 'relied': 0.017019458942477188, 'sn': 0.016967656042969324, 'apache': 0.016914374646177743, 'large': 0.016911409355127485, 'correlate': 0.01684464928545581, 'absorbing': 0.016843673803698184, 'budget': 0.01684061977289374, 'transiting': 0.016764076161385064, 'assembly': 0.016742840473055125, 'fragment': 0.016736290613645052, 'board': 0.016635725929467205, 'tube': 0.01660832760079013, 'originates': 0.016598667024571197, 'anchored': 0.016584370435926362, 'ray': 0.0164420043480883, 'pathway': 0.016426082222904797, 'included': 0.016365829547662417, 'organic': 0.016271542506383758, 'landscape': 0.01621472988120794, 'launched': 0.016200266643013037, 'rest': 0.0158751003737738, 'sim': 0.015866687300832547, 'escape': 0.015857395311211032, 'hr': 0.015776083784519782, 'goodnessoffit': 0.01576457736604778, 'ec': 0.015762151287622872, 'massive': 0.01572310992637809, 'inclination': 0.015694234385041698, 'x1': 0.015684317290072778, 'reviewed': 0.015576634221837993, 'river': 0.015574700734526594, 'lambda': 0.015494883659403744, 'neptune': 0.015475073084294053, 'clustering': 0.015469617515989234, 'confounding': 0.01545354739868784, 'meteorite': 0.015425614991163097, 'deposition': 0.015410106273647499, 'battery': 0.0153789441947908, 'november': 0.015202070350739914, 'distinct': 0.015161355000161376, 'affecting': 0.01509634354462669, 'harvested': 0.015049202933880297, 'sigma_8': 0.01503430649134339, 'coherent': 0.015008679325094735, 'pv': 0.014998041697924566, 'summer': 0.014989816795655383, 'basin': 0.014862424125508316, 'fading': 0.014830620106063987, 'extrapolated': 0.014796510116592892, 'diffuse': 0.014792647489061048, 'interpret': 0.014786038356305639, 'pid': 0.014758265252057187, 'wind': 0.014733068443152924, 'optimised': 0.014728408454742268, 'photometry': 0.014666273817231169, 'chamber': 0.014624902418122369, 'spectral': 0.014610279029547936, 'favor': 0.014550376144048851, 's_': 0.014534773397815098, 'fragmentation': 0.01440053224501331, 'overestimation': 0.01440053224501331, 'simultaneous': 0.014285493829858326, 'mev': 0.014237926167506604, 'percent': 0.014201635610890863, 'intended': 0.014185792818629146, 'incidence': 0.014084070430568672, 'kinetics': 0.013994270757963797, 'swing': 0.013963087247361698, 'calibrated': 0.013945719322810073, 'moonlet': 0.013878841447579147, 'moonlets': 0.013878841447579147, 'pdf': 0.013867218625577462, 'streamwise': 0.013771894628136109, 'phi_': 0.013753564359687694, 'propagating': 0.013725846696880465, 'covariates': 0.013612454683535257, 'viewing': 0.013609379365789353, 'crowding': 0.013490358270969303, 'hst': 0.013485897864167963, 'license': 0.013475941515922057, 'bright': 0.013382278240493919, 'orbital': 0.013184613168988467, 'nh': 0.01312008303634222, 'psf': 0.013118514440736351, 'dynamo': 0.013108645597487182, 'polarisation': 0.013052014927237517, 'heated': 0.012950422161476443, 'enclosure': 0.01294417480375132, 'cdm': 0.012941580042274374, 'jet': 0.01262106839659503, 'connect': 0.012580901017343053, 'z3': 0.01258034460672507, 'differentiating': 0.012536244484969511, 'preparation': 0.01252605574759903, 'hill': 0.012500674992187872, 'pointing': 0.012478528112693153, 'logarithmic': 0.0124631514048727, 'oxygen': 0.012276433325544239, 'superposition': 0.012254109308414196, 'furthermore': 0.012215574514065875, 'mdp': 0.012199981635238576, 'shifted': 0.012153375866727371, 'remote': 0.012147117256923926, 'ultraviolet': 0.012136103037739866, 'retains': 0.012128810468898306, 'prime': 0.01180127857341874, 'texture': 0.011648459772230085, 'marginalizing': 0.011507868131142294, 'bt': 0.011421494146469723, 'receiving': 0.011331279685861652, 'revealing': 0.01125371338658851, 'century': 0.011215382578633148, 'hubble': 0.011211188762481469, 'amended': 0.010976230169495949, 'ch': 0.01086899493915979, 'punishment': 0.010742740822869195, 'plot': 0.0107248527326944, 'analyse': 0.010699208109223934, 'principal': 0.010691423021963952, 'compiled': 0.010653404097944881, 'depletion': 0.010644279230731859, 'branch': 0.010622688173316668, 'choosing': 0.010163490833235334, 's2': 0.010063957976778845, 'keeping': 0.010008363427843366, 'lensing': 0.009906193281800839, 'relativity': 0.009795409677400894, 'silicon': 0.009560623654949729, 'prescription': 0.009502364105681045, 'seed': 0.009333950261371831, 'hide': 0.008988535563625983, 'homogenization': 0.008896341504952577, 'crime': 0.008664851206136755, 'primary': 0.008599318405327993, 'merging': 0.008590118494955013, 'gathering': 0.008209902597716593, 'cooperating': 0.008155478979096593, 'inappropriate': 0.007937088938035797, 'arrangement': 0.007534176274621781, 'yz': 0.007499681248836806, 'interferometer': 0.00742237285776494, 'subregion': 0.007277862243119647, 'examining': 0.0072759533139808395, 'brazil': 0.007260706678540101, 'lifting': 0.006836109889523155, 'terminology': 0.005997380022178253, 'instrumentation': 0.005908767863995041, 'solar': 0.005137558220755246}\n",
      "\n",
      "\n",
      "2 ------------>\n",
      "{'adopts': 0.15249857033260467, 'barrier': 0.15249857033260467, 'cache': 0.15249857033260467, 'cause': 0.15249857033260467, 'command': 0.15249857033260467, 'dedicated': 0.15249857033260467, 'delivered': 0.15249857033260467, 'dispatch': 0.15249857033260467, 'eliminating': 0.15249857033260467, 'enabled': 0.15249857033260467, 'enforcing': 0.15249857033260467, 'ensuring': 0.15249857033260467, 'epoch': 0.15249857033260467, 'exploiting': 0.15249857033260467, 'filesystem': 0.15249857033260467, 'flash': 0.15249857033260467, 'guaranteeing': 0.15249857033260467, 'implement': 0.15249857033260467, 'imposed': 0.15249857033260467, 'ingredient': 0.15249857033260467, 'io': 0.15249857033260467, 'journal': 0.15249857033260467, 'layer': 0.15249857033260467, 'level': 0.15249857033260467, 'module': 0.15249857033260467, 'mysql': 0.15249857033260467, 'overhead': 0.15249857033260467, 'preserve': 0.15249857033260467, 'preserving': 0.15249857033260467, 'relaxing': 0.15249857033260467, 'request': 0.15249857033260467, 'resort': 0.15249857033260467, 'root': 0.15249857033260467, 'scheduler': 0.15249857033260467, 'scheduling': 0.15249857033260467, 'smartphone': 0.15249857033260467, 'stack': 0.15249857033260467, 'storage': 0.15249857033260467, 'strength': 0.15249857033260467, 'thread': 0.15249857033260467, 'transaction': 0.15249857033260467, 'transportation': 0.15249857033260467, 'write': 0.15249857033260467}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ------------>\n",
      "{'consequence': 0.1346594154098533, 'study': 0.1328409795093879, 'state': 0.12475156718076676, 'field': 0.1221139599460664, 'interaction': 0.1181253797293613, 'effect': 0.11795084942496425, 'order': 0.1149973075131323, 'property': 0.11234552246693545, 'phase': 0.110621323560561, 'energy': 0.1100454165031105, 'change': 0.10567578512848365, 'structure': 0.10388342764420956, 'theory': 0.10235895687433762, 'temperature': 0.09871914330016297, 'dynamic': 0.09834278273263554, 'transition': 0.09799224470478177, 'degree': 0.09443861361742106, 'spin': 0.09256732500858725, 'quantum': 0.09223323190297006, 'factor': 0.09017714422220173, 'matter': 0.0885159993118121, 'pairing': 0.0866720721389098, 'calculation': 0.08630867427388192, 'material': 0.0861949290914919, 'behavior': 0.08580162492625722, 'symmetry': 0.08573367436973096, 'response': 0.08434025160520589, 'electron': 0.08411836907818637, 'wave': 0.0835727461171055, 'decrease': 0.08313160312107228, 'surface': 0.08232826307887638, 'measured': 0.08194173709116655, 'increase': 0.08072159796956391, 'group': 0.08038010729514986, 'studied': 0.07652240724022553, 'volume': 0.07647140445865791, 'gap': 0.07612562520577765, 'performed': 0.07521956839858518, 'developed': 0.07472604299002071, 'presence': 0.07359068115786495, 'mode': 0.07297781578285328, 'exhibit': 0.07225098334630206, 'basis': 0.07189788043199324, 'characterized': 0.07147142556553031, 'investigate': 0.07141750737947475, 'resonance': 0.07086587782722466, 'coupled': 0.07069088711884242, 'liquid': 0.0699704747408348, 'description': 0.06975629914350231, 'charge': 0.0697523874309276, 'applied': 0.06887942700315866, 'development': 0.06871728087071452, 'device': 0.06838767638462012, 'influence': 0.06797897594789648, 'described': 0.06795554710693237, 'regime': 0.0678738529089175, 'direction': 0.06758899058315435, 'scattering': 0.06751980912247738, 'transfer': 0.06720411122420371, 'edge': 0.06719514194692565, 'phenomenon': 0.0671580223567724, 'lattice': 0.06605352407015491, 'superconducting': 0.06584818401818385, 'contrast': 0.06417649532166365, 'physic': 0.06289723967350165, 'reveals': 0.0627312860799248, 'excitation': 0.06246747370267798, 'include': 0.062293958969764036, 'configuration': 0.06228973066429642, 'atom': 0.06172224763962801, 'chain': 0.06104417278810348, 'principle': 0.06035920352322068, 'pair': 0.06008402924062887, 'generated': 0.059887658783246575, 'discover': 0.05967906130280124, 'reduced': 0.05927383070691625, 'remains': 0.0586273667251714, 'demonstrated': 0.05792058751212146, 'depends': 0.05784061981163519, 'topology': 0.057706898630618494, 'investigated': 0.05749037976660095, 'signature': 0.05728293714971737, 'insulator': 0.056874881720076265, 'connected': 0.05677079517380884, 'shape': 0.05645334466148361, 'instability': 0.05617740997744477, 'expansion': 0.05579415780643049, 'photon': 0.055623663037101014, 'spectroscopy': 0.05538349347518079, 'comparison': 0.055267627091545514, 'amplitude': 0.05518944907189883, 'extended': 0.05511855672022629, 'fluid': 0.05430848304759259, 'decay': 0.05382826044931428, 'implication': 0.053382462277426455, 'correlated': 0.053318533123705346, 'polarization': 0.05302274911300172, 'established': 0.05289892615512387, 'exchange': 0.0527409574195671, 'suggests': 0.052282465289687094, 'imaging': 0.05216717801944228, 'consists': 0.052105563779051636, 'magnetization': 0.05189403349605318, 'discussed': 0.05172942663171789, 'intensity': 0.05163741474119911, 'increasing': 0.051478368365661636, 'rise': 0.051361335659202985, 'includes': 0.05130439700835601, 'disorder': 0.05120998594648799, 'nature': 0.05113793195300676, 'doping': 0.05111766567394853, 'angle': 0.05108627486906944, 'diagram': 0.05108134791439747, 'modulation': 0.051074844372334526, 'compound': 0.05100360428502639, 'relaxation': 0.05095202054039852, 'frequency': 0.05078513010208984, 'fermi': 0.050540388399146735, 'ion': 0.050202147101545386, 'correction': 0.05011051530243248, 'moment': 0.049811094824056996, 'shift': 0.049019007905227466, 'fluctuation': 0.04872305558378705, 'array': 0.04869425479016244, 'transmit': 0.048672365103552634, 'predict': 0.04859601341733243, 'ordering': 0.048565849511667765, 'momentum': 0.04840167898101354, 'treatment': 0.04807062263160034, 'mixture': 0.047567057911301266, 'driven': 0.04739425899024783, 'fermion': 0.04734614758135624, 'oscillation': 0.04707072366504964, 'reach': 0.04689330978833231, 'concentration': 0.046759240468998035, 'resistance': 0.046729255179667126, 'section': 0.04643069868248829, 'induced': 0.046207095153966565, 'depending': 0.04618627834350206, 'composed': 0.04594646762546466, 'cell': 0.04584431596601826, 'potential': 0.045705843772893856, 'propagation': 0.04527383026424689, 'vicinity': 0.04526480824170445, 'trajectory': 0.04489760438007568, 'induces': 0.04453286936149539, 'constant': 0.043561919235605706, 'arising': 0.043175084993227836, 'arises': 0.04300876757607581, 'quasiparticle': 0.04289398205668981, 'introduction': 0.04242363964616748, 'neutron': 0.042104919091106544, 'argue': 0.041953757027004566, 'heat': 0.04193471723747984, 'defect': 0.04172662632305339, 'setup': 0.04172616768240617, 'laser': 0.04166759502952004, 'replaced': 0.04160454849045423, 'threshold': 0.041592463682517525, 'curvature': 0.04117786008256491, 'ev': 0.0411038665104205, 'indicating': 0.04104045508017788, 'confirm': 0.040987133474538945, 'suppressed': 0.04091456568440017, 'reported': 0.040841588689796676, 'neighbor': 0.040820253335325137, 'coming': 0.040776305050240505, 'phys': 0.040689660064802236, 'cavity': 0.040612751799389904, 'excited': 0.040551638431564514, 'interference': 0.040409361392292356, 'interacting': 0.04028669456427993, 'diffusion': 0.04019680789656598, 'modulated': 0.040168455361462636, 'caused': 0.0401150925366377, 'measuring': 0.03958496273836825, 'production': 0.03944197595847388, 'occurrence': 0.03943129016859918, 'contact': 0.03933889140255071, 'created': 0.03919912694683049, 'similarity': 0.03900421618114474, 'avoid': 0.03898241599435537, 'starting': 0.03886372780839735, 'paradigm': 0.03882198755831854, 'force': 0.03870398805180031, '_x': 0.03848545059639252, 'hall': 0.038311177246788224, 'heisenberg': 0.03829068445653764, 'conductivity': 0.03818821453193423, 'rev': 0.03810588958862039, 'changing': 0.03777841128057534, 'substitution': 0.037602826440280984, 'pulse': 0.03755139176571735, 'diffraction': 0.03742697842042507, 'consistent': 0.037264556050083435, 'circuit': 0.037002725562962774, '_2': 0.036990570851738076, 'examine': 0.03676414149775109, 'molecule': 0.03674847206362553, 'doped': 0.03673460519525792, 'revealed': 0.03643912022984055, 'kondo': 0.03630763365528641, 'dc': 0.03566257813815191, 'junction': 0.03558087345123737, 'crystal': 0.035488200599643645, 'interplay': 0.035459926671777796, 'precursor': 0.035438421117746276, 'si': 0.035008414934008185, 'majorana': 0.034848583933435914, 'anomaly': 0.034847040656685965, 'lie': 0.03469175993048819, 'finite': 0.03466744717248046, 'appears': 0.0345329443557077, 'semiconductor': 0.034430782905336986, 'andreev': 0.034309929570900725, 'fabrication': 0.03429056512844442, 'longrange': 0.03423232098166446, 'center': 0.03400744410706063, 'tuned': 0.03391756152120466, 'collision': 0.03378932088774041, 'sector': 0.033729897658123176, 'insulating': 0.03348407840016087, 'honeycomb': 0.03344347640351877, 'composition': 0.03337421917929075, 'predicts': 0.03292841185608129, 'transforms': 0.03287090015378894, 'frame': 0.032734310829696786, 'emerge': 0.03234562525365197, 'pb': 0.03231415009422925, 'protein': 0.031955853613339136, 'mn': 0.03195090350069831, 'expect': 0.03193521685479037, 'condensate': 0.031886271448126086, 'photoemission': 0.03163120145854506, 'optic': 0.031624269419604875, 'triggered': 0.0316151328449704, 'cooper': 0.03120576972292232, 'open': 0.030844633729344005, 'correspondence': 0.03077721781215717, 'dirac': 0.030692088451805145, 'nm': 0.030685181464819036, 'complex': 0.03058567088821681, 'appearance': 0.030497258740689665, 'magnet': 0.030073455392997668, 'metal': 0.029865838043202583, 'superconductors': 0.029848779776907, 'vacuum': 0.02981993794194742, 'room': 0.02967755045033057, 'renormalization': 0.0296703706770074, 'focusing': 0.029607088041823278, 'magnetism': 0.02954192135036717, 'distortion': 0.029406142220723068, 'substrate': 0.029382769690577633, 'stress': 0.029357104547872142, 'ionization': 0.029269189575960856, 'diagonalization': 0.029156103340897636, 'macroscopic': 0.029139114632645662, 'calculate': 0.02905762971899605, 'ranging': 0.029040153751586348, 'echo': 0.02902684139842319, 'schrödinger': 0.02892045679111903, 'microscopic': 0.028909932642687746, 'powder': 0.028854222291186667, 'protected': 0.028726635637646766, 'actuator': 0.02843062080047088, 'confined': 0.028425192995064547, 'beta': 0.028298048418542613, 'act': 0.028179235153270584, 'detector': 0.028152898250685343, 'flexibility': 0.028122544310469434, 'branching': 0.028065385523208836, 'realized': 0.028051803213525874, 'drop': 0.02790880957398839, 'vanishes': 0.02785435175388629, 'ba': 0.027799404938107845, 'realizing': 0.027696588362358675, 'quark': 0.027606419153572988, 'raman': 0.02734803429185949, 'carrier': 0.027107552522811593, 'soliton': 0.027100360487365513, 'reason': 0.027048515085352196, 'rotating': 0.02703505382905219, 'emerges': 0.02702668657889047, 'fe': 0.0270212489540355, 'phenomenology': 0.02684714117045169, 'trapped': 0.026749665829758146, 'marked': 0.026693590484937687, 'terminating': 0.02667587131689247, 'enhances': 0.02662216252354462, 'screening': 0.026497208438431057, 'tissue': 0.02640302361579446, 'couple': 0.026322196017366777, 'realization': 0.026264661262258765, 'localized': 0.02617957427347761, 'floquet': 0.026174887929764957, 'ladder': 0.02610972837597083, 'quasi': 0.026004716228154878, 'josephson': 0.02563699445025752, 'luttinger': 0.02561125186420106, 'enable': 0.025578080997008385, 'boseeinstein': 0.025531695759169255, 'tunneling': 0.02551844263303534, 'mirror': 0.02539868228203512, 'hydrogen': 0.02537894003174183, 'filling': 0.025159556966047943, 'absorption': 0.02514105739174315, 'meson': 0.025125048665927057, 'droplet': 0.024976026460085052, 'melting': 0.024938656331452806, 'diamond': 0.024920031937489567, 'magnetoresistance': 0.024861284933776786, 'behaves': 0.024850702603515455, 'fractionalization': 0.02468848204654631, 'soc': 0.024606873713781542, 'oriented': 0.024597080616729897, 'sign': 0.0243950692794631, 'wavefunctions': 0.024383080732048822, 'conversion': 0.02410578355913644, 'fall': 0.024079570695444894, 'aided': 0.02406261273106748, 'rightarrow': 0.024023130501534682, 'ac': 0.023938519889940443, 'acting': 0.023843156317717138, 'van': 0.023835145183265193, 'wall': 0.02377090085804459, 'suppression': 0.023726265060081766, 'gauge': 0.023703973802524196, 'susceptibility': 0.023593744758725586, 'gpa': 0.02358542323187931, 'axis': 0.02354191449825851, 'ni': 0.023448049652073043, 'inner': 0.023439175907704158, 'break': 0.023418043169392163, 'polymer': 0.023260312704518046, 'ab': 0.023231914883855072, 'nitrogenvacancy': 0.02318121331122278, 'nv': 0.02318121331122278, 'qcd': 0.023013981567954932, 'polarized': 0.023012050915573484, 'dm': 0.02296267961025298, 'remaining': 0.022890327206140114, 'fingerprint': 0.022700527876990555, 'landau': 0.022650069760484063, 'explained': 0.02262841937216155, 'su': 0.02262809057377694, 'transverse': 0.022624171191525703, 'decoupling': 0.022621736224648404, 'reversal': 0.02259474338559421, 'subsystem': 0.022584782596030282, 'sr': 0.022485956167424267, 'monolayer': 0.022457942956213405, 'eigenvalue': 0.022406442824477214, 'viscosity': 0.02237150737813032, 'mimic': 0.022364568725082253, 'proximity': 0.022363809368413222, 'superfluid': 0.022196987440104468, 'encountered': 0.02218381091407189, 't_mathrm': 0.022176574835906265, 'chirality': 0.022146513117763816, 'window': 0.021993742037084638, 'breathing': 0.021913060039975264, 'tendency': 0.021909262205916893, 'applicable': 0.021868810545910156, 'chaos': 0.02179007392593126, 'convection': 0.02178579626954557, 'tuning': 0.021766970765250686, 'suggested': 0.021741009548100144, 'disordered': 0.021710915366884413, 'schwinger': 0.02169442134300006, 'ed': 0.021544311380401283, 'vacancy': 0.02150192525505023, 'injection': 0.02148508087546908, 'bath': 0.021473916053783147, 'semiconducting': 0.021378586924147486, 'facility': 0.021340283267405877, 'constrains': 0.02131928617259522, 'calculating': 0.021319270885371513, 'metallic': 0.021242181131460577, 'skyrmion': 0.021120261358156884, 'differ': 0.021098391920254745, 'graphene': 0.02106282991501193, 'ca': 0.02097944170469846, 'zigzag': 0.02093881519773126, 'termination': 0.020901056839686637, 'initio': 0.020898534500584987, 'sc': 0.020851758619236074, 'occupation': 0.02084786657662091, 'quadrature': 0.020836219388748772, 'bar': 0.02079827310302567, 'lee': 0.020788084752701757, 'circumstance': 0.020759082953631658, 'anisotropy': 0.020612508315562616, 'outline': 0.02057405997678677, 'phonons': 0.020547285028108375, 'impurity': 0.02052716054699366, 'compact': 0.020504417562250993, 'sigma': 0.02049472893296972, 'owing': 0.02049421123067162, 'display': 0.020448273206586143, 'zone': 0.02041802971475043, 'dipole': 0.02039092593842089, 'curved': 0.020343783464657095, 'signaling': 0.020335433986263918, 'torque': 0.020306125065885517, 'bond': 0.02030170399582784, 'enhancement': 0.02022963466547208, 'superconductor': 0.02022215941933743, 'persistence': 0.02004365402070372, 'valence': 0.019701747137678593, 'waveguide': 0.019630959405196362, 'hybridization': 0.019586344955763675, 'photoelectron': 0.01954873781670868, 'devised': 0.019548622638142485, 'simulating': 0.01951087380519726, 'qubits': 0.019451828702121997, 'hopping': 0.019423412947025733, 'universality': 0.01939650285739639, 'sm': 0.019358959523598694, 'truncation': 0.019302597905196353, 'stemming': 0.019272541123353363, 'dimer': 0.01925393016911637, 'weyl': 0.01922097509535607, 'microscopy': 0.01918400393575755, 'paving': 0.019104607213589295, 'tracing': 0.01906457117291551, 'dns': 0.019040247993527423, 'semimetals': 0.018975418323018217, 'colliding': 0.018957565790767173, 'asymmetry': 0.01879053310336968, 'membrane': 0.01872474725862862, 'manipulate': 0.01866024433395195, 'induce': 0.018587651802773837, 'superconductivity': 0.018543111104177234, 'xy': 0.01854036141501473, 'ligand': 0.018521353301200253, 'classifying': 0.018514960054192904, 'kitaev': 0.018493486200139707, 'carbon': 0.01845332590842775, 't_c': 0.018438565891809405, 'accelerator': 0.01836629554890369, 'isotropic': 0.01826042396897494, 'pas': 0.018258525799482287, 'manybody': 0.018233992937625947, 'rms': 0.018071342865519677, 'conduction': 0.01802370468322298, 'elucidated': 0.01799699323143649, 'prevalence': 0.017993367416412914, 'avenue': 0.01794865786199506, 'sto': 0.017899488044460732, 'modifying': 0.017889062671645684, 'proton': 0.017819882326997247, '_6': 0.017787519697375295, 'modulus': 0.01778634634003315, 'singleparticle': 0.017751057077704677, 'realspace': 0.017747770438227648, 'helicity': 0.017670510826177054, 'wavefront': 0.01765428901303736, 'air': 0.01763728494133005, 'cuprates': 0.017600891044196303, 'resemblance': 0.0175280999644158, 'weakly': 0.017452575046537893, 'conductor': 0.017420999494633056, 'national': 0.017311746113590702, 'crossing': 0.01730402641856002, 'hadron': 0.01729251377440259, 'suppress': 0.017217363157211164, 'ass': 0.017203599590269736, 'prefer': 0.017073087130373157, 'emergence': 0.01700544560375757, 'strain': 0.016999810430288493, 'apparatus': 0.016968640322917082, 'bring': 0.016834024011940132, 'tmds': 0.016819801520213756, 'arriving': 0.016750080231286584, 'emulsion': 0.016741341150897354, 'maximization': 0.016698082133908176, 'develops': 0.016689253295232333, 'neck': 0.016680691254580167, 'mit': 0.01666362038052382, 'higgs': 0.01661366742992334, 'electroweak': 0.0166061544474249, 'inspection': 0.01657522747455187, 'pulsed': 0.016451371820993748, 'exoplanet': 0.016350676133121207, 'promise': 0.016346658647465047, 'hotspot': 0.01631003959219034, 'eu': 0.016176031621777276, 'wigner': 0.016161305262961563, 'suspension': 0.016148580388508707, 'periodic': 0.015972261563256016, 'conserved': 0.015876575900849076, 'amplifier': 0.015858845202317597, 'gapped': 0.015851739021588433, 'bessel': 0.015843311682330337, 'election': 0.015769287366044476, 'downstream': 0.01576244174644687, 'ge': 0.015760651533258844, 'fluorescent': 0.015697114135170748, 'wire': 0.015636196215988007, 'planned': 0.015592969086849732, 'possessing': 0.01556288539864941, 'fc': 0.015335222887101691, 'mentioned': 0.015332048714551879, 'helium': 0.015331073952952596, 'radiative': 0.015296322129377782, 'coexisting': 0.015248965163665078, 'doubling': 0.015203824966040141, 'draw': 0.01514301420147436, 'degenerate': 0.01511517660976739, 'bcs': 0.015089225101220264, 'summation': 0.014964530484276524, 'grade': 0.014934664002783331, 'spacing': 0.014799941173911845, 'maintenance': 0.014768262714486162, 'mr': 0.014713235204717, 'bc': 0.014708476194995393, 'simplifies': 0.014693299206009577, 'chern': 0.014669920388859347, 'crystallization': 0.01456618280014163, 'charged': 0.014457604405916204, 'entanglement': 0.01443025250437134, 'split': 0.014419066399735642, 'cern': 0.01440556175741063, 'parity': 0.014399861029724167, 'packet': 0.014391938779916898, 'wavelet': 0.014379954469377385, 'binding': 0.014299547538147028, 'planar': 0.014297840609222574, 'exclusion': 0.014171983979674013, 'fused': 0.01415186919891916, 'der': 0.014100869990093325, 'waals': 0.014100869990093325, 'comprising': 0.014052384698045262, 'accompanied': 0.013949824427014234, 'ce': 0.013926958223693808, 'hindered': 0.013881947799334573, 'tau': 0.01383658416637032, 'corrected': 0.013817399453171056, 'dilute': 0.013784729419550652, 'translate': 0.013775004963503036, 'roughness': 0.013735480093764612, 'bonding': 0.013702356043678995, 'selectivity': 0.013698382524535868, 'renormalized': 0.013687226119443074, 'determination': 0.01367667114396876, 'byproduct': 0.013660874279368452, 'dichalcogenides': 0.01364302007270034, 'fine': 0.013497249392753527, 'marangoni': 0.013467232592729934, 'monitored': 0.013462064907048873, 'intermittency': 0.013443584197807576, 'conducting': 0.013438658779092805, 'switch': 0.013411867671486414, 'pocket': 0.013360876525561156, 'switching': 0.013304775034621684, 'progression': 0.01328746256744646, 'deploy': 0.013283977046969105, 'semimetal': 0.013279780734357894, 'polycrystalline': 0.013195570384238919, 'bundle': 0.01317254423966276, 'knot': 0.013156908908365171, 'driver': 0.013068853887782209, 'obstacle': 0.01292025642116596, 'hint': 0.012781759804801491, 'triple': 0.012759533163137753, 'contributing': 0.012747362112847327, 'suited': 0.012704193368862823, 'vapor': 0.012663388437141095, 'hit': 0.012638166810471967, 'receptor': 0.01241905566352104, 'suspected': 0.012403808864779, 'centroid': 0.012364620466102894, 'germany': 0.012363738310256193, 't_': 0.012357114814153159, 'muon': 0.0122261557491272, 'overlayer': 0.012136936525443938, 'se': 0.012124785875951179, 'oh': 0.01201390992354981, 'signed': 0.011991540260458835, 'coincidence': 0.011928242465719012, 'migrating': 0.011890386890554017, 'md': 0.011703106510475082, 'experimental': 0.01169100550071473, 'hyperthermia': 0.011680315343892333, 'nanoparticles': 0.011680315343892333, 'suffices': 0.011612722699417568, 'tempering': 0.011459581520113879, 'twisted': 0.01145018193072278, 'coating': 0.011315137743853796, 'happen': 0.01128225612838952, 'contraction': 0.011210450454487727, 'perturbative': 0.010972019527750359, 'sic': 0.010953966108750095, 'thz': 0.010930483723648307, 'perceived': 0.010904463275641924, 'quoted': 0.010898556341420331, 'c24h12': 0.010846796031719225, 'coronene': 0.010846796031719225, 'hydrocarbon': 0.010846796031719225, 'pyrene': 0.010846796031719225, 'spectrometry': 0.010846796031719225, 'staggered': 0.010670250978114313, 'hampered': 0.010620663087755753, 'advantageous': 0.010499199560382401, 'engineered': 0.01047531809094071, 'horn': 0.010468188594639907, 'thickness': 0.010380076979081092, 'inclusion': 0.010216318072005504, 'obeys': 0.010135510585129397, 'attitude': 0.01011443535156266, 'warping': 0.010084835127027578, 'stock': 0.010031925789224972, 'resting': 0.009960947003099067, 'plasmon': 0.009854046563139991, 'transparency': 0.009784111303107681, 'interacts': 0.009710671812845694, 'bone': 0.009311579359137774, 'elasticity': 0.009134039291120711, 'render': 0.008914205933082332, 'grosspitaevskii': 0.008881501287898429, 'tunability': 0.008807195339233947, 'sitter': 0.00871906722469369, 'range': 0.008701263067117746, 'stepping': 0.008528087572345102, 'mouse': 0.008491889807269153, 'independence': 0.008362984305092969, 'dune': 0.008138721529503934, 'dominates': 0.008114440778639447, 'nu': 0.007951166902695588, 'pupil': 0.007886446565668137, 'tapered': 0.007822880477007561, 'wrt': 0.007759954112847503, 'freezing': 0.007601917270230055, 'higherorder': 0.007579624599384462, 'firm': 0.0075555521284274285, 'disrupt': 0.007352351563341464, 'synthesized': 0.0073080249753626845, 'translating': 0.007251083103456955, 'microwave': 0.0071892550155958366, 'metaphor': 0.007081908097651284, 'foliation': 0.006452392495835483, 'utilising': 0.00634272902049839, 'spinning': 0.006316497938494614, 'voting': 0.005639349625605663, 'gyroscope': 0.005429195580717162}\n",
      "\n",
      "\n",
      "4 ------------>\n",
      "{'beamforming': 0.19436746045648604, 'channel': 0.19436746045648604, 'power': 0.19436746045648604, 'gain': 0.18727337810022746, 'reduces': 0.18576150363627275, 'matching': 0.18540293235703642, 'scenario': 0.18477703498150244, 'base': 0.183398973955833, 'coordination': 0.183398973955833, 'csi': 0.183398973955833, 'station': 0.183398973955833, 'filter': 0.1832223949055395, 'trend': 0.1832223949055395, 'degradation': 0.18266865667944415, 'high': 0.18266865667944415, 'incorporated': 0.18234712769491068, 'cooperation': 0.18233287499691933, 'aiming': 0.1809953990861521, 'assessing': 0.1809953990861521, 'denser': 0.1809953990861521, 'deployment': 0.1809953990861521, 'expected': 0.1809953990861521, 'incorporating': 0.1809953990861521, 'multi': 0.1809953990861521, 'receive': 0.1809953990861521, 'resilience': 0.1809953990861521, 'termed': 0.1809953990861521, 'trial': 0.1809953990861521, 'wider': 0.1809953990861521, 'mmwave': 0.07075776826825166, 'receiver': 0.06555943655690243, 'serf': 0.04576595604174646, 'rf': 0.03947716251280493, 'having': 0.03937287394516903, 'quantifies': 0.033179288791753116, 'quantization': 0.033179288791753116, 'raised': 0.033179288791753116, 'worstcase': 0.033179288791753116, 'coding': 0.02898169351785288, 'handled': 0.020277299040311215, 'accommodates': 0.019516289309086738}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ------------>\n",
      "{'problem': 0.11989131400791403, 'function': 0.11322725702098871, 'number': 0.11116632947436289, 'case': 0.1111550582486041, 'given': 0.10815589032192152, 'point': 0.10311479739010837, 'solution': 0.10153505946537618, 'example': 0.1008036873911166, 'considered': 0.09998242213817851, 'space': 0.09826997368598792, 'condition': 0.09779817778778302, 'parameter': 0.09699500637782026, 'value': 0.09569436109008661, 'limit': 0.09539233536473911, 'equation': 0.09509065008246351, 'class': 0.09351833318046573, 'term': 0.09225288569166872, 'prove': 0.09198407111757552, 'known': 0.0912142010295268, 'obtained': 0.08764875656752065, 'shown': 0.08626790802574183, 'allows': 0.08550672678183911, 'matrix': 0.08382495179803129, 'size': 0.08381520060955622, 'form': 0.08316546483347613, 'obtain': 0.08279045736940839, 'concept': 0.08215784470582768, 'type': 0.08174178818212262, 'optimization': 0.08017706865340885, 'complexity': 0.07991220335245332, 'variable': 0.07962076210031604, 'defined': 0.07894985114637393, 'assumption': 0.0787932304691796, 'scheme': 0.07866875440898898, 'dimension': 0.07733959875343696, 'develop': 0.0767420564538481, 'probability': 0.07654791101265437, 'proof': 0.07645699281027198, 'like': 0.07546266182088601, 'family': 0.07475598918433612, 'approximation': 0.07426159205523312, 'random': 0.07420290970279106, 'constraint': 0.07317113535432367, 'solve': 0.07313199098930691, 'sequence': 0.07281258868825488, 'variation': 0.07273771108304969, 'associated': 0.07264060821329768, 'version': 0.07253254858499811, 'error': 0.07129191037653042, 'operator': 0.07124247849757799, 'considering': 0.07114514005879832, 'vector': 0.07075096181901222, 'graph': 0.0695521322804316, 'convergence': 0.06725626438395041, 'iteration': 0.06715989161510276, 'construction': 0.0664303634524387, 'generalized': 0.06625328732778607, 'introduced': 0.06620973362106128, 'literature': 0.06619032049760082, 'combination': 0.06547316358375928, 'derived': 0.06533845334829612, 'hypothesis': 0.06514472788080733, 'flow': 0.06508545197318782, 'extension': 0.06504447794018191, 'theorem': 0.06401937881724713, 'idea': 0.06369766570952208, 'generalization': 0.06345489580668488, 'bound': 0.0632289872812619, 'step': 0.06217747997828043, 'formula': 0.06215644489885883, 'coefficient': 0.06214778408208893, 'following': 0.06167128787612521, 'extends': 0.061647675036888575, 'distributed': 0.061196067810605374, 'respect': 0.06095912098642742, 'procedure': 0.06062550900277172, 'unit': 0.06043727167499275, 'solving': 0.05998289378133278, 'difference': 0.059959524262761715, 'mathbb': 0.05945336537984875, 'distance': 0.05936445567167454, 'gradient': 0.05879403654827569, 'product': 0.05855808441594827, 'geometry': 0.05840356112672194, 'block': 0.05796726291617327, 'noise': 0.05767120118573041, 'allow': 0.05757699029816194, 'connection': 0.05729778357060304, 'map': 0.057148179486164415, 'statistic': 0.0570637472284074, 'convex': 0.05693986030151865, 'notion': 0.05655481659224606, 'contains': 0.05626800153149327, 'establish': 0.05622954817027283, 'article': 0.05572167004606502, 'square': 0.055517097109768744, 'bounded': 0.05533803598723451, 'norm': 0.055028466919163126, 'formulation': 0.05496940037250898, 'compare': 0.05475072882995334, 'stability': 0.05443722084522664, 'polynomial': 0.05411553308802251, 'series': 0.054021599816871504, 'relation': 0.05374173524992324, 'subset': 0.05318999976815307, 'descent': 0.052867365055626475, 'choice': 0.05277457943739421, 'estimator': 0.052643877280803074, 'index': 0.05242496662797335, 'projection': 0.051897429599085, 'inequality': 0.051897374713311614, 'ii': 0.051826616256366725, 'related': 0.05172738643824484, 'situation': 0.05101146052030891, 'guarantee': 0.05098272314029655, 'computing': 0.050895852864510406, 'algebra': 0.05087258944786346, 'requirement': 0.050560503804684305, 'match': 0.050528946409764484, 'leading': 0.05043249535494524, 'existence': 0.0501227932239397, 'linear': 0.05002217280706552, 'frac': 0.04955581325028877, 'left': 0.048997384576788275, 'building': 0.048930081871468585, 'determine': 0.048821229922787854, 'perturbation': 0.048599172751983194, 'regularity': 0.04852957369936588, 'computed': 0.0482349021653852, 'sense': 0.048216513681450406, 'constructed': 0.04807853060396886, 'defining': 0.04799245690313123, 'regression': 0.04787663336213021, 'rank': 0.04768337375459457, 'source': 0.04758442204347868, 'path': 0.047353871735564226, 'expression': 0.04707930031783494, 'sum': 0.046843109574151706, 'instance': 0.046666808523831205, 'sparse': 0.0462076037601981, 'robustness': 0.04604926775703158, 'transformation': 0.04599632810293025, 'restricted': 0.045971179784923745, 'sampling': 0.04587153850365115, 'estimated': 0.04561348714924241, 'quantity': 0.04537094623864158, 'kind': 0.04523634582424654, 'decomposition': 0.0448972669386444, 'integral': 0.04474440890334783, 'manifold': 0.04470193710394523, 'characterization': 0.044649546848042704, 'derivative': 0.04461773353247503, 'closed': 0.044436497148523275, 'involving': 0.04427984312633335, 'assumed': 0.043700764496734545, 'resolved': 0.04333853474799878, 'alternating': 0.04329250335730413, 'relies': 0.04249019938324529, 'generator': 0.04214611507836708, 'motivated': 0.04194537897415154, 'vertex': 0.041935695267894806, 'definition': 0.04164694774897244, 'minimization': 0.04145344028528735, 'law': 0.04123131261528731, 'integer': 0.040915140959452125, 'tree': 0.04090863428943023, 'fact': 0.04082925452105847, 'regularization': 0.04066221472687722, 'taking': 0.04060375989508324, 'argument': 0.040326380651492216, 'gaussian': 0.04024801951255477, 'iii': 0.03982761715720808, 'chosen': 0.03945728951752543, 'boundary': 0.03942092678455878, 'exist': 0.0392298223056993, 'recover': 0.038947709862472306, 'length': 0.03892448214188557, 'involves': 0.038857616068931816, 'theta': 0.03882975960449324, 'verify': 0.03849214628073845, 'sparsity': 0.03837735626462303, 'transform': 0.0383456433976367, 'exists': 0.03827415600041054, 'capacity': 0.038199735714711094, 'determining': 0.038194429128039456, 'generalizes': 0.03785999146691392, 'viewed': 0.03749590808170876, 'illustrated': 0.037269442968040564, 'limiting': 0.036939956142462996, 'applies': 0.03692774261746572, 'studying': 0.0368722992605151, 'assume': 0.03685649548659311, 'minimizing': 0.03677805308836646, 'log': 0.03668356963643673, 'converge': 0.03666423463421601, 'interpretation': 0.036417613537915575, 'consistency': 0.036328419730230224, 'embedding': 0.03617480343103415, 'optimality': 0.03606249085492565, 'formalism': 0.035893213420895256, 'involved': 0.03586473735144808, 'approximate': 0.03572073628210721, 'involve': 0.03563559001017367, 'row': 0.03554470019060819, 'tensor': 0.03543632576021721, 'right': 0.035396791104522304, 'obtaining': 0.03535670605860483, 'proved': 0.035068930284638575, 'heart': 0.0350152156947932, 'concerning': 0.034687301588219685, 'minimize': 0.03452764821844603, 'covered': 0.03447485179757952, 'divergence': 0.034450182436280216, 'implies': 0.03432385349181188, 'guaranteed': 0.03426891064012691, 'reducing': 0.03413166560955176, 'represented': 0.0340839256384447, 'intersection': 0.033922402666346864, 'discussion': 0.033917233879372136, 'coordinate': 0.03385584586797995, 'category': 0.033645925702984865, 'column': 0.03358705307064646, 'recovery': 0.03345432432125454, 'synthesis': 0.033349526739423145, 'entry': 0.033174979110687265, 'augmented': 0.03296349427531051, 'scaling': 0.03292436775504034, 'et': 0.032801181656661925, 'suffer': 0.03253588967039217, 'poisson': 0.03243085236093333, 'deformation': 0.032379597230882594, 'equilibrium': 0.03233402267752005, 'multivariate': 0.032025159377126196, 'aforementioned': 0.03184189360551379, 'failure': 0.03180576376441434, 'explicit': 0.03154745474767417, 'linking': 0.0315399364741538, 'hamiltonian': 0.03136357957125756, 'cube': 0.031320821717231356, 'iid': 0.03116375481828984, 'restriction': 0.03114878681557329, 'modelling': 0.031141081637726983, 'subspace': 0.030941112020107294, 'avoiding': 0.030911471746695705, 'subject': 0.03087640410634484, 'mechanic': 0.03087306155423018, 'bit': 0.030861220571002605, 'translation': 0.030783908336190328, 'hierarchy': 0.03071356607917399, 'reconstruction': 0.030709839939895466, 'scaled': 0.030568851123853432, 'geometric': 0.03023504714983728, 'satisfy': 0.030184830449024015, 'separated': 0.030127799416539067, 'foundation': 0.03011620289598206, 'cdot': 0.030114109822161367, 'equality': 0.030093648532788314, 'answer': 0.030066195316462936, 'load': 0.02968168941865897, 'discrete': 0.029644754076202873, 'maximum': 0.029558438409054772, 'fails': 0.029555525955125075, 'cauchy': 0.029500764728956474, 'deriving': 0.029467570527832502, 'union': 0.029307724584286172, 'inverse': 0.02929045111799235, 'recovered': 0.029207404044057635, 'considers': 0.02897830585255773, 'examined': 0.028970801218135896, 'filtering': 0.02889456931916776, 'know': 0.028844153080993168, 'adapted': 0.028773348941121997, 'smoothness': 0.02868731385773862, 'height': 0.0286787103442475, 'relative': 0.028658364525029997, 'admits': 0.02858792650566411, 'priori': 0.02858258614823483, 'algebraic': 0.028496580933483406, 'satisfies': 0.02841266047022706, 'recovers': 0.028380872761569684, 'invariant': 0.02823417634768197, 'infty': 0.028163741677448777, 'approximating': 0.02811194619501274, 'smooth': 0.028062227225004344, 'smoothing': 0.028040094754062342, 'consensus': 0.027995207224018825, 'transmission': 0.02792513055482636, 'pca': 0.027851833105883426, 'ldots': 0.027783241867034503, 'completion': 0.02771751473976215, 'analogue': 0.02757281832903575, 'logic': 0.027557164340962493, 'frobenius': 0.02754137484105046, 'note': 0.027514768127468527, 'count': 0.02747387814941584, 'homology': 0.02706874179001906, 'outlier': 0.027051141170628037, 'vanishing': 0.026959380702507918, 'dot': 0.026953107358155617, 'conservation': 0.02692330317437675, 'singularity': 0.026899922095131822, 'elimination': 0.0268910536790207, 'discretization': 0.02674296099421843, 'generalizing': 0.02663789234081371, 'simple': 0.026636441369833255, 'replacing': 0.026313500392837832, 'constructing': 0.026226916118842772, 'maximize': 0.026057860466523874, 'omega': 0.025956550871501824, 'jacobi': 0.025949224258075852, 'affine': 0.025919954437118704, 'ising': 0.02580657318598769, 'supported': 0.02578082613497262, 'ensemble': 0.0257507997507423, 'lipschitz': 0.025568751503659268, 'emph': 0.02537669651642322, 'symbol': 0.025375679979892932, 'ball': 0.025112256750777214, 'assumes': 0.02499401898445464, 'optimal': 0.024831117538552036, 'minimax': 0.024775953062474813, 'pde': 0.024600273109844844, 'motivates': 0.024304173411555878, 'integrability': 0.024298035259632624, 'leaf': 0.024195109232538307, 'l2': 0.024190729365398227, 'general': 0.02418783937673417, 'nphard': 0.024172752152550565, 'f_': 0.024161831831508242, 'drawn': 0.02411785522698772, 'exploited': 0.024058829587867394, 'continuity': 0.023955614798579876, 'sampler': 0.02388721318173047, 'clock': 0.023697732934258448, 'trace': 0.023676541440864347, 'improves': 0.023669340774397783, 'randomized': 0.02357865423654839, 'math': 0.02357858662576822, 'infinity': 0.023533853334886827, 'posse': 0.02348096004714614, 'duality': 0.023438178978095206, 'wasserstein': 0.02336981297078803, 'kdv': 0.02325745404078038, 'cone': 0.023231885301972673, 'cite': 0.023129307290218865, 'wireless': 0.023115424784059993, 'solves': 0.023051991413867354, 'standing': 0.022996424678455377, 'meet': 0.022891334740503554, 'convexity': 0.022887188727696524, 'containing': 0.022853026181987694, 'max': 0.022780280682005268, 'statement': 0.02269517277637181, 'briefly': 0.02260326486068034, 'bernoulli': 0.02245539727397613, 'covariance': 0.02241579485851567, 'corresponds': 0.022397463329913367, 'riemann': 0.02235911742293347, 'denotes': 0.022285157443167974, 'captured': 0.02219931170538563, 'sl': 0.02215715947305994, 'discrepancy': 0.021967638387040984, 'graded': 0.02195570794009164, 'parametric': 0.021934159962701136, 'identity': 0.02190904197831743, 'predictor': 0.021820219513021138, 'p_1': 0.021803849922281696, 'ellipsoid': 0.021770660617827352, 'subseteq': 0.02171981996554261, 'walk': 0.02171642693953543, 'adjacent': 0.021601951761870193, 'approximated': 0.021529850187868675, 'winning': 0.021488500495372657, 'euler': 0.021416396131749317, 'gamma': 0.021411146750010237, 'leq': 0.02139948594296766, 'leader': 0.021396104656492172, 'seek': 0.021378707255386094, 'invariance': 0.021273372538182754, 'novelty': 0.021239192442124, 'admm': 0.02119517389483358, 'commuting': 0.02112004785721708, 'cascade': 0.021117120301324566, 'simulate': 0.020889222525450796, 'emphasis': 0.020678055041149702, 'subproblems': 0.020590860884273286, 'mcmc': 0.02056575953499231, 'dirichlet': 0.020540312200282684, 'choose': 0.020516963587764205, 'omegasubset': 0.02040437087188663, 'specified': 0.020354689351933478, 'derivation': 0.02033827452277791, 'spacetime': 0.020271980632875074, 'weighted': 0.020232957762530153, 'sampled': 0.02018105137474894, 'bipartite': 0.020177443643366683, 'oscillator': 0.020139588239807788, 'classify': 0.020119851106567326, 'compatibility': 0.020111974078025705, 'corroborate': 0.02008567793415637, 'penalty': 0.02004248778836773, 'polytope': 0.020006510505581835, 'simplex': 0.019966209382326832, 'subgroup': 0.019899430719628543, 'averaging': 0.019878627695993512, 'monotone': 0.019785736010799485, 'boolean': 0.01972706187706666, 'parametrized': 0.01972287981587509, 'simplified': 0.019713878714288365, 'darboux': 0.01967869409166101, 'satisfied': 0.01961805038851164, 'dropping': 0.019573610705289762, 'checked': 0.019514197094044474, 'cohomology': 0.019513566082836147, 'written': 0.01947766928881382, 'uniform': 0.019321505195478005, 'certificate': 0.019317662900391063, 'directed': 0.019211964838109642, 'comprises': 0.019195678379481936, 'lu': 0.01915214862109304, 'cap': 0.019151415884227745, 'nonlinear': 0.0190247323823167, 'determinant': 0.019022967251118128, 'circle': 0.018967828066764496, 'observability': 0.018944244382749702, 'corner': 0.018864487275942823, 'interpolating': 0.018790367476145105, 'reconstruct': 0.01878188639254769, 'normalized': 0.018668162381082223, 'subgraphs': 0.018512020735785683, 'simplify': 0.018510720051062395, 'nonlinearity': 0.018458191125020305, 'multiplicity': 0.018381448468553004, 'obstruction': 0.018358078100511946, 'neumann': 0.01835798243512808, 'tail': 0.018339826006580816, 'denote': 0.018322951636292793, 'jump': 0.01828442056789382, 'determines': 0.01824389411014779, 'sgd': 0.018128299625325663, 'lecture': 0.01809323734790336, 'lax': 0.018062342284869807, 'eigenfunctions': 0.01795685143127175, 'drift': 0.01792732657469097, 'polytopes': 0.017883073013483474, 'automaton': 0.01784351621846358, 'ascent': 0.0178251140134519, 'siam': 0.017815868792198798, 'ij': 0.017800515043874046, 'initialization': 0.017727094031858986, 'tuples': 0.017682198797865013, 'span': 0.017644980919101376, 'transmitted': 0.017567157999565527, 'belongs': 0.01753051001771466, 'poly': 0.01737319922134529, 'concerned': 0.01734517068559579, 'kl': 0.017325806389611627, 'hyperplanes': 0.01730013947462159, 'interpretability': 0.017285709633895033, 'constituent': 0.01726900023126854, 'log2': 0.01726639013377751, 'harmonic': 0.017225166266423588, 'describing': 0.017199796524713026, 'correct': 0.0170052362337922, 'planted': 0.0170006237044317, 'hilbert': 0.0169331515752775, 'coincides': 0.016927143701603822, 'freedom': 0.016895638785999586, 'minimizes': 0.01687409246459211, 'permutation': 0.01681510174367339, 'interpolation': 0.01681424656884468, 'min': 0.01673406984716947, 'throughput': 0.016674631696829957, 'lyapunov': 0.016608122119160088, 'adversary': 0.016583818126324777, 'interesting': 0.016540378669716138, 'deduce': 0.01649597874110716, 'gibbs': 0.016485397602272345, 'absence': 0.01648423675752549, 'pi': 0.016464234604047664, 'vorticity': 0.0164606177395886, 'delta': 0.016437786816472955, 'digraph': 0.016416336986824424, 'phi': 0.01636541364933787, 'sqrt': 0.016327839282041044, 'i1': 0.016292809054957353, 'multiplier': 0.016287724035715517, 'positivity': 0.016267467304841944, 'unknown': 0.01625893732241334, 'transferring': 0.016240435671200426, 'laplace': 0.01622507819879489, 'f_1': 0.016156079877439656, 'cantor': 0.016141714560794305, 'parameterized': 0.016103667026644945, 'splitting': 0.016082408274260274, 'sf': 0.01606018257699379, 'ideal': 0.016016194289693093, 'replace': 0.016012603659695753, 'ax': 0.015994266615974986, 'losing': 0.015970934046282973, 'logarithm': 0.015959710291945872, 'preconditioning': 0.015906974572207487, 'regard': 0.01589695175170639, 'simplicity': 0.015887580604551664, 'asymptotics': 0.015852844819896645, 'satisfaction': 0.015845223365981827, 'stabilize': 0.015835421749641074, 'hinge': 0.01582862853213489, 'k2': 0.01582653537045211, 'bimodal': 0.015813984508738155, 'joint': 0.015785659741427142, 'nonzero': 0.015753880508755553, 'appendix': 0.01573191536937145, 'axiom': 0.015731550896762838, 'gröbner': 0.01573083532310272, 'mathbf': 0.015706496082872303, 'framed': 0.015666379092889166, 'x_n': 0.015627732158023263, 'net': 0.015581384256369327, 'clarify': 0.015522119764919282, 'lmi': 0.015521312797570476, 'sea': 0.01550434480736077, 'x_t': 0.01546356296754312, 'surrogate': 0.01545106141430385, 'selfadjoint': 0.015376449752853424, 'straightforward': 0.01536095864054451, 'coloring': 0.015336400831440397, 'putting': 0.01533135856414997, 'nashmoser': 0.015308116716502368, 'solvability': 0.01529804101042008, 'vanilla': 0.015248475041804961, 'grows': 0.01521031020733094, 'minimizers': 0.015199718524392778, 'spanning': 0.015133478977470695, 'automorphism': 0.0151000199662693, 'calculus': 0.01509007695887228, 'illustration': 0.01507524575812183, 'glass': 0.015021675744825281, 'boltzmann': 0.014995485987812843, 'regularized': 0.014980640640234457, 'regularizer': 0.014980640640234457, 'emphasize': 0.014941802833368276, 'implying': 0.014916738840996863, 'puzzle': 0.014907649147097206, 'transitivity': 0.014870191002932355, 'torus': 0.014809334673047153, 'bracket': 0.014807238798228248, 'perturbed': 0.014745309147233755, 'randomness': 0.014689589113291037, 'pareto': 0.01467779488217657, 'analog': 0.014601301637176854, 'peakon': 0.014599428480179808, 'divisor': 0.014596556324793921, 'distinguish': 0.014556087854131641, 'disturbance': 0.014549215583539638, 'encompasses': 0.014503672480211362, 'departure': 0.014493094260522543, 'nabla': 0.01448502465076507, 'qquad': 0.01448502465076507, 'characterizing': 0.014450664333173312, 'unifies': 0.014382752289506836, 'kortewegde': 0.014381715818595453, 'vries': 0.014381715818595453, 'epsilon': 0.014375731717405787, 'tiling': 0.014335539066159567, 'undersampling': 0.014312174891670358, 'stirling': 0.014308034009728552, 'inconsistency': 0.014242662853056644, 'lowcomplexity': 0.014231279557919049, 'kullbackleibler': 0.0142152832568285, 'k1': 0.014202982455570314, 'zero': 0.014142858408226901, 'visit': 0.014135851882739626, 'governed': 0.014129674474463316, 'timevarying': 0.014123305308180362, 'linearity': 0.01406401053503696, 'linfty': 0.014062987530257188, 'coexistence': 0.014039757636346573, 'monotonicity': 0.013966762532640167, 'n2': 0.013917989458309046, 'chi': 0.013904320750300672, 'page': 0.013895985525062013, 'quantile': 0.013878260110900601, 'constellation': 0.013869736094394469, 'scope': 0.013860487975644995, 'arbitrary': 0.013817568010527232, 'corrupted': 0.01374245027099923, 'orthogonality': 0.0137418284390392, 'analogy': 0.013724703993120826, 'round': 0.0136910493099783, 'triangle': 0.013684406791459438, 'bellman': 0.013669135846734867, 'valued': 0.01366665917377084, 'ramanujan': 0.013589202735937536, 'unique': 0.013556088418274562, 'genuine': 0.013530965072725038, 'packing': 0.01353082283550709, 'motif': 0.013517855202863615, 'kam': 0.013515461951604727, 'eigenvectors': 0.013468208147603635, 'discretizations': 0.01343873426400753, 'sequential': 0.013412653940166136, 'normality': 0.01336135773852977, 'accumulating': 0.013360263749743244, 'highorder': 0.013358287190196284, 'devoted': 0.01335653818720243, 'routing': 0.013344671156567603, 'proportion': 0.013322128836975103, 'fisher': 0.01331407097622369, 'checking': 0.013275800034356562, 'bijection': 0.01326336131778441, 'assigned': 0.013258678160385102, 'identifiability': 0.013255820090727103, 'integrands': 0.013249321328986107, 'ell': 0.013226837205562154, 'mbox': 0.013157768746952046, 'discontinuity': 0.013130945298268446, 'linearized': 0.01309308854836456, 'traveling': 0.0130685236474311, 'shrinkage': 0.013050755574603959, 'cutoff': 0.013047716117592822, 'lim_': 0.013010402845530738, 'exhibiting': 0.012967114406845287, 'adjacency': 0.012934904420858852, 'saga': 0.012926097637894644, 'la': 0.012902687892346758, 'kähler': 0.012901822062831346, 'syzygy': 0.01287322713110745, 'associate': 0.012830903243960778, 'burger': 0.012814646760482122, 'ghost': 0.012782096382792941, 'stochastic': 0.012763091927097929, 'drinfeld': 0.01265272387357052, 'rendered': 0.012602835794760089, 'hamiltonians': 0.012584859100403703, 'riccati': 0.012528060103825397, 'central': 0.012488942018138518, 'f2': 0.012455542330471815, 'maximizes': 0.012450130252246719, 'hamilton': 0.012388978265971334, 'convergent': 0.012336801117486513, 'integrated': 0.01232738233961341, 'sci': 0.012302299643292935, 'noetherian': 0.012268199689331377, 'semigroup': 0.012258741542639203, 'finiteness': 0.012218896357545521, 'centralized': 0.012200665881062125, 'decide': 0.012184966370929374, 'autocorrelation': 0.012169111345577443, 'rogue': 0.012158271438521282, 'dimensional': 0.012137891284611417, 'coincide': 0.012123123577668031, 'l_1': 0.012096852251568174, 'l_n': 0.012096852251568174, 'rearrangement': 0.012064257461176377, 'assertion': 0.012054472222601177, 'coupler': 0.011975374005679197, 'connecting': 0.011948809959712215, 'pure': 0.011882410219365138, 'chooses': 0.011866582337354954, 'functional': 0.011845733218446878, 'inversion': 0.011828735906393807, 'discretizing': 0.011821149197533543, 'np': 0.011812910289386877, 'featuring': 0.01181088767371196, 'infection': 0.011789099553802602, 'helmholtz': 0.011788116598558529, 'stationary': 0.011782779147317148, 'nlog': 0.011763817276086396, 'recurrence': 0.011712488526989945, 'divide': 0.01169066880881951, 'attracting': 0.011617410931102697, 'attempting': 0.011585619207748959, 'npcomplete': 0.011524543765921502, 'disjoint': 0.011511588645004242, 'observable': 0.011497061445006439, 'supervisor': 0.011497061445006439, 'magnetic': 0.011482947632095473, 'inefficiency': 0.011442716677320226, 'inducing': 0.011441560690486114, 'counting': 0.01143111680465946, 'unperturbed': 0.011418402190023455, 'asked': 0.011407696435088717, 'interfering': 0.011380069076005628, 'nls': 0.011316109280839865, 'arrives': 0.011296195087430511, 'widetilde': 0.011265518063798894, 'indexed': 0.011242277516416266, 'slice': 0.01122354793180989, 'attained': 0.011203507496523204, 'reweighted': 0.011146919818957315, 'galerkin': 0.011111118221697507, 'conjectured': 0.011092253318910122, 'skeleton': 0.010985625219140248, 'evolves': 0.010865915608928007, 'additive': 0.010847098378818195, 'holonomy': 0.01083978020075453, 'nonconvex': 0.010790944658544686, 'discretize': 0.01071538674963339, 'tomography': 0.010711387758574034, 'abc': 0.010707994732246644, 'componentwise': 0.010691763362969894, 'misspecification': 0.010637095395424512, 'reflected': 0.010625747368552282, 'l_p': 0.010615780886669476, 'alphabet': 0.010599290611477491, 'robin': 0.010529473156471186, 'transformer': 0.01050937637597685, 'genome': 0.010432283256937373, 'n1': 0.010428009782152942, 'equivalent': 0.01037885317796804, 'think': 0.010372589171474133, 'ot': 0.010370528745105898, 'stopping': 0.010354237625129761, 'regulating': 0.010312689425637527, 'interact': 0.010310429587316811, 'bivariate': 0.010309049524603174, 'copula': 0.010303673956677039, 'eigenstates': 0.010295145050217551, 'converse': 0.01028612294698459, 'virtue': 0.010286100838398952, 'nested': 0.010279366307213425, 'folding': 0.01027317617761884, 'preconditioner': 0.010268600193011793, 'referring': 0.010263934947266743, 'adleman': 0.010246767927778426, 'discretized': 0.010132906067547257, 'generalisation': 0.009970625987013084, 'piecewise': 0.009926137791829857, 'converges': 0.009910091218199215, 'lebesgue': 0.009892051512919943, 'decided': 0.009884530642481655, 'diameter': 0.009871062668544912, 'seminar': 0.009863521031517167, 'appl': 0.009849403013734291, 'visiting': 0.009845860119852048, 'setminus': 0.009785449013062306, 'indifference': 0.009779855441727502, 'rna': 0.009759045296378045, 'rational': 0.009732360199762428, 'zeta': 0.009728494399228807, 'koopman': 0.009713320129383654, 'occurred': 0.009652662898949222, 'sphere': 0.009650471857182494, 'valuation': 0.00964505227888884, 'visited': 0.009523912206263802, 'substituting': 0.009516344588022868, 'recursion': 0.00951432589107036, 'digit': 0.009508968441221115, 'permittivity': 0.00948604798676996, 'rotated': 0.009478832453407218, 'neighborhood': 0.009472515295616548, 'reynolds': 0.009463719554733286, 'combinatorics': 0.009378706203902876, 'atomic': 0.009279206844641123, 'twostage': 0.009257038774725265, 'c_2': 0.009196185106826169, 'bayes': 0.009122245267786913, 'clique': 0.009078396540145191, 'exploitation': 0.008970589779533463, 'better': 0.008964256506862445, 'waypoints': 0.008961015195250168, 'exchanging': 0.008932482627226837, 'stabilization': 0.008869299338346029, 'coin': 0.008861490840883935, 'fourthorder': 0.008832292719496662, 'cover': 0.008806756810837896, 'lambda2': 0.008803199925244434, 'hankel': 0.00878552453994278, 'clause': 0.008785445759185188, 'substitute': 0.008758094941297655, 'anderson': 0.008738047744007991, 'r_0': 0.008735581061426247, 'gl': 0.008625973901358965, 'worked': 0.00857164914895914, 'going': 0.008553251696443644, 'kept': 0.008513161036516836, 'cayley': 0.008510396081534654, 'cancellation': 0.008402397555620294, 'elevation': 0.00832909965789988, 'partitioned': 0.008312153292665376, 'summary': 0.00829661114827242, 'retracts': 0.008192101318630901, 'lorentz': 0.008154063028486985, 'ricci': 0.008138669970474315, 'lagrangian': 0.008069181708594097, 'linearization': 0.007994072232653419, 'universal': 0.007890936361651824, 'xxz': 0.007828611230263875, 'reformulated': 0.00782222946017939, 'reverse': 0.007768277994690981, 'oracle': 0.007708443479284986, 'homomorphism': 0.0076803964201680236, 'laplacebeltrami': 0.007639967812840343, 'tao': 0.007629664085951923, 'perfect': 0.007602086477185034, 'admit': 0.007599190896771156, 'multiphase': 0.007573397035538687, 'montecarlo': 0.007541614777985343, 'simpler': 0.0074500929377983305, 'cut': 0.007440244156350906, 'formalized': 0.00736485233216374, 'alexander': 0.007296816168766884, 'acceleration': 0.007215623825376771, 'euclidean': 0.007181922126406046, 'thompson': 0.00696197795377303, 'divergent': 0.006906949099574611, 'ro': 0.006841571580847663, 'mixed': 0.006813192731167091, 'phrasing': 0.006771951771001172, 'hardy': 0.006771877346492097, 'gp': 0.006761163679023054, 'stated': 0.006746219803715543, 'conservatism': 0.006736683346158419, 'isomorphism': 0.00670979043437421, 'simplification': 0.006661150926199344, 'congestion': 0.006549439258559876, 'book': 0.006475056536894922, 'formalization': 0.006461162909185882, 'container': 0.00590299882529685, 'cup': 0.005872625266082443, 'rainbow': 0.005775359180740865, 'asks': 0.005652483720153584, 'dim': 0.005556809028868191, 'subcategories': 0.005474277304858784, 'ford': 0.005458370076560844, 'stein': 0.005410491479173974, 'admissibility': 0.005274085931402631, 'half': 0.004935840566910579, 'advice': 0.004435658602276693, 'mathfrak': 0.003707993506825918, 'functors': 0.0032799451308268483}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(community_word)):\n",
    "    importent = {}\n",
    "    j_count = []\n",
    "    com = community_word[i]\n",
    "    G6 = nx.Graph()\n",
    "    for e in range(0, len(node1)):\n",
    "        if(node1[e] in com  and node2[e] in com):\n",
    "            G6.add_edge(node1[e], node2[e], weight=value[e])\n",
    "            \n",
    "    centrality = nx.eigenvector_centrality(G6)      \n",
    "    a = sorted(centrality.items())\n",
    "    eg = {}\n",
    "    for j in a:\n",
    "        eg[j[0]] = j[1]\n",
    "    sorted_dict = {k: v for k, v in sorted(eg.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(i,\"------------>\")\n",
    "    print(sorted_dict)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "27bf1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------------>\n",
      "['model', 'paper', 'approach', 'data', 'proposed', 'method', 'work', 'based', 'network', 'learning']\n",
      "\n",
      "1 ------------>\n",
      "['set', 'rate', 'time', 'observation', 'present', 'simulation', 'distribution', 'discovered', 'mass', 'evolution']\n",
      "\n",
      "2 ------------>\n",
      "['adopts', 'barrier', 'cache', 'cause', 'command', 'dedicated', 'delivered', 'dispatch', 'eliminating', 'enabled']\n",
      "\n",
      "3 ------------>\n",
      "['consequence', 'study', 'state', 'field', 'interaction', 'effect', 'order', 'property', 'phase', 'energy']\n",
      "\n",
      "4 ------------>\n",
      "['beamforming', 'channel', 'power', 'gain', 'reduces', 'matching', 'scenario', 'base', 'coordination', 'csi']\n",
      "\n",
      "5 ------------>\n",
      "['problem', 'function', 'number', 'case', 'given', 'point', 'solution', 'example', 'considered', 'space']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aa = []\n",
    "for i in range(0, len(community_word)):\n",
    "    importent = {}\n",
    "    j_count = []\n",
    "    com = community_word[i]\n",
    "    G6 = nx.Graph()\n",
    "    for e in range(0, len(node1)):\n",
    "        if(node1[e] in com  and node2[e] in com):\n",
    "            G6.add_edge(node1[e], node2[e], weight=value[e])\n",
    "            \n",
    "    centrality = nx.eigenvector_centrality(G6)      \n",
    "    a = sorted(centrality.items())\n",
    "    eg = {}\n",
    "    for j in a:\n",
    "        eg[j[0]] = j[1]\n",
    "    print(i,\"------------>\")\n",
    "    b = sorted(eg, key=eg.get, reverse=True)[:10]\n",
    "    print(b)\n",
    "    aa.append(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ed31b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>paper</td>\n",
       "      <td>approach</td>\n",
       "      <td>data</td>\n",
       "      <td>proposed</td>\n",
       "      <td>method</td>\n",
       "      <td>work</td>\n",
       "      <td>based</td>\n",
       "      <td>network</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>set</td>\n",
       "      <td>rate</td>\n",
       "      <td>time</td>\n",
       "      <td>observation</td>\n",
       "      <td>present</td>\n",
       "      <td>simulation</td>\n",
       "      <td>distribution</td>\n",
       "      <td>discovered</td>\n",
       "      <td>mass</td>\n",
       "      <td>evolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adopts</td>\n",
       "      <td>barrier</td>\n",
       "      <td>cache</td>\n",
       "      <td>cause</td>\n",
       "      <td>command</td>\n",
       "      <td>dedicated</td>\n",
       "      <td>delivered</td>\n",
       "      <td>dispatch</td>\n",
       "      <td>eliminating</td>\n",
       "      <td>enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consequence</td>\n",
       "      <td>study</td>\n",
       "      <td>state</td>\n",
       "      <td>field</td>\n",
       "      <td>interaction</td>\n",
       "      <td>effect</td>\n",
       "      <td>order</td>\n",
       "      <td>property</td>\n",
       "      <td>phase</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beamforming</td>\n",
       "      <td>channel</td>\n",
       "      <td>power</td>\n",
       "      <td>gain</td>\n",
       "      <td>reduces</td>\n",
       "      <td>matching</td>\n",
       "      <td>scenario</td>\n",
       "      <td>base</td>\n",
       "      <td>coordination</td>\n",
       "      <td>csi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem</td>\n",
       "      <td>function</td>\n",
       "      <td>number</td>\n",
       "      <td>case</td>\n",
       "      <td>given</td>\n",
       "      <td>point</td>\n",
       "      <td>solution</td>\n",
       "      <td>example</td>\n",
       "      <td>considered</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2            3            4           5  \\\n",
       "0        model     paper  approach         data     proposed      method   \n",
       "1          set      rate      time  observation      present  simulation   \n",
       "2       adopts   barrier     cache        cause      command   dedicated   \n",
       "3  consequence     study     state        field  interaction      effect   \n",
       "4  beamforming   channel     power         gain      reduces    matching   \n",
       "5      problem  function    number         case        given       point   \n",
       "\n",
       "              6           7             8          9  \n",
       "0          work       based       network   learning  \n",
       "1  distribution  discovered          mass  evolution  \n",
       "2     delivered    dispatch   eliminating    enabled  \n",
       "3         order    property         phase     energy  \n",
       "4      scenario        base  coordination        csi  \n",
       "5      solution     example    considered      space  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(aa, columns=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41613175",
   "metadata": {},
   "source": [
    "LDA with Community Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6cb5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/intesurahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "57181dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "57b3b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5b5e9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1ca34db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in part1:\n",
    "    article = re.sub(r'[^\\w\\s]','',str(i))\n",
    "    article = article.lower()\n",
    "    article = remove_stopwords(article)\n",
    "    words_article = word_tokenize(article)\n",
    "    s = []\n",
    "    for w in words_article:\n",
    "        e = wn.lemmatize(w)\n",
    "        if e not in stop_words:\n",
    "            s.append(e)\n",
    "    data.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d37c3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.80, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "316b0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in data:\n",
    "    s = \"\"\n",
    "    for j in i:\n",
    "        s = s+\" \"+j\n",
    "    documents.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a3481225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9a8548dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e0878c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/intesurahmed/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5058"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7920c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f48a012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in data:\n",
    "    s = []\n",
    "    for j in i:\n",
    "        if j in valid:\n",
    "            s.append(j)\n",
    "    final.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2636cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d18e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "some_obj = {'article':final}\n",
    "\n",
    "with open('experiment_3.pickle', 'wb') as f:\n",
    "    pickle.dump(some_obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9832d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 2), (17, 1), (18, 1), (19, 3), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 2), (38, 2)]]\n"
     ]
    }
   ],
   "source": [
    "texts = final\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4aab9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=total_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bd36cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"number\" + 0.007*\"problem\" + 0.006*\"result\" + 0.006*\"model\" + '\n",
      "  '0.006*\"data\" + 0.005*\"function\" + 0.004*\"network\" + 0.004*\"algorithm\" + '\n",
      "  '0.004*\"parameter\" + 0.004*\"study\"'),\n",
      " (1,\n",
      "  '0.011*\"model\" + 0.007*\"method\" + 0.006*\"data\" + 0.006*\"result\" + '\n",
      "  '0.006*\"learning\" + 0.006*\"approach\" + 0.005*\"paper\" + 0.005*\"information\" + '\n",
      "  '0.004*\"algorithm\" + 0.004*\"feature\"'),\n",
      " (2,\n",
      "  '0.010*\"algorithm\" + 0.010*\"model\" + 0.010*\"problem\" + 0.010*\"method\" + '\n",
      "  '0.009*\"network\" + 0.007*\"data\" + 0.006*\"learning\" + 0.006*\"paper\" + '\n",
      "  '0.005*\"based\" + 0.005*\"function\"'),\n",
      " (3,\n",
      "  '0.011*\"model\" + 0.009*\"data\" + 0.007*\"method\" + 0.006*\"result\" + '\n",
      "  '0.006*\"algorithm\" + 0.005*\"function\" + 0.005*\"field\" + 0.005*\"state\" + '\n",
      "  '0.004*\"time\" + 0.004*\"study\"'),\n",
      " (4,\n",
      "  '0.010*\"model\" + 0.007*\"paper\" + 0.006*\"data\" + 0.006*\"method\" + '\n",
      "  '0.006*\"problem\" + 0.006*\"network\" + 0.005*\"time\" + 0.005*\"result\" + '\n",
      "  '0.004*\"study\" + 0.004*\"distribution\"'),\n",
      " (5,\n",
      "  '0.007*\"network\" + 0.006*\"result\" + 0.005*\"paper\" + 0.005*\"method\" + '\n",
      "  '0.005*\"model\" + 0.004*\"based\" + 0.004*\"state\" + 0.004*\"data\" + '\n",
      "  '0.004*\"algorithm\" + 0.004*\"energy\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e092363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number</td>\n",
       "      <td>problem</td>\n",
       "      <td>result</td>\n",
       "      <td>model</td>\n",
       "      <td>data</td>\n",
       "      <td>function</td>\n",
       "      <td>network</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>parameter</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>method</td>\n",
       "      <td>data</td>\n",
       "      <td>result</td>\n",
       "      <td>learning</td>\n",
       "      <td>approach</td>\n",
       "      <td>paper</td>\n",
       "      <td>information</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>model</td>\n",
       "      <td>problem</td>\n",
       "      <td>method</td>\n",
       "      <td>network</td>\n",
       "      <td>data</td>\n",
       "      <td>learning</td>\n",
       "      <td>paper</td>\n",
       "      <td>based</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>data</td>\n",
       "      <td>method</td>\n",
       "      <td>result</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>function</td>\n",
       "      <td>field</td>\n",
       "      <td>state</td>\n",
       "      <td>time</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model</td>\n",
       "      <td>paper</td>\n",
       "      <td>data</td>\n",
       "      <td>method</td>\n",
       "      <td>problem</td>\n",
       "      <td>network</td>\n",
       "      <td>time</td>\n",
       "      <td>result</td>\n",
       "      <td>study</td>\n",
       "      <td>distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>network</td>\n",
       "      <td>result</td>\n",
       "      <td>paper</td>\n",
       "      <td>method</td>\n",
       "      <td>model</td>\n",
       "      <td>based</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2       3          4         5         6  \\\n",
       "0     number  problem   result   model       data  function   network   \n",
       "1      model   method     data  result   learning  approach     paper   \n",
       "2  algorithm    model  problem  method    network      data  learning   \n",
       "3      model     data   method  result  algorithm  function     field   \n",
       "4      model    paper     data  method    problem   network      time   \n",
       "5    network   result    paper  method      model     based     state   \n",
       "\n",
       "             7          8             9  \n",
       "0    algorithm  parameter         study  \n",
       "1  information  algorithm       feature  \n",
       "2        paper      based      function  \n",
       "3        state       time         study  \n",
       "4       result      study  distribution  \n",
       "5         data  algorithm        energy  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lda_model.print_topics()\n",
    "a = []\n",
    "for i in x:\n",
    "    b = i[1].split('\"')\n",
    "    c = []\n",
    "    for j in range(0, len(b)):\n",
    "        if(j%2!=0):\n",
    "            c.append(b[j])\n",
    "    a.append(c)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(a, columns=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896e0af",
   "metadata": {},
   "source": [
    "LDA with Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0a630516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_coherence(topic):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=topic)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=final, dictionary=id2word, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "72c9f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(1, 40):\n",
    "    x.append(i+1)\n",
    "    y.append(take_coherence(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "30f06cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d51b967e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(\n",
    "    data=y,  err_style=\"bars\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d9ada7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "m = y.index(max(y))\n",
    "print(m+1)\n",
    "b = m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c1f027d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "06a6b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.011*\"model\" + 0.008*\"network\" + 0.007*\"method\" + 0.007*\"problem\" + '\n",
      "  '0.006*\"algorithm\" + 0.006*\"data\" + 0.006*\"result\" + 0.004*\"paper\" + '\n",
      "  '0.004*\"based\" + 0.004*\"proposed\"'),\n",
      " (1,\n",
      "  '0.010*\"model\" + 0.007*\"data\" + 0.006*\"method\" + 0.005*\"result\" + '\n",
      "  '0.005*\"learning\" + 0.004*\"paper\" + 0.004*\"study\" + 0.004*\"network\" + '\n",
      "  '0.004*\"present\" + 0.004*\"algorithm\"'),\n",
      " (2,\n",
      "  '0.007*\"data\" + 0.007*\"result\" + 0.006*\"paper\" + 0.006*\"model\" + '\n",
      "  '0.006*\"method\" + 0.006*\"function\" + 0.006*\"algorithm\" + 0.005*\"field\" + '\n",
      "  '0.004*\"study\" + 0.004*\"approach\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics(num_topics=b, num_words=10))\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "afc90fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"model\" + 0.008*\"network\" + 0.007*\"method\" + 0.007*\"problem\" + 0.006*\"algorithm\" + 0.006*\"data\" + 0.006*\"result\" + 0.004*\"paper\" + 0.004*\"based\" + 0.004*\"proposed\"'),\n",
       " (1,\n",
       "  '0.010*\"model\" + 0.007*\"data\" + 0.006*\"method\" + 0.005*\"result\" + 0.005*\"learning\" + 0.004*\"paper\" + 0.004*\"study\" + 0.004*\"network\" + 0.004*\"present\" + 0.004*\"algorithm\"'),\n",
       " (2,\n",
       "  '0.007*\"data\" + 0.007*\"result\" + 0.006*\"paper\" + 0.006*\"model\" + 0.006*\"method\" + 0.006*\"function\" + 0.006*\"algorithm\" + 0.005*\"field\" + 0.004*\"study\" + 0.004*\"approach\"')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lda_model.print_topics(num_topics=b, num_words=10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "715794bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "760c8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in x:\n",
    "    b = i[1].split('\"')\n",
    "    c = []\n",
    "    for j in range(0, len(b)):\n",
    "        if(j%2!=0):\n",
    "            c.append(b[j])\n",
    "    a.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3ab88251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['model',\n",
       "  'network',\n",
       "  'method',\n",
       "  'problem',\n",
       "  'algorithm',\n",
       "  'data',\n",
       "  'result',\n",
       "  'paper',\n",
       "  'based',\n",
       "  'proposed'],\n",
       " ['model',\n",
       "  'data',\n",
       "  'method',\n",
       "  'result',\n",
       "  'learning',\n",
       "  'paper',\n",
       "  'study',\n",
       "  'network',\n",
       "  'present',\n",
       "  'algorithm'],\n",
       " ['data',\n",
       "  'result',\n",
       "  'paper',\n",
       "  'model',\n",
       "  'method',\n",
       "  'function',\n",
       "  'algorithm',\n",
       "  'field',\n",
       "  'study',\n",
       "  'approach']]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "42c019ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a, columns=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5b5d759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model</td>\n",
       "      <td>network</td>\n",
       "      <td>method</td>\n",
       "      <td>problem</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>data</td>\n",
       "      <td>result</td>\n",
       "      <td>paper</td>\n",
       "      <td>based</td>\n",
       "      <td>proposed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>data</td>\n",
       "      <td>method</td>\n",
       "      <td>result</td>\n",
       "      <td>learning</td>\n",
       "      <td>paper</td>\n",
       "      <td>study</td>\n",
       "      <td>network</td>\n",
       "      <td>present</td>\n",
       "      <td>algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>result</td>\n",
       "      <td>paper</td>\n",
       "      <td>model</td>\n",
       "      <td>method</td>\n",
       "      <td>function</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>field</td>\n",
       "      <td>study</td>\n",
       "      <td>approach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2        3          4         5          6        7  \\\n",
       "0  model  network  method  problem  algorithm      data     result    paper   \n",
       "1  model     data  method   result   learning     paper      study  network   \n",
       "2   data   result   paper    model     method  function  algorithm    field   \n",
       "\n",
       "         8          9  \n",
       "0    based   proposed  \n",
       "1  present  algorithm  \n",
       "2    study   approach  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e4b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
